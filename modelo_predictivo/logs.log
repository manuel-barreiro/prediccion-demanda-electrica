2023-10-13 22:57:06,133:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 22:57:06,585:INFO:PyCaret TSForecastingExperiment
2023-10-13 22:57:06,585:INFO:Logging name: ts-default-name
2023-10-13 22:57:06,585:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 22:57:06,585:INFO:version 3.1.0
2023-10-13 22:57:06,585:INFO:Initializing setup()
2023-10-13 22:57:06,585:INFO:self.USI: f20e
2023-10-13 22:57:06,585:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 22:57:06,585:INFO:Checking environment
2023-10-13 22:57:06,585:INFO:python_version: 3.10.6
2023-10-13 22:57:06,586:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 22:57:06,586:INFO:machine: AMD64
2023-10-13 22:57:06,586:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 22:57:06,586:INFO:Memory: svmem(total=8273383424, available=1347518464, percent=83.7, used=6925864960, free=1347518464)
2023-10-13 22:57:06,586:INFO:Physical Core: 4
2023-10-13 22:57:06,586:INFO:Logical Core: 8
2023-10-13 22:57:06,586:INFO:Checking libraries
2023-10-13 22:57:06,586:INFO:System:
2023-10-13 22:57:06,586:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 22:57:06,586:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 22:57:06,586:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 22:57:06,586:INFO:PyCaret required dependencies:
2023-10-13 22:57:06,616:INFO:                 pip: 22.2.1
2023-10-13 22:57:06,616:INFO:          setuptools: 63.2.0
2023-10-13 22:57:06,616:INFO:             pycaret: 3.1.0
2023-10-13 22:57:06,616:INFO:             IPython: 8.4.0
2023-10-13 22:57:06,616:INFO:          ipywidgets: 8.1.1
2023-10-13 22:57:06,616:INFO:                tqdm: 4.66.1
2023-10-13 22:57:06,616:INFO:               numpy: 1.23.2
2023-10-13 22:57:06,616:INFO:              pandas: 1.4.3
2023-10-13 22:57:06,616:INFO:              jinja2: 3.1.2
2023-10-13 22:57:06,616:INFO:               scipy: 1.10.1
2023-10-13 22:57:06,616:INFO:              joblib: 1.2.0
2023-10-13 22:57:06,616:INFO:             sklearn: 1.1.2
2023-10-13 22:57:06,616:INFO:                pyod: 1.1.0
2023-10-13 22:57:06,616:INFO:            imblearn: 0.11.0
2023-10-13 22:57:06,616:INFO:   category_encoders: 2.6.2
2023-10-13 22:57:06,616:INFO:            lightgbm: 4.1.0
2023-10-13 22:57:06,616:INFO:               numba: 0.58.0
2023-10-13 22:57:06,616:INFO:            requests: 2.28.1
2023-10-13 22:57:06,616:INFO:          matplotlib: 3.6.0
2023-10-13 22:57:06,616:INFO:          scikitplot: 0.3.7
2023-10-13 22:57:06,616:INFO:         yellowbrick: 1.5
2023-10-13 22:57:06,616:INFO:              plotly: 5.17.0
2023-10-13 22:57:06,616:INFO:    plotly-resampler: Not installed
2023-10-13 22:57:06,617:INFO:             kaleido: 0.2.1
2023-10-13 22:57:06,617:INFO:           schemdraw: 0.15
2023-10-13 22:57:06,617:INFO:         statsmodels: 0.13.2
2023-10-13 22:57:06,617:INFO:              sktime: 0.21.1
2023-10-13 22:57:06,617:INFO:               tbats: 1.1.3
2023-10-13 22:57:06,617:INFO:            pmdarima: 2.0.3
2023-10-13 22:57:06,617:INFO:              psutil: 5.9.1
2023-10-13 22:57:06,617:INFO:          markupsafe: 2.1.1
2023-10-13 22:57:06,617:INFO:             pickle5: Not installed
2023-10-13 22:57:06,617:INFO:         cloudpickle: 2.2.1
2023-10-13 22:57:06,617:INFO:         deprecation: 2.1.0
2023-10-13 22:57:06,617:INFO:              xxhash: 3.4.1
2023-10-13 22:57:06,617:INFO:           wurlitzer: Not installed
2023-10-13 22:57:06,617:INFO:PyCaret optional dependencies:
2023-10-13 22:57:06,680:INFO:                shap: Not installed
2023-10-13 22:57:06,680:INFO:           interpret: Not installed
2023-10-13 22:57:06,680:INFO:                umap: Not installed
2023-10-13 22:57:06,680:INFO:     ydata_profiling: Not installed
2023-10-13 22:57:06,680:INFO:  explainerdashboard: Not installed
2023-10-13 22:57:06,680:INFO:             autoviz: Not installed
2023-10-13 22:57:06,680:INFO:           fairlearn: Not installed
2023-10-13 22:57:06,680:INFO:          deepchecks: Not installed
2023-10-13 22:57:06,680:INFO:             xgboost: 2.0.0
2023-10-13 22:57:06,680:INFO:            catboost: Not installed
2023-10-13 22:57:06,680:INFO:              kmodes: Not installed
2023-10-13 22:57:06,680:INFO:             mlxtend: Not installed
2023-10-13 22:57:06,680:INFO:       statsforecast: Not installed
2023-10-13 22:57:06,680:INFO:        tune_sklearn: Not installed
2023-10-13 22:57:06,680:INFO:                 ray: Not installed
2023-10-13 22:57:06,680:INFO:            hyperopt: Not installed
2023-10-13 22:57:06,680:INFO:              optuna: Not installed
2023-10-13 22:57:06,680:INFO:               skopt: Not installed
2023-10-13 22:57:06,680:INFO:              mlflow: Not installed
2023-10-13 22:57:06,680:INFO:              gradio: Not installed
2023-10-13 22:57:06,680:INFO:             fastapi: Not installed
2023-10-13 22:57:06,680:INFO:             uvicorn: Not installed
2023-10-13 22:57:06,680:INFO:              m2cgen: Not installed
2023-10-13 22:57:06,680:INFO:           evidently: Not installed
2023-10-13 22:57:06,680:INFO:               fugue: Not installed
2023-10-13 22:57:06,680:INFO:           streamlit: Not installed
2023-10-13 22:57:06,680:INFO:             prophet: Not installed
2023-10-13 22:57:06,680:INFO:None
2023-10-13 22:57:56,109:INFO:PyCaret TSForecastingExperiment
2023-10-13 22:57:56,109:INFO:Logging name: ts-default-name
2023-10-13 22:57:56,110:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 22:57:56,110:INFO:version 3.1.0
2023-10-13 22:57:56,110:INFO:Initializing setup()
2023-10-13 22:57:56,110:INFO:self.USI: a391
2023-10-13 22:57:56,110:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 22:57:56,110:INFO:Checking environment
2023-10-13 22:57:56,110:INFO:python_version: 3.10.6
2023-10-13 22:57:56,110:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 22:57:56,110:INFO:machine: AMD64
2023-10-13 22:57:56,110:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 22:57:56,110:INFO:Memory: svmem(total=8273383424, available=1266319360, percent=84.7, used=7007064064, free=1266319360)
2023-10-13 22:57:56,110:INFO:Physical Core: 4
2023-10-13 22:57:56,111:INFO:Logical Core: 8
2023-10-13 22:57:56,111:INFO:Checking libraries
2023-10-13 22:57:56,111:INFO:System:
2023-10-13 22:57:56,111:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 22:57:56,111:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 22:57:56,111:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 22:57:56,111:INFO:PyCaret required dependencies:
2023-10-13 22:57:56,111:INFO:                 pip: 22.2.1
2023-10-13 22:57:56,111:INFO:          setuptools: 63.2.0
2023-10-13 22:57:56,111:INFO:             pycaret: 3.1.0
2023-10-13 22:57:56,111:INFO:             IPython: 8.4.0
2023-10-13 22:57:56,111:INFO:          ipywidgets: 8.1.1
2023-10-13 22:57:56,112:INFO:                tqdm: 4.66.1
2023-10-13 22:57:56,112:INFO:               numpy: 1.23.2
2023-10-13 22:57:56,112:INFO:              pandas: 1.4.3
2023-10-13 22:57:56,112:INFO:              jinja2: 3.1.2
2023-10-13 22:57:56,112:INFO:               scipy: 1.10.1
2023-10-13 22:57:56,112:INFO:              joblib: 1.2.0
2023-10-13 22:57:56,112:INFO:             sklearn: 1.1.2
2023-10-13 22:57:56,112:INFO:                pyod: 1.1.0
2023-10-13 22:57:56,112:INFO:            imblearn: 0.11.0
2023-10-13 22:57:56,112:INFO:   category_encoders: 2.6.2
2023-10-13 22:57:56,112:INFO:            lightgbm: 4.1.0
2023-10-13 22:57:56,112:INFO:               numba: 0.58.0
2023-10-13 22:57:56,112:INFO:            requests: 2.28.1
2023-10-13 22:57:56,112:INFO:          matplotlib: 3.6.0
2023-10-13 22:57:56,112:INFO:          scikitplot: 0.3.7
2023-10-13 22:57:56,112:INFO:         yellowbrick: 1.5
2023-10-13 22:57:56,112:INFO:              plotly: 5.17.0
2023-10-13 22:57:56,112:INFO:    plotly-resampler: Not installed
2023-10-13 22:57:56,112:INFO:             kaleido: 0.2.1
2023-10-13 22:57:56,113:INFO:           schemdraw: 0.15
2023-10-13 22:57:56,113:INFO:         statsmodels: 0.13.2
2023-10-13 22:57:56,113:INFO:              sktime: 0.21.1
2023-10-13 22:57:56,113:INFO:               tbats: 1.1.3
2023-10-13 22:57:56,113:INFO:            pmdarima: 2.0.3
2023-10-13 22:57:56,113:INFO:              psutil: 5.9.1
2023-10-13 22:57:56,113:INFO:          markupsafe: 2.1.1
2023-10-13 22:57:56,113:INFO:             pickle5: Not installed
2023-10-13 22:57:56,113:INFO:         cloudpickle: 2.2.1
2023-10-13 22:57:56,113:INFO:         deprecation: 2.1.0
2023-10-13 22:57:56,113:INFO:              xxhash: 3.4.1
2023-10-13 22:57:56,113:INFO:           wurlitzer: Not installed
2023-10-13 22:57:56,113:INFO:PyCaret optional dependencies:
2023-10-13 22:57:56,114:INFO:                shap: Not installed
2023-10-13 22:57:56,114:INFO:           interpret: Not installed
2023-10-13 22:57:56,114:INFO:                umap: Not installed
2023-10-13 22:57:56,114:INFO:     ydata_profiling: Not installed
2023-10-13 22:57:56,114:INFO:  explainerdashboard: Not installed
2023-10-13 22:57:56,114:INFO:             autoviz: Not installed
2023-10-13 22:57:56,114:INFO:           fairlearn: Not installed
2023-10-13 22:57:56,114:INFO:          deepchecks: Not installed
2023-10-13 22:57:56,114:INFO:             xgboost: 2.0.0
2023-10-13 22:57:56,114:INFO:            catboost: Not installed
2023-10-13 22:57:56,114:INFO:              kmodes: Not installed
2023-10-13 22:57:56,114:INFO:             mlxtend: Not installed
2023-10-13 22:57:56,114:INFO:       statsforecast: Not installed
2023-10-13 22:57:56,114:INFO:        tune_sklearn: Not installed
2023-10-13 22:57:56,114:INFO:                 ray: Not installed
2023-10-13 22:57:56,115:INFO:            hyperopt: Not installed
2023-10-13 22:57:56,115:INFO:              optuna: Not installed
2023-10-13 22:57:56,115:INFO:               skopt: Not installed
2023-10-13 22:57:56,115:INFO:              mlflow: Not installed
2023-10-13 22:57:56,115:INFO:              gradio: Not installed
2023-10-13 22:57:56,115:INFO:             fastapi: Not installed
2023-10-13 22:57:56,115:INFO:             uvicorn: Not installed
2023-10-13 22:57:56,115:INFO:              m2cgen: Not installed
2023-10-13 22:57:56,115:INFO:           evidently: Not installed
2023-10-13 22:57:56,115:INFO:               fugue: Not installed
2023-10-13 22:57:56,115:INFO:           streamlit: Not installed
2023-10-13 22:57:56,115:INFO:             prophet: Not installed
2023-10-13 22:57:56,115:INFO:None
2023-10-13 22:58:32,845:INFO:PyCaret TSForecastingExperiment
2023-10-13 22:58:32,845:INFO:Logging name: ts-default-name
2023-10-13 22:58:32,845:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 22:58:32,845:INFO:version 3.1.0
2023-10-13 22:58:32,845:INFO:Initializing setup()
2023-10-13 22:58:32,845:INFO:self.USI: 2053
2023-10-13 22:58:32,845:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 22:58:32,845:INFO:Checking environment
2023-10-13 22:58:32,846:INFO:python_version: 3.10.6
2023-10-13 22:58:32,846:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 22:58:32,846:INFO:machine: AMD64
2023-10-13 22:58:32,846:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 22:58:32,846:INFO:Memory: svmem(total=8273383424, available=1199624192, percent=85.5, used=7073759232, free=1199624192)
2023-10-13 22:58:32,846:INFO:Physical Core: 4
2023-10-13 22:58:32,846:INFO:Logical Core: 8
2023-10-13 22:58:32,846:INFO:Checking libraries
2023-10-13 22:58:32,846:INFO:System:
2023-10-13 22:58:32,846:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 22:58:32,846:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 22:58:32,846:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 22:58:32,846:INFO:PyCaret required dependencies:
2023-10-13 22:58:32,846:INFO:                 pip: 22.2.1
2023-10-13 22:58:32,846:INFO:          setuptools: 63.2.0
2023-10-13 22:58:32,846:INFO:             pycaret: 3.1.0
2023-10-13 22:58:32,846:INFO:             IPython: 8.4.0
2023-10-13 22:58:32,846:INFO:          ipywidgets: 8.1.1
2023-10-13 22:58:32,847:INFO:                tqdm: 4.66.1
2023-10-13 22:58:32,847:INFO:               numpy: 1.23.2
2023-10-13 22:58:32,847:INFO:              pandas: 1.4.3
2023-10-13 22:58:32,847:INFO:              jinja2: 3.1.2
2023-10-13 22:58:32,847:INFO:               scipy: 1.10.1
2023-10-13 22:58:32,847:INFO:              joblib: 1.2.0
2023-10-13 22:58:32,847:INFO:             sklearn: 1.1.2
2023-10-13 22:58:32,847:INFO:                pyod: 1.1.0
2023-10-13 22:58:32,847:INFO:            imblearn: 0.11.0
2023-10-13 22:58:32,847:INFO:   category_encoders: 2.6.2
2023-10-13 22:58:32,847:INFO:            lightgbm: 4.1.0
2023-10-13 22:58:32,847:INFO:               numba: 0.58.0
2023-10-13 22:58:32,847:INFO:            requests: 2.28.1
2023-10-13 22:58:32,847:INFO:          matplotlib: 3.6.0
2023-10-13 22:58:32,847:INFO:          scikitplot: 0.3.7
2023-10-13 22:58:32,847:INFO:         yellowbrick: 1.5
2023-10-13 22:58:32,847:INFO:              plotly: 5.17.0
2023-10-13 22:58:32,847:INFO:    plotly-resampler: Not installed
2023-10-13 22:58:32,847:INFO:             kaleido: 0.2.1
2023-10-13 22:58:32,847:INFO:           schemdraw: 0.15
2023-10-13 22:58:32,847:INFO:         statsmodels: 0.13.2
2023-10-13 22:58:32,847:INFO:              sktime: 0.21.1
2023-10-13 22:58:32,847:INFO:               tbats: 1.1.3
2023-10-13 22:58:32,847:INFO:            pmdarima: 2.0.3
2023-10-13 22:58:32,847:INFO:              psutil: 5.9.1
2023-10-13 22:58:32,847:INFO:          markupsafe: 2.1.1
2023-10-13 22:58:32,847:INFO:             pickle5: Not installed
2023-10-13 22:58:32,847:INFO:         cloudpickle: 2.2.1
2023-10-13 22:58:32,848:INFO:         deprecation: 2.1.0
2023-10-13 22:58:32,848:INFO:              xxhash: 3.4.1
2023-10-13 22:58:32,848:INFO:           wurlitzer: Not installed
2023-10-13 22:58:32,848:INFO:PyCaret optional dependencies:
2023-10-13 22:58:32,848:INFO:                shap: Not installed
2023-10-13 22:58:32,848:INFO:           interpret: Not installed
2023-10-13 22:58:32,848:INFO:                umap: Not installed
2023-10-13 22:58:32,848:INFO:     ydata_profiling: Not installed
2023-10-13 22:58:32,848:INFO:  explainerdashboard: Not installed
2023-10-13 22:58:32,848:INFO:             autoviz: Not installed
2023-10-13 22:58:32,848:INFO:           fairlearn: Not installed
2023-10-13 22:58:32,848:INFO:          deepchecks: Not installed
2023-10-13 22:58:32,848:INFO:             xgboost: 2.0.0
2023-10-13 22:58:32,848:INFO:            catboost: Not installed
2023-10-13 22:58:32,848:INFO:              kmodes: Not installed
2023-10-13 22:58:32,848:INFO:             mlxtend: Not installed
2023-10-13 22:58:32,848:INFO:       statsforecast: Not installed
2023-10-13 22:58:32,848:INFO:        tune_sklearn: Not installed
2023-10-13 22:58:32,848:INFO:                 ray: Not installed
2023-10-13 22:58:32,848:INFO:            hyperopt: Not installed
2023-10-13 22:58:32,848:INFO:              optuna: Not installed
2023-10-13 22:58:32,848:INFO:               skopt: Not installed
2023-10-13 22:58:32,848:INFO:              mlflow: Not installed
2023-10-13 22:58:32,849:INFO:              gradio: Not installed
2023-10-13 22:58:32,849:INFO:             fastapi: Not installed
2023-10-13 22:58:32,849:INFO:             uvicorn: Not installed
2023-10-13 22:58:32,849:INFO:              m2cgen: Not installed
2023-10-13 22:58:32,849:INFO:           evidently: Not installed
2023-10-13 22:58:32,849:INFO:               fugue: Not installed
2023-10-13 22:58:32,849:INFO:           streamlit: Not installed
2023-10-13 22:58:32,849:INFO:             prophet: Not installed
2023-10-13 22:58:32,849:INFO:None
2023-10-13 22:58:57,559:INFO:PyCaret TSForecastingExperiment
2023-10-13 22:58:57,559:INFO:Logging name: ts-default-name
2023-10-13 22:58:57,559:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 22:58:57,559:INFO:version 3.1.0
2023-10-13 22:58:57,559:INFO:Initializing setup()
2023-10-13 22:58:57,559:INFO:self.USI: 1ad7
2023-10-13 22:58:57,559:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 22:58:57,559:INFO:Checking environment
2023-10-13 22:58:57,559:INFO:python_version: 3.10.6
2023-10-13 22:58:57,559:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 22:58:57,559:INFO:machine: AMD64
2023-10-13 22:58:57,560:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 22:58:57,560:INFO:Memory: svmem(total=8273383424, available=1263640576, percent=84.7, used=7009742848, free=1263640576)
2023-10-13 22:58:57,560:INFO:Physical Core: 4
2023-10-13 22:58:57,560:INFO:Logical Core: 8
2023-10-13 22:58:57,560:INFO:Checking libraries
2023-10-13 22:58:57,560:INFO:System:
2023-10-13 22:58:57,560:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 22:58:57,560:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 22:58:57,560:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 22:58:57,560:INFO:PyCaret required dependencies:
2023-10-13 22:58:57,560:INFO:                 pip: 22.2.1
2023-10-13 22:58:57,560:INFO:          setuptools: 63.2.0
2023-10-13 22:58:57,560:INFO:             pycaret: 3.1.0
2023-10-13 22:58:57,560:INFO:             IPython: 8.4.0
2023-10-13 22:58:57,560:INFO:          ipywidgets: 8.1.1
2023-10-13 22:58:57,560:INFO:                tqdm: 4.66.1
2023-10-13 22:58:57,560:INFO:               numpy: 1.23.2
2023-10-13 22:58:57,560:INFO:              pandas: 1.4.3
2023-10-13 22:58:57,560:INFO:              jinja2: 3.1.2
2023-10-13 22:58:57,560:INFO:               scipy: 1.10.1
2023-10-13 22:58:57,560:INFO:              joblib: 1.2.0
2023-10-13 22:58:57,560:INFO:             sklearn: 1.1.2
2023-10-13 22:58:57,560:INFO:                pyod: 1.1.0
2023-10-13 22:58:57,561:INFO:            imblearn: 0.11.0
2023-10-13 22:58:57,561:INFO:   category_encoders: 2.6.2
2023-10-13 22:58:57,561:INFO:            lightgbm: 4.1.0
2023-10-13 22:58:57,561:INFO:               numba: 0.58.0
2023-10-13 22:58:57,561:INFO:            requests: 2.28.1
2023-10-13 22:58:57,561:INFO:          matplotlib: 3.6.0
2023-10-13 22:58:57,561:INFO:          scikitplot: 0.3.7
2023-10-13 22:58:57,561:INFO:         yellowbrick: 1.5
2023-10-13 22:58:57,561:INFO:              plotly: 5.17.0
2023-10-13 22:58:57,561:INFO:    plotly-resampler: Not installed
2023-10-13 22:58:57,561:INFO:             kaleido: 0.2.1
2023-10-13 22:58:57,561:INFO:           schemdraw: 0.15
2023-10-13 22:58:57,561:INFO:         statsmodels: 0.13.2
2023-10-13 22:58:57,561:INFO:              sktime: 0.21.1
2023-10-13 22:58:57,561:INFO:               tbats: 1.1.3
2023-10-13 22:58:57,561:INFO:            pmdarima: 2.0.3
2023-10-13 22:58:57,561:INFO:              psutil: 5.9.1
2023-10-13 22:58:57,561:INFO:          markupsafe: 2.1.1
2023-10-13 22:58:57,561:INFO:             pickle5: Not installed
2023-10-13 22:58:57,561:INFO:         cloudpickle: 2.2.1
2023-10-13 22:58:57,561:INFO:         deprecation: 2.1.0
2023-10-13 22:58:57,562:INFO:              xxhash: 3.4.1
2023-10-13 22:58:57,562:INFO:           wurlitzer: Not installed
2023-10-13 22:58:57,562:INFO:PyCaret optional dependencies:
2023-10-13 22:58:57,562:INFO:                shap: Not installed
2023-10-13 22:58:57,562:INFO:           interpret: Not installed
2023-10-13 22:58:57,562:INFO:                umap: Not installed
2023-10-13 22:58:57,562:INFO:     ydata_profiling: Not installed
2023-10-13 22:58:57,562:INFO:  explainerdashboard: Not installed
2023-10-13 22:58:57,562:INFO:             autoviz: Not installed
2023-10-13 22:58:57,562:INFO:           fairlearn: Not installed
2023-10-13 22:58:57,562:INFO:          deepchecks: Not installed
2023-10-13 22:58:57,562:INFO:             xgboost: 2.0.0
2023-10-13 22:58:57,562:INFO:            catboost: Not installed
2023-10-13 22:58:57,562:INFO:              kmodes: Not installed
2023-10-13 22:58:57,562:INFO:             mlxtend: Not installed
2023-10-13 22:58:57,563:INFO:       statsforecast: Not installed
2023-10-13 22:58:57,563:INFO:        tune_sklearn: Not installed
2023-10-13 22:58:57,563:INFO:                 ray: Not installed
2023-10-13 22:58:57,563:INFO:            hyperopt: Not installed
2023-10-13 22:58:57,563:INFO:              optuna: Not installed
2023-10-13 22:58:57,563:INFO:               skopt: Not installed
2023-10-13 22:58:57,563:INFO:              mlflow: Not installed
2023-10-13 22:58:57,563:INFO:              gradio: Not installed
2023-10-13 22:58:57,563:INFO:             fastapi: Not installed
2023-10-13 22:58:57,563:INFO:             uvicorn: Not installed
2023-10-13 22:58:57,563:INFO:              m2cgen: Not installed
2023-10-13 22:58:57,563:INFO:           evidently: Not installed
2023-10-13 22:58:57,563:INFO:               fugue: Not installed
2023-10-13 22:58:57,563:INFO:           streamlit: Not installed
2023-10-13 22:58:57,563:INFO:             prophet: Not installed
2023-10-13 22:58:57,563:INFO:None
2023-10-13 22:59:06,733:INFO:PyCaret TSForecastingExperiment
2023-10-13 22:59:06,733:INFO:Logging name: ts-default-name
2023-10-13 22:59:06,733:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 22:59:06,733:INFO:version 3.1.0
2023-10-13 22:59:06,733:INFO:Initializing setup()
2023-10-13 22:59:06,733:INFO:self.USI: a712
2023-10-13 22:59:06,733:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 22:59:06,733:INFO:Checking environment
2023-10-13 22:59:06,733:INFO:python_version: 3.10.6
2023-10-13 22:59:06,733:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 22:59:06,733:INFO:machine: AMD64
2023-10-13 22:59:06,733:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 22:59:06,734:INFO:Memory: svmem(total=8273383424, available=1202618368, percent=85.5, used=7070765056, free=1202618368)
2023-10-13 22:59:06,734:INFO:Physical Core: 4
2023-10-13 22:59:06,734:INFO:Logical Core: 8
2023-10-13 22:59:06,734:INFO:Checking libraries
2023-10-13 22:59:06,734:INFO:System:
2023-10-13 22:59:06,734:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 22:59:06,734:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 22:59:06,734:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 22:59:06,734:INFO:PyCaret required dependencies:
2023-10-13 22:59:06,734:INFO:                 pip: 22.2.1
2023-10-13 22:59:06,734:INFO:          setuptools: 63.2.0
2023-10-13 22:59:06,734:INFO:             pycaret: 3.1.0
2023-10-13 22:59:06,734:INFO:             IPython: 8.4.0
2023-10-13 22:59:06,734:INFO:          ipywidgets: 8.1.1
2023-10-13 22:59:06,734:INFO:                tqdm: 4.66.1
2023-10-13 22:59:06,734:INFO:               numpy: 1.23.2
2023-10-13 22:59:06,734:INFO:              pandas: 1.4.3
2023-10-13 22:59:06,734:INFO:              jinja2: 3.1.2
2023-10-13 22:59:06,734:INFO:               scipy: 1.10.1
2023-10-13 22:59:06,734:INFO:              joblib: 1.2.0
2023-10-13 22:59:06,735:INFO:             sklearn: 1.1.2
2023-10-13 22:59:06,735:INFO:                pyod: 1.1.0
2023-10-13 22:59:06,735:INFO:            imblearn: 0.11.0
2023-10-13 22:59:06,735:INFO:   category_encoders: 2.6.2
2023-10-13 22:59:06,735:INFO:            lightgbm: 4.1.0
2023-10-13 22:59:06,735:INFO:               numba: 0.58.0
2023-10-13 22:59:06,735:INFO:            requests: 2.28.1
2023-10-13 22:59:06,735:INFO:          matplotlib: 3.6.0
2023-10-13 22:59:06,735:INFO:          scikitplot: 0.3.7
2023-10-13 22:59:06,735:INFO:         yellowbrick: 1.5
2023-10-13 22:59:06,735:INFO:              plotly: 5.17.0
2023-10-13 22:59:06,735:INFO:    plotly-resampler: Not installed
2023-10-13 22:59:06,735:INFO:             kaleido: 0.2.1
2023-10-13 22:59:06,735:INFO:           schemdraw: 0.15
2023-10-13 22:59:06,735:INFO:         statsmodels: 0.13.2
2023-10-13 22:59:06,735:INFO:              sktime: 0.21.1
2023-10-13 22:59:06,735:INFO:               tbats: 1.1.3
2023-10-13 22:59:06,735:INFO:            pmdarima: 2.0.3
2023-10-13 22:59:06,735:INFO:              psutil: 5.9.1
2023-10-13 22:59:06,735:INFO:          markupsafe: 2.1.1
2023-10-13 22:59:06,735:INFO:             pickle5: Not installed
2023-10-13 22:59:06,735:INFO:         cloudpickle: 2.2.1
2023-10-13 22:59:06,735:INFO:         deprecation: 2.1.0
2023-10-13 22:59:06,735:INFO:              xxhash: 3.4.1
2023-10-13 22:59:06,735:INFO:           wurlitzer: Not installed
2023-10-13 22:59:06,736:INFO:PyCaret optional dependencies:
2023-10-13 22:59:06,736:INFO:                shap: Not installed
2023-10-13 22:59:06,736:INFO:           interpret: Not installed
2023-10-13 22:59:06,736:INFO:                umap: Not installed
2023-10-13 22:59:06,736:INFO:     ydata_profiling: Not installed
2023-10-13 22:59:06,736:INFO:  explainerdashboard: Not installed
2023-10-13 22:59:06,736:INFO:             autoviz: Not installed
2023-10-13 22:59:06,736:INFO:           fairlearn: Not installed
2023-10-13 22:59:06,736:INFO:          deepchecks: Not installed
2023-10-13 22:59:06,736:INFO:             xgboost: 2.0.0
2023-10-13 22:59:06,736:INFO:            catboost: Not installed
2023-10-13 22:59:06,736:INFO:              kmodes: Not installed
2023-10-13 22:59:06,736:INFO:             mlxtend: Not installed
2023-10-13 22:59:06,736:INFO:       statsforecast: Not installed
2023-10-13 22:59:06,736:INFO:        tune_sklearn: Not installed
2023-10-13 22:59:06,736:INFO:                 ray: Not installed
2023-10-13 22:59:06,736:INFO:            hyperopt: Not installed
2023-10-13 22:59:06,736:INFO:              optuna: Not installed
2023-10-13 22:59:06,736:INFO:               skopt: Not installed
2023-10-13 22:59:06,736:INFO:              mlflow: Not installed
2023-10-13 22:59:06,736:INFO:              gradio: Not installed
2023-10-13 22:59:06,736:INFO:             fastapi: Not installed
2023-10-13 22:59:06,736:INFO:             uvicorn: Not installed
2023-10-13 22:59:06,736:INFO:              m2cgen: Not installed
2023-10-13 22:59:06,736:INFO:           evidently: Not installed
2023-10-13 22:59:06,736:INFO:               fugue: Not installed
2023-10-13 22:59:06,736:INFO:           streamlit: Not installed
2023-10-13 22:59:06,736:INFO:             prophet: Not installed
2023-10-13 22:59:06,736:INFO:None
2023-10-13 22:59:06,737:INFO:Set Forecast Horizon.
2023-10-13 22:59:06,738:INFO:Set up Train-Test Splits.
2023-10-13 23:02:54,456:INFO:PyCaret TSForecastingExperiment
2023-10-13 23:02:54,456:INFO:Logging name: ts-default-name
2023-10-13 23:02:54,456:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 23:02:54,456:INFO:version 3.1.0
2023-10-13 23:02:54,456:INFO:Initializing setup()
2023-10-13 23:02:54,456:INFO:self.USI: 504c
2023-10-13 23:02:54,456:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 23:02:54,456:INFO:Checking environment
2023-10-13 23:02:54,456:INFO:python_version: 3.10.6
2023-10-13 23:02:54,456:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 23:02:54,456:INFO:machine: AMD64
2023-10-13 23:02:54,457:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 23:02:54,457:INFO:Memory: svmem(total=8273383424, available=1540943872, percent=81.4, used=6732439552, free=1540943872)
2023-10-13 23:02:54,457:INFO:Physical Core: 4
2023-10-13 23:02:54,457:INFO:Logical Core: 8
2023-10-13 23:02:54,457:INFO:Checking libraries
2023-10-13 23:02:54,457:INFO:System:
2023-10-13 23:02:54,457:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 23:02:54,457:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 23:02:54,457:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 23:02:54,457:INFO:PyCaret required dependencies:
2023-10-13 23:02:54,457:INFO:                 pip: 22.2.1
2023-10-13 23:02:54,457:INFO:          setuptools: 63.2.0
2023-10-13 23:02:54,457:INFO:             pycaret: 3.1.0
2023-10-13 23:02:54,457:INFO:             IPython: 8.4.0
2023-10-13 23:02:54,457:INFO:          ipywidgets: 8.1.1
2023-10-13 23:02:54,457:INFO:                tqdm: 4.66.1
2023-10-13 23:02:54,458:INFO:               numpy: 1.23.2
2023-10-13 23:02:54,458:INFO:              pandas: 1.4.3
2023-10-13 23:02:54,458:INFO:              jinja2: 3.1.2
2023-10-13 23:02:54,458:INFO:               scipy: 1.10.1
2023-10-13 23:02:54,458:INFO:              joblib: 1.2.0
2023-10-13 23:02:54,458:INFO:             sklearn: 1.1.2
2023-10-13 23:02:54,458:INFO:                pyod: 1.1.0
2023-10-13 23:02:54,458:INFO:            imblearn: 0.11.0
2023-10-13 23:02:54,458:INFO:   category_encoders: 2.6.2
2023-10-13 23:02:54,458:INFO:            lightgbm: 4.1.0
2023-10-13 23:02:54,458:INFO:               numba: 0.58.0
2023-10-13 23:02:54,458:INFO:            requests: 2.28.1
2023-10-13 23:02:54,458:INFO:          matplotlib: 3.6.0
2023-10-13 23:02:54,458:INFO:          scikitplot: 0.3.7
2023-10-13 23:02:54,458:INFO:         yellowbrick: 1.5
2023-10-13 23:02:54,458:INFO:              plotly: 5.17.0
2023-10-13 23:02:54,458:INFO:    plotly-resampler: Not installed
2023-10-13 23:02:54,458:INFO:             kaleido: 0.2.1
2023-10-13 23:02:54,458:INFO:           schemdraw: 0.15
2023-10-13 23:02:54,458:INFO:         statsmodels: 0.13.2
2023-10-13 23:02:54,458:INFO:              sktime: 0.21.1
2023-10-13 23:02:54,458:INFO:               tbats: 1.1.3
2023-10-13 23:02:54,458:INFO:            pmdarima: 2.0.3
2023-10-13 23:02:54,458:INFO:              psutil: 5.9.1
2023-10-13 23:02:54,458:INFO:          markupsafe: 2.1.1
2023-10-13 23:02:54,458:INFO:             pickle5: Not installed
2023-10-13 23:02:54,458:INFO:         cloudpickle: 2.2.1
2023-10-13 23:02:54,458:INFO:         deprecation: 2.1.0
2023-10-13 23:02:54,459:INFO:              xxhash: 3.4.1
2023-10-13 23:02:54,459:INFO:           wurlitzer: Not installed
2023-10-13 23:02:54,459:INFO:PyCaret optional dependencies:
2023-10-13 23:02:54,459:INFO:                shap: Not installed
2023-10-13 23:02:54,459:INFO:           interpret: Not installed
2023-10-13 23:02:54,459:INFO:                umap: Not installed
2023-10-13 23:02:54,459:INFO:     ydata_profiling: Not installed
2023-10-13 23:02:54,459:INFO:  explainerdashboard: Not installed
2023-10-13 23:02:54,459:INFO:             autoviz: Not installed
2023-10-13 23:02:54,459:INFO:           fairlearn: Not installed
2023-10-13 23:02:54,459:INFO:          deepchecks: Not installed
2023-10-13 23:02:54,459:INFO:             xgboost: 2.0.0
2023-10-13 23:02:54,459:INFO:            catboost: Not installed
2023-10-13 23:02:54,459:INFO:              kmodes: Not installed
2023-10-13 23:02:54,459:INFO:             mlxtend: Not installed
2023-10-13 23:02:54,459:INFO:       statsforecast: Not installed
2023-10-13 23:02:54,459:INFO:        tune_sklearn: Not installed
2023-10-13 23:02:54,459:INFO:                 ray: Not installed
2023-10-13 23:02:54,459:INFO:            hyperopt: Not installed
2023-10-13 23:02:54,459:INFO:              optuna: Not installed
2023-10-13 23:02:54,459:INFO:               skopt: Not installed
2023-10-13 23:02:54,459:INFO:              mlflow: Not installed
2023-10-13 23:02:54,459:INFO:              gradio: Not installed
2023-10-13 23:02:54,460:INFO:             fastapi: Not installed
2023-10-13 23:02:54,460:INFO:             uvicorn: Not installed
2023-10-13 23:02:54,460:INFO:              m2cgen: Not installed
2023-10-13 23:02:54,460:INFO:           evidently: Not installed
2023-10-13 23:02:54,460:INFO:               fugue: Not installed
2023-10-13 23:02:54,460:INFO:           streamlit: Not installed
2023-10-13 23:02:54,460:INFO:             prophet: Not installed
2023-10-13 23:02:54,460:INFO:None
2023-10-13 23:02:54,461:INFO:Set Forecast Horizon.
2023-10-13 23:02:54,461:INFO:Set up Train-Test Splits.
2023-10-13 23:03:54,620:INFO:PyCaret TSForecastingExperiment
2023-10-13 23:03:54,621:INFO:Logging name: ts-default-name
2023-10-13 23:03:54,621:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 23:03:54,621:INFO:version 3.1.0
2023-10-13 23:03:54,621:INFO:Initializing setup()
2023-10-13 23:03:54,621:INFO:self.USI: f4a4
2023-10-13 23:03:54,621:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 23:03:54,622:INFO:Checking environment
2023-10-13 23:03:54,622:INFO:python_version: 3.10.6
2023-10-13 23:03:54,622:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 23:03:54,622:INFO:machine: AMD64
2023-10-13 23:03:54,622:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 23:03:54,622:INFO:Memory: svmem(total=8273383424, available=1438539776, percent=82.6, used=6834843648, free=1438539776)
2023-10-13 23:03:54,622:INFO:Physical Core: 4
2023-10-13 23:03:54,622:INFO:Logical Core: 8
2023-10-13 23:03:54,622:INFO:Checking libraries
2023-10-13 23:03:54,622:INFO:System:
2023-10-13 23:03:54,622:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 23:03:54,623:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 23:03:54,623:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 23:03:54,623:INFO:PyCaret required dependencies:
2023-10-13 23:03:54,623:INFO:                 pip: 22.2.1
2023-10-13 23:03:54,623:INFO:          setuptools: 63.2.0
2023-10-13 23:03:54,623:INFO:             pycaret: 3.1.0
2023-10-13 23:03:54,623:INFO:             IPython: 8.4.0
2023-10-13 23:03:54,623:INFO:          ipywidgets: 8.1.1
2023-10-13 23:03:54,623:INFO:                tqdm: 4.66.1
2023-10-13 23:03:54,623:INFO:               numpy: 1.23.2
2023-10-13 23:03:54,623:INFO:              pandas: 1.4.3
2023-10-13 23:03:54,623:INFO:              jinja2: 3.1.2
2023-10-13 23:03:54,623:INFO:               scipy: 1.10.1
2023-10-13 23:03:54,623:INFO:              joblib: 1.2.0
2023-10-13 23:03:54,623:INFO:             sklearn: 1.1.2
2023-10-13 23:03:54,623:INFO:                pyod: 1.1.0
2023-10-13 23:03:54,623:INFO:            imblearn: 0.11.0
2023-10-13 23:03:54,623:INFO:   category_encoders: 2.6.2
2023-10-13 23:03:54,623:INFO:            lightgbm: 4.1.0
2023-10-13 23:03:54,623:INFO:               numba: 0.58.0
2023-10-13 23:03:54,623:INFO:            requests: 2.28.1
2023-10-13 23:03:54,623:INFO:          matplotlib: 3.6.0
2023-10-13 23:03:54,624:INFO:          scikitplot: 0.3.7
2023-10-13 23:03:54,624:INFO:         yellowbrick: 1.5
2023-10-13 23:03:54,624:INFO:              plotly: 5.17.0
2023-10-13 23:03:54,624:INFO:    plotly-resampler: Not installed
2023-10-13 23:03:54,624:INFO:             kaleido: 0.2.1
2023-10-13 23:03:54,624:INFO:           schemdraw: 0.15
2023-10-13 23:03:54,624:INFO:         statsmodels: 0.13.2
2023-10-13 23:03:54,624:INFO:              sktime: 0.21.1
2023-10-13 23:03:54,624:INFO:               tbats: 1.1.3
2023-10-13 23:03:54,624:INFO:            pmdarima: 2.0.3
2023-10-13 23:03:54,624:INFO:              psutil: 5.9.1
2023-10-13 23:03:54,624:INFO:          markupsafe: 2.1.1
2023-10-13 23:03:54,624:INFO:             pickle5: Not installed
2023-10-13 23:03:54,624:INFO:         cloudpickle: 2.2.1
2023-10-13 23:03:54,624:INFO:         deprecation: 2.1.0
2023-10-13 23:03:54,624:INFO:              xxhash: 3.4.1
2023-10-13 23:03:54,624:INFO:           wurlitzer: Not installed
2023-10-13 23:03:54,624:INFO:PyCaret optional dependencies:
2023-10-13 23:03:54,624:INFO:                shap: Not installed
2023-10-13 23:03:54,624:INFO:           interpret: Not installed
2023-10-13 23:03:54,624:INFO:                umap: Not installed
2023-10-13 23:03:54,624:INFO:     ydata_profiling: Not installed
2023-10-13 23:03:54,624:INFO:  explainerdashboard: Not installed
2023-10-13 23:03:54,625:INFO:             autoviz: Not installed
2023-10-13 23:03:54,625:INFO:           fairlearn: Not installed
2023-10-13 23:03:54,625:INFO:          deepchecks: Not installed
2023-10-13 23:03:54,625:INFO:             xgboost: 2.0.0
2023-10-13 23:03:54,625:INFO:            catboost: Not installed
2023-10-13 23:03:54,625:INFO:              kmodes: Not installed
2023-10-13 23:03:54,625:INFO:             mlxtend: Not installed
2023-10-13 23:03:54,625:INFO:       statsforecast: Not installed
2023-10-13 23:03:54,625:INFO:        tune_sklearn: Not installed
2023-10-13 23:03:54,625:INFO:                 ray: Not installed
2023-10-13 23:03:54,625:INFO:            hyperopt: Not installed
2023-10-13 23:03:54,625:INFO:              optuna: Not installed
2023-10-13 23:03:54,625:INFO:               skopt: Not installed
2023-10-13 23:03:54,625:INFO:              mlflow: Not installed
2023-10-13 23:03:54,625:INFO:              gradio: Not installed
2023-10-13 23:03:54,625:INFO:             fastapi: Not installed
2023-10-13 23:03:54,625:INFO:             uvicorn: Not installed
2023-10-13 23:03:54,625:INFO:              m2cgen: Not installed
2023-10-13 23:03:54,625:INFO:           evidently: Not installed
2023-10-13 23:03:54,625:INFO:               fugue: Not installed
2023-10-13 23:03:54,625:INFO:           streamlit: Not installed
2023-10-13 23:03:54,625:INFO:             prophet: Not installed
2023-10-13 23:03:54,625:INFO:None
2023-10-13 23:03:54,853:INFO:Set Forecast Horizon.
2023-10-13 23:03:54,853:INFO:Set up Train-Test Splits.
2023-10-13 23:04:34,844:INFO:PyCaret TSForecastingExperiment
2023-10-13 23:04:34,844:INFO:Logging name: ts-default-name
2023-10-13 23:04:34,844:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 23:04:34,844:INFO:version 3.1.0
2023-10-13 23:04:34,844:INFO:Initializing setup()
2023-10-13 23:04:34,844:INFO:self.USI: 494d
2023-10-13 23:04:34,844:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 23:04:34,844:INFO:Checking environment
2023-10-13 23:04:34,845:INFO:python_version: 3.10.6
2023-10-13 23:04:34,845:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 23:04:34,845:INFO:machine: AMD64
2023-10-13 23:04:34,845:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 23:04:34,845:INFO:Memory: svmem(total=8273383424, available=1519894528, percent=81.6, used=6753488896, free=1519894528)
2023-10-13 23:04:34,845:INFO:Physical Core: 4
2023-10-13 23:04:34,845:INFO:Logical Core: 8
2023-10-13 23:04:34,845:INFO:Checking libraries
2023-10-13 23:04:34,845:INFO:System:
2023-10-13 23:04:34,845:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 23:04:34,845:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 23:04:34,845:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 23:04:34,845:INFO:PyCaret required dependencies:
2023-10-13 23:04:34,845:INFO:                 pip: 22.2.1
2023-10-13 23:04:34,845:INFO:          setuptools: 63.2.0
2023-10-13 23:04:34,845:INFO:             pycaret: 3.1.0
2023-10-13 23:04:34,845:INFO:             IPython: 8.4.0
2023-10-13 23:04:34,845:INFO:          ipywidgets: 8.1.1
2023-10-13 23:04:34,845:INFO:                tqdm: 4.66.1
2023-10-13 23:04:34,845:INFO:               numpy: 1.23.2
2023-10-13 23:04:34,846:INFO:              pandas: 1.4.3
2023-10-13 23:04:34,846:INFO:              jinja2: 3.1.2
2023-10-13 23:04:34,846:INFO:               scipy: 1.10.1
2023-10-13 23:04:34,846:INFO:              joblib: 1.2.0
2023-10-13 23:04:34,846:INFO:             sklearn: 1.1.2
2023-10-13 23:04:34,846:INFO:                pyod: 1.1.0
2023-10-13 23:04:34,846:INFO:            imblearn: 0.11.0
2023-10-13 23:04:34,846:INFO:   category_encoders: 2.6.2
2023-10-13 23:04:34,846:INFO:            lightgbm: 4.1.0
2023-10-13 23:04:34,846:INFO:               numba: 0.58.0
2023-10-13 23:04:34,846:INFO:            requests: 2.28.1
2023-10-13 23:04:34,846:INFO:          matplotlib: 3.6.0
2023-10-13 23:04:34,846:INFO:          scikitplot: 0.3.7
2023-10-13 23:04:34,846:INFO:         yellowbrick: 1.5
2023-10-13 23:04:34,846:INFO:              plotly: 5.17.0
2023-10-13 23:04:34,846:INFO:    plotly-resampler: Not installed
2023-10-13 23:04:34,846:INFO:             kaleido: 0.2.1
2023-10-13 23:04:34,846:INFO:           schemdraw: 0.15
2023-10-13 23:04:34,846:INFO:         statsmodels: 0.13.2
2023-10-13 23:04:34,846:INFO:              sktime: 0.21.1
2023-10-13 23:04:34,846:INFO:               tbats: 1.1.3
2023-10-13 23:04:34,846:INFO:            pmdarima: 2.0.3
2023-10-13 23:04:34,846:INFO:              psutil: 5.9.1
2023-10-13 23:04:34,846:INFO:          markupsafe: 2.1.1
2023-10-13 23:04:34,846:INFO:             pickle5: Not installed
2023-10-13 23:04:34,846:INFO:         cloudpickle: 2.2.1
2023-10-13 23:04:34,846:INFO:         deprecation: 2.1.0
2023-10-13 23:04:34,846:INFO:              xxhash: 3.4.1
2023-10-13 23:04:34,846:INFO:           wurlitzer: Not installed
2023-10-13 23:04:34,846:INFO:PyCaret optional dependencies:
2023-10-13 23:04:34,847:INFO:                shap: Not installed
2023-10-13 23:04:34,847:INFO:           interpret: Not installed
2023-10-13 23:04:34,847:INFO:                umap: Not installed
2023-10-13 23:04:34,847:INFO:     ydata_profiling: Not installed
2023-10-13 23:04:34,847:INFO:  explainerdashboard: Not installed
2023-10-13 23:04:34,847:INFO:             autoviz: Not installed
2023-10-13 23:04:34,847:INFO:           fairlearn: Not installed
2023-10-13 23:04:34,847:INFO:          deepchecks: Not installed
2023-10-13 23:04:34,847:INFO:             xgboost: 2.0.0
2023-10-13 23:04:34,847:INFO:            catboost: Not installed
2023-10-13 23:04:34,847:INFO:              kmodes: Not installed
2023-10-13 23:04:34,847:INFO:             mlxtend: Not installed
2023-10-13 23:04:34,847:INFO:       statsforecast: Not installed
2023-10-13 23:04:34,847:INFO:        tune_sklearn: Not installed
2023-10-13 23:04:34,847:INFO:                 ray: Not installed
2023-10-13 23:04:34,847:INFO:            hyperopt: Not installed
2023-10-13 23:04:34,847:INFO:              optuna: Not installed
2023-10-13 23:04:34,847:INFO:               skopt: Not installed
2023-10-13 23:04:34,847:INFO:              mlflow: Not installed
2023-10-13 23:04:34,847:INFO:              gradio: Not installed
2023-10-13 23:04:34,847:INFO:             fastapi: Not installed
2023-10-13 23:04:34,847:INFO:             uvicorn: Not installed
2023-10-13 23:04:34,847:INFO:              m2cgen: Not installed
2023-10-13 23:04:34,847:INFO:           evidently: Not installed
2023-10-13 23:04:34,847:INFO:               fugue: Not installed
2023-10-13 23:04:34,847:INFO:           streamlit: Not installed
2023-10-13 23:04:34,847:INFO:             prophet: Not installed
2023-10-13 23:04:34,847:INFO:None
2023-10-13 23:05:00,343:INFO:PyCaret TSForecastingExperiment
2023-10-13 23:05:00,343:INFO:Logging name: ts-default-name
2023-10-13 23:05:00,343:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 23:05:00,343:INFO:version 3.1.0
2023-10-13 23:05:00,343:INFO:Initializing setup()
2023-10-13 23:05:00,343:INFO:self.USI: 0201
2023-10-13 23:05:00,343:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 23:05:00,343:INFO:Checking environment
2023-10-13 23:05:00,343:INFO:python_version: 3.10.6
2023-10-13 23:05:00,343:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 23:05:00,344:INFO:machine: AMD64
2023-10-13 23:05:00,344:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 23:05:00,344:INFO:Memory: svmem(total=8273383424, available=1479987200, percent=82.1, used=6793396224, free=1479987200)
2023-10-13 23:05:00,344:INFO:Physical Core: 4
2023-10-13 23:05:00,344:INFO:Logical Core: 8
2023-10-13 23:05:00,344:INFO:Checking libraries
2023-10-13 23:05:00,344:INFO:System:
2023-10-13 23:05:00,344:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 23:05:00,344:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 23:05:00,344:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 23:05:00,344:INFO:PyCaret required dependencies:
2023-10-13 23:05:00,344:INFO:                 pip: 22.2.1
2023-10-13 23:05:00,344:INFO:          setuptools: 63.2.0
2023-10-13 23:05:00,344:INFO:             pycaret: 3.1.0
2023-10-13 23:05:00,344:INFO:             IPython: 8.4.0
2023-10-13 23:05:00,344:INFO:          ipywidgets: 8.1.1
2023-10-13 23:05:00,344:INFO:                tqdm: 4.66.1
2023-10-13 23:05:00,344:INFO:               numpy: 1.23.2
2023-10-13 23:05:00,344:INFO:              pandas: 1.4.3
2023-10-13 23:05:00,344:INFO:              jinja2: 3.1.2
2023-10-13 23:05:00,344:INFO:               scipy: 1.10.1
2023-10-13 23:05:00,344:INFO:              joblib: 1.2.0
2023-10-13 23:05:00,344:INFO:             sklearn: 1.1.2
2023-10-13 23:05:00,344:INFO:                pyod: 1.1.0
2023-10-13 23:05:00,344:INFO:            imblearn: 0.11.0
2023-10-13 23:05:00,344:INFO:   category_encoders: 2.6.2
2023-10-13 23:05:00,344:INFO:            lightgbm: 4.1.0
2023-10-13 23:05:00,344:INFO:               numba: 0.58.0
2023-10-13 23:05:00,344:INFO:            requests: 2.28.1
2023-10-13 23:05:00,345:INFO:          matplotlib: 3.6.0
2023-10-13 23:05:00,345:INFO:          scikitplot: 0.3.7
2023-10-13 23:05:00,345:INFO:         yellowbrick: 1.5
2023-10-13 23:05:00,345:INFO:              plotly: 5.17.0
2023-10-13 23:05:00,345:INFO:    plotly-resampler: Not installed
2023-10-13 23:05:00,345:INFO:             kaleido: 0.2.1
2023-10-13 23:05:00,345:INFO:           schemdraw: 0.15
2023-10-13 23:05:00,345:INFO:         statsmodels: 0.13.2
2023-10-13 23:05:00,345:INFO:              sktime: 0.21.1
2023-10-13 23:05:00,345:INFO:               tbats: 1.1.3
2023-10-13 23:05:00,345:INFO:            pmdarima: 2.0.3
2023-10-13 23:05:00,345:INFO:              psutil: 5.9.1
2023-10-13 23:05:00,345:INFO:          markupsafe: 2.1.1
2023-10-13 23:05:00,345:INFO:             pickle5: Not installed
2023-10-13 23:05:00,345:INFO:         cloudpickle: 2.2.1
2023-10-13 23:05:00,345:INFO:         deprecation: 2.1.0
2023-10-13 23:05:00,345:INFO:              xxhash: 3.4.1
2023-10-13 23:05:00,345:INFO:           wurlitzer: Not installed
2023-10-13 23:05:00,345:INFO:PyCaret optional dependencies:
2023-10-13 23:05:00,345:INFO:                shap: Not installed
2023-10-13 23:05:00,345:INFO:           interpret: Not installed
2023-10-13 23:05:00,345:INFO:                umap: Not installed
2023-10-13 23:05:00,345:INFO:     ydata_profiling: Not installed
2023-10-13 23:05:00,345:INFO:  explainerdashboard: Not installed
2023-10-13 23:05:00,345:INFO:             autoviz: Not installed
2023-10-13 23:05:00,345:INFO:           fairlearn: Not installed
2023-10-13 23:05:00,346:INFO:          deepchecks: Not installed
2023-10-13 23:05:00,346:INFO:             xgboost: 2.0.0
2023-10-13 23:05:00,346:INFO:            catboost: Not installed
2023-10-13 23:05:00,346:INFO:              kmodes: Not installed
2023-10-13 23:05:00,346:INFO:             mlxtend: Not installed
2023-10-13 23:05:00,346:INFO:       statsforecast: Not installed
2023-10-13 23:05:00,346:INFO:        tune_sklearn: Not installed
2023-10-13 23:05:00,346:INFO:                 ray: Not installed
2023-10-13 23:05:00,346:INFO:            hyperopt: Not installed
2023-10-13 23:05:00,346:INFO:              optuna: Not installed
2023-10-13 23:05:00,346:INFO:               skopt: Not installed
2023-10-13 23:05:00,346:INFO:              mlflow: Not installed
2023-10-13 23:05:00,346:INFO:              gradio: Not installed
2023-10-13 23:05:00,346:INFO:             fastapi: Not installed
2023-10-13 23:05:00,346:INFO:             uvicorn: Not installed
2023-10-13 23:05:00,346:INFO:              m2cgen: Not installed
2023-10-13 23:05:00,346:INFO:           evidently: Not installed
2023-10-13 23:05:00,346:INFO:               fugue: Not installed
2023-10-13 23:05:00,346:INFO:           streamlit: Not installed
2023-10-13 23:05:00,346:INFO:             prophet: Not installed
2023-10-13 23:05:00,346:INFO:None
2023-10-13 23:05:00,581:INFO:Set Forecast Horizon.
2023-10-13 23:05:00,581:INFO:Set up Train-Test Splits.
2023-10-13 23:09:21,776:INFO:PyCaret TSForecastingExperiment
2023-10-13 23:09:21,776:INFO:Logging name: ts-default-name
2023-10-13 23:09:21,776:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 23:09:21,776:INFO:version 3.1.0
2023-10-13 23:09:21,776:INFO:Initializing setup()
2023-10-13 23:09:21,776:INFO:self.USI: b494
2023-10-13 23:09:21,776:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 23:09:21,776:INFO:Checking environment
2023-10-13 23:09:21,776:INFO:python_version: 3.10.6
2023-10-13 23:09:21,776:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 23:09:21,776:INFO:machine: AMD64
2023-10-13 23:09:21,776:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 23:09:21,776:INFO:Memory: svmem(total=8273383424, available=1622487040, percent=80.4, used=6650896384, free=1622487040)
2023-10-13 23:09:21,776:INFO:Physical Core: 4
2023-10-13 23:09:21,776:INFO:Logical Core: 8
2023-10-13 23:09:21,776:INFO:Checking libraries
2023-10-13 23:09:21,776:INFO:System:
2023-10-13 23:09:21,776:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 23:09:21,776:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 23:09:21,776:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 23:09:21,776:INFO:PyCaret required dependencies:
2023-10-13 23:09:21,776:INFO:                 pip: 22.2.1
2023-10-13 23:09:21,776:INFO:          setuptools: 63.2.0
2023-10-13 23:09:21,776:INFO:             pycaret: 3.1.0
2023-10-13 23:09:21,776:INFO:             IPython: 8.4.0
2023-10-13 23:09:21,776:INFO:          ipywidgets: 8.1.1
2023-10-13 23:09:21,776:INFO:                tqdm: 4.66.1
2023-10-13 23:09:21,776:INFO:               numpy: 1.23.2
2023-10-13 23:09:21,776:INFO:              pandas: 1.4.3
2023-10-13 23:09:21,776:INFO:              jinja2: 3.1.2
2023-10-13 23:09:21,776:INFO:               scipy: 1.10.1
2023-10-13 23:09:21,792:INFO:              joblib: 1.2.0
2023-10-13 23:09:21,792:INFO:             sklearn: 1.1.2
2023-10-13 23:09:21,792:INFO:                pyod: 1.1.0
2023-10-13 23:09:21,792:INFO:            imblearn: 0.11.0
2023-10-13 23:09:21,792:INFO:   category_encoders: 2.6.2
2023-10-13 23:09:21,792:INFO:            lightgbm: 4.1.0
2023-10-13 23:09:21,792:INFO:               numba: 0.58.0
2023-10-13 23:09:21,792:INFO:            requests: 2.28.1
2023-10-13 23:09:21,792:INFO:          matplotlib: 3.6.0
2023-10-13 23:09:21,792:INFO:          scikitplot: 0.3.7
2023-10-13 23:09:21,792:INFO:         yellowbrick: 1.5
2023-10-13 23:09:21,792:INFO:              plotly: 5.17.0
2023-10-13 23:09:21,792:INFO:    plotly-resampler: Not installed
2023-10-13 23:09:21,792:INFO:             kaleido: 0.2.1
2023-10-13 23:09:21,792:INFO:           schemdraw: 0.15
2023-10-13 23:09:21,792:INFO:         statsmodels: 0.13.2
2023-10-13 23:09:21,792:INFO:              sktime: 0.21.1
2023-10-13 23:09:21,792:INFO:               tbats: 1.1.3
2023-10-13 23:09:21,792:INFO:            pmdarima: 2.0.3
2023-10-13 23:09:21,792:INFO:              psutil: 5.9.1
2023-10-13 23:09:21,792:INFO:          markupsafe: 2.1.1
2023-10-13 23:09:21,792:INFO:             pickle5: Not installed
2023-10-13 23:09:21,792:INFO:         cloudpickle: 2.2.1
2023-10-13 23:09:21,792:INFO:         deprecation: 2.1.0
2023-10-13 23:09:21,792:INFO:              xxhash: 3.4.1
2023-10-13 23:09:21,792:INFO:           wurlitzer: Not installed
2023-10-13 23:09:21,792:INFO:PyCaret optional dependencies:
2023-10-13 23:09:21,792:INFO:                shap: Not installed
2023-10-13 23:09:21,792:INFO:           interpret: Not installed
2023-10-13 23:09:21,792:INFO:                umap: Not installed
2023-10-13 23:09:21,792:INFO:     ydata_profiling: Not installed
2023-10-13 23:09:21,792:INFO:  explainerdashboard: Not installed
2023-10-13 23:09:21,792:INFO:             autoviz: Not installed
2023-10-13 23:09:21,792:INFO:           fairlearn: Not installed
2023-10-13 23:09:21,792:INFO:          deepchecks: Not installed
2023-10-13 23:09:21,792:INFO:             xgboost: 2.0.0
2023-10-13 23:09:21,792:INFO:            catboost: Not installed
2023-10-13 23:09:21,792:INFO:              kmodes: Not installed
2023-10-13 23:09:21,792:INFO:             mlxtend: Not installed
2023-10-13 23:09:21,792:INFO:       statsforecast: Not installed
2023-10-13 23:09:21,792:INFO:        tune_sklearn: Not installed
2023-10-13 23:09:21,792:INFO:                 ray: Not installed
2023-10-13 23:09:21,792:INFO:            hyperopt: Not installed
2023-10-13 23:09:21,792:INFO:              optuna: Not installed
2023-10-13 23:09:21,792:INFO:               skopt: Not installed
2023-10-13 23:09:21,792:INFO:              mlflow: Not installed
2023-10-13 23:09:21,792:INFO:              gradio: Not installed
2023-10-13 23:09:21,792:INFO:             fastapi: Not installed
2023-10-13 23:09:21,792:INFO:             uvicorn: Not installed
2023-10-13 23:09:21,792:INFO:              m2cgen: Not installed
2023-10-13 23:09:21,792:INFO:           evidently: Not installed
2023-10-13 23:09:21,792:INFO:               fugue: Not installed
2023-10-13 23:09:21,792:INFO:           streamlit: Not installed
2023-10-13 23:09:21,792:INFO:             prophet: Not installed
2023-10-13 23:09:21,792:INFO:None
2023-10-13 23:09:21,792:INFO:Set Forecast Horizon.
2023-10-13 23:09:21,792:INFO:Set up Train-Test Splits.
2023-10-13 23:09:21,823:INFO:Finished creating preprocessing pipeline.
2023-10-13 23:09:21,823:INFO:Pipeline: ForecastingPipeline(steps=[('forecaster',
                            TransformedTargetForecaster(steps=[('model',
                                                                DummyForecaster())]))])
2023-10-13 23:09:21,823:INFO:Set up Seasonal Period.
2023-10-13 23:09:21,839:INFO:Setting the seasonal component type - 'add' or 'mul'.
2023-10-13 23:09:21,839:INFO:Checking if data is strictly positive.
2023-10-13 23:09:21,886:INFO:Creating final display dataframe.
2023-10-13 23:09:21,886:INFO:Setup Display Container:                                          Description  \
0                                         session_id   
1                                             Target   
2                                           Approach   
3                                Exogenous Variables   
4                                Original data shape   
5                             Transformed data shape   
6                        Transformed train set shape   
7                         Transformed test set shape   
8                           Rows with missing values   
9                                     Fold Generator   
10                                       Fold Number   
11                       Enforce Prediction Interval   
12                   Splits used for hyperparameters   
13                   User Defined Seasonal Period(s)   
14                           Ignore Seasonality Test   
15                        Seasonality Detection Algo   
16                            Max Period to Consider   
17                         Seasonal Period(s) Tested   
18                    Significant Seasonal Period(s)   
19  Significant Seasonal Period(s) without Harmonics   
20                                  Remove Harmonics   
21                            Harmonics Order Method   
22                          Num Seasonalities to Use   
23                          All Seasonalities to Use   
24                               Primary Seasonality   
25                               Seasonality Present   
26                                  Seasonality Type   
27                          Target Strictly Positive   
28                                Target White Noise   
29                                     Recommended d   
30                            Recommended Seasonal D   
31                                        Preprocess   
32                                          CPU Jobs   
33                                           Use GPU   
34                                    Log Experiment   
35                                   Experiment Name   
36                                               USI   

                           Value  
0                            123  
1   Number of airline passengers  
2                     Univariate  
3                    Not Present  
4                       (144, 1)  
5                       (144, 1)  
6                       (141, 1)  
7                         (3, 1)  
8                           0.0%  
9        ExpandingWindowSplitter  
10                             3  
11                         False  
12                           all  
13                          None  
14                         False  
15                          auto  
16                            60  
17          [12, 24, 36, 11, 48]  
18          [12, 24, 36, 11, 48]  
19                  [48, 36, 11]  
20                         False  
21                  harmonic_max  
22                             1  
23                          [12]  
24                            12  
25                          True  
26                           mul  
27                          True  
28                            No  
29                             1  
30                             1  
31                         False  
32                            -1  
33                         False  
34                         False  
35               ts-default-name  
36                          b494  
2023-10-13 23:09:21,901:INFO:Engine successfully changes for model 'auto_arima' to 'pmdarima'.
2023-10-13 23:09:22,006:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,006:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,006:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,012:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,012:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,012:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,012:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,012:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,028:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,028:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,028:INFO:Engine successfully changes for model 'lr_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,028:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,028:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,028:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,043:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,043:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,043:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,043:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,043:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,043:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,043:INFO:Engine successfully changes for model 'en_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,059:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,059:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,059:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,059:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,075:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,075:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,075:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,075:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,075:INFO:Engine successfully changes for model 'ridge_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,075:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,075:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,090:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,090:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,106:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,106:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,106:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,106:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,106:INFO:Engine successfully changes for model 'lasso_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,106:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,122:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,122:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,122:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,122:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,122:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,122:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,138:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,138:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,138:INFO:Engine successfully changes for model 'lar_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,138:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,138:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,138:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,153:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,153:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,153:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,153:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,153:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,169:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,169:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,169:INFO:Engine successfully changes for model 'llar_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,169:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,169:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,169:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,169:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,184:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,184:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,184:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,184:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,184:INFO:Engine successfully changes for model 'br_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,200:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,200:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,200:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,200:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,200:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,200:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,200:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,207:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,207:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,207:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,207:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,207:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,207:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,207:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,207:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,207:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,216:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,216:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,216:INFO:Engine successfully changes for model 'huber_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,216:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,216:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,216:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,232:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,232:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,232:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,232:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,232:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,232:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,232:INFO:Engine successfully changes for model 'par_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,248:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,248:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,248:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,248:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,263:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,263:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,263:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,263:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,263:INFO:Engine successfully changes for model 'omp_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,279:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,279:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,279:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,279:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,279:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,279:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,279:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,295:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,295:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,295:INFO:Engine successfully changes for model 'knn_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,295:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,295:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,295:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,307:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,307:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,307:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,307:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,307:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,307:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,311:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,311:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,311:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,311:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,311:INFO:Engine successfully changes for model 'dt_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,311:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,326:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,326:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,326:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,326:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,342:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,342:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,342:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,342:INFO:Engine successfully changes for model 'rf_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,342:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,342:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,342:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,342:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,358:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,358:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,358:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,358:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,358:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,358:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,358:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,358:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,358:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,358:INFO:Engine successfully changes for model 'et_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,373:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,373:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,373:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,373:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,373:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,373:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,373:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,373:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,373:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,389:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,389:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,389:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,389:INFO:Engine successfully changes for model 'gbr_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,389:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,389:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,389:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,389:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,408:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,408:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,408:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,408:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,408:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,408:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,408:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,408:INFO:Engine successfully changes for model 'ada_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,421:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,421:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,421:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,421:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,421:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,421:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,421:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,436:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,436:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,436:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,436:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,436:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,436:INFO:Engine successfully changes for model 'xgboost_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,436:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,452:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,452:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,452:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,452:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,452:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,452:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,452:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,452:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,452:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,452:INFO:Engine successfully changes for model 'lightgbm_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,468:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,468:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,468:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,468:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,483:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,483:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,483:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,483:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:22,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,483:INFO:Engine successfully changes for model 'catboost_cds_dt' to 'sklearn'.
2023-10-13 23:09:22,483:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,499:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,499:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,499:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,508:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,508:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,515:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,515:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,515:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,515:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:22,531:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,531:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:22,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:22,531:INFO:setup() successfully completed in 0.75s...............
2023-10-13 23:09:46,354:INFO:PyCaret TSForecastingExperiment
2023-10-13 23:09:46,354:INFO:Logging name: ts-default-name
2023-10-13 23:09:46,355:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-10-13 23:09:46,355:INFO:version 3.1.0
2023-10-13 23:09:46,355:INFO:Initializing setup()
2023-10-13 23:09:46,355:INFO:self.USI: 0221
2023-10-13 23:09:46,355:INFO:self._variable_keys: {'approach_type', 'y_test', 'gpu_param', 'primary_sp_to_use', 'significant_sps_no_harmonics', 'log_plots_param', 'index_type', 'significant_sps', 'seed', 'fold_generator', 'X', '_available_plots', 'fh', 'USI', 'exogenous_present', 'n_jobs_param', 'exp_id', 'fold_param', 'seasonality_present', 'html_param', 'logging_param', 'y', 'all_sps_to_use', 'y_train', 'y_train_transformed', 'X_train_transformed', 'gpu_n_jobs_param', 'exp_name_log', 'X_test_transformed', 'enforce_pi', 'X_transformed', 'y_test_transformed', 'enforce_exogenous', '_ml_usecase', 'data', 'model_engines', 'X_test', 'idx', 'candidate_sps', 'strictly_positive', 'pipeline', 'y_transformed', 'memory', 'X_train'}
2023-10-13 23:09:46,355:INFO:Checking environment
2023-10-13 23:09:46,355:INFO:python_version: 3.10.6
2023-10-13 23:09:46,355:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-13 23:09:46,355:INFO:machine: AMD64
2023-10-13 23:09:46,355:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-13 23:09:46,355:INFO:Memory: svmem(total=8273383424, available=1636347904, percent=80.2, used=6637035520, free=1636347904)
2023-10-13 23:09:46,356:INFO:Physical Core: 4
2023-10-13 23:09:46,356:INFO:Logical Core: 8
2023-10-13 23:09:46,356:INFO:Checking libraries
2023-10-13 23:09:46,356:INFO:System:
2023-10-13 23:09:46,356:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-13 23:09:46,356:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-13 23:09:46,356:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-13 23:09:46,356:INFO:PyCaret required dependencies:
2023-10-13 23:09:46,356:INFO:                 pip: 22.2.1
2023-10-13 23:09:46,356:INFO:          setuptools: 63.2.0
2023-10-13 23:09:46,356:INFO:             pycaret: 3.1.0
2023-10-13 23:09:46,356:INFO:             IPython: 8.4.0
2023-10-13 23:09:46,356:INFO:          ipywidgets: 8.1.1
2023-10-13 23:09:46,356:INFO:                tqdm: 4.66.1
2023-10-13 23:09:46,356:INFO:               numpy: 1.23.2
2023-10-13 23:09:46,356:INFO:              pandas: 1.4.3
2023-10-13 23:09:46,356:INFO:              jinja2: 3.1.2
2023-10-13 23:09:46,356:INFO:               scipy: 1.10.1
2023-10-13 23:09:46,356:INFO:              joblib: 1.2.0
2023-10-13 23:09:46,356:INFO:             sklearn: 1.1.2
2023-10-13 23:09:46,357:INFO:                pyod: 1.1.0
2023-10-13 23:09:46,357:INFO:            imblearn: 0.11.0
2023-10-13 23:09:46,357:INFO:   category_encoders: 2.6.2
2023-10-13 23:09:46,357:INFO:            lightgbm: 4.1.0
2023-10-13 23:09:46,357:INFO:               numba: 0.58.0
2023-10-13 23:09:46,357:INFO:            requests: 2.28.1
2023-10-13 23:09:46,357:INFO:          matplotlib: 3.6.0
2023-10-13 23:09:46,357:INFO:          scikitplot: 0.3.7
2023-10-13 23:09:46,357:INFO:         yellowbrick: 1.5
2023-10-13 23:09:46,357:INFO:              plotly: 5.17.0
2023-10-13 23:09:46,357:INFO:    plotly-resampler: Not installed
2023-10-13 23:09:46,357:INFO:             kaleido: 0.2.1
2023-10-13 23:09:46,357:INFO:           schemdraw: 0.15
2023-10-13 23:09:46,357:INFO:         statsmodels: 0.13.2
2023-10-13 23:09:46,357:INFO:              sktime: 0.21.1
2023-10-13 23:09:46,357:INFO:               tbats: 1.1.3
2023-10-13 23:09:46,357:INFO:            pmdarima: 2.0.3
2023-10-13 23:09:46,357:INFO:              psutil: 5.9.1
2023-10-13 23:09:46,357:INFO:          markupsafe: 2.1.1
2023-10-13 23:09:46,357:INFO:             pickle5: Not installed
2023-10-13 23:09:46,357:INFO:         cloudpickle: 2.2.1
2023-10-13 23:09:46,357:INFO:         deprecation: 2.1.0
2023-10-13 23:09:46,357:INFO:              xxhash: 3.4.1
2023-10-13 23:09:46,357:INFO:           wurlitzer: Not installed
2023-10-13 23:09:46,357:INFO:PyCaret optional dependencies:
2023-10-13 23:09:46,357:INFO:                shap: Not installed
2023-10-13 23:09:46,357:INFO:           interpret: Not installed
2023-10-13 23:09:46,358:INFO:                umap: Not installed
2023-10-13 23:09:46,358:INFO:     ydata_profiling: Not installed
2023-10-13 23:09:46,358:INFO:  explainerdashboard: Not installed
2023-10-13 23:09:46,358:INFO:             autoviz: Not installed
2023-10-13 23:09:46,358:INFO:           fairlearn: Not installed
2023-10-13 23:09:46,358:INFO:          deepchecks: Not installed
2023-10-13 23:09:46,358:INFO:             xgboost: 2.0.0
2023-10-13 23:09:46,358:INFO:            catboost: Not installed
2023-10-13 23:09:46,358:INFO:              kmodes: Not installed
2023-10-13 23:09:46,358:INFO:             mlxtend: Not installed
2023-10-13 23:09:46,358:INFO:       statsforecast: Not installed
2023-10-13 23:09:46,358:INFO:        tune_sklearn: Not installed
2023-10-13 23:09:46,358:INFO:                 ray: Not installed
2023-10-13 23:09:46,358:INFO:            hyperopt: Not installed
2023-10-13 23:09:46,358:INFO:              optuna: Not installed
2023-10-13 23:09:46,358:INFO:               skopt: Not installed
2023-10-13 23:09:46,358:INFO:              mlflow: Not installed
2023-10-13 23:09:46,358:INFO:              gradio: Not installed
2023-10-13 23:09:46,358:INFO:             fastapi: Not installed
2023-10-13 23:09:46,358:INFO:             uvicorn: Not installed
2023-10-13 23:09:46,358:INFO:              m2cgen: Not installed
2023-10-13 23:09:46,358:INFO:           evidently: Not installed
2023-10-13 23:09:46,359:INFO:               fugue: Not installed
2023-10-13 23:09:46,359:INFO:           streamlit: Not installed
2023-10-13 23:09:46,359:INFO:             prophet: Not installed
2023-10-13 23:09:46,359:INFO:None
2023-10-13 23:09:46,361:INFO:Set Forecast Horizon.
2023-10-13 23:09:46,361:INFO:Set up Train-Test Splits.
2023-10-13 23:09:46,385:INFO:Finished creating preprocessing pipeline.
2023-10-13 23:09:46,386:INFO:Pipeline: ForecastingPipeline(steps=[('forecaster',
                            TransformedTargetForecaster(steps=[('model',
                                                                DummyForecaster())]))])
2023-10-13 23:09:46,386:INFO:Set up Seasonal Period.
2023-10-13 23:09:46,394:INFO:Setting the seasonal component type - 'add' or 'mul'.
2023-10-13 23:09:46,394:INFO:Checking if data is strictly positive.
2023-10-13 23:09:46,418:INFO:Creating final display dataframe.
2023-10-13 23:09:46,428:INFO:Setup Display Container:                                          Description  \
0                                         session_id   
1                                             Target   
2                                           Approach   
3                                Exogenous Variables   
4                                Original data shape   
5                             Transformed data shape   
6                        Transformed train set shape   
7                         Transformed test set shape   
8                           Rows with missing values   
9                                     Fold Generator   
10                                       Fold Number   
11                       Enforce Prediction Interval   
12                   Splits used for hyperparameters   
13                   User Defined Seasonal Period(s)   
14                           Ignore Seasonality Test   
15                        Seasonality Detection Algo   
16                            Max Period to Consider   
17                         Seasonal Period(s) Tested   
18                    Significant Seasonal Period(s)   
19  Significant Seasonal Period(s) without Harmonics   
20                                  Remove Harmonics   
21                            Harmonics Order Method   
22                          Num Seasonalities to Use   
23                          All Seasonalities to Use   
24                               Primary Seasonality   
25                               Seasonality Present   
26                                  Seasonality Type   
27                          Target Strictly Positive   
28                                Target White Noise   
29                                     Recommended d   
30                            Recommended Seasonal D   
31                                        Preprocess   
32                                          CPU Jobs   
33                                           Use GPU   
34                                    Log Experiment   
35                                   Experiment Name   
36                                               USI   

                           Value  
0                            123  
1   Number of airline passengers  
2                     Univariate  
3                    Not Present  
4                       (144, 1)  
5                       (144, 1)  
6                       (141, 1)  
7                         (3, 1)  
8                           0.0%  
9        ExpandingWindowSplitter  
10                             3  
11                         False  
12                           all  
13                          None  
14                         False  
15                          auto  
16                            60  
17          [12, 24, 36, 11, 48]  
18          [12, 24, 36, 11, 48]  
19                  [48, 36, 11]  
20                         False  
21                  harmonic_max  
22                             1  
23                          [12]  
24                            12  
25                          True  
26                           mul  
27                          True  
28                            No  
29                             1  
30                             1  
31                         False  
32                            -1  
33                         False  
34                         False  
35               ts-default-name  
36                          0221  
2023-10-13 23:09:46,434:INFO:Engine successfully changes for model 'auto_arima' to 'pmdarima'.
2023-10-13 23:09:46,440:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,441:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,441:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,441:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,441:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,442:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,442:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,442:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,444:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,445:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,446:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,446:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,446:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,446:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,447:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,447:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,447:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,447:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,447:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,448:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,452:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,452:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,452:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,452:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,452:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,453:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,453:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,454:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,455:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,457:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,457:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,457:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,458:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,458:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,458:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,459:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,459:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,459:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,459:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,459:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,459:INFO:Engine successfully changes for model 'lr_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,466:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,466:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,467:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,467:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,468:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,468:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,468:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,470:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,472:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,473:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,473:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,474:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,474:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,475:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,475:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,475:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,475:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,475:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,476:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,482:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,482:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,483:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,483:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,483:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,484:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,484:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,486:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,489:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,490:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,490:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,491:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,491:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,492:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,492:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,492:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,492:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,492:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,493:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,493:INFO:Engine successfully changes for model 'en_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,499:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,499:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,499:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,500:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,501:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,501:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,503:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,506:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,506:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,506:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,506:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,507:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,507:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,507:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,507:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,507:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,507:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,508:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,512:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,513:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,513:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,513:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,513:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,513:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,514:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,516:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,516:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,516:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,516:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,516:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,517:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,517:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,517:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,517:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,517:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,518:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,518:INFO:Engine successfully changes for model 'ridge_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,524:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,524:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,525:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,525:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,525:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,527:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,528:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,528:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,528:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,528:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,529:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,529:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,529:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,529:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,529:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,529:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,530:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,534:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,535:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,535:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,536:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,536:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,539:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,540:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,540:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,541:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,541:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,542:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,542:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,542:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,542:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,542:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,543:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,543:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,543:INFO:Engine successfully changes for model 'lasso_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,549:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,551:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,551:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,551:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,554:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,556:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,556:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,557:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,557:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,557:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,558:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,558:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,558:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,558:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,558:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,559:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,564:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,565:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,566:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,566:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,568:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,569:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,570:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,571:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,571:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,571:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,572:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,572:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,572:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,572:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,572:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,573:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,573:INFO:Engine successfully changes for model 'lar_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,579:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,580:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,580:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,580:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,582:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,583:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,584:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,584:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,584:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,585:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,585:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,586:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,586:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,586:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,586:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,587:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,593:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,594:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,594:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,595:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,597:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,599:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,599:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,600:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,600:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,601:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,601:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,601:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,601:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,601:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,602:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,602:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,602:INFO:Engine successfully changes for model 'llar_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,609:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,610:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,610:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,613:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,614:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,615:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,615:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,615:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,616:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,616:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,616:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,616:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,616:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,617:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,617:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,623:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,625:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,625:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,626:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,627:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,628:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,628:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,628:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,629:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,629:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,629:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,629:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,630:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,630:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,630:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,631:INFO:Engine successfully changes for model 'br_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,636:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,638:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,640:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,641:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,642:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,642:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,642:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,642:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,643:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,643:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,643:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,643:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,644:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,644:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,649:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,651:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,653:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,655:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,655:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,655:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,656:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,656:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,656:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,657:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,657:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,657:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,657:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,657:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,658:INFO:Engine successfully changes for model 'huber_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,663:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,666:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,667:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,668:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,668:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,668:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,669:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,669:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,669:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,669:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,671:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,671:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,671:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,678:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,680:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,682:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,682:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,683:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,683:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,683:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,684:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,684:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,684:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,684:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,684:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,685:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,685:INFO:Engine successfully changes for model 'par_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,690:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,694:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,694:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,695:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,695:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,695:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,697:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,697:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,697:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,697:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,697:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,698:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,698:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,703:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,708:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,709:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,709:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,709:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,710:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,710:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,710:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,710:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,710:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,710:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,710:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,711:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,711:INFO:Engine successfully changes for model 'omp_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,717:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,721:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,722:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,722:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,722:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,722:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,722:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,723:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,723:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,723:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,723:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,723:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,728:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,731:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,731:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,731:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,731:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,732:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,732:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,732:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,732:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,732:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,732:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,733:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,733:INFO:Engine successfully changes for model 'knn_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,738:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,742:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,742:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,742:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,742:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,742:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,742:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,742:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,742:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,743:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,743:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,748:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,751:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,751:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,752:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,752:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,753:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,753:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,753:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,753:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,754:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,754:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,754:INFO:Engine successfully changes for model 'dt_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,760:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,765:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,765:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,765:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,765:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,766:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,766:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,766:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,766:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,767:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,773:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,778:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,778:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,778:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,779:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,779:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,779:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,779:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,780:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,780:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,780:INFO:Engine successfully changes for model 'rf_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,786:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,792:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,792:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,793:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,793:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,793:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,793:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,794:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,794:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,799:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,805:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,805:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,806:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,806:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,806:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,806:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,806:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,807:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,807:INFO:Engine successfully changes for model 'et_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,812:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,818:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,819:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,819:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,819:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,819:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,819:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,820:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,826:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,831:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,831:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,832:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,832:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,832:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,832:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,832:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,833:INFO:Engine successfully changes for model 'gbr_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,838:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,843:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,844:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,844:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,844:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,844:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,845:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,851:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,857:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,858:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,858:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,858:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,858:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,858:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,859:INFO:Engine successfully changes for model 'ada_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,864:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,870:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,870:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,870:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,871:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,871:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,877:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,882:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,882:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,882:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,883:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,883:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,883:INFO:Engine successfully changes for model 'xgboost_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,890:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,895:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,895:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,896:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,896:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,901:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,908:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,908:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,908:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,908:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,909:INFO:Engine successfully changes for model 'lightgbm_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,914:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,920:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,921:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,921:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,927:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,932:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,932:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,933:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2023-10-13 23:09:46,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,933:INFO:Engine successfully changes for model 'catboost_cds_dt' to 'sklearn'.
2023-10-13 23:09:46,939:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,945:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,945:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,950:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,957:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,957:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,963:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,970:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,970:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,978:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:09:46,984:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,984:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-13 23:09:46,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-13 23:09:46,985:INFO:setup() successfully completed in 0.63s...............
2023-10-13 23:09:58,288:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\statsmodels\tsa\stattools.py:2022: InterpolationWarning: The test statistic is outside of the range of p-values available in the
look-up table. The actual p-value is greater than the p-value returned.

  warnings.warn(

2023-10-13 23:10:13,856:INFO:Initializing compare_models()
2023-10-13 23:10:13,856:INFO:compare_models(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, include=None, fold=None, round=4, cross_validation=True, sort=MASE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MASE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.time_series.forecasting.oop.TSForecastingExperiment'>}, exclude=None)
2023-10-13 23:10:13,856:INFO:Checking exceptions
2023-10-13 23:10:13,856:INFO:Preparing display monitor
2023-10-13 23:10:13,903:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:713: UserWarning: Unsupported estimator `ensemble_forecaster` for method `compare_models()`, removing from model_library
  warnings.warn(

2023-10-13 23:10:13,903:INFO:Initializing Naive Forecaster
2023-10-13 23:10:13,903:INFO:Total runtime is 0.0 minutes
2023-10-13 23:10:13,919:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:13,919:INFO:Initializing create_model()
2023-10-13 23:10:13,919:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=naive, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:13,919:INFO:Checking exceptions
2023-10-13 23:10:13,919:INFO:Importing libraries
2023-10-13 23:10:13,919:INFO:Copying training dataset
2023-10-13 23:10:13,919:INFO:Defining folds
2023-10-13 23:10:13,919:INFO:Declaring metric variables
2023-10-13 23:10:13,919:INFO:Importing untrained model
2023-10-13 23:10:13,934:INFO:Naive Forecaster Imported successfully
2023-10-13 23:10:13,934:INFO:Starting cross validation
2023-10-13 23:10:13,934:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:17,077:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:17,083:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:17,083:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:17,101:INFO:Calculating mean and std
2023-10-13 23:10:17,102:INFO:Creating metrics dataframe
2023-10-13 23:10:17,109:INFO:Uploading results into container
2023-10-13 23:10:17,109:INFO:Uploading model into container now
2023-10-13 23:10:17,110:INFO:_master_model_container: 1
2023-10-13 23:10:17,110:INFO:_display_container: 2
2023-10-13 23:10:17,111:INFO:NaiveForecaster()
2023-10-13 23:10:17,111:INFO:create_model() successfully completed......................................
2023-10-13 23:10:17,288:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:17,288:INFO:Creating metrics dataframe
2023-10-13 23:10:17,296:INFO:Initializing Grand Means Forecaster
2023-10-13 23:10:17,296:INFO:Total runtime is 0.05654930273691813 minutes
2023-10-13 23:10:17,299:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:17,299:INFO:Initializing create_model()
2023-10-13 23:10:17,299:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=grand_means, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:17,299:INFO:Checking exceptions
2023-10-13 23:10:17,299:INFO:Importing libraries
2023-10-13 23:10:17,299:INFO:Copying training dataset
2023-10-13 23:10:17,303:INFO:Defining folds
2023-10-13 23:10:17,303:INFO:Declaring metric variables
2023-10-13 23:10:17,306:INFO:Importing untrained model
2023-10-13 23:10:17,310:INFO:Grand Means Forecaster Imported successfully
2023-10-13 23:10:17,319:INFO:Starting cross validation
2023-10-13 23:10:17,320:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:19,159:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:19,166:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:19,166:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:19,181:INFO:Calculating mean and std
2023-10-13 23:10:19,184:INFO:Creating metrics dataframe
2023-10-13 23:10:19,195:INFO:Uploading results into container
2023-10-13 23:10:19,196:INFO:Uploading model into container now
2023-10-13 23:10:19,196:INFO:_master_model_container: 2
2023-10-13 23:10:19,197:INFO:_display_container: 2
2023-10-13 23:10:19,197:INFO:NaiveForecaster(strategy='mean')
2023-10-13 23:10:19,197:INFO:create_model() successfully completed......................................
2023-10-13 23:10:19,351:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:19,351:INFO:Creating metrics dataframe
2023-10-13 23:10:19,358:INFO:Initializing Seasonal Naive Forecaster
2023-10-13 23:10:19,358:INFO:Total runtime is 0.09090788364410402 minutes
2023-10-13 23:10:19,362:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:19,362:INFO:Initializing create_model()
2023-10-13 23:10:19,362:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=snaive, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:19,362:INFO:Checking exceptions
2023-10-13 23:10:19,362:INFO:Importing libraries
2023-10-13 23:10:19,362:INFO:Copying training dataset
2023-10-13 23:10:19,366:INFO:Defining folds
2023-10-13 23:10:19,366:INFO:Declaring metric variables
2023-10-13 23:10:19,369:INFO:Importing untrained model
2023-10-13 23:10:19,374:INFO:Seasonal Naive Forecaster Imported successfully
2023-10-13 23:10:19,383:INFO:Starting cross validation
2023-10-13 23:10:19,384:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:19,443:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:21,207:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:21,210:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:21,239:INFO:Calculating mean and std
2023-10-13 23:10:21,241:INFO:Creating metrics dataframe
2023-10-13 23:10:21,250:INFO:Uploading results into container
2023-10-13 23:10:21,250:INFO:Uploading model into container now
2023-10-13 23:10:21,251:INFO:_master_model_container: 3
2023-10-13 23:10:21,251:INFO:_display_container: 2
2023-10-13 23:10:21,251:INFO:NaiveForecaster(sp=12)
2023-10-13 23:10:21,251:INFO:create_model() successfully completed......................................
2023-10-13 23:10:21,392:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:21,393:INFO:Creating metrics dataframe
2023-10-13 23:10:21,400:INFO:Initializing Polynomial Trend Forecaster
2023-10-13 23:10:21,401:INFO:Total runtime is 0.12496387958526613 minutes
2023-10-13 23:10:21,404:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:21,404:INFO:Initializing create_model()
2023-10-13 23:10:21,404:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=polytrend, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:21,404:INFO:Checking exceptions
2023-10-13 23:10:21,404:INFO:Importing libraries
2023-10-13 23:10:21,405:INFO:Copying training dataset
2023-10-13 23:10:21,410:INFO:Defining folds
2023-10-13 23:10:21,410:INFO:Declaring metric variables
2023-10-13 23:10:21,413:INFO:Importing untrained model
2023-10-13 23:10:21,418:INFO:Polynomial Trend Forecaster Imported successfully
2023-10-13 23:10:21,426:INFO:Starting cross validation
2023-10-13 23:10:21,428:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:21,470:INFO:Calculating mean and std
2023-10-13 23:10:21,470:INFO:Creating metrics dataframe
2023-10-13 23:10:21,474:INFO:Uploading results into container
2023-10-13 23:10:21,474:INFO:Uploading model into container now
2023-10-13 23:10:21,474:INFO:_master_model_container: 4
2023-10-13 23:10:21,474:INFO:_display_container: 2
2023-10-13 23:10:21,474:INFO:PolynomialTrendForecaster()
2023-10-13 23:10:21,474:INFO:create_model() successfully completed......................................
2023-10-13 23:10:21,620:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:21,621:INFO:Creating metrics dataframe
2023-10-13 23:10:21,631:INFO:Initializing ARIMA
2023-10-13 23:10:21,631:INFO:Total runtime is 0.12879368066787722 minutes
2023-10-13 23:10:21,633:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:21,633:INFO:Initializing create_model()
2023-10-13 23:10:21,634:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=arima, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:21,634:INFO:Checking exceptions
2023-10-13 23:10:21,634:INFO:Importing libraries
2023-10-13 23:10:21,634:INFO:Copying training dataset
2023-10-13 23:10:21,638:INFO:Defining folds
2023-10-13 23:10:21,638:INFO:Declaring metric variables
2023-10-13 23:10:21,641:INFO:Importing untrained model
2023-10-13 23:10:21,647:INFO:ARIMA Imported successfully
2023-10-13 23:10:21,654:INFO:Starting cross validation
2023-10-13 23:10:21,656:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:21,772:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:21,779:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:21,779:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:21,820:INFO:Calculating mean and std
2023-10-13 23:10:21,821:INFO:Creating metrics dataframe
2023-10-13 23:10:21,826:INFO:Uploading results into container
2023-10-13 23:10:21,826:INFO:Uploading model into container now
2023-10-13 23:10:21,826:INFO:_master_model_container: 5
2023-10-13 23:10:21,826:INFO:_display_container: 2
2023-10-13 23:10:21,827:INFO:ARIMA(seasonal_order=(0, 1, 0, 12))
2023-10-13 23:10:21,827:INFO:create_model() successfully completed......................................
2023-10-13 23:10:21,961:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:21,961:INFO:Creating metrics dataframe
2023-10-13 23:10:21,970:INFO:Initializing Auto ARIMA
2023-10-13 23:10:21,970:INFO:Total runtime is 0.13445250193277997 minutes
2023-10-13 23:10:21,973:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:21,973:INFO:Initializing create_model()
2023-10-13 23:10:21,973:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=auto_arima, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:21,974:INFO:Checking exceptions
2023-10-13 23:10:21,974:INFO:Importing libraries
2023-10-13 23:10:21,974:INFO:Copying training dataset
2023-10-13 23:10:21,979:INFO:Defining folds
2023-10-13 23:10:21,979:INFO:Declaring metric variables
2023-10-13 23:10:21,982:INFO:Importing untrained model
2023-10-13 23:10:21,988:INFO:Auto ARIMA Imported successfully
2023-10-13 23:10:21,997:INFO:Starting cross validation
2023-10-13 23:10:21,999:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:27,216:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:36,387:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:37,551:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:37,617:INFO:Calculating mean and std
2023-10-13 23:10:37,623:INFO:Creating metrics dataframe
2023-10-13 23:10:37,633:INFO:Uploading results into container
2023-10-13 23:10:37,633:INFO:Uploading model into container now
2023-10-13 23:10:37,634:INFO:_master_model_container: 6
2023-10-13 23:10:37,634:INFO:_display_container: 2
2023-10-13 23:10:37,636:INFO:AutoARIMA(random_state=123, sp=12, suppress_warnings=True)
2023-10-13 23:10:37,637:INFO:create_model() successfully completed......................................
2023-10-13 23:10:37,817:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:37,818:INFO:Creating metrics dataframe
2023-10-13 23:10:37,826:INFO:Initializing Exponential Smoothing
2023-10-13 23:10:37,826:INFO:Total runtime is 0.39872013727823896 minutes
2023-10-13 23:10:37,829:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:37,829:INFO:Initializing create_model()
2023-10-13 23:10:37,829:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=exp_smooth, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:37,829:INFO:Checking exceptions
2023-10-13 23:10:37,829:INFO:Importing libraries
2023-10-13 23:10:37,829:INFO:Copying training dataset
2023-10-13 23:10:37,833:INFO:Defining folds
2023-10-13 23:10:37,833:INFO:Declaring metric variables
2023-10-13 23:10:37,837:INFO:Importing untrained model
2023-10-13 23:10:37,843:INFO:Exponential Smoothing Imported successfully
2023-10-13 23:10:37,852:INFO:Starting cross validation
2023-10-13 23:10:37,852:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:38,041:INFO:Calculating mean and std
2023-10-13 23:10:38,042:INFO:Creating metrics dataframe
2023-10-13 23:10:38,046:INFO:Uploading results into container
2023-10-13 23:10:38,046:INFO:Uploading model into container now
2023-10-13 23:10:38,046:INFO:_master_model_container: 7
2023-10-13 23:10:38,046:INFO:_display_container: 2
2023-10-13 23:10:38,046:INFO:ExponentialSmoothing(seasonal='mul', sp=12, trend='add')
2023-10-13 23:10:38,046:INFO:create_model() successfully completed......................................
2023-10-13 23:10:38,168:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:38,168:INFO:Creating metrics dataframe
2023-10-13 23:10:38,179:INFO:Initializing ETS
2023-10-13 23:10:38,179:INFO:Total runtime is 0.4045996983846029 minutes
2023-10-13 23:10:38,181:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:38,181:INFO:Initializing create_model()
2023-10-13 23:10:38,181:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=ets, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:38,181:INFO:Checking exceptions
2023-10-13 23:10:38,182:INFO:Importing libraries
2023-10-13 23:10:38,182:INFO:Copying training dataset
2023-10-13 23:10:38,186:INFO:Defining folds
2023-10-13 23:10:38,186:INFO:Declaring metric variables
2023-10-13 23:10:38,190:INFO:Importing untrained model
2023-10-13 23:10:38,194:INFO:ETS Imported successfully
2023-10-13 23:10:38,203:INFO:Starting cross validation
2023-10-13 23:10:38,204:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:38,331:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:38,338:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:38,342:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:38,368:INFO:Calculating mean and std
2023-10-13 23:10:38,370:INFO:Creating metrics dataframe
2023-10-13 23:10:38,374:INFO:Uploading results into container
2023-10-13 23:10:38,374:INFO:Uploading model into container now
2023-10-13 23:10:38,375:INFO:_master_model_container: 8
2023-10-13 23:10:38,375:INFO:_display_container: 2
2023-10-13 23:10:38,375:INFO:AutoETS(seasonal='mul', sp=12, trend='add')
2023-10-13 23:10:38,375:INFO:create_model() successfully completed......................................
2023-10-13 23:10:38,499:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:38,499:INFO:Creating metrics dataframe
2023-10-13 23:10:38,512:INFO:Initializing Theta Forecaster
2023-10-13 23:10:38,513:INFO:Total runtime is 0.41014097134272265 minutes
2023-10-13 23:10:38,515:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:38,516:INFO:Initializing create_model()
2023-10-13 23:10:38,516:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=theta, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:38,516:INFO:Checking exceptions
2023-10-13 23:10:38,516:INFO:Importing libraries
2023-10-13 23:10:38,516:INFO:Copying training dataset
2023-10-13 23:10:38,520:INFO:Defining folds
2023-10-13 23:10:38,521:INFO:Declaring metric variables
2023-10-13 23:10:38,525:INFO:Importing untrained model
2023-10-13 23:10:38,532:INFO:Theta Forecaster Imported successfully
2023-10-13 23:10:38,542:INFO:Starting cross validation
2023-10-13 23:10:38,544:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:38,611:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:38,625:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:38,636:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:10:38,650:INFO:Calculating mean and std
2023-10-13 23:10:38,651:INFO:Creating metrics dataframe
2023-10-13 23:10:38,655:INFO:Uploading results into container
2023-10-13 23:10:38,655:INFO:Uploading model into container now
2023-10-13 23:10:38,656:INFO:_master_model_container: 9
2023-10-13 23:10:38,656:INFO:_display_container: 2
2023-10-13 23:10:38,656:INFO:ThetaForecaster(sp=12)
2023-10-13 23:10:38,656:INFO:create_model() successfully completed......................................
2023-10-13 23:10:38,793:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:38,793:INFO:Creating metrics dataframe
2023-10-13 23:10:38,802:INFO:Initializing STLF
2023-10-13 23:10:38,803:INFO:Total runtime is 0.414998471736908 minutes
2023-10-13 23:10:38,807:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:38,807:INFO:Initializing create_model()
2023-10-13 23:10:38,807:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=stlf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:38,807:INFO:Checking exceptions
2023-10-13 23:10:38,807:INFO:Importing libraries
2023-10-13 23:10:38,807:INFO:Copying training dataset
2023-10-13 23:10:38,812:INFO:Defining folds
2023-10-13 23:10:38,812:INFO:Declaring metric variables
2023-10-13 23:10:38,816:INFO:Importing untrained model
2023-10-13 23:10:38,822:INFO:STLF Imported successfully
2023-10-13 23:10:38,833:INFO:Starting cross validation
2023-10-13 23:10:38,834:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:38,932:INFO:Calculating mean and std
2023-10-13 23:10:38,933:INFO:Creating metrics dataframe
2023-10-13 23:10:38,938:INFO:Uploading results into container
2023-10-13 23:10:38,938:INFO:Uploading model into container now
2023-10-13 23:10:38,939:INFO:_master_model_container: 10
2023-10-13 23:10:38,939:INFO:_display_container: 2
2023-10-13 23:10:38,939:INFO:STLForecaster(sp=12)
2023-10-13 23:10:38,939:INFO:create_model() successfully completed......................................
2023-10-13 23:10:39,065:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:39,065:INFO:Creating metrics dataframe
2023-10-13 23:10:39,077:INFO:Initializing Croston
2023-10-13 23:10:39,077:INFO:Total runtime is 0.41956562598546354 minutes
2023-10-13 23:10:39,081:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:39,081:INFO:Initializing create_model()
2023-10-13 23:10:39,081:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=croston, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:39,081:INFO:Checking exceptions
2023-10-13 23:10:39,081:INFO:Importing libraries
2023-10-13 23:10:39,081:INFO:Copying training dataset
2023-10-13 23:10:39,085:INFO:Defining folds
2023-10-13 23:10:39,086:INFO:Declaring metric variables
2023-10-13 23:10:39,091:INFO:Importing untrained model
2023-10-13 23:10:39,094:INFO:Croston Imported successfully
2023-10-13 23:10:39,105:INFO:Starting cross validation
2023-10-13 23:10:39,106:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:39,142:INFO:Calculating mean and std
2023-10-13 23:10:39,142:INFO:Creating metrics dataframe
2023-10-13 23:10:39,146:INFO:Uploading results into container
2023-10-13 23:10:39,146:INFO:Uploading model into container now
2023-10-13 23:10:39,146:INFO:_master_model_container: 11
2023-10-13 23:10:39,146:INFO:_display_container: 2
2023-10-13 23:10:39,146:INFO:Croston()
2023-10-13 23:10:39,146:INFO:create_model() successfully completed......................................
2023-10-13 23:10:39,275:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:39,275:INFO:Creating metrics dataframe
2023-10-13 23:10:39,287:INFO:Initializing Linear w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:39,287:INFO:Total runtime is 0.4230605800946554 minutes
2023-10-13 23:10:39,290:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:39,291:INFO:Initializing create_model()
2023-10-13 23:10:39,291:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=lr_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:39,291:INFO:Checking exceptions
2023-10-13 23:10:39,291:INFO:Importing libraries
2023-10-13 23:10:39,291:INFO:Copying training dataset
2023-10-13 23:10:39,295:INFO:Defining folds
2023-10-13 23:10:39,296:INFO:Declaring metric variables
2023-10-13 23:10:39,299:INFO:Importing untrained model
2023-10-13 23:10:39,305:INFO:Linear w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:39,313:INFO:Starting cross validation
2023-10-13 23:10:39,314:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:39,585:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:39,585:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:39,585:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:39,743:INFO:Calculating mean and std
2023-10-13 23:10:39,744:INFO:Creating metrics dataframe
2023-10-13 23:10:39,748:INFO:Uploading results into container
2023-10-13 23:10:39,748:INFO:Uploading model into container now
2023-10-13 23:10:39,748:INFO:_master_model_container: 12
2023-10-13 23:10:39,748:INFO:_display_container: 2
2023-10-13 23:10:39,754:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=LinearRegression(n_jobs=-1), sp=12,
                    window_length=12)
2023-10-13 23:10:39,754:INFO:create_model() successfully completed......................................
2023-10-13 23:10:39,894:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:39,894:INFO:Creating metrics dataframe
2023-10-13 23:10:39,906:INFO:Initializing Elastic Net w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:39,906:INFO:Total runtime is 0.43337651093800866 minutes
2023-10-13 23:10:39,908:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:39,909:INFO:Initializing create_model()
2023-10-13 23:10:39,909:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=en_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:39,909:INFO:Checking exceptions
2023-10-13 23:10:39,909:INFO:Importing libraries
2023-10-13 23:10:39,909:INFO:Copying training dataset
2023-10-13 23:10:39,914:INFO:Defining folds
2023-10-13 23:10:39,914:INFO:Declaring metric variables
2023-10-13 23:10:39,917:INFO:Importing untrained model
2023-10-13 23:10:39,923:INFO:Elastic Net w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:39,932:INFO:Starting cross validation
2023-10-13 23:10:39,933:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:40,119:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:40,127:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:40,131:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:40,297:INFO:Calculating mean and std
2023-10-13 23:10:40,298:INFO:Creating metrics dataframe
2023-10-13 23:10:40,302:INFO:Uploading results into container
2023-10-13 23:10:40,303:INFO:Uploading model into container now
2023-10-13 23:10:40,303:INFO:_master_model_container: 13
2023-10-13 23:10:40,303:INFO:_display_container: 2
2023-10-13 23:10:40,305:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=ElasticNet(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:10:40,305:INFO:create_model() successfully completed......................................
2023-10-13 23:10:40,431:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:40,431:INFO:Creating metrics dataframe
2023-10-13 23:10:40,445:INFO:Initializing Ridge w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:40,445:INFO:Total runtime is 0.4423715710639954 minutes
2023-10-13 23:10:40,449:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:40,449:INFO:Initializing create_model()
2023-10-13 23:10:40,449:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=ridge_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:40,449:INFO:Checking exceptions
2023-10-13 23:10:40,449:INFO:Importing libraries
2023-10-13 23:10:40,450:INFO:Copying training dataset
2023-10-13 23:10:40,455:INFO:Defining folds
2023-10-13 23:10:40,456:INFO:Declaring metric variables
2023-10-13 23:10:40,459:INFO:Importing untrained model
2023-10-13 23:10:40,464:INFO:Ridge w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:40,475:INFO:Starting cross validation
2023-10-13 23:10:40,476:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:40,669:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:40,678:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-13 23:10:40,818:INFO:Calculating mean and std
2023-10-13 23:10:40,820:INFO:Creating metrics dataframe
2023-10-13 23:10:40,824:INFO:Uploading results into container
2023-10-13 23:10:40,824:INFO:Uploading model into container now
2023-10-13 23:10:40,825:INFO:_master_model_container: 14
2023-10-13 23:10:40,825:INFO:_display_container: 2
2023-10-13 23:10:40,826:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=Ridge(random_state=123), sp=12, window_length=12)
2023-10-13 23:10:40,826:INFO:create_model() successfully completed......................................
2023-10-13 23:10:40,954:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:40,954:INFO:Creating metrics dataframe
2023-10-13 23:10:40,965:INFO:Initializing Lasso w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:40,965:INFO:Total runtime is 0.4510316133499146 minutes
2023-10-13 23:10:40,969:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:40,970:INFO:Initializing create_model()
2023-10-13 23:10:40,970:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=lasso_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:40,970:INFO:Checking exceptions
2023-10-13 23:10:40,970:INFO:Importing libraries
2023-10-13 23:10:40,970:INFO:Copying training dataset
2023-10-13 23:10:40,974:INFO:Defining folds
2023-10-13 23:10:40,974:INFO:Declaring metric variables
2023-10-13 23:10:40,977:INFO:Importing untrained model
2023-10-13 23:10:40,982:INFO:Lasso w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:40,992:INFO:Starting cross validation
2023-10-13 23:10:40,993:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:41,183:INFO:Calculating mean and std
2023-10-13 23:10:41,185:INFO:Creating metrics dataframe
2023-10-13 23:10:41,190:INFO:Uploading results into container
2023-10-13 23:10:41,190:INFO:Uploading model into container now
2023-10-13 23:10:41,190:INFO:_master_model_container: 15
2023-10-13 23:10:41,190:INFO:_display_container: 2
2023-10-13 23:10:41,192:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=Lasso(random_state=123), sp=12, window_length=12)
2023-10-13 23:10:41,192:INFO:create_model() successfully completed......................................
2023-10-13 23:10:41,322:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:41,322:INFO:Creating metrics dataframe
2023-10-13 23:10:41,335:INFO:Initializing Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:41,336:INFO:Total runtime is 0.4572200655937195 minutes
2023-10-13 23:10:41,339:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:41,339:INFO:Initializing create_model()
2023-10-13 23:10:41,339:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=llar_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:41,339:INFO:Checking exceptions
2023-10-13 23:10:41,339:INFO:Importing libraries
2023-10-13 23:10:41,339:INFO:Copying training dataset
2023-10-13 23:10:41,343:INFO:Defining folds
2023-10-13 23:10:41,344:INFO:Declaring metric variables
2023-10-13 23:10:41,347:INFO:Importing untrained model
2023-10-13 23:10:41,351:INFO:Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:41,359:INFO:Starting cross validation
2023-10-13 23:10:41,360:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:41,479:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-13 23:10:41,479:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-13 23:10:41,479:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-13 23:10:41,573:INFO:Calculating mean and std
2023-10-13 23:10:41,575:INFO:Creating metrics dataframe
2023-10-13 23:10:41,580:INFO:Uploading results into container
2023-10-13 23:10:41,580:INFO:Uploading model into container now
2023-10-13 23:10:41,580:INFO:_master_model_container: 16
2023-10-13 23:10:41,581:INFO:_display_container: 2
2023-10-13 23:10:41,583:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=LassoLars(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:10:41,584:INFO:create_model() successfully completed......................................
2023-10-13 23:10:41,714:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:41,714:INFO:Creating metrics dataframe
2023-10-13 23:10:41,729:INFO:Initializing Bayesian Ridge w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:41,729:INFO:Total runtime is 0.4637646476427714 minutes
2023-10-13 23:10:41,733:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:41,733:INFO:Initializing create_model()
2023-10-13 23:10:41,733:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=br_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:41,733:INFO:Checking exceptions
2023-10-13 23:10:41,733:INFO:Importing libraries
2023-10-13 23:10:41,733:INFO:Copying training dataset
2023-10-13 23:10:41,738:INFO:Defining folds
2023-10-13 23:10:41,738:INFO:Declaring metric variables
2023-10-13 23:10:41,742:INFO:Importing untrained model
2023-10-13 23:10:41,746:INFO:Bayesian Ridge w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:41,759:INFO:Starting cross validation
2023-10-13 23:10:41,761:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:41,963:INFO:Calculating mean and std
2023-10-13 23:10:41,964:INFO:Creating metrics dataframe
2023-10-13 23:10:41,969:INFO:Uploading results into container
2023-10-13 23:10:41,969:INFO:Uploading model into container now
2023-10-13 23:10:41,970:INFO:_master_model_container: 17
2023-10-13 23:10:41,970:INFO:_display_container: 2
2023-10-13 23:10:41,972:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=BayesianRidge(), sp=12, window_length=12)
2023-10-13 23:10:41,972:INFO:create_model() successfully completed......................................
2023-10-13 23:10:42,104:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:42,104:INFO:Creating metrics dataframe
2023-10-13 23:10:42,117:INFO:Initializing Huber w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:42,117:INFO:Total runtime is 0.4702333490053813 minutes
2023-10-13 23:10:42,121:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:42,121:INFO:Initializing create_model()
2023-10-13 23:10:42,121:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=huber_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:42,121:INFO:Checking exceptions
2023-10-13 23:10:42,121:INFO:Importing libraries
2023-10-13 23:10:42,121:INFO:Copying training dataset
2023-10-13 23:10:42,126:INFO:Defining folds
2023-10-13 23:10:42,126:INFO:Declaring metric variables
2023-10-13 23:10:42,131:INFO:Importing untrained model
2023-10-13 23:10:42,137:INFO:Huber w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:42,145:INFO:Starting cross validation
2023-10-13 23:10:42,147:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:42,342:INFO:Calculating mean and std
2023-10-13 23:10:42,344:INFO:Creating metrics dataframe
2023-10-13 23:10:42,348:INFO:Uploading results into container
2023-10-13 23:10:42,348:INFO:Uploading model into container now
2023-10-13 23:10:42,348:INFO:_master_model_container: 18
2023-10-13 23:10:42,348:INFO:_display_container: 2
2023-10-13 23:10:42,350:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=HuberRegressor(), sp=12, window_length=12)
2023-10-13 23:10:42,350:INFO:create_model() successfully completed......................................
2023-10-13 23:10:42,476:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:42,476:INFO:Creating metrics dataframe
2023-10-13 23:10:42,476:INFO:Initializing Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:42,476:INFO:Total runtime is 0.47620982726415 minutes
2023-10-13 23:10:42,491:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:42,491:INFO:Initializing create_model()
2023-10-13 23:10:42,491:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=omp_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:42,491:INFO:Checking exceptions
2023-10-13 23:10:42,491:INFO:Importing libraries
2023-10-13 23:10:42,491:INFO:Copying training dataset
2023-10-13 23:10:42,491:INFO:Defining folds
2023-10-13 23:10:42,491:INFO:Declaring metric variables
2023-10-13 23:10:42,491:INFO:Importing untrained model
2023-10-13 23:10:42,491:INFO:Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:42,529:INFO:Starting cross validation
2023-10-13 23:10:42,535:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:42,613:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-13 23:10:42,622:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-13 23:10:42,622:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-13 23:10:42,707:INFO:Calculating mean and std
2023-10-13 23:10:42,707:INFO:Creating metrics dataframe
2023-10-13 23:10:42,707:INFO:Uploading results into container
2023-10-13 23:10:42,707:INFO:Uploading model into container now
2023-10-13 23:10:42,722:INFO:_master_model_container: 19
2023-10-13 23:10:42,722:INFO:_display_container: 2
2023-10-13 23:10:42,723:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=OrthogonalMatchingPursuit(), sp=12,
                    window_length=12)
2023-10-13 23:10:42,723:INFO:create_model() successfully completed......................................
2023-10-13 23:10:42,849:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:42,849:INFO:Creating metrics dataframe
2023-10-13 23:10:42,849:INFO:Initializing K Neighbors w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:42,849:INFO:Total runtime is 0.4824302395184835 minutes
2023-10-13 23:10:42,864:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:42,864:INFO:Initializing create_model()
2023-10-13 23:10:42,864:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=knn_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:42,864:INFO:Checking exceptions
2023-10-13 23:10:42,864:INFO:Importing libraries
2023-10-13 23:10:42,864:INFO:Copying training dataset
2023-10-13 23:10:42,864:INFO:Defining folds
2023-10-13 23:10:42,864:INFO:Declaring metric variables
2023-10-13 23:10:42,864:INFO:Importing untrained model
2023-10-13 23:10:42,880:INFO:K Neighbors w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:42,880:INFO:Starting cross validation
2023-10-13 23:10:42,880:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:43,099:INFO:Calculating mean and std
2023-10-13 23:10:43,099:INFO:Creating metrics dataframe
2023-10-13 23:10:43,099:INFO:Uploading results into container
2023-10-13 23:10:43,099:INFO:Uploading model into container now
2023-10-13 23:10:43,099:INFO:_master_model_container: 20
2023-10-13 23:10:43,099:INFO:_display_container: 2
2023-10-13 23:10:43,099:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=KNeighborsRegressor(n_jobs=-1), sp=12,
                    window_length=12)
2023-10-13 23:10:43,099:INFO:create_model() successfully completed......................................
2023-10-13 23:10:43,226:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:43,226:INFO:Creating metrics dataframe
2023-10-13 23:10:43,241:INFO:Initializing Decision Tree w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:43,241:INFO:Total runtime is 0.4889722267786662 minutes
2023-10-13 23:10:43,241:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:43,241:INFO:Initializing create_model()
2023-10-13 23:10:43,241:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=dt_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:43,241:INFO:Checking exceptions
2023-10-13 23:10:43,241:INFO:Importing libraries
2023-10-13 23:10:43,241:INFO:Copying training dataset
2023-10-13 23:10:43,257:INFO:Defining folds
2023-10-13 23:10:43,257:INFO:Declaring metric variables
2023-10-13 23:10:43,257:INFO:Importing untrained model
2023-10-13 23:10:43,257:INFO:Decision Tree w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:43,273:INFO:Starting cross validation
2023-10-13 23:10:43,273:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:43,462:INFO:Calculating mean and std
2023-10-13 23:10:43,462:INFO:Creating metrics dataframe
2023-10-13 23:10:43,462:INFO:Uploading results into container
2023-10-13 23:10:43,462:INFO:Uploading model into container now
2023-10-13 23:10:43,462:INFO:_master_model_container: 21
2023-10-13 23:10:43,462:INFO:_display_container: 2
2023-10-13 23:10:43,477:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=DecisionTreeRegressor(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:10:43,477:INFO:create_model() successfully completed......................................
2023-10-13 23:10:43,608:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:43,608:INFO:Creating metrics dataframe
2023-10-13 23:10:43,622:INFO:Initializing Random Forest w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:43,622:INFO:Total runtime is 0.4953151305516561 minutes
2023-10-13 23:10:43,622:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:43,622:INFO:Initializing create_model()
2023-10-13 23:10:43,622:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=rf_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:43,622:INFO:Checking exceptions
2023-10-13 23:10:43,622:INFO:Importing libraries
2023-10-13 23:10:43,622:INFO:Copying training dataset
2023-10-13 23:10:43,637:INFO:Defining folds
2023-10-13 23:10:43,637:INFO:Declaring metric variables
2023-10-13 23:10:43,640:INFO:Importing untrained model
2023-10-13 23:10:43,645:INFO:Random Forest w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:43,653:INFO:Starting cross validation
2023-10-13 23:10:43,654:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:44,012:INFO:Calculating mean and std
2023-10-13 23:10:44,012:INFO:Creating metrics dataframe
2023-10-13 23:10:44,012:INFO:Uploading results into container
2023-10-13 23:10:44,022:INFO:Uploading model into container now
2023-10-13 23:10:44,022:INFO:_master_model_container: 22
2023-10-13 23:10:44,022:INFO:_display_container: 2
2023-10-13 23:10:44,022:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=RandomForestRegressor(n_jobs=-1, random_state=123),
                    sp=12, window_length=12)
2023-10-13 23:10:44,022:INFO:create_model() successfully completed......................................
2023-10-13 23:10:44,147:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:44,147:INFO:Creating metrics dataframe
2023-10-13 23:10:44,147:INFO:Initializing Extra Trees w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:44,147:INFO:Total runtime is 0.5040698965390523 minutes
2023-10-13 23:10:44,165:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:44,166:INFO:Initializing create_model()
2023-10-13 23:10:44,166:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=et_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:44,166:INFO:Checking exceptions
2023-10-13 23:10:44,166:INFO:Importing libraries
2023-10-13 23:10:44,166:INFO:Copying training dataset
2023-10-13 23:10:44,173:INFO:Defining folds
2023-10-13 23:10:44,173:INFO:Declaring metric variables
2023-10-13 23:10:44,178:INFO:Importing untrained model
2023-10-13 23:10:44,183:INFO:Extra Trees w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:44,183:INFO:Starting cross validation
2023-10-13 23:10:44,183:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:44,548:INFO:Calculating mean and std
2023-10-13 23:10:44,548:INFO:Creating metrics dataframe
2023-10-13 23:10:44,548:INFO:Uploading results into container
2023-10-13 23:10:44,548:INFO:Uploading model into container now
2023-10-13 23:10:44,548:INFO:_master_model_container: 23
2023-10-13 23:10:44,548:INFO:_display_container: 2
2023-10-13 23:10:44,548:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=ExtraTreesRegressor(n_jobs=-1, random_state=123),
                    sp=12, window_length=12)
2023-10-13 23:10:44,548:INFO:create_model() successfully completed......................................
2023-10-13 23:10:44,674:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:44,674:INFO:Creating metrics dataframe
2023-10-13 23:10:44,689:INFO:Initializing Gradient Boosting w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:44,689:INFO:Total runtime is 0.5131058931350708 minutes
2023-10-13 23:10:44,689:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:44,689:INFO:Initializing create_model()
2023-10-13 23:10:44,689:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=gbr_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:44,689:INFO:Checking exceptions
2023-10-13 23:10:44,689:INFO:Importing libraries
2023-10-13 23:10:44,689:INFO:Copying training dataset
2023-10-13 23:10:44,705:INFO:Defining folds
2023-10-13 23:10:44,705:INFO:Declaring metric variables
2023-10-13 23:10:44,705:INFO:Importing untrained model
2023-10-13 23:10:44,705:INFO:Gradient Boosting w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:44,724:INFO:Starting cross validation
2023-10-13 23:10:44,724:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:44,957:INFO:Calculating mean and std
2023-10-13 23:10:44,957:INFO:Creating metrics dataframe
2023-10-13 23:10:44,973:INFO:Uploading results into container
2023-10-13 23:10:44,973:INFO:Uploading model into container now
2023-10-13 23:10:44,973:INFO:_master_model_container: 24
2023-10-13 23:10:44,973:INFO:_display_container: 2
2023-10-13 23:10:44,973:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=GradientBoostingRegressor(random_state=123),
                    sp=12, window_length=12)
2023-10-13 23:10:44,973:INFO:create_model() successfully completed......................................
2023-10-13 23:10:45,098:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:45,098:INFO:Creating metrics dataframe
2023-10-13 23:10:45,114:INFO:Initializing AdaBoost w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:45,114:INFO:Total runtime is 0.5201782941818237 minutes
2023-10-13 23:10:45,114:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:45,114:INFO:Initializing create_model()
2023-10-13 23:10:45,114:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=ada_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:45,114:INFO:Checking exceptions
2023-10-13 23:10:45,114:INFO:Importing libraries
2023-10-13 23:10:45,114:INFO:Copying training dataset
2023-10-13 23:10:45,125:INFO:Defining folds
2023-10-13 23:10:45,125:INFO:Declaring metric variables
2023-10-13 23:10:45,130:INFO:Importing untrained model
2023-10-13 23:10:45,130:INFO:AdaBoost w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:45,145:INFO:Starting cross validation
2023-10-13 23:10:45,145:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:45,412:INFO:Calculating mean and std
2023-10-13 23:10:45,412:INFO:Creating metrics dataframe
2023-10-13 23:10:45,425:INFO:Uploading results into container
2023-10-13 23:10:45,425:INFO:Uploading model into container now
2023-10-13 23:10:45,425:INFO:_master_model_container: 25
2023-10-13 23:10:45,425:INFO:_display_container: 2
2023-10-13 23:10:45,428:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=AdaBoostRegressor(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:10:45,428:INFO:create_model() successfully completed......................................
2023-10-13 23:10:45,558:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:45,558:INFO:Creating metrics dataframe
2023-10-13 23:10:45,566:INFO:Initializing Extreme Gradient Boosting w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:45,566:INFO:Total runtime is 0.5277126391728719 minutes
2023-10-13 23:10:45,566:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:45,566:INFO:Initializing create_model()
2023-10-13 23:10:45,566:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=xgboost_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:45,566:INFO:Checking exceptions
2023-10-13 23:10:45,566:INFO:Importing libraries
2023-10-13 23:10:45,566:INFO:Copying training dataset
2023-10-13 23:10:45,566:INFO:Defining folds
2023-10-13 23:10:45,566:INFO:Declaring metric variables
2023-10-13 23:10:45,582:INFO:Importing untrained model
2023-10-13 23:10:45,582:INFO:Extreme Gradient Boosting w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:45,597:INFO:Starting cross validation
2023-10-13 23:10:45,597:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:45,926:INFO:Calculating mean and std
2023-10-13 23:10:45,926:INFO:Creating metrics dataframe
2023-10-13 23:10:45,932:INFO:Uploading results into container
2023-10-13 23:10:45,932:INFO:Uploading model into container now
2023-10-13 23:10:45,933:INFO:_master_model_container: 26
2023-10-13 23:10:45,933:INFO:_display_container: 2
2023-10-13 23:10:45,939:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             g...tance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...),
                    sp=12, window_length=12)
2023-10-13 23:10:45,939:INFO:create_model() successfully completed......................................
2023-10-13 23:10:46,067:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:46,067:INFO:Creating metrics dataframe
2023-10-13 23:10:46,083:INFO:Initializing Light Gradient Boosting w/ Cond. Deseasonalize & Detrending
2023-10-13 23:10:46,083:INFO:Total runtime is 0.5363229831059774 minutes
2023-10-13 23:10:46,083:INFO:SubProcess create_model() called ==================================
2023-10-13 23:10:46,083:INFO:Initializing create_model()
2023-10-13 23:10:46,083:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=lightgbm_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002155829D870>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:46,083:INFO:Checking exceptions
2023-10-13 23:10:46,083:INFO:Importing libraries
2023-10-13 23:10:46,083:INFO:Copying training dataset
2023-10-13 23:10:46,083:INFO:Defining folds
2023-10-13 23:10:46,083:INFO:Declaring metric variables
2023-10-13 23:10:46,098:INFO:Importing untrained model
2023-10-13 23:10:46,098:INFO:Light Gradient Boosting w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:10:46,098:INFO:Starting cross validation
2023-10-13 23:10:46,114:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:10:46,334:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,334:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,334:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,396:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,396:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:10:46,412:INFO:Calculating mean and std
2023-10-13 23:10:46,412:INFO:Creating metrics dataframe
2023-10-13 23:10:46,428:INFO:Uploading results into container
2023-10-13 23:10:46,428:INFO:Uploading model into container now
2023-10-13 23:10:46,428:INFO:_master_model_container: 27
2023-10-13 23:10:46,428:INFO:_display_container: 2
2023-10-13 23:10:46,428:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=LGBMRegressor(n_jobs=-1, random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:10:46,428:INFO:create_model() successfully completed......................................
2023-10-13 23:10:46,593:INFO:SubProcess create_model() end ==================================
2023-10-13 23:10:46,593:INFO:Creating metrics dataframe
2023-10-13 23:10:46,616:INFO:Initializing create_model()
2023-10-13 23:10:46,616:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x0000021558688670>, estimator=STLForecaster(sp=12), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:10:46,616:INFO:Checking exceptions
2023-10-13 23:10:46,616:INFO:Importing libraries
2023-10-13 23:10:46,616:INFO:Copying training dataset
2023-10-13 23:10:46,616:INFO:Defining folds
2023-10-13 23:10:46,627:INFO:Declaring metric variables
2023-10-13 23:10:46,627:INFO:Importing untrained model
2023-10-13 23:10:46,627:INFO:Declaring custom model
2023-10-13 23:10:46,627:INFO:STLF Imported successfully
2023-10-13 23:10:46,627:INFO:Cross validation set to False
2023-10-13 23:10:46,627:INFO:Fitting Model
2023-10-13 23:10:46,648:INFO:STLForecaster(sp=12)
2023-10-13 23:10:46,648:INFO:create_model() successfully completed......................................
2023-10-13 23:10:46,840:INFO:_master_model_container: 27
2023-10-13 23:10:46,840:INFO:_display_container: 2
2023-10-13 23:10:46,840:INFO:STLForecaster(sp=12)
2023-10-13 23:10:46,840:INFO:compare_models() successfully completed......................................
2023-10-13 23:12:22,279:INFO:Initializing compare_models()
2023-10-13 23:12:22,279:INFO:compare_models(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, include=None, fold=None, round=4, cross_validation=True, sort=MASE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MASE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.time_series.forecasting.oop.TSForecastingExperiment'>}, exclude=None)
2023-10-13 23:12:22,279:INFO:Checking exceptions
2023-10-13 23:12:22,279:INFO:Preparing display monitor
2023-10-13 23:12:22,326:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:713: UserWarning: Unsupported estimator `ensemble_forecaster` for method `compare_models()`, removing from model_library
  warnings.warn(

2023-10-13 23:12:22,326:INFO:Initializing Naive Forecaster
2023-10-13 23:12:22,326:INFO:Total runtime is 0.0 minutes
2023-10-13 23:12:22,326:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:22,341:INFO:Initializing create_model()
2023-10-13 23:12:22,341:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=naive, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:22,341:INFO:Checking exceptions
2023-10-13 23:12:22,341:INFO:Importing libraries
2023-10-13 23:12:22,341:INFO:Copying training dataset
2023-10-13 23:12:22,341:INFO:Defining folds
2023-10-13 23:12:22,341:INFO:Declaring metric variables
2023-10-13 23:12:22,341:INFO:Importing untrained model
2023-10-13 23:12:22,341:INFO:Naive Forecaster Imported successfully
2023-10-13 23:12:22,357:INFO:Starting cross validation
2023-10-13 23:12:22,357:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:22,404:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,404:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,415:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,436:INFO:Calculating mean and std
2023-10-13 23:12:22,436:INFO:Creating metrics dataframe
2023-10-13 23:12:22,451:INFO:Uploading results into container
2023-10-13 23:12:22,451:INFO:Uploading model into container now
2023-10-13 23:12:22,451:INFO:_master_model_container: 1
2023-10-13 23:12:22,451:INFO:_display_container: 2
2023-10-13 23:12:22,451:INFO:NaiveForecaster()
2023-10-13 23:12:22,451:INFO:create_model() successfully completed......................................
2023-10-13 23:12:22,592:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:22,592:INFO:Creating metrics dataframe
2023-10-13 23:12:22,592:INFO:Initializing Grand Means Forecaster
2023-10-13 23:12:22,592:INFO:Total runtime is 0.004442195097605388 minutes
2023-10-13 23:12:22,592:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:22,592:INFO:Initializing create_model()
2023-10-13 23:12:22,592:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=grand_means, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:22,592:INFO:Checking exceptions
2023-10-13 23:12:22,592:INFO:Importing libraries
2023-10-13 23:12:22,592:INFO:Copying training dataset
2023-10-13 23:12:22,608:INFO:Defining folds
2023-10-13 23:12:22,608:INFO:Declaring metric variables
2023-10-13 23:12:22,608:INFO:Importing untrained model
2023-10-13 23:12:22,616:INFO:Grand Means Forecaster Imported successfully
2023-10-13 23:12:22,624:INFO:Starting cross validation
2023-10-13 23:12:22,624:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:22,640:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,640:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,640:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,655:INFO:Calculating mean and std
2023-10-13 23:12:22,655:INFO:Creating metrics dataframe
2023-10-13 23:12:22,655:INFO:Uploading results into container
2023-10-13 23:12:22,655:INFO:Uploading model into container now
2023-10-13 23:12:22,655:INFO:_master_model_container: 2
2023-10-13 23:12:22,655:INFO:_display_container: 2
2023-10-13 23:12:22,655:INFO:NaiveForecaster(strategy='mean')
2023-10-13 23:12:22,655:INFO:create_model() successfully completed......................................
2023-10-13 23:12:22,828:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:22,828:INFO:Creating metrics dataframe
2023-10-13 23:12:22,828:INFO:Initializing Seasonal Naive Forecaster
2023-10-13 23:12:22,828:INFO:Total runtime is 0.008372461795806885 minutes
2023-10-13 23:12:22,844:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:22,844:INFO:Initializing create_model()
2023-10-13 23:12:22,844:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=snaive, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:22,844:INFO:Checking exceptions
2023-10-13 23:12:22,844:INFO:Importing libraries
2023-10-13 23:12:22,844:INFO:Copying training dataset
2023-10-13 23:12:22,844:INFO:Defining folds
2023-10-13 23:12:22,844:INFO:Declaring metric variables
2023-10-13 23:12:22,844:INFO:Importing untrained model
2023-10-13 23:12:22,844:INFO:Seasonal Naive Forecaster Imported successfully
2023-10-13 23:12:22,859:INFO:Starting cross validation
2023-10-13 23:12:22,859:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:22,916:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,923:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,923:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:22,954:INFO:Calculating mean and std
2023-10-13 23:12:22,954:INFO:Creating metrics dataframe
2023-10-13 23:12:22,954:INFO:Uploading results into container
2023-10-13 23:12:22,954:INFO:Uploading model into container now
2023-10-13 23:12:22,954:INFO:_master_model_container: 3
2023-10-13 23:12:22,954:INFO:_display_container: 2
2023-10-13 23:12:22,954:INFO:NaiveForecaster(sp=12)
2023-10-13 23:12:22,954:INFO:create_model() successfully completed......................................
2023-10-13 23:12:23,079:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:23,079:INFO:Creating metrics dataframe
2023-10-13 23:12:23,094:INFO:Initializing Polynomial Trend Forecaster
2023-10-13 23:12:23,094:INFO:Total runtime is 0.012809793154398601 minutes
2023-10-13 23:12:23,094:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:23,094:INFO:Initializing create_model()
2023-10-13 23:12:23,094:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=polytrend, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:23,094:INFO:Checking exceptions
2023-10-13 23:12:23,094:INFO:Importing libraries
2023-10-13 23:12:23,094:INFO:Copying training dataset
2023-10-13 23:12:23,110:INFO:Defining folds
2023-10-13 23:12:23,110:INFO:Declaring metric variables
2023-10-13 23:12:23,110:INFO:Importing untrained model
2023-10-13 23:12:23,117:INFO:Polynomial Trend Forecaster Imported successfully
2023-10-13 23:12:23,117:INFO:Starting cross validation
2023-10-13 23:12:23,126:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:23,157:INFO:Calculating mean and std
2023-10-13 23:12:23,157:INFO:Creating metrics dataframe
2023-10-13 23:12:23,157:INFO:Uploading results into container
2023-10-13 23:12:23,157:INFO:Uploading model into container now
2023-10-13 23:12:23,157:INFO:_master_model_container: 4
2023-10-13 23:12:23,157:INFO:_display_container: 2
2023-10-13 23:12:23,157:INFO:PolynomialTrendForecaster()
2023-10-13 23:12:23,157:INFO:create_model() successfully completed......................................
2023-10-13 23:12:23,298:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:23,298:INFO:Creating metrics dataframe
2023-10-13 23:12:23,317:INFO:Initializing ARIMA
2023-10-13 23:12:23,317:INFO:Total runtime is 0.01651972532272339 minutes
2023-10-13 23:12:23,317:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:23,317:INFO:Initializing create_model()
2023-10-13 23:12:23,317:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=arima, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:23,317:INFO:Checking exceptions
2023-10-13 23:12:23,317:INFO:Importing libraries
2023-10-13 23:12:23,317:INFO:Copying training dataset
2023-10-13 23:12:23,317:INFO:Defining folds
2023-10-13 23:12:23,317:INFO:Declaring metric variables
2023-10-13 23:12:23,330:INFO:Importing untrained model
2023-10-13 23:12:23,330:INFO:ARIMA Imported successfully
2023-10-13 23:12:23,346:INFO:Starting cross validation
2023-10-13 23:12:23,346:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:23,440:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:23,440:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:23,440:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:23,487:INFO:Calculating mean and std
2023-10-13 23:12:23,487:INFO:Creating metrics dataframe
2023-10-13 23:12:23,487:INFO:Uploading results into container
2023-10-13 23:12:23,487:INFO:Uploading model into container now
2023-10-13 23:12:23,487:INFO:_master_model_container: 5
2023-10-13 23:12:23,487:INFO:_display_container: 2
2023-10-13 23:12:23,487:INFO:ARIMA(seasonal_order=(0, 1, 0, 12))
2023-10-13 23:12:23,502:INFO:create_model() successfully completed......................................
2023-10-13 23:12:23,629:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:23,629:INFO:Creating metrics dataframe
2023-10-13 23:12:23,644:INFO:Initializing Auto ARIMA
2023-10-13 23:12:23,644:INFO:Total runtime is 0.02197054624557495 minutes
2023-10-13 23:12:23,644:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:23,644:INFO:Initializing create_model()
2023-10-13 23:12:23,644:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=auto_arima, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:23,644:INFO:Checking exceptions
2023-10-13 23:12:23,644:INFO:Importing libraries
2023-10-13 23:12:23,644:INFO:Copying training dataset
2023-10-13 23:12:23,644:INFO:Defining folds
2023-10-13 23:12:23,644:INFO:Declaring metric variables
2023-10-13 23:12:23,660:INFO:Importing untrained model
2023-10-13 23:12:23,660:INFO:Auto ARIMA Imported successfully
2023-10-13 23:12:23,675:INFO:Starting cross validation
2023-10-13 23:12:23,675:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:28,897:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:37,011:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:37,914:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:37,945:INFO:Calculating mean and std
2023-10-13 23:12:37,947:INFO:Creating metrics dataframe
2023-10-13 23:12:37,952:INFO:Uploading results into container
2023-10-13 23:12:37,952:INFO:Uploading model into container now
2023-10-13 23:12:37,953:INFO:_master_model_container: 6
2023-10-13 23:12:37,953:INFO:_display_container: 2
2023-10-13 23:12:37,953:INFO:AutoARIMA(random_state=123, sp=12, suppress_warnings=True)
2023-10-13 23:12:37,954:INFO:create_model() successfully completed......................................
2023-10-13 23:12:38,095:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:38,095:INFO:Creating metrics dataframe
2023-10-13 23:12:38,103:INFO:Initializing Exponential Smoothing
2023-10-13 23:12:38,104:INFO:Total runtime is 0.26297545035680137 minutes
2023-10-13 23:12:38,107:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:38,107:INFO:Initializing create_model()
2023-10-13 23:12:38,107:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=exp_smooth, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:38,107:INFO:Checking exceptions
2023-10-13 23:12:38,107:INFO:Importing libraries
2023-10-13 23:12:38,107:INFO:Copying training dataset
2023-10-13 23:12:38,111:INFO:Defining folds
2023-10-13 23:12:38,111:INFO:Declaring metric variables
2023-10-13 23:12:38,116:INFO:Importing untrained model
2023-10-13 23:12:38,120:INFO:Exponential Smoothing Imported successfully
2023-10-13 23:12:38,129:INFO:Starting cross validation
2023-10-13 23:12:38,131:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:38,294:INFO:Calculating mean and std
2023-10-13 23:12:38,295:INFO:Creating metrics dataframe
2023-10-13 23:12:38,299:INFO:Uploading results into container
2023-10-13 23:12:38,299:INFO:Uploading model into container now
2023-10-13 23:12:38,300:INFO:_master_model_container: 7
2023-10-13 23:12:38,300:INFO:_display_container: 2
2023-10-13 23:12:38,300:INFO:ExponentialSmoothing(seasonal='mul', sp=12, trend='add')
2023-10-13 23:12:38,300:INFO:create_model() successfully completed......................................
2023-10-13 23:12:38,422:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:38,422:INFO:Creating metrics dataframe
2023-10-13 23:12:38,433:INFO:Initializing ETS
2023-10-13 23:12:38,433:INFO:Total runtime is 0.26845362186431887 minutes
2023-10-13 23:12:38,437:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:38,437:INFO:Initializing create_model()
2023-10-13 23:12:38,438:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=ets, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:38,438:INFO:Checking exceptions
2023-10-13 23:12:38,438:INFO:Importing libraries
2023-10-13 23:12:38,438:INFO:Copying training dataset
2023-10-13 23:12:38,441:INFO:Defining folds
2023-10-13 23:12:38,441:INFO:Declaring metric variables
2023-10-13 23:12:38,444:INFO:Importing untrained model
2023-10-13 23:12:38,451:INFO:ETS Imported successfully
2023-10-13 23:12:38,460:INFO:Starting cross validation
2023-10-13 23:12:38,460:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:38,600:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:38,601:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:38,608:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:38,635:INFO:Calculating mean and std
2023-10-13 23:12:38,636:INFO:Creating metrics dataframe
2023-10-13 23:12:38,640:INFO:Uploading results into container
2023-10-13 23:12:38,640:INFO:Uploading model into container now
2023-10-13 23:12:38,640:INFO:_master_model_container: 8
2023-10-13 23:12:38,640:INFO:_display_container: 2
2023-10-13 23:12:38,641:INFO:AutoETS(seasonal='mul', sp=12, trend='add')
2023-10-13 23:12:38,641:INFO:create_model() successfully completed......................................
2023-10-13 23:12:38,768:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:38,768:INFO:Creating metrics dataframe
2023-10-13 23:12:38,778:INFO:Initializing Theta Forecaster
2023-10-13 23:12:38,778:INFO:Total runtime is 0.2742028991381327 minutes
2023-10-13 23:12:38,782:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:38,782:INFO:Initializing create_model()
2023-10-13 23:12:38,782:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=theta, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:38,782:INFO:Checking exceptions
2023-10-13 23:12:38,783:INFO:Importing libraries
2023-10-13 23:12:38,783:INFO:Copying training dataset
2023-10-13 23:12:38,787:INFO:Defining folds
2023-10-13 23:12:38,787:INFO:Declaring metric variables
2023-10-13 23:12:38,790:INFO:Importing untrained model
2023-10-13 23:12:38,815:INFO:Theta Forecaster Imported successfully
2023-10-13 23:12:38,833:INFO:Starting cross validation
2023-10-13 23:12:38,835:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:38,877:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:38,882:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:38,882:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\forecasting\base\_base.py:557: UserWarning: In 0.22.0, predict_quantiles return default column level 0 name will change for univariate probabilistic quantile forecasts from 'Quantiles' to variable name. The old behaviour can be retained by setting the legacy_interface argument to True, until 0.23.0 when the legacy_interface argument will be removed.
  warn(

2023-10-13 23:12:38,895:INFO:Calculating mean and std
2023-10-13 23:12:38,896:INFO:Creating metrics dataframe
2023-10-13 23:12:38,901:INFO:Uploading results into container
2023-10-13 23:12:38,901:INFO:Uploading model into container now
2023-10-13 23:12:38,901:INFO:_master_model_container: 9
2023-10-13 23:12:38,901:INFO:_display_container: 2
2023-10-13 23:12:38,901:INFO:ThetaForecaster(sp=12)
2023-10-13 23:12:38,901:INFO:create_model() successfully completed......................................
2023-10-13 23:12:39,024:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:39,024:INFO:Creating metrics dataframe
2023-10-13 23:12:39,034:INFO:Initializing STLF
2023-10-13 23:12:39,034:INFO:Total runtime is 0.27847553888956705 minutes
2023-10-13 23:12:39,037:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:39,039:INFO:Initializing create_model()
2023-10-13 23:12:39,039:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=stlf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:39,039:INFO:Checking exceptions
2023-10-13 23:12:39,039:INFO:Importing libraries
2023-10-13 23:12:39,039:INFO:Copying training dataset
2023-10-13 23:12:39,042:INFO:Defining folds
2023-10-13 23:12:39,043:INFO:Declaring metric variables
2023-10-13 23:12:39,046:INFO:Importing untrained model
2023-10-13 23:12:39,052:INFO:STLF Imported successfully
2023-10-13 23:12:39,059:INFO:Starting cross validation
2023-10-13 23:12:39,060:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:39,133:INFO:Calculating mean and std
2023-10-13 23:12:39,133:INFO:Creating metrics dataframe
2023-10-13 23:12:39,137:INFO:Uploading results into container
2023-10-13 23:12:39,137:INFO:Uploading model into container now
2023-10-13 23:12:39,137:INFO:_master_model_container: 10
2023-10-13 23:12:39,137:INFO:_display_container: 2
2023-10-13 23:12:39,137:INFO:STLForecaster(sp=12)
2023-10-13 23:12:39,137:INFO:create_model() successfully completed......................................
2023-10-13 23:12:39,258:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:39,258:INFO:Creating metrics dataframe
2023-10-13 23:12:39,269:INFO:Initializing Croston
2023-10-13 23:12:39,269:INFO:Total runtime is 0.2823920448621114 minutes
2023-10-13 23:12:39,271:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:39,272:INFO:Initializing create_model()
2023-10-13 23:12:39,272:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=croston, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:39,272:INFO:Checking exceptions
2023-10-13 23:12:39,272:INFO:Importing libraries
2023-10-13 23:12:39,272:INFO:Copying training dataset
2023-10-13 23:12:39,277:INFO:Defining folds
2023-10-13 23:12:39,277:INFO:Declaring metric variables
2023-10-13 23:12:39,280:INFO:Importing untrained model
2023-10-13 23:12:39,284:INFO:Croston Imported successfully
2023-10-13 23:12:39,291:INFO:Starting cross validation
2023-10-13 23:12:39,292:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:39,322:INFO:Calculating mean and std
2023-10-13 23:12:39,322:INFO:Creating metrics dataframe
2023-10-13 23:12:39,325:INFO:Uploading results into container
2023-10-13 23:12:39,325:INFO:Uploading model into container now
2023-10-13 23:12:39,326:INFO:_master_model_container: 11
2023-10-13 23:12:39,326:INFO:_display_container: 2
2023-10-13 23:12:39,326:INFO:Croston()
2023-10-13 23:12:39,326:INFO:create_model() successfully completed......................................
2023-10-13 23:12:39,448:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:39,448:INFO:Creating metrics dataframe
2023-10-13 23:12:39,458:INFO:Initializing Linear w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:39,458:INFO:Total runtime is 0.285539702574412 minutes
2023-10-13 23:12:39,460:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:39,460:INFO:Initializing create_model()
2023-10-13 23:12:39,460:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=lr_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:39,460:INFO:Checking exceptions
2023-10-13 23:12:39,460:INFO:Importing libraries
2023-10-13 23:12:39,460:INFO:Copying training dataset
2023-10-13 23:12:39,465:INFO:Defining folds
2023-10-13 23:12:39,465:INFO:Declaring metric variables
2023-10-13 23:12:39,468:INFO:Importing untrained model
2023-10-13 23:12:39,473:INFO:Linear w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:39,481:INFO:Starting cross validation
2023-10-13 23:12:39,482:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:39,652:INFO:Calculating mean and std
2023-10-13 23:12:39,653:INFO:Creating metrics dataframe
2023-10-13 23:12:39,656:INFO:Uploading results into container
2023-10-13 23:12:39,657:INFO:Uploading model into container now
2023-10-13 23:12:39,657:INFO:_master_model_container: 12
2023-10-13 23:12:39,657:INFO:_display_container: 2
2023-10-13 23:12:39,658:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=LinearRegression(n_jobs=-1), sp=12,
                    window_length=12)
2023-10-13 23:12:39,658:INFO:create_model() successfully completed......................................
2023-10-13 23:12:39,781:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:39,781:INFO:Creating metrics dataframe
2023-10-13 23:12:39,793:INFO:Initializing Elastic Net w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:39,793:INFO:Total runtime is 0.2911206642786662 minutes
2023-10-13 23:12:39,798:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:39,798:INFO:Initializing create_model()
2023-10-13 23:12:39,798:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=en_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:39,798:INFO:Checking exceptions
2023-10-13 23:12:39,799:INFO:Importing libraries
2023-10-13 23:12:39,799:INFO:Copying training dataset
2023-10-13 23:12:39,803:INFO:Defining folds
2023-10-13 23:12:39,803:INFO:Declaring metric variables
2023-10-13 23:12:39,806:INFO:Importing untrained model
2023-10-13 23:12:39,810:INFO:Elastic Net w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:39,819:INFO:Starting cross validation
2023-10-13 23:12:39,820:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:39,983:INFO:Calculating mean and std
2023-10-13 23:12:39,984:INFO:Creating metrics dataframe
2023-10-13 23:12:39,988:INFO:Uploading results into container
2023-10-13 23:12:39,988:INFO:Uploading model into container now
2023-10-13 23:12:39,988:INFO:_master_model_container: 13
2023-10-13 23:12:39,989:INFO:_display_container: 2
2023-10-13 23:12:39,990:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=ElasticNet(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:12:39,991:INFO:create_model() successfully completed......................................
2023-10-13 23:12:40,113:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:40,113:INFO:Creating metrics dataframe
2023-10-13 23:12:40,124:INFO:Initializing Ridge w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:40,124:INFO:Total runtime is 0.2966396490732829 minutes
2023-10-13 23:12:40,128:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:40,129:INFO:Initializing create_model()
2023-10-13 23:12:40,129:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=ridge_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:40,129:INFO:Checking exceptions
2023-10-13 23:12:40,129:INFO:Importing libraries
2023-10-13 23:12:40,129:INFO:Copying training dataset
2023-10-13 23:12:40,133:INFO:Defining folds
2023-10-13 23:12:40,133:INFO:Declaring metric variables
2023-10-13 23:12:40,137:INFO:Importing untrained model
2023-10-13 23:12:40,140:INFO:Ridge w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:40,149:INFO:Starting cross validation
2023-10-13 23:12:40,150:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:40,308:INFO:Calculating mean and std
2023-10-13 23:12:40,309:INFO:Creating metrics dataframe
2023-10-13 23:12:40,314:INFO:Uploading results into container
2023-10-13 23:12:40,314:INFO:Uploading model into container now
2023-10-13 23:12:40,314:INFO:_master_model_container: 14
2023-10-13 23:12:40,314:INFO:_display_container: 2
2023-10-13 23:12:40,316:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=Ridge(random_state=123), sp=12, window_length=12)
2023-10-13 23:12:40,316:INFO:create_model() successfully completed......................................
2023-10-13 23:12:40,437:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:40,437:INFO:Creating metrics dataframe
2023-10-13 23:12:40,447:INFO:Initializing Lasso w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:40,447:INFO:Total runtime is 0.30202686389287314 minutes
2023-10-13 23:12:40,450:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:40,451:INFO:Initializing create_model()
2023-10-13 23:12:40,451:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=lasso_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:40,451:INFO:Checking exceptions
2023-10-13 23:12:40,451:INFO:Importing libraries
2023-10-13 23:12:40,451:INFO:Copying training dataset
2023-10-13 23:12:40,455:INFO:Defining folds
2023-10-13 23:12:40,455:INFO:Declaring metric variables
2023-10-13 23:12:40,458:INFO:Importing untrained model
2023-10-13 23:12:40,462:INFO:Lasso w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:40,471:INFO:Starting cross validation
2023-10-13 23:12:40,472:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:40,644:INFO:Calculating mean and std
2023-10-13 23:12:40,645:INFO:Creating metrics dataframe
2023-10-13 23:12:40,650:INFO:Uploading results into container
2023-10-13 23:12:40,650:INFO:Uploading model into container now
2023-10-13 23:12:40,650:INFO:_master_model_container: 15
2023-10-13 23:12:40,650:INFO:_display_container: 2
2023-10-13 23:12:40,653:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=Lasso(random_state=123), sp=12, window_length=12)
2023-10-13 23:12:40,653:INFO:create_model() successfully completed......................................
2023-10-13 23:12:40,775:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:40,775:INFO:Creating metrics dataframe
2023-10-13 23:12:40,787:INFO:Initializing Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:40,787:INFO:Total runtime is 0.30768833160400394 minutes
2023-10-13 23:12:40,790:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:40,791:INFO:Initializing create_model()
2023-10-13 23:12:40,791:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=llar_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:40,791:INFO:Checking exceptions
2023-10-13 23:12:40,791:INFO:Importing libraries
2023-10-13 23:12:40,791:INFO:Copying training dataset
2023-10-13 23:12:40,795:INFO:Defining folds
2023-10-13 23:12:40,795:INFO:Declaring metric variables
2023-10-13 23:12:40,798:INFO:Importing untrained model
2023-10-13 23:12:40,801:INFO:Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:40,810:INFO:Starting cross validation
2023-10-13 23:12:40,811:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:40,889:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-13 23:12:40,892:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-13 23:12:40,900:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-13 23:12:40,987:INFO:Calculating mean and std
2023-10-13 23:12:40,988:INFO:Creating metrics dataframe
2023-10-13 23:12:40,992:INFO:Uploading results into container
2023-10-13 23:12:40,992:INFO:Uploading model into container now
2023-10-13 23:12:40,992:INFO:_master_model_container: 16
2023-10-13 23:12:40,992:INFO:_display_container: 2
2023-10-13 23:12:40,994:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=LassoLars(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:12:40,994:INFO:create_model() successfully completed......................................
2023-10-13 23:12:41,145:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:41,145:INFO:Creating metrics dataframe
2023-10-13 23:12:41,155:INFO:Initializing Bayesian Ridge w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:41,155:INFO:Total runtime is 0.31381861368815106 minutes
2023-10-13 23:12:41,159:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:41,159:INFO:Initializing create_model()
2023-10-13 23:12:41,159:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=br_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:41,159:INFO:Checking exceptions
2023-10-13 23:12:41,159:INFO:Importing libraries
2023-10-13 23:12:41,159:INFO:Copying training dataset
2023-10-13 23:12:41,163:INFO:Defining folds
2023-10-13 23:12:41,163:INFO:Declaring metric variables
2023-10-13 23:12:41,166:INFO:Importing untrained model
2023-10-13 23:12:41,171:INFO:Bayesian Ridge w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:41,178:INFO:Starting cross validation
2023-10-13 23:12:41,180:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:41,336:INFO:Calculating mean and std
2023-10-13 23:12:41,337:INFO:Creating metrics dataframe
2023-10-13 23:12:41,341:INFO:Uploading results into container
2023-10-13 23:12:41,341:INFO:Uploading model into container now
2023-10-13 23:12:41,341:INFO:_master_model_container: 17
2023-10-13 23:12:41,341:INFO:_display_container: 2
2023-10-13 23:12:41,343:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=BayesianRidge(), sp=12, window_length=12)
2023-10-13 23:12:41,343:INFO:create_model() successfully completed......................................
2023-10-13 23:12:41,465:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:41,465:INFO:Creating metrics dataframe
2023-10-13 23:12:41,475:INFO:Initializing Huber w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:41,475:INFO:Total runtime is 0.3191500504811605 minutes
2023-10-13 23:12:41,480:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:41,480:INFO:Initializing create_model()
2023-10-13 23:12:41,480:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=huber_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:41,480:INFO:Checking exceptions
2023-10-13 23:12:41,480:INFO:Importing libraries
2023-10-13 23:12:41,480:INFO:Copying training dataset
2023-10-13 23:12:41,484:INFO:Defining folds
2023-10-13 23:12:41,484:INFO:Declaring metric variables
2023-10-13 23:12:41,487:INFO:Importing untrained model
2023-10-13 23:12:41,491:INFO:Huber w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:41,499:INFO:Starting cross validation
2023-10-13 23:12:41,500:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:41,665:INFO:Calculating mean and std
2023-10-13 23:12:41,667:INFO:Creating metrics dataframe
2023-10-13 23:12:41,671:INFO:Uploading results into container
2023-10-13 23:12:41,672:INFO:Uploading model into container now
2023-10-13 23:12:41,672:INFO:_master_model_container: 18
2023-10-13 23:12:41,672:INFO:_display_container: 2
2023-10-13 23:12:41,673:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=HuberRegressor(), sp=12, window_length=12)
2023-10-13 23:12:41,673:INFO:create_model() successfully completed......................................
2023-10-13 23:12:41,798:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:41,798:INFO:Creating metrics dataframe
2023-10-13 23:12:41,811:INFO:Initializing Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:41,811:INFO:Total runtime is 0.3247588555018108 minutes
2023-10-13 23:12:41,816:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:41,816:INFO:Initializing create_model()
2023-10-13 23:12:41,816:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=omp_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:41,816:INFO:Checking exceptions
2023-10-13 23:12:41,816:INFO:Importing libraries
2023-10-13 23:12:41,816:INFO:Copying training dataset
2023-10-13 23:12:41,819:INFO:Defining folds
2023-10-13 23:12:41,819:INFO:Declaring metric variables
2023-10-13 23:12:41,823:INFO:Importing untrained model
2023-10-13 23:12:41,828:INFO:Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:41,836:INFO:Starting cross validation
2023-10-13 23:12:41,837:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:41,900:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-13 23:12:41,903:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-13 23:12:41,907:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-13 23:12:41,989:INFO:Calculating mean and std
2023-10-13 23:12:41,991:INFO:Creating metrics dataframe
2023-10-13 23:12:41,995:INFO:Uploading results into container
2023-10-13 23:12:41,995:INFO:Uploading model into container now
2023-10-13 23:12:41,995:INFO:_master_model_container: 19
2023-10-13 23:12:41,995:INFO:_display_container: 2
2023-10-13 23:12:41,998:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=OrthogonalMatchingPursuit(), sp=12,
                    window_length=12)
2023-10-13 23:12:41,998:INFO:create_model() successfully completed......................................
2023-10-13 23:12:42,124:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:42,124:INFO:Creating metrics dataframe
2023-10-13 23:12:42,139:INFO:Initializing K Neighbors w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:42,139:INFO:Total runtime is 0.33021152416865035 minutes
2023-10-13 23:12:42,142:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:42,142:INFO:Initializing create_model()
2023-10-13 23:12:42,142:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=knn_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:42,142:INFO:Checking exceptions
2023-10-13 23:12:42,142:INFO:Importing libraries
2023-10-13 23:12:42,142:INFO:Copying training dataset
2023-10-13 23:12:42,146:INFO:Defining folds
2023-10-13 23:12:42,147:INFO:Declaring metric variables
2023-10-13 23:12:42,150:INFO:Importing untrained model
2023-10-13 23:12:42,154:INFO:K Neighbors w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:42,163:INFO:Starting cross validation
2023-10-13 23:12:42,165:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:42,355:INFO:Calculating mean and std
2023-10-13 23:12:42,356:INFO:Creating metrics dataframe
2023-10-13 23:12:42,359:INFO:Uploading results into container
2023-10-13 23:12:42,360:INFO:Uploading model into container now
2023-10-13 23:12:42,360:INFO:_master_model_container: 20
2023-10-13 23:12:42,360:INFO:_display_container: 2
2023-10-13 23:12:42,362:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=KNeighborsRegressor(n_jobs=-1), sp=12,
                    window_length=12)
2023-10-13 23:12:42,362:INFO:create_model() successfully completed......................................
2023-10-13 23:12:42,483:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:42,483:INFO:Creating metrics dataframe
2023-10-13 23:12:42,496:INFO:Initializing Decision Tree w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:42,497:INFO:Total runtime is 0.336180845896403 minutes
2023-10-13 23:12:42,500:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:42,501:INFO:Initializing create_model()
2023-10-13 23:12:42,501:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=dt_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:42,501:INFO:Checking exceptions
2023-10-13 23:12:42,501:INFO:Importing libraries
2023-10-13 23:12:42,501:INFO:Copying training dataset
2023-10-13 23:12:42,505:INFO:Defining folds
2023-10-13 23:12:42,505:INFO:Declaring metric variables
2023-10-13 23:12:42,508:INFO:Importing untrained model
2023-10-13 23:12:42,513:INFO:Decision Tree w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:42,519:INFO:Starting cross validation
2023-10-13 23:12:42,521:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:42,683:INFO:Calculating mean and std
2023-10-13 23:12:42,684:INFO:Creating metrics dataframe
2023-10-13 23:12:42,688:INFO:Uploading results into container
2023-10-13 23:12:42,688:INFO:Uploading model into container now
2023-10-13 23:12:42,688:INFO:_master_model_container: 21
2023-10-13 23:12:42,688:INFO:_display_container: 2
2023-10-13 23:12:42,690:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=DecisionTreeRegressor(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:12:42,690:INFO:create_model() successfully completed......................................
2023-10-13 23:12:42,815:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:42,815:INFO:Creating metrics dataframe
2023-10-13 23:12:42,829:INFO:Initializing Random Forest w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:42,829:INFO:Total runtime is 0.3417164444923401 minutes
2023-10-13 23:12:42,833:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:42,833:INFO:Initializing create_model()
2023-10-13 23:12:42,833:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=rf_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:42,833:INFO:Checking exceptions
2023-10-13 23:12:42,833:INFO:Importing libraries
2023-10-13 23:12:42,833:INFO:Copying training dataset
2023-10-13 23:12:42,837:INFO:Defining folds
2023-10-13 23:12:42,837:INFO:Declaring metric variables
2023-10-13 23:12:42,841:INFO:Importing untrained model
2023-10-13 23:12:42,845:INFO:Random Forest w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:42,853:INFO:Starting cross validation
2023-10-13 23:12:42,854:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:43,207:INFO:Calculating mean and std
2023-10-13 23:12:43,208:INFO:Creating metrics dataframe
2023-10-13 23:12:43,213:INFO:Uploading results into container
2023-10-13 23:12:43,213:INFO:Uploading model into container now
2023-10-13 23:12:43,213:INFO:_master_model_container: 22
2023-10-13 23:12:43,214:INFO:_display_container: 2
2023-10-13 23:12:43,216:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=RandomForestRegressor(n_jobs=-1, random_state=123),
                    sp=12, window_length=12)
2023-10-13 23:12:43,216:INFO:create_model() successfully completed......................................
2023-10-13 23:12:43,343:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:43,343:INFO:Creating metrics dataframe
2023-10-13 23:12:43,357:INFO:Initializing Extra Trees w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:43,357:INFO:Total runtime is 0.35052103996276857 minutes
2023-10-13 23:12:43,359:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:43,360:INFO:Initializing create_model()
2023-10-13 23:12:43,360:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=et_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:43,360:INFO:Checking exceptions
2023-10-13 23:12:43,360:INFO:Importing libraries
2023-10-13 23:12:43,360:INFO:Copying training dataset
2023-10-13 23:12:43,365:INFO:Defining folds
2023-10-13 23:12:43,365:INFO:Declaring metric variables
2023-10-13 23:12:43,368:INFO:Importing untrained model
2023-10-13 23:12:43,373:INFO:Extra Trees w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:43,381:INFO:Starting cross validation
2023-10-13 23:12:43,383:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:43,671:INFO:Calculating mean and std
2023-10-13 23:12:43,672:INFO:Creating metrics dataframe
2023-10-13 23:12:43,676:INFO:Uploading results into container
2023-10-13 23:12:43,677:INFO:Uploading model into container now
2023-10-13 23:12:43,677:INFO:_master_model_container: 23
2023-10-13 23:12:43,677:INFO:_display_container: 2
2023-10-13 23:12:43,679:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=ExtraTreesRegressor(n_jobs=-1, random_state=123),
                    sp=12, window_length=12)
2023-10-13 23:12:43,680:INFO:create_model() successfully completed......................................
2023-10-13 23:12:43,835:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:43,835:INFO:Creating metrics dataframe
2023-10-13 23:12:43,849:INFO:Initializing Gradient Boosting w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:43,849:INFO:Total runtime is 0.35872578620910645 minutes
2023-10-13 23:12:43,852:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:43,852:INFO:Initializing create_model()
2023-10-13 23:12:43,852:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=gbr_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:43,852:INFO:Checking exceptions
2023-10-13 23:12:43,852:INFO:Importing libraries
2023-10-13 23:12:43,852:INFO:Copying training dataset
2023-10-13 23:12:43,857:INFO:Defining folds
2023-10-13 23:12:43,857:INFO:Declaring metric variables
2023-10-13 23:12:43,860:INFO:Importing untrained model
2023-10-13 23:12:43,865:INFO:Gradient Boosting w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:43,873:INFO:Starting cross validation
2023-10-13 23:12:43,875:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:44,071:INFO:Calculating mean and std
2023-10-13 23:12:44,073:INFO:Creating metrics dataframe
2023-10-13 23:12:44,076:INFO:Uploading results into container
2023-10-13 23:12:44,077:INFO:Uploading model into container now
2023-10-13 23:12:44,077:INFO:_master_model_container: 24
2023-10-13 23:12:44,077:INFO:_display_container: 2
2023-10-13 23:12:44,080:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=GradientBoostingRegressor(random_state=123),
                    sp=12, window_length=12)
2023-10-13 23:12:44,081:INFO:create_model() successfully completed......................................
2023-10-13 23:12:44,203:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:44,203:INFO:Creating metrics dataframe
2023-10-13 23:12:44,218:INFO:Initializing AdaBoost w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:44,218:INFO:Total runtime is 0.364872666200002 minutes
2023-10-13 23:12:44,221:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:44,221:INFO:Initializing create_model()
2023-10-13 23:12:44,221:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=ada_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:44,221:INFO:Checking exceptions
2023-10-13 23:12:44,221:INFO:Importing libraries
2023-10-13 23:12:44,221:INFO:Copying training dataset
2023-10-13 23:12:44,226:INFO:Defining folds
2023-10-13 23:12:44,226:INFO:Declaring metric variables
2023-10-13 23:12:44,229:INFO:Importing untrained model
2023-10-13 23:12:44,233:INFO:AdaBoost w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:44,241:INFO:Starting cross validation
2023-10-13 23:12:44,242:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:44,468:INFO:Calculating mean and std
2023-10-13 23:12:44,470:INFO:Creating metrics dataframe
2023-10-13 23:12:44,473:INFO:Uploading results into container
2023-10-13 23:12:44,473:INFO:Uploading model into container now
2023-10-13 23:12:44,474:INFO:_master_model_container: 25
2023-10-13 23:12:44,474:INFO:_display_container: 2
2023-10-13 23:12:44,475:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=AdaBoostRegressor(random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:12:44,475:INFO:create_model() successfully completed......................................
2023-10-13 23:12:44,597:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:44,597:INFO:Creating metrics dataframe
2023-10-13 23:12:44,610:INFO:Initializing Extreme Gradient Boosting w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:44,610:INFO:Total runtime is 0.37140613396962485 minutes
2023-10-13 23:12:44,615:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:44,615:INFO:Initializing create_model()
2023-10-13 23:12:44,615:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=xgboost_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:44,615:INFO:Checking exceptions
2023-10-13 23:12:44,615:INFO:Importing libraries
2023-10-13 23:12:44,615:INFO:Copying training dataset
2023-10-13 23:12:44,618:INFO:Defining folds
2023-10-13 23:12:44,618:INFO:Declaring metric variables
2023-10-13 23:12:44,622:INFO:Importing untrained model
2023-10-13 23:12:44,625:INFO:Extreme Gradient Boosting w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:44,633:INFO:Starting cross validation
2023-10-13 23:12:44,634:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:44,934:INFO:Calculating mean and std
2023-10-13 23:12:44,936:INFO:Creating metrics dataframe
2023-10-13 23:12:44,941:INFO:Uploading results into container
2023-10-13 23:12:44,941:INFO:Uploading model into container now
2023-10-13 23:12:44,942:INFO:_master_model_container: 26
2023-10-13 23:12:44,942:INFO:_display_container: 2
2023-10-13 23:12:44,948:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             g...tance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...),
                    sp=12, window_length=12)
2023-10-13 23:12:44,949:INFO:create_model() successfully completed......................................
2023-10-13 23:12:45,085:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:45,085:INFO:Creating metrics dataframe
2023-10-13 23:12:45,100:INFO:Initializing Light Gradient Boosting w/ Cond. Deseasonalize & Detrending
2023-10-13 23:12:45,100:INFO:Total runtime is 0.3795677781105042 minutes
2023-10-13 23:12:45,102:INFO:SubProcess create_model() called ==================================
2023-10-13 23:12:45,102:INFO:Initializing create_model()
2023-10-13 23:12:45,103:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=lightgbm_cds_dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000215586B3E80>, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:45,103:INFO:Checking exceptions
2023-10-13 23:12:45,103:INFO:Importing libraries
2023-10-13 23:12:45,103:INFO:Copying training dataset
2023-10-13 23:12:45,107:INFO:Defining folds
2023-10-13 23:12:45,107:INFO:Declaring metric variables
2023-10-13 23:12:45,110:INFO:Importing untrained model
2023-10-13 23:12:45,115:INFO:Light Gradient Boosting w/ Cond. Deseasonalize & Detrending Imported successfully
2023-10-13 23:12:45,124:INFO:Starting cross validation
2023-10-13 23:12:45,125:INFO:Cross validating with ExpandingWindowSplitter(fh=ForecastingHorizon([1, 2, 3], dtype='int64', is_relative=True),
                        initial_window=132, step_length=3), n_jobs=-1
2023-10-13 23:12:45,258:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,286:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,291:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,293:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,315:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,321:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,322:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,349:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,352:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py:599: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.
  _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "

2023-10-13 23:12:45,368:INFO:Calculating mean and std
2023-10-13 23:12:45,370:INFO:Creating metrics dataframe
2023-10-13 23:12:45,377:INFO:Uploading results into container
2023-10-13 23:12:45,378:INFO:Uploading model into container now
2023-10-13 23:12:45,378:INFO:_master_model_container: 27
2023-10-13 23:12:45,378:INFO:_display_container: 2
2023-10-13 23:12:45,381:INFO:BaseCdsDtForecaster(fe_target_rr=[WindowSummarizer(lag_feature={'lag': [12, 11,
                                                                        10, 9,
                                                                        8, 7, 6,
                                                                        5, 4, 3,
                                                                        2, 1]},
                                                   n_jobs=1)],
                    regressor=LGBMRegressor(n_jobs=-1, random_state=123), sp=12,
                    window_length=12)
2023-10-13 23:12:45,381:INFO:create_model() successfully completed......................................
2023-10-13 23:12:45,524:INFO:SubProcess create_model() end ==================================
2023-10-13 23:12:45,524:INFO:Creating metrics dataframe
2023-10-13 23:12:45,550:INFO:Initializing create_model()
2023-10-13 23:12:45,550:INFO:create_model(self=<pycaret.time_series.forecasting.oop.TSForecastingExperiment object at 0x000002155829DE70>, estimator=STLForecaster(sp=12), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-13 23:12:45,550:INFO:Checking exceptions
2023-10-13 23:12:45,552:INFO:Importing libraries
2023-10-13 23:12:45,553:INFO:Copying training dataset
2023-10-13 23:12:45,554:INFO:Defining folds
2023-10-13 23:12:45,554:INFO:Declaring metric variables
2023-10-13 23:12:45,555:INFO:Importing untrained model
2023-10-13 23:12:45,555:INFO:Declaring custom model
2023-10-13 23:12:45,556:INFO:STLF Imported successfully
2023-10-13 23:12:45,556:INFO:Cross validation set to False
2023-10-13 23:12:45,556:INFO:Fitting Model
2023-10-13 23:12:45,571:INFO:STLForecaster(sp=12)
2023-10-13 23:12:45,571:INFO:create_model() successfully completed......................................
2023-10-13 23:12:45,736:INFO:_master_model_container: 27
2023-10-13 23:12:45,737:INFO:_display_container: 2
2023-10-13 23:12:45,737:INFO:STLForecaster(sp=12)
2023-10-13 23:12:45,737:INFO:compare_models() successfully completed......................................
2023-10-13 23:13:32,524:INFO:Visual Rendered Successfully
2023-10-13 23:14:07,464:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
TypeError: mase() got an unexpected keyword argument 'sample_weight'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\containers\metrics\time_series.py", line 175, in mase
    return mean_absolute_scaled_error(
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\performance_metrics\forecasting\_functions.py", line 417, in mean_absolute_scaled_error
    _, y_true, y_pred, multioutput = _check_reg_targets(y_true, y_pred, multioutput)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,465:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
TypeError: rmsse() got an unexpected keyword argument 'sample_weight'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\containers\metrics\time_series.py", line 185, in rmsse
    return mean_squared_scaled_error(
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\performance_metrics\forecasting\_functions.py", line 680, in mean_squared_scaled_error
    _, y_true, y_pred, multioutput = _check_reg_targets(y_true, y_pred, multioutput)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,466:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 196, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,466:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,467:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\containers\metrics\time_series.py", line 168, in mape
    return mean_absolute_percentage_error(
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\performance_metrics\forecasting\_functions.py", line 1537, in mean_absolute_percentage_error
    _, y_true, y_pred, multioutput = _check_reg_targets(y_true, y_pred, multioutput)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\containers\metrics\time_series.py", line 168, in mape
    return mean_absolute_percentage_error(
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\performance_metrics\forecasting\_functions.py", line 1537, in mean_absolute_percentage_error
    _, y_true, y_pred, multioutput = _check_reg_targets(y_true, y_pred, multioutput)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,467:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\containers\metrics\time_series.py", line 159, in _smape_loss
    return mean_absolute_percentage_error(
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\performance_metrics\forecasting\_functions.py", line 1537, in mean_absolute_percentage_error
    _, y_true, y_pred, multioutput = _check_reg_targets(y_true, y_pred, multioutput)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\containers\metrics\time_series.py", line 159, in _smape_loss
    return mean_absolute_percentage_error(
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\sktime\performance_metrics\forecasting\_functions.py", line 1537, in mean_absolute_percentage_error
    _, y_true, y_pred, multioutput = _check_reg_targets(y_true, y_pred, multioutput)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,468:WARNING:C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py:586: UserWarning:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 911, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py", line 100, in _check_reg_targets
    check_consistent_length(y_true, y_pred)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\validation.py", line 387, in check_consistent_length
    raise ValueError(
ValueError: Found input variables with inconsistent numbers of samples: [3, 36]



2023-10-13 23:14:07,470:WARNING:predict_model >> Prediction Indices do not match test indices. Metrics will not be displayed.
2023-10-13 23:14:07,649:INFO:Visual Rendered Successfully
2023-10-14 15:35:16,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-14 15:35:16,016:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-14 15:35:16,016:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-14 15:35:16,016:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-14 15:35:26,430:INFO:PyCaret RegressionExperiment
2023-10-14 15:35:26,430:INFO:Logging name: reg-default-name
2023-10-14 15:35:26,430:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-14 15:35:26,430:INFO:version 3.1.0
2023-10-14 15:35:26,430:INFO:Initializing setup()
2023-10-14 15:35:26,430:INFO:self.USI: 2041
2023-10-14 15:35:26,430:INFO:self._variable_keys: {'exp_id', 'seed', 'idx', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'logging_param', '_available_plots', 'gpu_param', 'y', 'y_train', 'y_test', 'target_param', 'memory', 'transform_target_param', 'X_train', 'X_test', 'fold_groups_param', '_ml_usecase', 'data', 'X', 'pipeline', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'USI'}
2023-10-14 15:35:26,430:INFO:Checking environment
2023-10-14 15:35:26,430:INFO:python_version: 3.10.6
2023-10-14 15:35:26,430:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-14 15:35:26,430:INFO:machine: AMD64
2023-10-14 15:35:26,430:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-14 15:35:26,431:INFO:Memory: svmem(total=8273383424, available=1072361472, percent=87.0, used=7201021952, free=1072361472)
2023-10-14 15:35:26,431:INFO:Physical Core: 4
2023-10-14 15:35:26,431:INFO:Logical Core: 8
2023-10-14 15:35:26,431:INFO:Checking libraries
2023-10-14 15:35:26,431:INFO:System:
2023-10-14 15:35:26,431:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-14 15:35:26,431:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-14 15:35:26,431:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-14 15:35:26,431:INFO:PyCaret required dependencies:
2023-10-14 15:35:26,522:INFO:                 pip: 22.2.1
2023-10-14 15:35:26,522:INFO:          setuptools: 63.2.0
2023-10-14 15:35:26,522:INFO:             pycaret: 3.1.0
2023-10-14 15:35:26,522:INFO:             IPython: 8.4.0
2023-10-14 15:35:26,522:INFO:          ipywidgets: 8.1.1
2023-10-14 15:35:26,522:INFO:                tqdm: 4.66.1
2023-10-14 15:35:26,523:INFO:               numpy: 1.23.2
2023-10-14 15:35:26,523:INFO:              pandas: 1.4.3
2023-10-14 15:35:26,523:INFO:              jinja2: 3.1.2
2023-10-14 15:35:26,523:INFO:               scipy: 1.10.1
2023-10-14 15:35:26,523:INFO:              joblib: 1.2.0
2023-10-14 15:35:26,523:INFO:             sklearn: 1.1.2
2023-10-14 15:35:26,523:INFO:                pyod: 1.1.0
2023-10-14 15:35:26,523:INFO:            imblearn: 0.11.0
2023-10-14 15:35:26,523:INFO:   category_encoders: 2.6.2
2023-10-14 15:35:26,523:INFO:            lightgbm: 4.1.0
2023-10-14 15:35:26,523:INFO:               numba: 0.58.0
2023-10-14 15:35:26,523:INFO:            requests: 2.28.1
2023-10-14 15:35:26,523:INFO:          matplotlib: 3.6.0
2023-10-14 15:35:26,523:INFO:          scikitplot: 0.3.7
2023-10-14 15:35:26,523:INFO:         yellowbrick: 1.5
2023-10-14 15:35:26,523:INFO:              plotly: 5.17.0
2023-10-14 15:35:26,523:INFO:    plotly-resampler: Not installed
2023-10-14 15:35:26,523:INFO:             kaleido: 0.2.1
2023-10-14 15:35:26,523:INFO:           schemdraw: 0.15
2023-10-14 15:35:26,523:INFO:         statsmodels: 0.13.2
2023-10-14 15:35:26,523:INFO:              sktime: 0.21.1
2023-10-14 15:35:26,523:INFO:               tbats: 1.1.3
2023-10-14 15:35:26,523:INFO:            pmdarima: 2.0.3
2023-10-14 15:35:26,523:INFO:              psutil: 5.9.1
2023-10-14 15:35:26,523:INFO:          markupsafe: 2.1.1
2023-10-14 15:35:26,523:INFO:             pickle5: Not installed
2023-10-14 15:35:26,523:INFO:         cloudpickle: 2.2.1
2023-10-14 15:35:26,523:INFO:         deprecation: 2.1.0
2023-10-14 15:35:26,523:INFO:              xxhash: 3.4.1
2023-10-14 15:35:26,523:INFO:           wurlitzer: Not installed
2023-10-14 15:35:26,523:INFO:PyCaret optional dependencies:
2023-10-14 15:35:26,765:INFO:                shap: Not installed
2023-10-14 15:35:26,765:INFO:           interpret: Not installed
2023-10-14 15:35:26,765:INFO:                umap: Not installed
2023-10-14 15:35:26,765:INFO:     ydata_profiling: Not installed
2023-10-14 15:35:26,765:INFO:  explainerdashboard: Not installed
2023-10-14 15:35:26,765:INFO:             autoviz: Not installed
2023-10-14 15:35:26,765:INFO:           fairlearn: Not installed
2023-10-14 15:35:26,765:INFO:          deepchecks: Not installed
2023-10-14 15:35:26,765:INFO:             xgboost: 2.0.0
2023-10-14 15:35:26,765:INFO:            catboost: Not installed
2023-10-14 15:35:26,765:INFO:              kmodes: Not installed
2023-10-14 15:35:26,765:INFO:             mlxtend: Not installed
2023-10-14 15:35:26,765:INFO:       statsforecast: Not installed
2023-10-14 15:35:26,765:INFO:        tune_sklearn: Not installed
2023-10-14 15:35:26,765:INFO:                 ray: Not installed
2023-10-14 15:35:26,765:INFO:            hyperopt: Not installed
2023-10-14 15:35:26,765:INFO:              optuna: Not installed
2023-10-14 15:35:26,765:INFO:               skopt: Not installed
2023-10-14 15:35:26,765:INFO:              mlflow: Not installed
2023-10-14 15:35:26,765:INFO:              gradio: Not installed
2023-10-14 15:35:26,765:INFO:             fastapi: Not installed
2023-10-14 15:35:26,765:INFO:             uvicorn: Not installed
2023-10-14 15:35:26,765:INFO:              m2cgen: Not installed
2023-10-14 15:35:26,765:INFO:           evidently: Not installed
2023-10-14 15:35:26,765:INFO:               fugue: Not installed
2023-10-14 15:35:26,765:INFO:           streamlit: Not installed
2023-10-14 15:35:26,765:INFO:             prophet: Not installed
2023-10-14 15:35:26,765:INFO:None
2023-10-14 15:35:26,765:INFO:Set up data.
2023-10-14 15:35:26,775:INFO:Set up folding strategy.
2023-10-14 15:36:42,199:INFO:PyCaret RegressionExperiment
2023-10-14 15:36:42,199:INFO:Logging name: reg-default-name
2023-10-14 15:36:42,199:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-14 15:36:42,199:INFO:version 3.1.0
2023-10-14 15:36:42,199:INFO:Initializing setup()
2023-10-14 15:36:42,199:INFO:self.USI: 0779
2023-10-14 15:36:42,199:INFO:self._variable_keys: {'exp_id', 'seed', 'idx', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'logging_param', '_available_plots', 'gpu_param', 'y', 'y_train', 'y_test', 'target_param', 'memory', 'transform_target_param', 'X_train', 'X_test', 'fold_groups_param', '_ml_usecase', 'data', 'X', 'pipeline', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'USI'}
2023-10-14 15:36:42,200:INFO:Checking environment
2023-10-14 15:36:42,200:INFO:python_version: 3.10.6
2023-10-14 15:36:42,200:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-14 15:36:42,200:INFO:machine: AMD64
2023-10-14 15:36:42,200:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-14 15:36:42,200:INFO:Memory: svmem(total=8273383424, available=1171206144, percent=85.8, used=7102177280, free=1171206144)
2023-10-14 15:36:42,200:INFO:Physical Core: 4
2023-10-14 15:36:42,200:INFO:Logical Core: 8
2023-10-14 15:36:42,200:INFO:Checking libraries
2023-10-14 15:36:42,200:INFO:System:
2023-10-14 15:36:42,200:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-14 15:36:42,200:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-14 15:36:42,200:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-14 15:36:42,200:INFO:PyCaret required dependencies:
2023-10-14 15:36:42,200:INFO:                 pip: 22.2.1
2023-10-14 15:36:42,200:INFO:          setuptools: 63.2.0
2023-10-14 15:36:42,200:INFO:             pycaret: 3.1.0
2023-10-14 15:36:42,200:INFO:             IPython: 8.4.0
2023-10-14 15:36:42,200:INFO:          ipywidgets: 8.1.1
2023-10-14 15:36:42,200:INFO:                tqdm: 4.66.1
2023-10-14 15:36:42,201:INFO:               numpy: 1.23.2
2023-10-14 15:36:42,201:INFO:              pandas: 1.4.3
2023-10-14 15:36:42,201:INFO:              jinja2: 3.1.2
2023-10-14 15:36:42,201:INFO:               scipy: 1.10.1
2023-10-14 15:36:42,201:INFO:              joblib: 1.2.0
2023-10-14 15:36:42,201:INFO:             sklearn: 1.1.2
2023-10-14 15:36:42,201:INFO:                pyod: 1.1.0
2023-10-14 15:36:42,201:INFO:            imblearn: 0.11.0
2023-10-14 15:36:42,201:INFO:   category_encoders: 2.6.2
2023-10-14 15:36:42,201:INFO:            lightgbm: 4.1.0
2023-10-14 15:36:42,201:INFO:               numba: 0.58.0
2023-10-14 15:36:42,201:INFO:            requests: 2.28.1
2023-10-14 15:36:42,201:INFO:          matplotlib: 3.6.0
2023-10-14 15:36:42,201:INFO:          scikitplot: 0.3.7
2023-10-14 15:36:42,201:INFO:         yellowbrick: 1.5
2023-10-14 15:36:42,201:INFO:              plotly: 5.17.0
2023-10-14 15:36:42,201:INFO:    plotly-resampler: Not installed
2023-10-14 15:36:42,201:INFO:             kaleido: 0.2.1
2023-10-14 15:36:42,201:INFO:           schemdraw: 0.15
2023-10-14 15:36:42,201:INFO:         statsmodels: 0.13.2
2023-10-14 15:36:42,201:INFO:              sktime: 0.21.1
2023-10-14 15:36:42,201:INFO:               tbats: 1.1.3
2023-10-14 15:36:42,201:INFO:            pmdarima: 2.0.3
2023-10-14 15:36:42,201:INFO:              psutil: 5.9.1
2023-10-14 15:36:42,201:INFO:          markupsafe: 2.1.1
2023-10-14 15:36:42,201:INFO:             pickle5: Not installed
2023-10-14 15:36:42,201:INFO:         cloudpickle: 2.2.1
2023-10-14 15:36:42,202:INFO:         deprecation: 2.1.0
2023-10-14 15:36:42,202:INFO:              xxhash: 3.4.1
2023-10-14 15:36:42,202:INFO:           wurlitzer: Not installed
2023-10-14 15:36:42,202:INFO:PyCaret optional dependencies:
2023-10-14 15:36:42,202:INFO:                shap: Not installed
2023-10-14 15:36:42,202:INFO:           interpret: Not installed
2023-10-14 15:36:42,202:INFO:                umap: Not installed
2023-10-14 15:36:42,202:INFO:     ydata_profiling: Not installed
2023-10-14 15:36:42,202:INFO:  explainerdashboard: Not installed
2023-10-14 15:36:42,202:INFO:             autoviz: Not installed
2023-10-14 15:36:42,202:INFO:           fairlearn: Not installed
2023-10-14 15:36:42,202:INFO:          deepchecks: Not installed
2023-10-14 15:36:42,202:INFO:             xgboost: 2.0.0
2023-10-14 15:36:42,202:INFO:            catboost: Not installed
2023-10-14 15:36:42,202:INFO:              kmodes: Not installed
2023-10-14 15:36:42,202:INFO:             mlxtend: Not installed
2023-10-14 15:36:42,202:INFO:       statsforecast: Not installed
2023-10-14 15:36:42,202:INFO:        tune_sklearn: Not installed
2023-10-14 15:36:42,202:INFO:                 ray: Not installed
2023-10-14 15:36:42,202:INFO:            hyperopt: Not installed
2023-10-14 15:36:42,202:INFO:              optuna: Not installed
2023-10-14 15:36:42,202:INFO:               skopt: Not installed
2023-10-14 15:36:42,202:INFO:              mlflow: Not installed
2023-10-14 15:36:42,202:INFO:              gradio: Not installed
2023-10-14 15:36:42,202:INFO:             fastapi: Not installed
2023-10-14 15:36:42,202:INFO:             uvicorn: Not installed
2023-10-14 15:36:42,203:INFO:              m2cgen: Not installed
2023-10-14 15:36:42,203:INFO:           evidently: Not installed
2023-10-14 15:36:42,203:INFO:               fugue: Not installed
2023-10-14 15:36:42,203:INFO:           streamlit: Not installed
2023-10-14 15:36:42,203:INFO:             prophet: Not installed
2023-10-14 15:36:42,203:INFO:None
2023-10-14 15:36:42,203:INFO:Set up data.
2023-10-14 15:36:42,209:INFO:Set up folding strategy.
2023-10-14 15:36:42,210:INFO:Set up train/test split.
2023-10-14 15:36:42,210:INFO:Set up data.
2023-10-14 15:36:42,215:INFO:Set up index.
2023-10-14 15:36:42,215:INFO:Assigning column types.
2023-10-14 15:36:42,220:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-14 15:36:42,221:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,226:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,231:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,317:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,320:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,324:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,328:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,414:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,417:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-14 15:36:42,421:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,424:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,515:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,521:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,525:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,573:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,609:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,612:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-14 15:36:42,619:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,711:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,809:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,812:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-14 15:36:42,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:42,904:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:42,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:42,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:43,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 15:36:43,004:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,007:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-14 15:36:43,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:43,102:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 15:36:43,198:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,200:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-14 15:36:43,299:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,390:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,397:INFO:Preparing preprocessing pipeline...
2023-10-14 15:36:43,397:INFO:Set up simple imputation.
2023-10-14 15:36:43,405:INFO:Set up encoding of categorical features.
2023-10-14 15:36:43,459:INFO:Finished creating preprocessing pipeline.
2023-10-14 15:36:43,466:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'temperature',
                                             'day_of_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-10-14 15:36:43,467:INFO:Creating final display dataframe.
2023-10-14 15:36:43,586:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            demand
2                   Target type        Regression
3           Original data shape         (6006, 7)
4        Transformed data shape        (6006, 24)
5   Transformed train set shape        (5506, 24)
6    Transformed test set shape         (500, 24)
7              Numeric features                 4
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   TimeSeriesSplit
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              0779
2023-10-14 15:36:43,677:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,770:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 15:36:43,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 15:36:43,773:INFO:setup() successfully completed in 1.58s...............
2023-10-14 15:37:16,858:INFO:Initializing compare_models()
2023-10-14 15:37:16,859:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-14 15:37:16,859:INFO:Checking exceptions
2023-10-14 15:37:16,863:INFO:Preparing display monitor
2023-10-14 15:37:16,907:INFO:Initializing Linear Regression
2023-10-14 15:37:16,907:INFO:Total runtime is 0.0 minutes
2023-10-14 15:37:16,911:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:16,911:INFO:Initializing create_model()
2023-10-14 15:37:16,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:16,911:INFO:Checking exceptions
2023-10-14 15:37:16,912:INFO:Importing libraries
2023-10-14 15:37:16,912:INFO:Copying training dataset
2023-10-14 15:37:16,917:INFO:Defining folds
2023-10-14 15:37:16,917:INFO:Declaring metric variables
2023-10-14 15:37:16,921:INFO:Importing untrained model
2023-10-14 15:37:16,925:INFO:Linear Regression Imported successfully
2023-10-14 15:37:16,959:INFO:Starting cross validation
2023-10-14 15:37:16,973:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:20,360:INFO:Calculating mean and std
2023-10-14 15:37:20,361:INFO:Creating metrics dataframe
2023-10-14 15:37:20,366:INFO:Uploading results into container
2023-10-14 15:37:20,367:INFO:Uploading model into container now
2023-10-14 15:37:20,368:INFO:_master_model_container: 1
2023-10-14 15:37:20,369:INFO:_display_container: 2
2023-10-14 15:37:20,369:INFO:LinearRegression(n_jobs=-1)
2023-10-14 15:37:20,370:INFO:create_model() successfully completed......................................
2023-10-14 15:37:20,543:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:20,543:INFO:Creating metrics dataframe
2023-10-14 15:37:20,549:INFO:Initializing Lasso Regression
2023-10-14 15:37:20,549:INFO:Total runtime is 0.060690538088480635 minutes
2023-10-14 15:37:20,552:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:20,552:INFO:Initializing create_model()
2023-10-14 15:37:20,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:20,553:INFO:Checking exceptions
2023-10-14 15:37:20,553:INFO:Importing libraries
2023-10-14 15:37:20,553:INFO:Copying training dataset
2023-10-14 15:37:20,558:INFO:Defining folds
2023-10-14 15:37:20,558:INFO:Declaring metric variables
2023-10-14 15:37:20,561:INFO:Importing untrained model
2023-10-14 15:37:20,566:INFO:Lasso Regression Imported successfully
2023-10-14 15:37:20,572:INFO:Starting cross validation
2023-10-14 15:37:20,574:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:22,300:INFO:Calculating mean and std
2023-10-14 15:37:22,302:INFO:Creating metrics dataframe
2023-10-14 15:37:22,306:INFO:Uploading results into container
2023-10-14 15:37:22,307:INFO:Uploading model into container now
2023-10-14 15:37:22,308:INFO:_master_model_container: 2
2023-10-14 15:37:22,308:INFO:_display_container: 2
2023-10-14 15:37:22,308:INFO:Lasso(random_state=123)
2023-10-14 15:37:22,308:INFO:create_model() successfully completed......................................
2023-10-14 15:37:22,459:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:22,459:INFO:Creating metrics dataframe
2023-10-14 15:37:22,467:INFO:Initializing Ridge Regression
2023-10-14 15:37:22,467:INFO:Total runtime is 0.0926718314488729 minutes
2023-10-14 15:37:22,469:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:22,470:INFO:Initializing create_model()
2023-10-14 15:37:22,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:22,470:INFO:Checking exceptions
2023-10-14 15:37:22,470:INFO:Importing libraries
2023-10-14 15:37:22,470:INFO:Copying training dataset
2023-10-14 15:37:22,476:INFO:Defining folds
2023-10-14 15:37:22,476:INFO:Declaring metric variables
2023-10-14 15:37:22,478:INFO:Importing untrained model
2023-10-14 15:37:22,482:INFO:Ridge Regression Imported successfully
2023-10-14 15:37:22,489:INFO:Starting cross validation
2023-10-14 15:37:22,490:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:24,076:INFO:Calculating mean and std
2023-10-14 15:37:24,078:INFO:Creating metrics dataframe
2023-10-14 15:37:24,084:INFO:Uploading results into container
2023-10-14 15:37:24,085:INFO:Uploading model into container now
2023-10-14 15:37:24,085:INFO:_master_model_container: 3
2023-10-14 15:37:24,085:INFO:_display_container: 2
2023-10-14 15:37:24,086:INFO:Ridge(random_state=123)
2023-10-14 15:37:24,086:INFO:create_model() successfully completed......................................
2023-10-14 15:37:24,258:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:24,258:INFO:Creating metrics dataframe
2023-10-14 15:37:24,266:INFO:Initializing Elastic Net
2023-10-14 15:37:24,266:INFO:Total runtime is 0.12265239953994753 minutes
2023-10-14 15:37:24,271:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:24,271:INFO:Initializing create_model()
2023-10-14 15:37:24,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:24,273:INFO:Checking exceptions
2023-10-14 15:37:24,273:INFO:Importing libraries
2023-10-14 15:37:24,273:INFO:Copying training dataset
2023-10-14 15:37:24,277:INFO:Defining folds
2023-10-14 15:37:24,277:INFO:Declaring metric variables
2023-10-14 15:37:24,281:INFO:Importing untrained model
2023-10-14 15:37:24,285:INFO:Elastic Net Imported successfully
2023-10-14 15:37:24,291:INFO:Starting cross validation
2023-10-14 15:37:24,292:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:24,391:INFO:Calculating mean and std
2023-10-14 15:37:24,392:INFO:Creating metrics dataframe
2023-10-14 15:37:24,395:INFO:Uploading results into container
2023-10-14 15:37:24,395:INFO:Uploading model into container now
2023-10-14 15:37:24,395:INFO:_master_model_container: 4
2023-10-14 15:37:24,395:INFO:_display_container: 2
2023-10-14 15:37:24,396:INFO:ElasticNet(random_state=123)
2023-10-14 15:37:24,396:INFO:create_model() successfully completed......................................
2023-10-14 15:37:24,523:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:24,523:INFO:Creating metrics dataframe
2023-10-14 15:37:24,531:INFO:Initializing Least Angle Regression
2023-10-14 15:37:24,532:INFO:Total runtime is 0.12707288662592572 minutes
2023-10-14 15:37:24,536:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:24,536:INFO:Initializing create_model()
2023-10-14 15:37:24,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:24,537:INFO:Checking exceptions
2023-10-14 15:37:24,537:INFO:Importing libraries
2023-10-14 15:37:24,537:INFO:Copying training dataset
2023-10-14 15:37:24,541:INFO:Defining folds
2023-10-14 15:37:24,541:INFO:Declaring metric variables
2023-10-14 15:37:24,544:INFO:Importing untrained model
2023-10-14 15:37:24,551:INFO:Least Angle Regression Imported successfully
2023-10-14 15:37:24,559:INFO:Starting cross validation
2023-10-14 15:37:24,560:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:24,668:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 15:37:24,692:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.136e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-14 15:37:24,693:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.733e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-14 15:37:24,693:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.633e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-14 15:37:24,710:INFO:Calculating mean and std
2023-10-14 15:37:24,711:INFO:Creating metrics dataframe
2023-10-14 15:37:24,714:INFO:Uploading results into container
2023-10-14 15:37:24,715:INFO:Uploading model into container now
2023-10-14 15:37:24,716:INFO:_master_model_container: 5
2023-10-14 15:37:24,716:INFO:_display_container: 2
2023-10-14 15:37:24,716:INFO:Lars(random_state=123)
2023-10-14 15:37:24,716:INFO:create_model() successfully completed......................................
2023-10-14 15:37:24,848:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:24,848:INFO:Creating metrics dataframe
2023-10-14 15:37:24,855:INFO:Initializing Lasso Least Angle Regression
2023-10-14 15:37:24,855:INFO:Total runtime is 0.1324690620104472 minutes
2023-10-14 15:37:24,857:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:24,858:INFO:Initializing create_model()
2023-10-14 15:37:24,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:24,858:INFO:Checking exceptions
2023-10-14 15:37:24,858:INFO:Importing libraries
2023-10-14 15:37:24,858:INFO:Copying training dataset
2023-10-14 15:37:24,864:INFO:Defining folds
2023-10-14 15:37:24,864:INFO:Declaring metric variables
2023-10-14 15:37:24,868:INFO:Importing untrained model
2023-10-14 15:37:24,872:INFO:Lasso Least Angle Regression Imported successfully
2023-10-14 15:37:24,878:INFO:Starting cross validation
2023-10-14 15:37:24,880:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:24,939:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 15:37:24,950:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 15:37:24,954:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 15:37:24,976:INFO:Calculating mean and std
2023-10-14 15:37:24,977:INFO:Creating metrics dataframe
2023-10-14 15:37:24,979:INFO:Uploading results into container
2023-10-14 15:37:24,980:INFO:Uploading model into container now
2023-10-14 15:37:24,980:INFO:_master_model_container: 6
2023-10-14 15:37:24,980:INFO:_display_container: 2
2023-10-14 15:37:24,981:INFO:LassoLars(random_state=123)
2023-10-14 15:37:24,981:INFO:create_model() successfully completed......................................
2023-10-14 15:37:25,106:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:25,106:INFO:Creating metrics dataframe
2023-10-14 15:37:25,116:INFO:Initializing Orthogonal Matching Pursuit
2023-10-14 15:37:25,116:INFO:Total runtime is 0.1368171532948812 minutes
2023-10-14 15:37:25,120:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:25,121:INFO:Initializing create_model()
2023-10-14 15:37:25,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:25,121:INFO:Checking exceptions
2023-10-14 15:37:25,121:INFO:Importing libraries
2023-10-14 15:37:25,121:INFO:Copying training dataset
2023-10-14 15:37:25,125:INFO:Defining folds
2023-10-14 15:37:25,125:INFO:Declaring metric variables
2023-10-14 15:37:25,130:INFO:Importing untrained model
2023-10-14 15:37:25,134:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-14 15:37:25,140:INFO:Starting cross validation
2023-10-14 15:37:25,142:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:25,204:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 15:37:25,218:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 15:37:25,228:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 15:37:25,251:INFO:Calculating mean and std
2023-10-14 15:37:25,252:INFO:Creating metrics dataframe
2023-10-14 15:37:25,255:INFO:Uploading results into container
2023-10-14 15:37:25,255:INFO:Uploading model into container now
2023-10-14 15:37:25,255:INFO:_master_model_container: 7
2023-10-14 15:37:25,255:INFO:_display_container: 2
2023-10-14 15:37:25,256:INFO:OrthogonalMatchingPursuit()
2023-10-14 15:37:25,256:INFO:create_model() successfully completed......................................
2023-10-14 15:37:25,385:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:25,385:INFO:Creating metrics dataframe
2023-10-14 15:37:25,394:INFO:Initializing Bayesian Ridge
2023-10-14 15:37:25,395:INFO:Total runtime is 0.14146052996317546 minutes
2023-10-14 15:37:25,399:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:25,399:INFO:Initializing create_model()
2023-10-14 15:37:25,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:25,399:INFO:Checking exceptions
2023-10-14 15:37:25,400:INFO:Importing libraries
2023-10-14 15:37:25,400:INFO:Copying training dataset
2023-10-14 15:37:25,405:INFO:Defining folds
2023-10-14 15:37:25,405:INFO:Declaring metric variables
2023-10-14 15:37:25,408:INFO:Importing untrained model
2023-10-14 15:37:25,413:INFO:Bayesian Ridge Imported successfully
2023-10-14 15:37:25,420:INFO:Starting cross validation
2023-10-14 15:37:25,422:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:25,517:INFO:Calculating mean and std
2023-10-14 15:37:25,518:INFO:Creating metrics dataframe
2023-10-14 15:37:25,521:INFO:Uploading results into container
2023-10-14 15:37:25,521:INFO:Uploading model into container now
2023-10-14 15:37:25,521:INFO:_master_model_container: 8
2023-10-14 15:37:25,521:INFO:_display_container: 2
2023-10-14 15:37:25,522:INFO:BayesianRidge()
2023-10-14 15:37:25,522:INFO:create_model() successfully completed......................................
2023-10-14 15:37:25,650:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:25,650:INFO:Creating metrics dataframe
2023-10-14 15:37:25,658:INFO:Initializing Passive Aggressive Regressor
2023-10-14 15:37:25,658:INFO:Total runtime is 0.14583985408147176 minutes
2023-10-14 15:37:25,662:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:25,663:INFO:Initializing create_model()
2023-10-14 15:37:25,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:25,663:INFO:Checking exceptions
2023-10-14 15:37:25,663:INFO:Importing libraries
2023-10-14 15:37:25,663:INFO:Copying training dataset
2023-10-14 15:37:25,669:INFO:Defining folds
2023-10-14 15:37:25,670:INFO:Declaring metric variables
2023-10-14 15:37:25,673:INFO:Importing untrained model
2023-10-14 15:37:25,677:INFO:Passive Aggressive Regressor Imported successfully
2023-10-14 15:37:25,684:INFO:Starting cross validation
2023-10-14 15:37:25,685:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:25,799:INFO:Calculating mean and std
2023-10-14 15:37:25,800:INFO:Creating metrics dataframe
2023-10-14 15:37:25,802:INFO:Uploading results into container
2023-10-14 15:37:25,802:INFO:Uploading model into container now
2023-10-14 15:37:25,803:INFO:_master_model_container: 9
2023-10-14 15:37:25,803:INFO:_display_container: 2
2023-10-14 15:37:25,803:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-14 15:37:25,803:INFO:create_model() successfully completed......................................
2023-10-14 15:37:25,926:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:25,926:INFO:Creating metrics dataframe
2023-10-14 15:37:25,935:INFO:Initializing Huber Regressor
2023-10-14 15:37:25,935:INFO:Total runtime is 0.15046096642812093 minutes
2023-10-14 15:37:25,940:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:25,940:INFO:Initializing create_model()
2023-10-14 15:37:25,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:25,940:INFO:Checking exceptions
2023-10-14 15:37:25,940:INFO:Importing libraries
2023-10-14 15:37:25,940:INFO:Copying training dataset
2023-10-14 15:37:25,945:INFO:Defining folds
2023-10-14 15:37:25,945:INFO:Declaring metric variables
2023-10-14 15:37:25,949:INFO:Importing untrained model
2023-10-14 15:37:25,953:INFO:Huber Regressor Imported successfully
2023-10-14 15:37:25,958:INFO:Starting cross validation
2023-10-14 15:37:25,960:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:26,056:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 15:37:26,061:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 15:37:26,078:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 15:37:26,098:INFO:Calculating mean and std
2023-10-14 15:37:26,099:INFO:Creating metrics dataframe
2023-10-14 15:37:26,102:INFO:Uploading results into container
2023-10-14 15:37:26,103:INFO:Uploading model into container now
2023-10-14 15:37:26,103:INFO:_master_model_container: 10
2023-10-14 15:37:26,103:INFO:_display_container: 2
2023-10-14 15:37:26,104:INFO:HuberRegressor()
2023-10-14 15:37:26,104:INFO:create_model() successfully completed......................................
2023-10-14 15:37:26,231:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:26,231:INFO:Creating metrics dataframe
2023-10-14 15:37:26,239:INFO:Initializing K Neighbors Regressor
2023-10-14 15:37:26,239:INFO:Total runtime is 0.15552481015523276 minutes
2023-10-14 15:37:26,241:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:26,241:INFO:Initializing create_model()
2023-10-14 15:37:26,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:26,241:INFO:Checking exceptions
2023-10-14 15:37:26,242:INFO:Importing libraries
2023-10-14 15:37:26,242:INFO:Copying training dataset
2023-10-14 15:37:26,247:INFO:Defining folds
2023-10-14 15:37:26,247:INFO:Declaring metric variables
2023-10-14 15:37:26,250:INFO:Importing untrained model
2023-10-14 15:37:26,254:INFO:K Neighbors Regressor Imported successfully
2023-10-14 15:37:26,261:INFO:Starting cross validation
2023-10-14 15:37:26,263:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:26,458:INFO:Calculating mean and std
2023-10-14 15:37:26,460:INFO:Creating metrics dataframe
2023-10-14 15:37:26,462:INFO:Uploading results into container
2023-10-14 15:37:26,463:INFO:Uploading model into container now
2023-10-14 15:37:26,463:INFO:_master_model_container: 11
2023-10-14 15:37:26,463:INFO:_display_container: 2
2023-10-14 15:37:26,464:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-14 15:37:26,464:INFO:create_model() successfully completed......................................
2023-10-14 15:37:26,587:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:26,587:INFO:Creating metrics dataframe
2023-10-14 15:37:26,597:INFO:Initializing Decision Tree Regressor
2023-10-14 15:37:26,597:INFO:Total runtime is 0.1614983638127645 minutes
2023-10-14 15:37:26,602:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:26,602:INFO:Initializing create_model()
2023-10-14 15:37:26,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:26,602:INFO:Checking exceptions
2023-10-14 15:37:26,602:INFO:Importing libraries
2023-10-14 15:37:26,602:INFO:Copying training dataset
2023-10-14 15:37:26,607:INFO:Defining folds
2023-10-14 15:37:26,607:INFO:Declaring metric variables
2023-10-14 15:37:26,611:INFO:Importing untrained model
2023-10-14 15:37:26,615:INFO:Decision Tree Regressor Imported successfully
2023-10-14 15:37:26,621:INFO:Starting cross validation
2023-10-14 15:37:26,622:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:26,764:INFO:Calculating mean and std
2023-10-14 15:37:26,765:INFO:Creating metrics dataframe
2023-10-14 15:37:26,768:INFO:Uploading results into container
2023-10-14 15:37:26,770:INFO:Uploading model into container now
2023-10-14 15:37:26,770:INFO:_master_model_container: 12
2023-10-14 15:37:26,771:INFO:_display_container: 2
2023-10-14 15:37:26,771:INFO:DecisionTreeRegressor(random_state=123)
2023-10-14 15:37:26,771:INFO:create_model() successfully completed......................................
2023-10-14 15:37:26,901:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:26,901:INFO:Creating metrics dataframe
2023-10-14 15:37:26,910:INFO:Initializing Random Forest Regressor
2023-10-14 15:37:26,910:INFO:Total runtime is 0.16672067244847616 minutes
2023-10-14 15:37:26,914:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:26,914:INFO:Initializing create_model()
2023-10-14 15:37:26,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:26,914:INFO:Checking exceptions
2023-10-14 15:37:26,914:INFO:Importing libraries
2023-10-14 15:37:26,915:INFO:Copying training dataset
2023-10-14 15:37:26,920:INFO:Defining folds
2023-10-14 15:37:26,920:INFO:Declaring metric variables
2023-10-14 15:37:26,923:INFO:Importing untrained model
2023-10-14 15:37:26,927:INFO:Random Forest Regressor Imported successfully
2023-10-14 15:37:26,935:INFO:Starting cross validation
2023-10-14 15:37:26,938:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:27,619:INFO:Calculating mean and std
2023-10-14 15:37:27,621:INFO:Creating metrics dataframe
2023-10-14 15:37:27,623:INFO:Uploading results into container
2023-10-14 15:37:27,624:INFO:Uploading model into container now
2023-10-14 15:37:27,624:INFO:_master_model_container: 13
2023-10-14 15:37:27,624:INFO:_display_container: 2
2023-10-14 15:37:27,624:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-14 15:37:27,625:INFO:create_model() successfully completed......................................
2023-10-14 15:37:27,753:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:27,753:INFO:Creating metrics dataframe
2023-10-14 15:37:27,770:INFO:Initializing Extra Trees Regressor
2023-10-14 15:37:27,770:INFO:Total runtime is 0.18103955189387003 minutes
2023-10-14 15:37:27,773:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:27,774:INFO:Initializing create_model()
2023-10-14 15:37:27,774:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:27,774:INFO:Checking exceptions
2023-10-14 15:37:27,774:INFO:Importing libraries
2023-10-14 15:37:27,774:INFO:Copying training dataset
2023-10-14 15:37:27,784:INFO:Defining folds
2023-10-14 15:37:27,784:INFO:Declaring metric variables
2023-10-14 15:37:27,788:INFO:Importing untrained model
2023-10-14 15:37:27,792:INFO:Extra Trees Regressor Imported successfully
2023-10-14 15:37:27,800:INFO:Starting cross validation
2023-10-14 15:37:27,801:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:28,411:INFO:Calculating mean and std
2023-10-14 15:37:28,412:INFO:Creating metrics dataframe
2023-10-14 15:37:28,415:INFO:Uploading results into container
2023-10-14 15:37:28,416:INFO:Uploading model into container now
2023-10-14 15:37:28,416:INFO:_master_model_container: 14
2023-10-14 15:37:28,416:INFO:_display_container: 2
2023-10-14 15:37:28,416:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-14 15:37:28,417:INFO:create_model() successfully completed......................................
2023-10-14 15:37:28,552:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:28,552:INFO:Creating metrics dataframe
2023-10-14 15:37:28,562:INFO:Initializing AdaBoost Regressor
2023-10-14 15:37:28,563:INFO:Total runtime is 0.19426631927490234 minutes
2023-10-14 15:37:28,565:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:28,566:INFO:Initializing create_model()
2023-10-14 15:37:28,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:28,566:INFO:Checking exceptions
2023-10-14 15:37:28,566:INFO:Importing libraries
2023-10-14 15:37:28,566:INFO:Copying training dataset
2023-10-14 15:37:28,570:INFO:Defining folds
2023-10-14 15:37:28,570:INFO:Declaring metric variables
2023-10-14 15:37:28,574:INFO:Importing untrained model
2023-10-14 15:37:28,578:INFO:AdaBoost Regressor Imported successfully
2023-10-14 15:37:28,585:INFO:Starting cross validation
2023-10-14 15:37:28,586:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:28,916:INFO:Calculating mean and std
2023-10-14 15:37:28,917:INFO:Creating metrics dataframe
2023-10-14 15:37:28,919:INFO:Uploading results into container
2023-10-14 15:37:28,920:INFO:Uploading model into container now
2023-10-14 15:37:28,920:INFO:_master_model_container: 15
2023-10-14 15:37:28,920:INFO:_display_container: 2
2023-10-14 15:37:28,920:INFO:AdaBoostRegressor(random_state=123)
2023-10-14 15:37:28,920:INFO:create_model() successfully completed......................................
2023-10-14 15:37:29,050:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:29,050:INFO:Creating metrics dataframe
2023-10-14 15:37:29,060:INFO:Initializing Gradient Boosting Regressor
2023-10-14 15:37:29,060:INFO:Total runtime is 0.2025416890780131 minutes
2023-10-14 15:37:29,064:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:29,065:INFO:Initializing create_model()
2023-10-14 15:37:29,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:29,065:INFO:Checking exceptions
2023-10-14 15:37:29,065:INFO:Importing libraries
2023-10-14 15:37:29,065:INFO:Copying training dataset
2023-10-14 15:37:29,069:INFO:Defining folds
2023-10-14 15:37:29,069:INFO:Declaring metric variables
2023-10-14 15:37:29,072:INFO:Importing untrained model
2023-10-14 15:37:29,075:INFO:Gradient Boosting Regressor Imported successfully
2023-10-14 15:37:29,082:INFO:Starting cross validation
2023-10-14 15:37:29,083:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:29,501:INFO:Calculating mean and std
2023-10-14 15:37:29,502:INFO:Creating metrics dataframe
2023-10-14 15:37:29,505:INFO:Uploading results into container
2023-10-14 15:37:29,505:INFO:Uploading model into container now
2023-10-14 15:37:29,505:INFO:_master_model_container: 16
2023-10-14 15:37:29,505:INFO:_display_container: 2
2023-10-14 15:37:29,506:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 15:37:29,506:INFO:create_model() successfully completed......................................
2023-10-14 15:37:29,627:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:29,628:INFO:Creating metrics dataframe
2023-10-14 15:37:29,637:INFO:Initializing Extreme Gradient Boosting
2023-10-14 15:37:29,638:INFO:Total runtime is 0.2121791362762451 minutes
2023-10-14 15:37:29,642:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:29,642:INFO:Initializing create_model()
2023-10-14 15:37:29,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:29,642:INFO:Checking exceptions
2023-10-14 15:37:29,642:INFO:Importing libraries
2023-10-14 15:37:29,642:INFO:Copying training dataset
2023-10-14 15:37:29,648:INFO:Defining folds
2023-10-14 15:37:29,648:INFO:Declaring metric variables
2023-10-14 15:37:29,651:INFO:Importing untrained model
2023-10-14 15:37:29,655:INFO:Extreme Gradient Boosting Imported successfully
2023-10-14 15:37:29,660:INFO:Starting cross validation
2023-10-14 15:37:29,662:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:29,934:INFO:Calculating mean and std
2023-10-14 15:37:29,935:INFO:Creating metrics dataframe
2023-10-14 15:37:29,938:INFO:Uploading results into container
2023-10-14 15:37:29,938:INFO:Uploading model into container now
2023-10-14 15:37:29,939:INFO:_master_model_container: 17
2023-10-14 15:37:29,939:INFO:_display_container: 2
2023-10-14 15:37:29,939:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2023-10-14 15:37:29,940:INFO:create_model() successfully completed......................................
2023-10-14 15:37:30,070:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:30,070:INFO:Creating metrics dataframe
2023-10-14 15:37:30,080:INFO:Initializing Light Gradient Boosting Machine
2023-10-14 15:37:30,080:INFO:Total runtime is 0.21954871416091917 minutes
2023-10-14 15:37:30,083:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:30,083:INFO:Initializing create_model()
2023-10-14 15:37:30,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:30,084:INFO:Checking exceptions
2023-10-14 15:37:30,084:INFO:Importing libraries
2023-10-14 15:37:30,084:INFO:Copying training dataset
2023-10-14 15:37:30,089:INFO:Defining folds
2023-10-14 15:37:30,089:INFO:Declaring metric variables
2023-10-14 15:37:30,092:INFO:Importing untrained model
2023-10-14 15:37:30,097:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-14 15:37:30,103:INFO:Starting cross validation
2023-10-14 15:37:30,105:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:30,433:INFO:Calculating mean and std
2023-10-14 15:37:30,435:INFO:Creating metrics dataframe
2023-10-14 15:37:30,440:INFO:Uploading results into container
2023-10-14 15:37:30,440:INFO:Uploading model into container now
2023-10-14 15:37:30,441:INFO:_master_model_container: 18
2023-10-14 15:37:30,441:INFO:_display_container: 2
2023-10-14 15:37:30,441:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-14 15:37:30,442:INFO:create_model() successfully completed......................................
2023-10-14 15:37:30,589:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:30,589:INFO:Creating metrics dataframe
2023-10-14 15:37:30,601:INFO:Initializing Dummy Regressor
2023-10-14 15:37:30,601:INFO:Total runtime is 0.22822581529617308 minutes
2023-10-14 15:37:30,604:INFO:SubProcess create_model() called ==================================
2023-10-14 15:37:30,604:INFO:Initializing create_model()
2023-10-14 15:37:30,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFD6B2F2B0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:30,604:INFO:Checking exceptions
2023-10-14 15:37:30,604:INFO:Importing libraries
2023-10-14 15:37:30,604:INFO:Copying training dataset
2023-10-14 15:37:30,610:INFO:Defining folds
2023-10-14 15:37:30,610:INFO:Declaring metric variables
2023-10-14 15:37:30,614:INFO:Importing untrained model
2023-10-14 15:37:30,618:INFO:Dummy Regressor Imported successfully
2023-10-14 15:37:30,625:INFO:Starting cross validation
2023-10-14 15:37:30,626:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 15:37:30,719:INFO:Calculating mean and std
2023-10-14 15:37:30,720:INFO:Creating metrics dataframe
2023-10-14 15:37:30,722:INFO:Uploading results into container
2023-10-14 15:37:30,723:INFO:Uploading model into container now
2023-10-14 15:37:30,723:INFO:_master_model_container: 19
2023-10-14 15:37:30,723:INFO:_display_container: 2
2023-10-14 15:37:30,724:INFO:DummyRegressor()
2023-10-14 15:37:30,724:INFO:create_model() successfully completed......................................
2023-10-14 15:37:30,847:INFO:SubProcess create_model() end ==================================
2023-10-14 15:37:30,847:INFO:Creating metrics dataframe
2023-10-14 15:37:30,868:INFO:Initializing create_model()
2023-10-14 15:37:30,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-14 15:37:30,869:INFO:Checking exceptions
2023-10-14 15:37:30,871:INFO:Importing libraries
2023-10-14 15:37:30,871:INFO:Copying training dataset
2023-10-14 15:37:30,874:INFO:Defining folds
2023-10-14 15:37:30,874:INFO:Declaring metric variables
2023-10-14 15:37:30,874:INFO:Importing untrained model
2023-10-14 15:37:30,874:INFO:Declaring custom model
2023-10-14 15:37:30,875:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-14 15:37:30,875:INFO:Cross validation set to False
2023-10-14 15:37:30,876:INFO:Fitting Model
2023-10-14 15:37:30,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2023-10-14 15:37:30,931:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-14 15:37:30,931:INFO:[LightGBM] [Info] Total Bins 812
2023-10-14 15:37:30,931:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 23
2023-10-14 15:37:30,932:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-14 15:37:30,990:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-14 15:37:30,990:INFO:create_model() successfully completed......................................
2023-10-14 15:37:31,174:INFO:_master_model_container: 19
2023-10-14 15:37:31,175:INFO:_display_container: 2
2023-10-14 15:37:31,175:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-14 15:37:31,175:INFO:compare_models() successfully completed......................................
2023-10-14 15:38:44,374:INFO:Initializing predict_model()
2023-10-14 15:38:44,375:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEB2941F0>)
2023-10-14 15:38:44,375:INFO:Checking exceptions
2023-10-14 15:38:44,375:INFO:Preloading libraries
2023-10-14 15:43:16,553:INFO:Initializing predict_model()
2023-10-14 15:43:16,553:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEB1D1870>)
2023-10-14 15:43:16,553:INFO:Checking exceptions
2023-10-14 15:43:16,553:INFO:Preloading libraries
2023-10-14 15:43:16,556:INFO:Set up data.
2023-10-14 15:43:16,565:INFO:Set up index.
2023-10-14 15:43:52,883:INFO:Initializing predict_model()
2023-10-14 15:43:52,883:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFC0A1D240>)
2023-10-14 15:43:52,884:INFO:Checking exceptions
2023-10-14 15:43:52,884:INFO:Preloading libraries
2023-10-14 15:43:52,886:INFO:Set up data.
2023-10-14 15:43:52,893:INFO:Set up index.
2023-10-14 15:44:15,037:INFO:Initializing predict_model()
2023-10-14 15:44:15,037:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEBF5AEF0>)
2023-10-14 15:44:15,037:INFO:Checking exceptions
2023-10-14 15:44:15,037:INFO:Preloading libraries
2023-10-14 15:44:15,039:INFO:Set up data.
2023-10-14 15:44:15,048:INFO:Set up index.
2023-10-14 15:45:00,696:INFO:Initializing predict_model()
2023-10-14 15:45:00,696:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEBF5B9A0>)
2023-10-14 15:45:00,696:INFO:Checking exceptions
2023-10-14 15:45:00,696:INFO:Preloading libraries
2023-10-14 15:45:00,698:INFO:Set up data.
2023-10-14 15:45:00,706:INFO:Set up index.
2023-10-14 15:46:28,144:INFO:Initializing predict_model()
2023-10-14 15:46:28,144:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEC0BBAC0>)
2023-10-14 15:46:28,144:INFO:Checking exceptions
2023-10-14 15:46:28,144:INFO:Preloading libraries
2023-10-14 15:46:28,147:INFO:Set up data.
2023-10-14 15:46:28,152:INFO:Set up index.
2023-10-14 15:47:03,571:INFO:Initializing predict_model()
2023-10-14 15:47:03,571:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEB8DF640>)
2023-10-14 15:47:03,571:INFO:Checking exceptions
2023-10-14 15:47:03,572:INFO:Preloading libraries
2023-10-14 15:47:03,573:INFO:Set up data.
2023-10-14 15:47:03,580:INFO:Set up index.
2023-10-14 15:47:30,662:INFO:Initializing predict_model()
2023-10-14 15:47:30,662:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEC0B8820>)
2023-10-14 15:47:30,664:INFO:Checking exceptions
2023-10-14 15:47:30,664:INFO:Preloading libraries
2023-10-14 15:47:30,667:INFO:Set up data.
2023-10-14 15:47:30,674:INFO:Set up index.
2023-10-14 15:47:46,650:INFO:Initializing predict_model()
2023-10-14 15:47:46,650:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEE79CE50>)
2023-10-14 15:47:46,650:INFO:Checking exceptions
2023-10-14 15:47:46,650:INFO:Preloading libraries
2023-10-14 15:47:46,654:INFO:Set up data.
2023-10-14 15:47:46,661:INFO:Set up index.
2023-10-14 15:50:25,792:INFO:Initializing predict_model()
2023-10-14 15:50:25,792:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEF2720E0>)
2023-10-14 15:50:25,792:INFO:Checking exceptions
2023-10-14 15:50:25,793:INFO:Preloading libraries
2023-10-14 15:50:25,796:INFO:Set up data.
2023-10-14 15:50:25,806:INFO:Set up index.
2023-10-14 15:51:56,995:WARNING:C:\Users\manue\AppData\Local\Temp\ipykernel_1612\2913609534.py:7: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy


2023-10-14 15:52:38,944:INFO:Initializing predict_model()
2023-10-14 15:52:38,944:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFD9FABC40>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEE7A6440>)
2023-10-14 15:52:38,944:INFO:Checking exceptions
2023-10-14 15:52:38,944:INFO:Preloading libraries
2023-10-14 15:52:38,946:INFO:Set up data.
2023-10-14 15:52:38,956:INFO:Set up index.
2023-10-14 16:03:44,119:WARNING:C:\Users\manue\AppData\Local\Temp\ipykernel_1612\2913609534.py:7: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy


2023-10-14 16:04:42,259:INFO:PyCaret RegressionExperiment
2023-10-14 16:04:42,260:INFO:Logging name: reg-default-name
2023-10-14 16:04:42,260:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-14 16:04:42,260:INFO:version 3.1.0
2023-10-14 16:04:42,260:INFO:Initializing setup()
2023-10-14 16:04:42,260:INFO:self.USI: e8cf
2023-10-14 16:04:42,260:INFO:self._variable_keys: {'exp_id', 'seed', 'idx', 'html_param', 'fold_shuffle_param', 'log_plots_param', 'logging_param', '_available_plots', 'gpu_param', 'y', 'y_train', 'y_test', 'target_param', 'memory', 'transform_target_param', 'X_train', 'X_test', 'fold_groups_param', '_ml_usecase', 'data', 'X', 'pipeline', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'gpu_n_jobs_param', 'USI'}
2023-10-14 16:04:42,260:INFO:Checking environment
2023-10-14 16:04:42,261:INFO:python_version: 3.10.6
2023-10-14 16:04:42,261:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-14 16:04:42,261:INFO:machine: AMD64
2023-10-14 16:04:42,261:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-14 16:04:42,261:INFO:Memory: svmem(total=8273383424, available=1312530432, percent=84.1, used=6960852992, free=1312530432)
2023-10-14 16:04:42,261:INFO:Physical Core: 4
2023-10-14 16:04:42,261:INFO:Logical Core: 8
2023-10-14 16:04:42,261:INFO:Checking libraries
2023-10-14 16:04:42,262:INFO:System:
2023-10-14 16:04:42,262:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-14 16:04:42,262:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-14 16:04:42,262:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-14 16:04:42,262:INFO:PyCaret required dependencies:
2023-10-14 16:04:42,262:INFO:                 pip: 22.2.1
2023-10-14 16:04:42,262:INFO:          setuptools: 63.2.0
2023-10-14 16:04:42,262:INFO:             pycaret: 3.1.0
2023-10-14 16:04:42,262:INFO:             IPython: 8.4.0
2023-10-14 16:04:42,262:INFO:          ipywidgets: 8.1.1
2023-10-14 16:04:42,262:INFO:                tqdm: 4.66.1
2023-10-14 16:04:42,262:INFO:               numpy: 1.23.2
2023-10-14 16:04:42,262:INFO:              pandas: 1.4.3
2023-10-14 16:04:42,262:INFO:              jinja2: 3.1.2
2023-10-14 16:04:42,262:INFO:               scipy: 1.10.1
2023-10-14 16:04:42,262:INFO:              joblib: 1.2.0
2023-10-14 16:04:42,262:INFO:             sklearn: 1.1.2
2023-10-14 16:04:42,262:INFO:                pyod: 1.1.0
2023-10-14 16:04:42,262:INFO:            imblearn: 0.11.0
2023-10-14 16:04:42,262:INFO:   category_encoders: 2.6.2
2023-10-14 16:04:42,262:INFO:            lightgbm: 4.1.0
2023-10-14 16:04:42,262:INFO:               numba: 0.58.0
2023-10-14 16:04:42,262:INFO:            requests: 2.28.1
2023-10-14 16:04:42,262:INFO:          matplotlib: 3.6.0
2023-10-14 16:04:42,262:INFO:          scikitplot: 0.3.7
2023-10-14 16:04:42,262:INFO:         yellowbrick: 1.5
2023-10-14 16:04:42,262:INFO:              plotly: 5.17.0
2023-10-14 16:04:42,262:INFO:    plotly-resampler: Not installed
2023-10-14 16:04:42,262:INFO:             kaleido: 0.2.1
2023-10-14 16:04:42,262:INFO:           schemdraw: 0.15
2023-10-14 16:04:42,262:INFO:         statsmodels: 0.13.2
2023-10-14 16:04:42,262:INFO:              sktime: 0.21.1
2023-10-14 16:04:42,262:INFO:               tbats: 1.1.3
2023-10-14 16:04:42,262:INFO:            pmdarima: 2.0.3
2023-10-14 16:04:42,262:INFO:              psutil: 5.9.1
2023-10-14 16:04:42,262:INFO:          markupsafe: 2.1.1
2023-10-14 16:04:42,263:INFO:             pickle5: Not installed
2023-10-14 16:04:42,263:INFO:         cloudpickle: 2.2.1
2023-10-14 16:04:42,263:INFO:         deprecation: 2.1.0
2023-10-14 16:04:42,263:INFO:              xxhash: 3.4.1
2023-10-14 16:04:42,263:INFO:           wurlitzer: Not installed
2023-10-14 16:04:42,263:INFO:PyCaret optional dependencies:
2023-10-14 16:04:42,263:INFO:                shap: Not installed
2023-10-14 16:04:42,263:INFO:           interpret: Not installed
2023-10-14 16:04:42,263:INFO:                umap: Not installed
2023-10-14 16:04:42,263:INFO:     ydata_profiling: Not installed
2023-10-14 16:04:42,263:INFO:  explainerdashboard: Not installed
2023-10-14 16:04:42,263:INFO:             autoviz: Not installed
2023-10-14 16:04:42,263:INFO:           fairlearn: Not installed
2023-10-14 16:04:42,263:INFO:          deepchecks: Not installed
2023-10-14 16:04:42,263:INFO:             xgboost: 2.0.0
2023-10-14 16:04:42,263:INFO:            catboost: Not installed
2023-10-14 16:04:42,263:INFO:              kmodes: Not installed
2023-10-14 16:04:42,263:INFO:             mlxtend: Not installed
2023-10-14 16:04:42,263:INFO:       statsforecast: Not installed
2023-10-14 16:04:42,263:INFO:        tune_sklearn: Not installed
2023-10-14 16:04:42,263:INFO:                 ray: Not installed
2023-10-14 16:04:42,263:INFO:            hyperopt: Not installed
2023-10-14 16:04:42,263:INFO:              optuna: Not installed
2023-10-14 16:04:42,263:INFO:               skopt: Not installed
2023-10-14 16:04:42,263:INFO:              mlflow: Not installed
2023-10-14 16:04:42,263:INFO:              gradio: Not installed
2023-10-14 16:04:42,263:INFO:             fastapi: Not installed
2023-10-14 16:04:42,264:INFO:             uvicorn: Not installed
2023-10-14 16:04:42,264:INFO:              m2cgen: Not installed
2023-10-14 16:04:42,264:INFO:           evidently: Not installed
2023-10-14 16:04:42,264:INFO:               fugue: Not installed
2023-10-14 16:04:42,264:INFO:           streamlit: Not installed
2023-10-14 16:04:42,264:INFO:             prophet: Not installed
2023-10-14 16:04:42,264:INFO:None
2023-10-14 16:04:42,264:INFO:Set up data.
2023-10-14 16:04:42,270:INFO:Set up folding strategy.
2023-10-14 16:04:42,270:INFO:Set up train/test split.
2023-10-14 16:04:42,270:INFO:Set up data.
2023-10-14 16:04:42,275:INFO:Set up index.
2023-10-14 16:04:42,275:INFO:Assigning column types.
2023-10-14 16:04:42,279:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-14 16:04:42,279:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,284:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,288:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,375:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:42,379:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,383:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,388:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,474:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:42,477:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-14 16:04:42,481:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,485:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,578:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:42,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,690:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:42,692:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-14 16:04:42,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,787:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:42,796:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,882:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:42,885:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-14 16:04:42,939:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:42,977:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:42,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,035:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:43,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-14 16:04:43,075:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,078:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-14 16:04:43,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:43,173:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-14 16:04:43,269:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,272:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-14 16:04:43,365:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,458:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,462:INFO:Preparing preprocessing pipeline...
2023-10-14 16:04:43,462:INFO:Set up simple imputation.
2023-10-14 16:04:43,465:INFO:Set up encoding of categorical features.
2023-10-14 16:04:43,530:INFO:Finished creating preprocessing pipeline.
2023-10-14 16:04:43,535:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-10-14 16:04:43,535:INFO:Creating final display dataframe.
2023-10-14 16:04:43,683:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            demand
2                   Target type        Regression
3           Original data shape         (6006, 6)
4        Transformed data shape        (6006, 23)
5   Transformed train set shape        (5506, 23)
6    Transformed test set shape         (500, 23)
7              Numeric features                 3
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   TimeSeriesSplit
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              e8cf
2023-10-14 16:04:43,775:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,873:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-14 16:04:43,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-14 16:04:43,876:INFO:setup() successfully completed in 1.62s...............
2023-10-14 16:04:45,578:INFO:Initializing compare_models()
2023-10-14 16:04:45,578:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-14 16:04:45,579:INFO:Checking exceptions
2023-10-14 16:04:45,582:INFO:Preparing display monitor
2023-10-14 16:04:45,623:INFO:Initializing Linear Regression
2023-10-14 16:04:45,624:INFO:Total runtime is 1.7940998077392578e-05 minutes
2023-10-14 16:04:45,629:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:45,630:INFO:Initializing create_model()
2023-10-14 16:04:45,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:45,630:INFO:Checking exceptions
2023-10-14 16:04:45,630:INFO:Importing libraries
2023-10-14 16:04:45,631:INFO:Copying training dataset
2023-10-14 16:04:45,638:INFO:Defining folds
2023-10-14 16:04:45,638:INFO:Declaring metric variables
2023-10-14 16:04:45,644:INFO:Importing untrained model
2023-10-14 16:04:45,649:INFO:Linear Regression Imported successfully
2023-10-14 16:04:45,658:INFO:Starting cross validation
2023-10-14 16:04:45,660:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:54,380:INFO:Calculating mean and std
2023-10-14 16:04:54,385:INFO:Creating metrics dataframe
2023-10-14 16:04:54,393:INFO:Uploading results into container
2023-10-14 16:04:54,395:INFO:Uploading model into container now
2023-10-14 16:04:54,396:INFO:_master_model_container: 1
2023-10-14 16:04:54,397:INFO:_display_container: 2
2023-10-14 16:04:54,398:INFO:LinearRegression(n_jobs=-1)
2023-10-14 16:04:54,398:INFO:create_model() successfully completed......................................
2023-10-14 16:04:54,643:INFO:SubProcess create_model() end ==================================
2023-10-14 16:04:54,643:INFO:Creating metrics dataframe
2023-10-14 16:04:54,649:INFO:Initializing Lasso Regression
2023-10-14 16:04:54,649:INFO:Total runtime is 0.15043491919835408 minutes
2023-10-14 16:04:54,651:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:54,651:INFO:Initializing create_model()
2023-10-14 16:04:54,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:54,651:INFO:Checking exceptions
2023-10-14 16:04:54,653:INFO:Importing libraries
2023-10-14 16:04:54,653:INFO:Copying training dataset
2023-10-14 16:04:54,658:INFO:Defining folds
2023-10-14 16:04:54,658:INFO:Declaring metric variables
2023-10-14 16:04:54,662:INFO:Importing untrained model
2023-10-14 16:04:54,666:INFO:Lasso Regression Imported successfully
2023-10-14 16:04:54,674:INFO:Starting cross validation
2023-10-14 16:04:54,675:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:56,488:INFO:Calculating mean and std
2023-10-14 16:04:56,491:INFO:Creating metrics dataframe
2023-10-14 16:04:56,499:INFO:Uploading results into container
2023-10-14 16:04:56,500:INFO:Uploading model into container now
2023-10-14 16:04:56,501:INFO:_master_model_container: 2
2023-10-14 16:04:56,501:INFO:_display_container: 2
2023-10-14 16:04:56,502:INFO:Lasso(random_state=123)
2023-10-14 16:04:56,502:INFO:create_model() successfully completed......................................
2023-10-14 16:04:56,697:INFO:SubProcess create_model() end ==================================
2023-10-14 16:04:56,697:INFO:Creating metrics dataframe
2023-10-14 16:04:56,705:INFO:Initializing Ridge Regression
2023-10-14 16:04:56,705:INFO:Total runtime is 0.1847024917602539 minutes
2023-10-14 16:04:56,708:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:56,709:INFO:Initializing create_model()
2023-10-14 16:04:56,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:56,709:INFO:Checking exceptions
2023-10-14 16:04:56,709:INFO:Importing libraries
2023-10-14 16:04:56,710:INFO:Copying training dataset
2023-10-14 16:04:56,716:INFO:Defining folds
2023-10-14 16:04:56,716:INFO:Declaring metric variables
2023-10-14 16:04:56,720:INFO:Importing untrained model
2023-10-14 16:04:56,726:INFO:Ridge Regression Imported successfully
2023-10-14 16:04:56,733:INFO:Starting cross validation
2023-10-14 16:04:56,735:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:58,606:INFO:Calculating mean and std
2023-10-14 16:04:58,609:INFO:Creating metrics dataframe
2023-10-14 16:04:58,616:INFO:Uploading results into container
2023-10-14 16:04:58,617:INFO:Uploading model into container now
2023-10-14 16:04:58,617:INFO:_master_model_container: 3
2023-10-14 16:04:58,617:INFO:_display_container: 2
2023-10-14 16:04:58,618:INFO:Ridge(random_state=123)
2023-10-14 16:04:58,618:INFO:create_model() successfully completed......................................
2023-10-14 16:04:58,841:INFO:SubProcess create_model() end ==================================
2023-10-14 16:04:58,841:INFO:Creating metrics dataframe
2023-10-14 16:04:58,849:INFO:Initializing Elastic Net
2023-10-14 16:04:58,850:INFO:Total runtime is 0.22044442494710287 minutes
2023-10-14 16:04:58,855:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:58,856:INFO:Initializing create_model()
2023-10-14 16:04:58,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:58,856:INFO:Checking exceptions
2023-10-14 16:04:58,857:INFO:Importing libraries
2023-10-14 16:04:58,857:INFO:Copying training dataset
2023-10-14 16:04:58,862:INFO:Defining folds
2023-10-14 16:04:58,862:INFO:Declaring metric variables
2023-10-14 16:04:58,864:INFO:Importing untrained model
2023-10-14 16:04:58,867:INFO:Elastic Net Imported successfully
2023-10-14 16:04:58,875:INFO:Starting cross validation
2023-10-14 16:04:58,877:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:58,971:INFO:Calculating mean and std
2023-10-14 16:04:58,973:INFO:Creating metrics dataframe
2023-10-14 16:04:58,977:INFO:Uploading results into container
2023-10-14 16:04:58,977:INFO:Uploading model into container now
2023-10-14 16:04:58,977:INFO:_master_model_container: 4
2023-10-14 16:04:58,977:INFO:_display_container: 2
2023-10-14 16:04:58,978:INFO:ElasticNet(random_state=123)
2023-10-14 16:04:58,978:INFO:create_model() successfully completed......................................
2023-10-14 16:04:59,127:INFO:SubProcess create_model() end ==================================
2023-10-14 16:04:59,127:INFO:Creating metrics dataframe
2023-10-14 16:04:59,136:INFO:Initializing Least Angle Regression
2023-10-14 16:04:59,136:INFO:Total runtime is 0.22521491448084513 minutes
2023-10-14 16:04:59,140:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:59,140:INFO:Initializing create_model()
2023-10-14 16:04:59,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:59,141:INFO:Checking exceptions
2023-10-14 16:04:59,141:INFO:Importing libraries
2023-10-14 16:04:59,141:INFO:Copying training dataset
2023-10-14 16:04:59,145:INFO:Defining folds
2023-10-14 16:04:59,146:INFO:Declaring metric variables
2023-10-14 16:04:59,149:INFO:Importing untrained model
2023-10-14 16:04:59,152:INFO:Least Angle Regression Imported successfully
2023-10-14 16:04:59,158:INFO:Starting cross validation
2023-10-14 16:04:59,159:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:59,251:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:04:59,253:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:04:59,271:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.736e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-14 16:04:59,294:INFO:Calculating mean and std
2023-10-14 16:04:59,295:INFO:Creating metrics dataframe
2023-10-14 16:04:59,297:INFO:Uploading results into container
2023-10-14 16:04:59,298:INFO:Uploading model into container now
2023-10-14 16:04:59,298:INFO:_master_model_container: 5
2023-10-14 16:04:59,298:INFO:_display_container: 2
2023-10-14 16:04:59,299:INFO:Lars(random_state=123)
2023-10-14 16:04:59,299:INFO:create_model() successfully completed......................................
2023-10-14 16:04:59,448:INFO:SubProcess create_model() end ==================================
2023-10-14 16:04:59,448:INFO:Creating metrics dataframe
2023-10-14 16:04:59,456:INFO:Initializing Lasso Least Angle Regression
2023-10-14 16:04:59,456:INFO:Total runtime is 0.23054303328196207 minutes
2023-10-14 16:04:59,459:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:59,460:INFO:Initializing create_model()
2023-10-14 16:04:59,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:59,460:INFO:Checking exceptions
2023-10-14 16:04:59,460:INFO:Importing libraries
2023-10-14 16:04:59,460:INFO:Copying training dataset
2023-10-14 16:04:59,465:INFO:Defining folds
2023-10-14 16:04:59,465:INFO:Declaring metric variables
2023-10-14 16:04:59,468:INFO:Importing untrained model
2023-10-14 16:04:59,473:INFO:Lasso Least Angle Regression Imported successfully
2023-10-14 16:04:59,480:INFO:Starting cross validation
2023-10-14 16:04:59,481:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:59,533:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 16:04:59,539:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 16:04:59,552:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 16:04:59,570:INFO:Calculating mean and std
2023-10-14 16:04:59,572:INFO:Creating metrics dataframe
2023-10-14 16:04:59,575:INFO:Uploading results into container
2023-10-14 16:04:59,576:INFO:Uploading model into container now
2023-10-14 16:04:59,576:INFO:_master_model_container: 6
2023-10-14 16:04:59,576:INFO:_display_container: 2
2023-10-14 16:04:59,577:INFO:LassoLars(random_state=123)
2023-10-14 16:04:59,577:INFO:create_model() successfully completed......................................
2023-10-14 16:04:59,726:INFO:SubProcess create_model() end ==================================
2023-10-14 16:04:59,726:INFO:Creating metrics dataframe
2023-10-14 16:04:59,735:INFO:Initializing Orthogonal Matching Pursuit
2023-10-14 16:04:59,735:INFO:Total runtime is 0.23520137866338095 minutes
2023-10-14 16:04:59,739:INFO:SubProcess create_model() called ==================================
2023-10-14 16:04:59,739:INFO:Initializing create_model()
2023-10-14 16:04:59,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:04:59,740:INFO:Checking exceptions
2023-10-14 16:04:59,740:INFO:Importing libraries
2023-10-14 16:04:59,740:INFO:Copying training dataset
2023-10-14 16:04:59,746:INFO:Defining folds
2023-10-14 16:04:59,746:INFO:Declaring metric variables
2023-10-14 16:04:59,748:INFO:Importing untrained model
2023-10-14 16:04:59,752:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-14 16:04:59,758:INFO:Starting cross validation
2023-10-14 16:04:59,760:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:04:59,813:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:04:59,815:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:04:59,829:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:04:59,850:INFO:Calculating mean and std
2023-10-14 16:04:59,851:INFO:Creating metrics dataframe
2023-10-14 16:04:59,854:INFO:Uploading results into container
2023-10-14 16:04:59,854:INFO:Uploading model into container now
2023-10-14 16:04:59,855:INFO:_master_model_container: 7
2023-10-14 16:04:59,855:INFO:_display_container: 2
2023-10-14 16:04:59,855:INFO:OrthogonalMatchingPursuit()
2023-10-14 16:04:59,855:INFO:create_model() successfully completed......................................
2023-10-14 16:05:00,002:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:00,002:INFO:Creating metrics dataframe
2023-10-14 16:05:00,015:INFO:Initializing Bayesian Ridge
2023-10-14 16:05:00,015:INFO:Total runtime is 0.23986813624699913 minutes
2023-10-14 16:05:00,020:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:00,020:INFO:Initializing create_model()
2023-10-14 16:05:00,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:00,020:INFO:Checking exceptions
2023-10-14 16:05:00,020:INFO:Importing libraries
2023-10-14 16:05:00,020:INFO:Copying training dataset
2023-10-14 16:05:00,029:INFO:Defining folds
2023-10-14 16:05:00,029:INFO:Declaring metric variables
2023-10-14 16:05:00,031:INFO:Importing untrained model
2023-10-14 16:05:00,036:INFO:Bayesian Ridge Imported successfully
2023-10-14 16:05:00,044:INFO:Starting cross validation
2023-10-14 16:05:00,045:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:00,132:INFO:Calculating mean and std
2023-10-14 16:05:00,133:INFO:Creating metrics dataframe
2023-10-14 16:05:00,136:INFO:Uploading results into container
2023-10-14 16:05:00,136:INFO:Uploading model into container now
2023-10-14 16:05:00,136:INFO:_master_model_container: 8
2023-10-14 16:05:00,137:INFO:_display_container: 2
2023-10-14 16:05:00,137:INFO:BayesianRidge()
2023-10-14 16:05:00,137:INFO:create_model() successfully completed......................................
2023-10-14 16:05:00,283:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:00,284:INFO:Creating metrics dataframe
2023-10-14 16:05:00,293:INFO:Initializing Passive Aggressive Regressor
2023-10-14 16:05:00,293:INFO:Total runtime is 0.24449683030446373 minutes
2023-10-14 16:05:00,297:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:00,298:INFO:Initializing create_model()
2023-10-14 16:05:00,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:00,298:INFO:Checking exceptions
2023-10-14 16:05:00,298:INFO:Importing libraries
2023-10-14 16:05:00,298:INFO:Copying training dataset
2023-10-14 16:05:00,304:INFO:Defining folds
2023-10-14 16:05:00,304:INFO:Declaring metric variables
2023-10-14 16:05:00,308:INFO:Importing untrained model
2023-10-14 16:05:00,311:INFO:Passive Aggressive Regressor Imported successfully
2023-10-14 16:05:00,316:INFO:Starting cross validation
2023-10-14 16:05:00,318:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:00,422:INFO:Calculating mean and std
2023-10-14 16:05:00,423:INFO:Creating metrics dataframe
2023-10-14 16:05:00,426:INFO:Uploading results into container
2023-10-14 16:05:00,427:INFO:Uploading model into container now
2023-10-14 16:05:00,427:INFO:_master_model_container: 9
2023-10-14 16:05:00,427:INFO:_display_container: 2
2023-10-14 16:05:00,427:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-14 16:05:00,427:INFO:create_model() successfully completed......................................
2023-10-14 16:05:00,576:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:00,576:INFO:Creating metrics dataframe
2023-10-14 16:05:00,587:INFO:Initializing Huber Regressor
2023-10-14 16:05:00,587:INFO:Total runtime is 0.24939458370208742 minutes
2023-10-14 16:05:00,592:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:00,592:INFO:Initializing create_model()
2023-10-14 16:05:00,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:00,592:INFO:Checking exceptions
2023-10-14 16:05:00,592:INFO:Importing libraries
2023-10-14 16:05:00,592:INFO:Copying training dataset
2023-10-14 16:05:00,596:INFO:Defining folds
2023-10-14 16:05:00,597:INFO:Declaring metric variables
2023-10-14 16:05:00,601:INFO:Importing untrained model
2023-10-14 16:05:00,605:INFO:Huber Regressor Imported successfully
2023-10-14 16:05:00,612:INFO:Starting cross validation
2023-10-14 16:05:00,612:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:00,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 16:05:00,714:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 16:05:00,721:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 16:05:00,741:INFO:Calculating mean and std
2023-10-14 16:05:00,743:INFO:Creating metrics dataframe
2023-10-14 16:05:00,746:INFO:Uploading results into container
2023-10-14 16:05:00,746:INFO:Uploading model into container now
2023-10-14 16:05:00,746:INFO:_master_model_container: 10
2023-10-14 16:05:00,746:INFO:_display_container: 2
2023-10-14 16:05:00,747:INFO:HuberRegressor()
2023-10-14 16:05:00,747:INFO:create_model() successfully completed......................................
2023-10-14 16:05:00,896:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:00,896:INFO:Creating metrics dataframe
2023-10-14 16:05:00,906:INFO:Initializing K Neighbors Regressor
2023-10-14 16:05:00,906:INFO:Total runtime is 0.2547199924786886 minutes
2023-10-14 16:05:00,909:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:00,910:INFO:Initializing create_model()
2023-10-14 16:05:00,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:00,910:INFO:Checking exceptions
2023-10-14 16:05:00,910:INFO:Importing libraries
2023-10-14 16:05:00,910:INFO:Copying training dataset
2023-10-14 16:05:00,915:INFO:Defining folds
2023-10-14 16:05:00,915:INFO:Declaring metric variables
2023-10-14 16:05:00,919:INFO:Importing untrained model
2023-10-14 16:05:00,925:INFO:K Neighbors Regressor Imported successfully
2023-10-14 16:05:00,930:INFO:Starting cross validation
2023-10-14 16:05:00,931:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:01,105:INFO:Calculating mean and std
2023-10-14 16:05:01,106:INFO:Creating metrics dataframe
2023-10-14 16:05:01,109:INFO:Uploading results into container
2023-10-14 16:05:01,109:INFO:Uploading model into container now
2023-10-14 16:05:01,109:INFO:_master_model_container: 11
2023-10-14 16:05:01,109:INFO:_display_container: 2
2023-10-14 16:05:01,110:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-14 16:05:01,110:INFO:create_model() successfully completed......................................
2023-10-14 16:05:01,266:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:01,266:INFO:Creating metrics dataframe
2023-10-14 16:05:01,280:INFO:Initializing Decision Tree Regressor
2023-10-14 16:05:01,280:INFO:Total runtime is 0.2609464486440023 minutes
2023-10-14 16:05:01,283:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:01,283:INFO:Initializing create_model()
2023-10-14 16:05:01,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:01,283:INFO:Checking exceptions
2023-10-14 16:05:01,283:INFO:Importing libraries
2023-10-14 16:05:01,283:INFO:Copying training dataset
2023-10-14 16:05:01,290:INFO:Defining folds
2023-10-14 16:05:01,290:INFO:Declaring metric variables
2023-10-14 16:05:01,293:INFO:Importing untrained model
2023-10-14 16:05:01,297:INFO:Decision Tree Regressor Imported successfully
2023-10-14 16:05:01,304:INFO:Starting cross validation
2023-10-14 16:05:01,306:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:01,421:INFO:Calculating mean and std
2023-10-14 16:05:01,423:INFO:Creating metrics dataframe
2023-10-14 16:05:01,426:INFO:Uploading results into container
2023-10-14 16:05:01,426:INFO:Uploading model into container now
2023-10-14 16:05:01,427:INFO:_master_model_container: 12
2023-10-14 16:05:01,427:INFO:_display_container: 2
2023-10-14 16:05:01,427:INFO:DecisionTreeRegressor(random_state=123)
2023-10-14 16:05:01,427:INFO:create_model() successfully completed......................................
2023-10-14 16:05:01,578:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:01,578:INFO:Creating metrics dataframe
2023-10-14 16:05:01,589:INFO:Initializing Random Forest Regressor
2023-10-14 16:05:01,590:INFO:Total runtime is 0.266110368569692 minutes
2023-10-14 16:05:01,593:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:01,594:INFO:Initializing create_model()
2023-10-14 16:05:01,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:01,594:INFO:Checking exceptions
2023-10-14 16:05:01,594:INFO:Importing libraries
2023-10-14 16:05:01,594:INFO:Copying training dataset
2023-10-14 16:05:01,599:INFO:Defining folds
2023-10-14 16:05:01,600:INFO:Declaring metric variables
2023-10-14 16:05:01,604:INFO:Importing untrained model
2023-10-14 16:05:01,609:INFO:Random Forest Regressor Imported successfully
2023-10-14 16:05:01,628:INFO:Starting cross validation
2023-10-14 16:05:01,630:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:02,256:INFO:Calculating mean and std
2023-10-14 16:05:02,258:INFO:Creating metrics dataframe
2023-10-14 16:05:02,260:INFO:Uploading results into container
2023-10-14 16:05:02,261:INFO:Uploading model into container now
2023-10-14 16:05:02,261:INFO:_master_model_container: 13
2023-10-14 16:05:02,261:INFO:_display_container: 2
2023-10-14 16:05:02,262:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-14 16:05:02,262:INFO:create_model() successfully completed......................................
2023-10-14 16:05:02,414:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:02,415:INFO:Creating metrics dataframe
2023-10-14 16:05:02,426:INFO:Initializing Extra Trees Regressor
2023-10-14 16:05:02,426:INFO:Total runtime is 0.28004002571105957 minutes
2023-10-14 16:05:02,429:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:02,429:INFO:Initializing create_model()
2023-10-14 16:05:02,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:02,429:INFO:Checking exceptions
2023-10-14 16:05:02,430:INFO:Importing libraries
2023-10-14 16:05:02,430:INFO:Copying training dataset
2023-10-14 16:05:02,434:INFO:Defining folds
2023-10-14 16:05:02,434:INFO:Declaring metric variables
2023-10-14 16:05:02,438:INFO:Importing untrained model
2023-10-14 16:05:02,443:INFO:Extra Trees Regressor Imported successfully
2023-10-14 16:05:02,450:INFO:Starting cross validation
2023-10-14 16:05:02,451:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:03,028:INFO:Calculating mean and std
2023-10-14 16:05:03,029:INFO:Creating metrics dataframe
2023-10-14 16:05:03,031:INFO:Uploading results into container
2023-10-14 16:05:03,033:INFO:Uploading model into container now
2023-10-14 16:05:03,033:INFO:_master_model_container: 14
2023-10-14 16:05:03,033:INFO:_display_container: 2
2023-10-14 16:05:03,034:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-14 16:05:03,034:INFO:create_model() successfully completed......................................
2023-10-14 16:05:03,190:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:03,190:INFO:Creating metrics dataframe
2023-10-14 16:05:03,199:INFO:Initializing AdaBoost Regressor
2023-10-14 16:05:03,199:INFO:Total runtime is 0.29293705622355143 minutes
2023-10-14 16:05:03,201:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:03,201:INFO:Initializing create_model()
2023-10-14 16:05:03,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:03,201:INFO:Checking exceptions
2023-10-14 16:05:03,203:INFO:Importing libraries
2023-10-14 16:05:03,203:INFO:Copying training dataset
2023-10-14 16:05:03,208:INFO:Defining folds
2023-10-14 16:05:03,208:INFO:Declaring metric variables
2023-10-14 16:05:03,211:INFO:Importing untrained model
2023-10-14 16:05:03,215:INFO:AdaBoost Regressor Imported successfully
2023-10-14 16:05:03,223:INFO:Starting cross validation
2023-10-14 16:05:03,224:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:03,479:INFO:Calculating mean and std
2023-10-14 16:05:03,480:INFO:Creating metrics dataframe
2023-10-14 16:05:03,483:INFO:Uploading results into container
2023-10-14 16:05:03,484:INFO:Uploading model into container now
2023-10-14 16:05:03,484:INFO:_master_model_container: 15
2023-10-14 16:05:03,484:INFO:_display_container: 2
2023-10-14 16:05:03,484:INFO:AdaBoostRegressor(random_state=123)
2023-10-14 16:05:03,484:INFO:create_model() successfully completed......................................
2023-10-14 16:05:03,635:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:03,635:INFO:Creating metrics dataframe
2023-10-14 16:05:03,647:INFO:Initializing Gradient Boosting Regressor
2023-10-14 16:05:03,647:INFO:Total runtime is 0.3004001537958781 minutes
2023-10-14 16:05:03,650:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:03,650:INFO:Initializing create_model()
2023-10-14 16:05:03,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:03,650:INFO:Checking exceptions
2023-10-14 16:05:03,651:INFO:Importing libraries
2023-10-14 16:05:03,651:INFO:Copying training dataset
2023-10-14 16:05:03,655:INFO:Defining folds
2023-10-14 16:05:03,656:INFO:Declaring metric variables
2023-10-14 16:05:03,659:INFO:Importing untrained model
2023-10-14 16:05:03,663:INFO:Gradient Boosting Regressor Imported successfully
2023-10-14 16:05:03,669:INFO:Starting cross validation
2023-10-14 16:05:03,671:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:04,041:INFO:Calculating mean and std
2023-10-14 16:05:04,042:INFO:Creating metrics dataframe
2023-10-14 16:05:04,045:INFO:Uploading results into container
2023-10-14 16:05:04,045:INFO:Uploading model into container now
2023-10-14 16:05:04,045:INFO:_master_model_container: 16
2023-10-14 16:05:04,045:INFO:_display_container: 2
2023-10-14 16:05:04,046:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 16:05:04,046:INFO:create_model() successfully completed......................................
2023-10-14 16:05:04,196:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:04,196:INFO:Creating metrics dataframe
2023-10-14 16:05:04,206:INFO:Initializing Extreme Gradient Boosting
2023-10-14 16:05:04,206:INFO:Total runtime is 0.3097074031829834 minutes
2023-10-14 16:05:04,208:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:04,209:INFO:Initializing create_model()
2023-10-14 16:05:04,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:04,209:INFO:Checking exceptions
2023-10-14 16:05:04,209:INFO:Importing libraries
2023-10-14 16:05:04,209:INFO:Copying training dataset
2023-10-14 16:05:04,214:INFO:Defining folds
2023-10-14 16:05:04,214:INFO:Declaring metric variables
2023-10-14 16:05:04,217:INFO:Importing untrained model
2023-10-14 16:05:04,221:INFO:Extreme Gradient Boosting Imported successfully
2023-10-14 16:05:04,229:INFO:Starting cross validation
2023-10-14 16:05:04,230:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:04,515:INFO:Calculating mean and std
2023-10-14 16:05:04,516:INFO:Creating metrics dataframe
2023-10-14 16:05:04,519:INFO:Uploading results into container
2023-10-14 16:05:04,520:INFO:Uploading model into container now
2023-10-14 16:05:04,521:INFO:_master_model_container: 17
2023-10-14 16:05:04,521:INFO:_display_container: 2
2023-10-14 16:05:04,521:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2023-10-14 16:05:04,521:INFO:create_model() successfully completed......................................
2023-10-14 16:05:04,674:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:04,674:INFO:Creating metrics dataframe
2023-10-14 16:05:04,685:INFO:Initializing Light Gradient Boosting Machine
2023-10-14 16:05:04,685:INFO:Total runtime is 0.3176877776781718 minutes
2023-10-14 16:05:04,689:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:04,689:INFO:Initializing create_model()
2023-10-14 16:05:04,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:04,689:INFO:Checking exceptions
2023-10-14 16:05:04,689:INFO:Importing libraries
2023-10-14 16:05:04,690:INFO:Copying training dataset
2023-10-14 16:05:04,694:INFO:Defining folds
2023-10-14 16:05:04,695:INFO:Declaring metric variables
2023-10-14 16:05:04,697:INFO:Importing untrained model
2023-10-14 16:05:04,702:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-14 16:05:04,710:INFO:Starting cross validation
2023-10-14 16:05:04,711:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:05,004:INFO:Calculating mean and std
2023-10-14 16:05:05,006:INFO:Creating metrics dataframe
2023-10-14 16:05:05,011:INFO:Uploading results into container
2023-10-14 16:05:05,011:INFO:Uploading model into container now
2023-10-14 16:05:05,012:INFO:_master_model_container: 18
2023-10-14 16:05:05,012:INFO:_display_container: 2
2023-10-14 16:05:05,013:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-14 16:05:05,013:INFO:create_model() successfully completed......................................
2023-10-14 16:05:05,183:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:05,183:INFO:Creating metrics dataframe
2023-10-14 16:05:05,194:INFO:Initializing Dummy Regressor
2023-10-14 16:05:05,194:INFO:Total runtime is 0.32618279854456583 minutes
2023-10-14 16:05:05,196:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:05,196:INFO:Initializing create_model()
2023-10-14 16:05:05,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFEF2C93F0>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:05,197:INFO:Checking exceptions
2023-10-14 16:05:05,197:INFO:Importing libraries
2023-10-14 16:05:05,197:INFO:Copying training dataset
2023-10-14 16:05:05,203:INFO:Defining folds
2023-10-14 16:05:05,203:INFO:Declaring metric variables
2023-10-14 16:05:05,205:INFO:Importing untrained model
2023-10-14 16:05:05,209:INFO:Dummy Regressor Imported successfully
2023-10-14 16:05:05,215:INFO:Starting cross validation
2023-10-14 16:05:05,217:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:05,309:INFO:Calculating mean and std
2023-10-14 16:05:05,310:INFO:Creating metrics dataframe
2023-10-14 16:05:05,312:INFO:Uploading results into container
2023-10-14 16:05:05,313:INFO:Uploading model into container now
2023-10-14 16:05:05,313:INFO:_master_model_container: 19
2023-10-14 16:05:05,313:INFO:_display_container: 2
2023-10-14 16:05:05,313:INFO:DummyRegressor()
2023-10-14 16:05:05,313:INFO:create_model() successfully completed......................................
2023-10-14 16:05:05,465:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:05,465:INFO:Creating metrics dataframe
2023-10-14 16:05:05,486:INFO:Initializing create_model()
2023-10-14 16:05:05,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=GradientBoostingRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:05,487:INFO:Checking exceptions
2023-10-14 16:05:05,490:INFO:Importing libraries
2023-10-14 16:05:05,490:INFO:Copying training dataset
2023-10-14 16:05:05,493:INFO:Defining folds
2023-10-14 16:05:05,493:INFO:Declaring metric variables
2023-10-14 16:05:05,493:INFO:Importing untrained model
2023-10-14 16:05:05,493:INFO:Declaring custom model
2023-10-14 16:05:05,493:INFO:Gradient Boosting Regressor Imported successfully
2023-10-14 16:05:05,494:INFO:Cross validation set to False
2023-10-14 16:05:05,494:INFO:Fitting Model
2023-10-14 16:05:05,893:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 16:05:05,893:INFO:create_model() successfully completed......................................
2023-10-14 16:05:06,077:INFO:_master_model_container: 19
2023-10-14 16:05:06,077:INFO:_display_container: 2
2023-10-14 16:05:06,077:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 16:05:06,077:INFO:compare_models() successfully completed......................................
2023-10-14 16:05:33,596:INFO:Initializing compare_models()
2023-10-14 16:05:33,596:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-14 16:05:33,596:INFO:Checking exceptions
2023-10-14 16:05:33,600:INFO:Preparing display monitor
2023-10-14 16:05:33,638:INFO:Initializing Linear Regression
2023-10-14 16:05:33,639:INFO:Total runtime is 0.0 minutes
2023-10-14 16:05:33,643:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:33,644:INFO:Initializing create_model()
2023-10-14 16:05:33,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:33,644:INFO:Checking exceptions
2023-10-14 16:05:33,644:INFO:Importing libraries
2023-10-14 16:05:33,644:INFO:Copying training dataset
2023-10-14 16:05:33,649:INFO:Defining folds
2023-10-14 16:05:33,649:INFO:Declaring metric variables
2023-10-14 16:05:33,653:INFO:Importing untrained model
2023-10-14 16:05:33,657:INFO:Linear Regression Imported successfully
2023-10-14 16:05:33,666:INFO:Starting cross validation
2023-10-14 16:05:33,670:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:33,807:INFO:Calculating mean and std
2023-10-14 16:05:33,807:INFO:Creating metrics dataframe
2023-10-14 16:05:33,811:INFO:Uploading results into container
2023-10-14 16:05:33,812:INFO:Uploading model into container now
2023-10-14 16:05:33,812:INFO:_master_model_container: 20
2023-10-14 16:05:33,812:INFO:_display_container: 3
2023-10-14 16:05:33,812:INFO:LinearRegression(n_jobs=-1)
2023-10-14 16:05:33,812:INFO:create_model() successfully completed......................................
2023-10-14 16:05:34,003:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:34,003:INFO:Creating metrics dataframe
2023-10-14 16:05:34,010:INFO:Initializing Lasso Regression
2023-10-14 16:05:34,011:INFO:Total runtime is 0.00622409184773763 minutes
2023-10-14 16:05:34,013:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:34,014:INFO:Initializing create_model()
2023-10-14 16:05:34,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:34,014:INFO:Checking exceptions
2023-10-14 16:05:34,014:INFO:Importing libraries
2023-10-14 16:05:34,014:INFO:Copying training dataset
2023-10-14 16:05:34,019:INFO:Defining folds
2023-10-14 16:05:34,019:INFO:Declaring metric variables
2023-10-14 16:05:34,022:INFO:Importing untrained model
2023-10-14 16:05:34,025:INFO:Lasso Regression Imported successfully
2023-10-14 16:05:34,031:INFO:Starting cross validation
2023-10-14 16:05:34,033:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:34,136:INFO:Calculating mean and std
2023-10-14 16:05:34,136:INFO:Creating metrics dataframe
2023-10-14 16:05:34,139:INFO:Uploading results into container
2023-10-14 16:05:34,139:INFO:Uploading model into container now
2023-10-14 16:05:34,139:INFO:_master_model_container: 21
2023-10-14 16:05:34,139:INFO:_display_container: 3
2023-10-14 16:05:34,140:INFO:Lasso(random_state=123)
2023-10-14 16:05:34,140:INFO:create_model() successfully completed......................................
2023-10-14 16:05:34,301:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:34,301:INFO:Creating metrics dataframe
2023-10-14 16:05:34,310:INFO:Initializing Ridge Regression
2023-10-14 16:05:34,310:INFO:Total runtime is 0.011204226811726888 minutes
2023-10-14 16:05:34,314:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:34,314:INFO:Initializing create_model()
2023-10-14 16:05:34,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:34,314:INFO:Checking exceptions
2023-10-14 16:05:34,314:INFO:Importing libraries
2023-10-14 16:05:34,314:INFO:Copying training dataset
2023-10-14 16:05:34,317:INFO:Defining folds
2023-10-14 16:05:34,318:INFO:Declaring metric variables
2023-10-14 16:05:34,321:INFO:Importing untrained model
2023-10-14 16:05:34,323:INFO:Ridge Regression Imported successfully
2023-10-14 16:05:34,330:INFO:Starting cross validation
2023-10-14 16:05:34,332:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:34,426:INFO:Calculating mean and std
2023-10-14 16:05:34,427:INFO:Creating metrics dataframe
2023-10-14 16:05:34,429:INFO:Uploading results into container
2023-10-14 16:05:34,429:INFO:Uploading model into container now
2023-10-14 16:05:34,430:INFO:_master_model_container: 22
2023-10-14 16:05:34,430:INFO:_display_container: 3
2023-10-14 16:05:34,430:INFO:Ridge(random_state=123)
2023-10-14 16:05:34,430:INFO:create_model() successfully completed......................................
2023-10-14 16:05:34,582:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:34,582:INFO:Creating metrics dataframe
2023-10-14 16:05:34,590:INFO:Initializing Elastic Net
2023-10-14 16:05:34,590:INFO:Total runtime is 0.015869295597076415 minutes
2023-10-14 16:05:34,593:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:34,594:INFO:Initializing create_model()
2023-10-14 16:05:34,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:34,594:INFO:Checking exceptions
2023-10-14 16:05:34,594:INFO:Importing libraries
2023-10-14 16:05:34,594:INFO:Copying training dataset
2023-10-14 16:05:34,598:INFO:Defining folds
2023-10-14 16:05:34,598:INFO:Declaring metric variables
2023-10-14 16:05:34,601:INFO:Importing untrained model
2023-10-14 16:05:34,603:INFO:Elastic Net Imported successfully
2023-10-14 16:05:34,610:INFO:Starting cross validation
2023-10-14 16:05:34,611:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:34,710:INFO:Calculating mean and std
2023-10-14 16:05:34,712:INFO:Creating metrics dataframe
2023-10-14 16:05:34,715:INFO:Uploading results into container
2023-10-14 16:05:34,715:INFO:Uploading model into container now
2023-10-14 16:05:34,715:INFO:_master_model_container: 23
2023-10-14 16:05:34,715:INFO:_display_container: 3
2023-10-14 16:05:34,717:INFO:ElasticNet(random_state=123)
2023-10-14 16:05:34,717:INFO:create_model() successfully completed......................................
2023-10-14 16:05:34,871:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:34,871:INFO:Creating metrics dataframe
2023-10-14 16:05:34,880:INFO:Initializing Least Angle Regression
2023-10-14 16:05:34,880:INFO:Total runtime is 0.02070659001668294 minutes
2023-10-14 16:05:34,883:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:34,883:INFO:Initializing create_model()
2023-10-14 16:05:34,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:34,883:INFO:Checking exceptions
2023-10-14 16:05:34,883:INFO:Importing libraries
2023-10-14 16:05:34,883:INFO:Copying training dataset
2023-10-14 16:05:34,888:INFO:Defining folds
2023-10-14 16:05:34,889:INFO:Declaring metric variables
2023-10-14 16:05:34,891:INFO:Importing untrained model
2023-10-14 16:05:34,897:INFO:Least Angle Regression Imported successfully
2023-10-14 16:05:34,903:INFO:Starting cross validation
2023-10-14 16:05:34,905:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:34,957:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:05:34,977:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:05:34,980:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:05:34,985:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.736e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-14 16:05:35,005:INFO:Calculating mean and std
2023-10-14 16:05:35,008:INFO:Creating metrics dataframe
2023-10-14 16:05:35,011:INFO:Uploading results into container
2023-10-14 16:05:35,011:INFO:Uploading model into container now
2023-10-14 16:05:35,011:INFO:_master_model_container: 24
2023-10-14 16:05:35,012:INFO:_display_container: 3
2023-10-14 16:05:35,012:INFO:Lars(random_state=123)
2023-10-14 16:05:35,012:INFO:create_model() successfully completed......................................
2023-10-14 16:05:35,187:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:35,187:INFO:Creating metrics dataframe
2023-10-14 16:05:35,198:INFO:Initializing Lasso Least Angle Regression
2023-10-14 16:05:35,198:INFO:Total runtime is 0.02599900960922241 minutes
2023-10-14 16:05:35,201:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:35,201:INFO:Initializing create_model()
2023-10-14 16:05:35,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:35,202:INFO:Checking exceptions
2023-10-14 16:05:35,202:INFO:Importing libraries
2023-10-14 16:05:35,202:INFO:Copying training dataset
2023-10-14 16:05:35,207:INFO:Defining folds
2023-10-14 16:05:35,208:INFO:Declaring metric variables
2023-10-14 16:05:35,213:INFO:Importing untrained model
2023-10-14 16:05:35,218:INFO:Lasso Least Angle Regression Imported successfully
2023-10-14 16:05:35,227:INFO:Starting cross validation
2023-10-14 16:05:35,229:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:35,292:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 16:05:35,300:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 16:05:35,317:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-14 16:05:35,337:INFO:Calculating mean and std
2023-10-14 16:05:35,338:INFO:Creating metrics dataframe
2023-10-14 16:05:35,340:INFO:Uploading results into container
2023-10-14 16:05:35,341:INFO:Uploading model into container now
2023-10-14 16:05:35,341:INFO:_master_model_container: 25
2023-10-14 16:05:35,341:INFO:_display_container: 3
2023-10-14 16:05:35,342:INFO:LassoLars(random_state=123)
2023-10-14 16:05:35,342:INFO:create_model() successfully completed......................................
2023-10-14 16:05:35,512:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:35,512:INFO:Creating metrics dataframe
2023-10-14 16:05:35,519:INFO:Initializing Orthogonal Matching Pursuit
2023-10-14 16:05:35,519:INFO:Total runtime is 0.031359569231669104 minutes
2023-10-14 16:05:35,523:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:35,523:INFO:Initializing create_model()
2023-10-14 16:05:35,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:35,523:INFO:Checking exceptions
2023-10-14 16:05:35,523:INFO:Importing libraries
2023-10-14 16:05:35,523:INFO:Copying training dataset
2023-10-14 16:05:35,531:INFO:Defining folds
2023-10-14 16:05:35,531:INFO:Declaring metric variables
2023-10-14 16:05:35,533:INFO:Importing untrained model
2023-10-14 16:05:35,538:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-14 16:05:35,547:INFO:Starting cross validation
2023-10-14 16:05:35,548:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:35,614:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:05:35,617:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:05:35,631:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-14 16:05:35,652:INFO:Calculating mean and std
2023-10-14 16:05:35,653:INFO:Creating metrics dataframe
2023-10-14 16:05:35,656:INFO:Uploading results into container
2023-10-14 16:05:35,657:INFO:Uploading model into container now
2023-10-14 16:05:35,657:INFO:_master_model_container: 26
2023-10-14 16:05:35,657:INFO:_display_container: 3
2023-10-14 16:05:35,658:INFO:OrthogonalMatchingPursuit()
2023-10-14 16:05:35,658:INFO:create_model() successfully completed......................................
2023-10-14 16:05:35,815:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:35,815:INFO:Creating metrics dataframe
2023-10-14 16:05:35,823:INFO:Initializing Bayesian Ridge
2023-10-14 16:05:35,823:INFO:Total runtime is 0.03641348282496134 minutes
2023-10-14 16:05:35,825:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:35,826:INFO:Initializing create_model()
2023-10-14 16:05:35,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:35,826:INFO:Checking exceptions
2023-10-14 16:05:35,826:INFO:Importing libraries
2023-10-14 16:05:35,826:INFO:Copying training dataset
2023-10-14 16:05:35,832:INFO:Defining folds
2023-10-14 16:05:35,832:INFO:Declaring metric variables
2023-10-14 16:05:35,835:INFO:Importing untrained model
2023-10-14 16:05:35,840:INFO:Bayesian Ridge Imported successfully
2023-10-14 16:05:35,847:INFO:Starting cross validation
2023-10-14 16:05:35,849:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:35,984:INFO:Calculating mean and std
2023-10-14 16:05:35,985:INFO:Creating metrics dataframe
2023-10-14 16:05:35,987:INFO:Uploading results into container
2023-10-14 16:05:35,987:INFO:Uploading model into container now
2023-10-14 16:05:35,988:INFO:_master_model_container: 27
2023-10-14 16:05:35,988:INFO:_display_container: 3
2023-10-14 16:05:35,988:INFO:BayesianRidge()
2023-10-14 16:05:35,988:INFO:create_model() successfully completed......................................
2023-10-14 16:05:36,158:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:36,159:INFO:Creating metrics dataframe
2023-10-14 16:05:36,170:INFO:Initializing Passive Aggressive Regressor
2023-10-14 16:05:36,170:INFO:Total runtime is 0.042208202679951984 minutes
2023-10-14 16:05:36,173:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:36,173:INFO:Initializing create_model()
2023-10-14 16:05:36,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:36,174:INFO:Checking exceptions
2023-10-14 16:05:36,174:INFO:Importing libraries
2023-10-14 16:05:36,174:INFO:Copying training dataset
2023-10-14 16:05:36,180:INFO:Defining folds
2023-10-14 16:05:36,180:INFO:Declaring metric variables
2023-10-14 16:05:36,183:INFO:Importing untrained model
2023-10-14 16:05:36,188:INFO:Passive Aggressive Regressor Imported successfully
2023-10-14 16:05:36,195:INFO:Starting cross validation
2023-10-14 16:05:36,198:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:36,312:INFO:Calculating mean and std
2023-10-14 16:05:36,313:INFO:Creating metrics dataframe
2023-10-14 16:05:36,315:INFO:Uploading results into container
2023-10-14 16:05:36,317:INFO:Uploading model into container now
2023-10-14 16:05:36,317:INFO:_master_model_container: 28
2023-10-14 16:05:36,317:INFO:_display_container: 3
2023-10-14 16:05:36,317:INFO:PassiveAggressiveRegressor(random_state=123)
2023-10-14 16:05:36,317:INFO:create_model() successfully completed......................................
2023-10-14 16:05:36,470:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:36,470:INFO:Creating metrics dataframe
2023-10-14 16:05:36,481:INFO:Initializing Huber Regressor
2023-10-14 16:05:36,481:INFO:Total runtime is 0.047391164302825924 minutes
2023-10-14 16:05:36,484:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:36,484:INFO:Initializing create_model()
2023-10-14 16:05:36,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:36,484:INFO:Checking exceptions
2023-10-14 16:05:36,484:INFO:Importing libraries
2023-10-14 16:05:36,485:INFO:Copying training dataset
2023-10-14 16:05:36,489:INFO:Defining folds
2023-10-14 16:05:36,489:INFO:Declaring metric variables
2023-10-14 16:05:36,494:INFO:Importing untrained model
2023-10-14 16:05:36,497:INFO:Huber Regressor Imported successfully
2023-10-14 16:05:36,504:INFO:Starting cross validation
2023-10-14 16:05:36,505:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:36,593:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 16:05:36,613:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 16:05:36,633:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-14 16:05:36,651:INFO:Calculating mean and std
2023-10-14 16:05:36,652:INFO:Creating metrics dataframe
2023-10-14 16:05:36,654:INFO:Uploading results into container
2023-10-14 16:05:36,654:INFO:Uploading model into container now
2023-10-14 16:05:36,655:INFO:_master_model_container: 29
2023-10-14 16:05:36,655:INFO:_display_container: 3
2023-10-14 16:05:36,655:INFO:HuberRegressor()
2023-10-14 16:05:36,655:INFO:create_model() successfully completed......................................
2023-10-14 16:05:36,806:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:36,806:INFO:Creating metrics dataframe
2023-10-14 16:05:36,815:INFO:Initializing K Neighbors Regressor
2023-10-14 16:05:36,815:INFO:Total runtime is 0.05295776526133219 minutes
2023-10-14 16:05:36,819:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:36,819:INFO:Initializing create_model()
2023-10-14 16:05:36,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:36,819:INFO:Checking exceptions
2023-10-14 16:05:36,819:INFO:Importing libraries
2023-10-14 16:05:36,819:INFO:Copying training dataset
2023-10-14 16:05:36,825:INFO:Defining folds
2023-10-14 16:05:36,825:INFO:Declaring metric variables
2023-10-14 16:05:36,830:INFO:Importing untrained model
2023-10-14 16:05:36,833:INFO:K Neighbors Regressor Imported successfully
2023-10-14 16:05:36,839:INFO:Starting cross validation
2023-10-14 16:05:36,842:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:37,020:INFO:Calculating mean and std
2023-10-14 16:05:37,021:INFO:Creating metrics dataframe
2023-10-14 16:05:37,023:INFO:Uploading results into container
2023-10-14 16:05:37,023:INFO:Uploading model into container now
2023-10-14 16:05:37,023:INFO:_master_model_container: 30
2023-10-14 16:05:37,024:INFO:_display_container: 3
2023-10-14 16:05:37,024:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-14 16:05:37,024:INFO:create_model() successfully completed......................................
2023-10-14 16:05:37,175:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:37,176:INFO:Creating metrics dataframe
2023-10-14 16:05:37,186:INFO:Initializing Decision Tree Regressor
2023-10-14 16:05:37,186:INFO:Total runtime is 0.05913293361663818 minutes
2023-10-14 16:05:37,190:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:37,190:INFO:Initializing create_model()
2023-10-14 16:05:37,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:37,190:INFO:Checking exceptions
2023-10-14 16:05:37,190:INFO:Importing libraries
2023-10-14 16:05:37,190:INFO:Copying training dataset
2023-10-14 16:05:37,197:INFO:Defining folds
2023-10-14 16:05:37,197:INFO:Declaring metric variables
2023-10-14 16:05:37,201:INFO:Importing untrained model
2023-10-14 16:05:37,205:INFO:Decision Tree Regressor Imported successfully
2023-10-14 16:05:37,214:INFO:Starting cross validation
2023-10-14 16:05:37,216:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:37,353:INFO:Calculating mean and std
2023-10-14 16:05:37,355:INFO:Creating metrics dataframe
2023-10-14 16:05:37,357:INFO:Uploading results into container
2023-10-14 16:05:37,357:INFO:Uploading model into container now
2023-10-14 16:05:37,359:INFO:_master_model_container: 31
2023-10-14 16:05:37,359:INFO:_display_container: 3
2023-10-14 16:05:37,360:INFO:DecisionTreeRegressor(random_state=123)
2023-10-14 16:05:37,360:INFO:create_model() successfully completed......................................
2023-10-14 16:05:37,523:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:37,523:INFO:Creating metrics dataframe
2023-10-14 16:05:37,531:INFO:Initializing Random Forest Regressor
2023-10-14 16:05:37,531:INFO:Total runtime is 0.06489526033401488 minutes
2023-10-14 16:05:37,534:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:37,534:INFO:Initializing create_model()
2023-10-14 16:05:37,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:37,534:INFO:Checking exceptions
2023-10-14 16:05:37,534:INFO:Importing libraries
2023-10-14 16:05:37,534:INFO:Copying training dataset
2023-10-14 16:05:37,561:INFO:Defining folds
2023-10-14 16:05:37,562:INFO:Declaring metric variables
2023-10-14 16:05:37,568:INFO:Importing untrained model
2023-10-14 16:05:37,573:INFO:Random Forest Regressor Imported successfully
2023-10-14 16:05:37,583:INFO:Starting cross validation
2023-10-14 16:05:37,584:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:38,198:INFO:Calculating mean and std
2023-10-14 16:05:38,200:INFO:Creating metrics dataframe
2023-10-14 16:05:38,202:INFO:Uploading results into container
2023-10-14 16:05:38,203:INFO:Uploading model into container now
2023-10-14 16:05:38,203:INFO:_master_model_container: 32
2023-10-14 16:05:38,203:INFO:_display_container: 3
2023-10-14 16:05:38,204:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-10-14 16:05:38,204:INFO:create_model() successfully completed......................................
2023-10-14 16:05:38,354:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:38,354:INFO:Creating metrics dataframe
2023-10-14 16:05:38,364:INFO:Initializing Extra Trees Regressor
2023-10-14 16:05:38,364:INFO:Total runtime is 0.07877057790756224 minutes
2023-10-14 16:05:38,366:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:38,367:INFO:Initializing create_model()
2023-10-14 16:05:38,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:38,367:INFO:Checking exceptions
2023-10-14 16:05:38,367:INFO:Importing libraries
2023-10-14 16:05:38,367:INFO:Copying training dataset
2023-10-14 16:05:38,372:INFO:Defining folds
2023-10-14 16:05:38,372:INFO:Declaring metric variables
2023-10-14 16:05:38,375:INFO:Importing untrained model
2023-10-14 16:05:38,379:INFO:Extra Trees Regressor Imported successfully
2023-10-14 16:05:38,387:INFO:Starting cross validation
2023-10-14 16:05:38,389:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:38,939:INFO:Calculating mean and std
2023-10-14 16:05:38,940:INFO:Creating metrics dataframe
2023-10-14 16:05:38,944:INFO:Uploading results into container
2023-10-14 16:05:38,944:INFO:Uploading model into container now
2023-10-14 16:05:38,944:INFO:_master_model_container: 33
2023-10-14 16:05:38,944:INFO:_display_container: 3
2023-10-14 16:05:38,944:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-10-14 16:05:38,944:INFO:create_model() successfully completed......................................
2023-10-14 16:05:39,101:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:39,101:INFO:Creating metrics dataframe
2023-10-14 16:05:39,111:INFO:Initializing AdaBoost Regressor
2023-10-14 16:05:39,111:INFO:Total runtime is 0.09121406873067218 minutes
2023-10-14 16:05:39,113:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:39,113:INFO:Initializing create_model()
2023-10-14 16:05:39,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:39,113:INFO:Checking exceptions
2023-10-14 16:05:39,114:INFO:Importing libraries
2023-10-14 16:05:39,114:INFO:Copying training dataset
2023-10-14 16:05:39,118:INFO:Defining folds
2023-10-14 16:05:39,118:INFO:Declaring metric variables
2023-10-14 16:05:39,121:INFO:Importing untrained model
2023-10-14 16:05:39,125:INFO:AdaBoost Regressor Imported successfully
2023-10-14 16:05:39,133:INFO:Starting cross validation
2023-10-14 16:05:39,135:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:39,390:INFO:Calculating mean and std
2023-10-14 16:05:39,393:INFO:Creating metrics dataframe
2023-10-14 16:05:39,395:INFO:Uploading results into container
2023-10-14 16:05:39,396:INFO:Uploading model into container now
2023-10-14 16:05:39,396:INFO:_master_model_container: 34
2023-10-14 16:05:39,396:INFO:_display_container: 3
2023-10-14 16:05:39,396:INFO:AdaBoostRegressor(random_state=123)
2023-10-14 16:05:39,396:INFO:create_model() successfully completed......................................
2023-10-14 16:05:39,546:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:39,546:INFO:Creating metrics dataframe
2023-10-14 16:05:39,555:INFO:Initializing Gradient Boosting Regressor
2023-10-14 16:05:39,555:INFO:Total runtime is 0.09862668514251707 minutes
2023-10-14 16:05:39,560:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:39,561:INFO:Initializing create_model()
2023-10-14 16:05:39,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:39,561:INFO:Checking exceptions
2023-10-14 16:05:39,561:INFO:Importing libraries
2023-10-14 16:05:39,561:INFO:Copying training dataset
2023-10-14 16:05:39,565:INFO:Defining folds
2023-10-14 16:05:39,566:INFO:Declaring metric variables
2023-10-14 16:05:39,569:INFO:Importing untrained model
2023-10-14 16:05:39,573:INFO:Gradient Boosting Regressor Imported successfully
2023-10-14 16:05:39,579:INFO:Starting cross validation
2023-10-14 16:05:39,581:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:39,948:INFO:Calculating mean and std
2023-10-14 16:05:39,950:INFO:Creating metrics dataframe
2023-10-14 16:05:39,952:INFO:Uploading results into container
2023-10-14 16:05:39,952:INFO:Uploading model into container now
2023-10-14 16:05:39,952:INFO:_master_model_container: 35
2023-10-14 16:05:39,953:INFO:_display_container: 3
2023-10-14 16:05:39,953:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 16:05:39,953:INFO:create_model() successfully completed......................................
2023-10-14 16:05:40,100:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:40,100:INFO:Creating metrics dataframe
2023-10-14 16:05:40,112:INFO:Initializing Extreme Gradient Boosting
2023-10-14 16:05:40,112:INFO:Total runtime is 0.10790820519129433 minutes
2023-10-14 16:05:40,115:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:40,115:INFO:Initializing create_model()
2023-10-14 16:05:40,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:40,115:INFO:Checking exceptions
2023-10-14 16:05:40,115:INFO:Importing libraries
2023-10-14 16:05:40,115:INFO:Copying training dataset
2023-10-14 16:05:40,120:INFO:Defining folds
2023-10-14 16:05:40,121:INFO:Declaring metric variables
2023-10-14 16:05:40,124:INFO:Importing untrained model
2023-10-14 16:05:40,130:INFO:Extreme Gradient Boosting Imported successfully
2023-10-14 16:05:40,136:INFO:Starting cross validation
2023-10-14 16:05:40,136:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:40,367:INFO:Calculating mean and std
2023-10-14 16:05:40,369:INFO:Creating metrics dataframe
2023-10-14 16:05:40,372:INFO:Uploading results into container
2023-10-14 16:05:40,373:INFO:Uploading model into container now
2023-10-14 16:05:40,373:INFO:_master_model_container: 36
2023-10-14 16:05:40,373:INFO:_display_container: 3
2023-10-14 16:05:40,375:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2023-10-14 16:05:40,375:INFO:create_model() successfully completed......................................
2023-10-14 16:05:40,549:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:40,549:INFO:Creating metrics dataframe
2023-10-14 16:05:40,558:INFO:Initializing Light Gradient Boosting Machine
2023-10-14 16:05:40,558:INFO:Total runtime is 0.11533941030502318 minutes
2023-10-14 16:05:40,561:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:40,562:INFO:Initializing create_model()
2023-10-14 16:05:40,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:40,562:INFO:Checking exceptions
2023-10-14 16:05:40,562:INFO:Importing libraries
2023-10-14 16:05:40,562:INFO:Copying training dataset
2023-10-14 16:05:40,567:INFO:Defining folds
2023-10-14 16:05:40,567:INFO:Declaring metric variables
2023-10-14 16:05:40,570:INFO:Importing untrained model
2023-10-14 16:05:40,574:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-14 16:05:40,582:INFO:Starting cross validation
2023-10-14 16:05:40,583:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:40,891:INFO:Calculating mean and std
2023-10-14 16:05:40,893:INFO:Creating metrics dataframe
2023-10-14 16:05:40,897:INFO:Uploading results into container
2023-10-14 16:05:40,898:INFO:Uploading model into container now
2023-10-14 16:05:40,899:INFO:_master_model_container: 37
2023-10-14 16:05:40,899:INFO:_display_container: 3
2023-10-14 16:05:40,900:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-10-14 16:05:40,900:INFO:create_model() successfully completed......................................
2023-10-14 16:05:41,121:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:41,121:INFO:Creating metrics dataframe
2023-10-14 16:05:41,134:INFO:Initializing Dummy Regressor
2023-10-14 16:05:41,135:INFO:Total runtime is 0.12495438257853189 minutes
2023-10-14 16:05:41,137:INFO:SubProcess create_model() called ==================================
2023-10-14 16:05:41,137:INFO:Initializing create_model()
2023-10-14 16:05:41,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FFCEE17D30>, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:41,137:INFO:Checking exceptions
2023-10-14 16:05:41,137:INFO:Importing libraries
2023-10-14 16:05:41,137:INFO:Copying training dataset
2023-10-14 16:05:41,144:INFO:Defining folds
2023-10-14 16:05:41,144:INFO:Declaring metric variables
2023-10-14 16:05:41,147:INFO:Importing untrained model
2023-10-14 16:05:41,151:INFO:Dummy Regressor Imported successfully
2023-10-14 16:05:41,160:INFO:Starting cross validation
2023-10-14 16:05:41,161:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-14 16:05:41,264:INFO:Calculating mean and std
2023-10-14 16:05:41,266:INFO:Creating metrics dataframe
2023-10-14 16:05:41,268:INFO:Uploading results into container
2023-10-14 16:05:41,268:INFO:Uploading model into container now
2023-10-14 16:05:41,268:INFO:_master_model_container: 38
2023-10-14 16:05:41,269:INFO:_display_container: 3
2023-10-14 16:05:41,269:INFO:DummyRegressor()
2023-10-14 16:05:41,269:INFO:create_model() successfully completed......................................
2023-10-14 16:05:41,417:INFO:SubProcess create_model() end ==================================
2023-10-14 16:05:41,417:INFO:Creating metrics dataframe
2023-10-14 16:05:41,439:INFO:Initializing create_model()
2023-10-14 16:05:41,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=GradientBoostingRegressor(random_state=123), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-14 16:05:41,440:INFO:Checking exceptions
2023-10-14 16:05:41,443:INFO:Importing libraries
2023-10-14 16:05:41,443:INFO:Copying training dataset
2023-10-14 16:05:41,446:INFO:Defining folds
2023-10-14 16:05:41,446:INFO:Declaring metric variables
2023-10-14 16:05:41,446:INFO:Importing untrained model
2023-10-14 16:05:41,446:INFO:Declaring custom model
2023-10-14 16:05:41,447:INFO:Gradient Boosting Regressor Imported successfully
2023-10-14 16:05:41,448:INFO:Cross validation set to False
2023-10-14 16:05:41,449:INFO:Fitting Model
2023-10-14 16:05:41,851:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 16:05:41,851:INFO:create_model() successfully completed......................................
2023-10-14 16:05:42,037:INFO:_master_model_container: 38
2023-10-14 16:05:42,037:INFO:_display_container: 3
2023-10-14 16:05:42,037:INFO:GradientBoostingRegressor(random_state=123)
2023-10-14 16:05:42,037:INFO:compare_models() successfully completed......................................
2023-10-14 16:05:57,680:INFO:Initializing predict_model()
2023-10-14 16:05:57,680:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEC0B9AB0>)
2023-10-14 16:05:57,680:INFO:Checking exceptions
2023-10-14 16:05:57,680:INFO:Preloading libraries
2023-10-14 16:06:03,727:INFO:Initializing predict_model()
2023-10-14 16:06:03,727:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEC457C70>)
2023-10-14 16:06:03,727:INFO:Checking exceptions
2023-10-14 16:06:03,727:INFO:Preloading libraries
2023-10-14 16:06:13,115:INFO:Initializing predict_model()
2023-10-14 16:06:13,115:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001FFF06B7730>, estimator=GradientBoostingRegressor(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FFEC457C70>)
2023-10-14 16:06:13,115:INFO:Checking exceptions
2023-10-14 16:06:13,115:INFO:Preloading libraries
2023-10-14 16:06:13,117:INFO:Set up data.
2023-10-14 16:06:13,123:INFO:Set up index.
2023-10-14 17:08:52,876:WARNING:C:\Users\manue\AppData\Local\Temp\ipykernel_1612\1041142005.py:7: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy


2023-10-14 20:35:33,882:WARNING:C:\Users\manue\AppData\Local\Temp\ipykernel_1612\59473513.py:13: FutureWarning:

reindexing with a non-unique Index is deprecated and will raise in a future version.


2023-10-14 20:38:39,191:WARNING:C:\Users\manue\AppData\Local\Temp\ipykernel_1612\973162004.py:1: UserWarning:

Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access


2023-10-15 22:36:55,826:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 22:36:55,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 22:36:55,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 22:36:55,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 22:36:55,933:INFO:PyCaret RegressionExperiment
2023-10-15 22:36:55,933:INFO:Logging name: reg-default-name
2023-10-15 22:36:55,934:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-15 22:36:55,934:INFO:version 3.1.0
2023-10-15 22:36:55,934:INFO:Initializing setup()
2023-10-15 22:36:55,934:INFO:self.USI: 2eb3
2023-10-15 22:36:55,934:INFO:self._variable_keys: {'y_train', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'idx', 'y', 'X_test', 'n_jobs_param', '_ml_usecase', 'memory', 'fold_generator', 'transform_target_param', 'data', 'y_test', 'exp_id', 'target_param', 'fold_groups_param', 'pipeline', 'seed', 'logging_param', 'X', 'log_plots_param', '_available_plots', 'exp_name_log', 'X_train', 'html_param', 'gpu_param'}
2023-10-15 22:36:55,934:INFO:Checking environment
2023-10-15 22:36:55,934:INFO:python_version: 3.10.6
2023-10-15 22:36:55,934:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-15 22:36:55,934:INFO:machine: AMD64
2023-10-15 22:36:55,934:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-15 22:36:55,934:INFO:Memory: svmem(total=8273383424, available=1587118080, percent=80.8, used=6686265344, free=1587118080)
2023-10-15 22:36:55,934:INFO:Physical Core: 4
2023-10-15 22:36:55,934:INFO:Logical Core: 8
2023-10-15 22:36:55,934:INFO:Checking libraries
2023-10-15 22:36:55,934:INFO:System:
2023-10-15 22:36:55,934:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-15 22:36:55,936:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-15 22:36:55,936:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-15 22:36:55,936:INFO:PyCaret required dependencies:
2023-10-15 22:36:56,006:INFO:                 pip: 22.2.1
2023-10-15 22:36:56,008:INFO:          setuptools: 63.2.0
2023-10-15 22:36:56,008:INFO:             pycaret: 3.1.0
2023-10-15 22:36:56,008:INFO:             IPython: 8.4.0
2023-10-15 22:36:56,008:INFO:          ipywidgets: 8.1.1
2023-10-15 22:36:56,008:INFO:                tqdm: 4.66.1
2023-10-15 22:36:56,008:INFO:               numpy: 1.23.2
2023-10-15 22:36:56,008:INFO:              pandas: 1.4.3
2023-10-15 22:36:56,008:INFO:              jinja2: 3.1.2
2023-10-15 22:36:56,008:INFO:               scipy: 1.10.1
2023-10-15 22:36:56,008:INFO:              joblib: 1.2.0
2023-10-15 22:36:56,008:INFO:             sklearn: 1.1.2
2023-10-15 22:36:56,008:INFO:                pyod: 1.1.0
2023-10-15 22:36:56,008:INFO:            imblearn: 0.11.0
2023-10-15 22:36:56,008:INFO:   category_encoders: 2.6.2
2023-10-15 22:36:56,008:INFO:            lightgbm: 4.1.0
2023-10-15 22:36:56,008:INFO:               numba: 0.58.0
2023-10-15 22:36:56,008:INFO:            requests: 2.28.1
2023-10-15 22:36:56,008:INFO:          matplotlib: 3.6.0
2023-10-15 22:36:56,008:INFO:          scikitplot: 0.3.7
2023-10-15 22:36:56,008:INFO:         yellowbrick: 1.5
2023-10-15 22:36:56,008:INFO:              plotly: 5.17.0
2023-10-15 22:36:56,008:INFO:    plotly-resampler: Not installed
2023-10-15 22:36:56,008:INFO:             kaleido: 0.2.1
2023-10-15 22:36:56,008:INFO:           schemdraw: 0.15
2023-10-15 22:36:56,008:INFO:         statsmodels: 0.13.2
2023-10-15 22:36:56,008:INFO:              sktime: 0.21.1
2023-10-15 22:36:56,008:INFO:               tbats: 1.1.3
2023-10-15 22:36:56,008:INFO:            pmdarima: 2.0.3
2023-10-15 22:36:56,008:INFO:              psutil: 5.9.1
2023-10-15 22:36:56,008:INFO:          markupsafe: 2.1.1
2023-10-15 22:36:56,008:INFO:             pickle5: Not installed
2023-10-15 22:36:56,008:INFO:         cloudpickle: 2.2.1
2023-10-15 22:36:56,008:INFO:         deprecation: 2.1.0
2023-10-15 22:36:56,008:INFO:              xxhash: 3.4.1
2023-10-15 22:36:56,008:INFO:           wurlitzer: Not installed
2023-10-15 22:36:56,009:INFO:PyCaret optional dependencies:
2023-10-15 22:36:56,116:INFO:                shap: Not installed
2023-10-15 22:36:56,116:INFO:           interpret: Not installed
2023-10-15 22:36:56,116:INFO:                umap: Not installed
2023-10-15 22:36:56,116:INFO:     ydata_profiling: Not installed
2023-10-15 22:36:56,116:INFO:  explainerdashboard: Not installed
2023-10-15 22:36:56,116:INFO:             autoviz: Not installed
2023-10-15 22:36:56,116:INFO:           fairlearn: Not installed
2023-10-15 22:36:56,116:INFO:          deepchecks: Not installed
2023-10-15 22:36:56,116:INFO:             xgboost: 2.0.0
2023-10-15 22:36:56,116:INFO:            catboost: Not installed
2023-10-15 22:36:56,116:INFO:              kmodes: Not installed
2023-10-15 22:36:56,116:INFO:             mlxtend: Not installed
2023-10-15 22:36:56,116:INFO:       statsforecast: Not installed
2023-10-15 22:36:56,116:INFO:        tune_sklearn: Not installed
2023-10-15 22:36:56,116:INFO:                 ray: Not installed
2023-10-15 22:36:56,116:INFO:            hyperopt: Not installed
2023-10-15 22:36:56,116:INFO:              optuna: Not installed
2023-10-15 22:36:56,117:INFO:               skopt: Not installed
2023-10-15 22:36:56,117:INFO:              mlflow: Not installed
2023-10-15 22:36:56,117:INFO:              gradio: Not installed
2023-10-15 22:36:56,117:INFO:             fastapi: Not installed
2023-10-15 22:36:56,117:INFO:             uvicorn: Not installed
2023-10-15 22:36:56,117:INFO:              m2cgen: Not installed
2023-10-15 22:36:56,117:INFO:           evidently: Not installed
2023-10-15 22:36:56,117:INFO:               fugue: Not installed
2023-10-15 22:36:56,117:INFO:           streamlit: Not installed
2023-10-15 22:36:56,117:INFO:             prophet: 1.1.5
2023-10-15 22:36:56,117:INFO:None
2023-10-15 22:36:56,117:INFO:Set up data.
2023-10-15 22:36:56,124:INFO:Set up folding strategy.
2023-10-15 22:36:56,124:INFO:Set up train/test split.
2023-10-15 22:36:56,124:INFO:Set up data.
2023-10-15 22:36:56,128:INFO:Set up index.
2023-10-15 22:36:56,128:INFO:Assigning column types.
2023-10-15 22:36:56,132:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-15 22:36:56,132:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,136:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,380:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:56,383:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,386:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,478:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:56,480:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-15 22:36:56,484:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,488:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,574:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:56,579:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,583:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,631:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,668:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:56,672:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-15 22:36:56,679:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,764:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:56,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,824:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,861:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:56,864:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-15 22:36:56,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,961:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:56,961:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:56,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:57,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:36:57,058:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,060:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-15 22:36:57,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:57,155:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:36:57,250:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,252:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-15 22:36:57,344:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,439:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,442:INFO:Preparing preprocessing pipeline...
2023-10-15 22:36:57,442:INFO:Set up simple imputation.
2023-10-15 22:36:57,448:INFO:Set up encoding of ordinal features.
2023-10-15 22:36:57,450:INFO:Set up encoding of categorical features.
2023-10-15 22:36:57,537:INFO:Finished creating preprocessing pipeline.
2023-10-15 22:36:57,562:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='...
                 TransformerWrapper(include=['is_working'],
                                    transformer=OrdinalEncoder(cols=['is_working'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-10-15 22:36:57,562:INFO:Creating final display dataframe.
2023-10-15 22:36:57,761:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target        demand_GWh
2                   Target type        Regression
3           Original data shape         (6006, 9)
4        Transformed data shape        (6006, 26)
5   Transformed train set shape        (5506, 26)
6    Transformed test set shape         (500, 26)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   TimeSeriesSplit
17                  Fold Number                 3
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              2eb3
2023-10-15 22:36:57,854:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,954:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:36:57,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:36:57,959:INFO:setup() successfully completed in 2.03s...............
2023-10-15 22:37:00,574:INFO:Initializing compare_models()
2023-10-15 22:37:00,574:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-15 22:37:00,574:INFO:Checking exceptions
2023-10-15 22:37:00,578:INFO:Preparing display monitor
2023-10-15 22:37:00,622:INFO:Initializing Linear Regression
2023-10-15 22:37:00,622:INFO:Total runtime is 0.0 minutes
2023-10-15 22:37:00,625:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:00,625:INFO:Initializing create_model()
2023-10-15 22:37:00,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:00,626:INFO:Checking exceptions
2023-10-15 22:37:00,626:INFO:Importing libraries
2023-10-15 22:37:00,626:INFO:Copying training dataset
2023-10-15 22:37:00,633:INFO:Defining folds
2023-10-15 22:37:00,633:INFO:Declaring metric variables
2023-10-15 22:37:00,638:INFO:Importing untrained model
2023-10-15 22:37:00,642:INFO:Linear Regression Imported successfully
2023-10-15 22:37:00,654:INFO:Starting cross validation
2023-10-15 22:37:00,664:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:04,929:INFO:Calculating mean and std
2023-10-15 22:37:04,931:INFO:Creating metrics dataframe
2023-10-15 22:37:04,938:INFO:Uploading results into container
2023-10-15 22:37:04,940:INFO:Uploading model into container now
2023-10-15 22:37:04,940:INFO:_master_model_container: 1
2023-10-15 22:37:04,940:INFO:_display_container: 2
2023-10-15 22:37:04,941:INFO:LinearRegression(n_jobs=-1)
2023-10-15 22:37:04,941:INFO:create_model() successfully completed......................................
2023-10-15 22:37:05,093:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:05,093:INFO:Creating metrics dataframe
2023-10-15 22:37:05,099:INFO:Initializing Lasso Regression
2023-10-15 22:37:05,099:INFO:Total runtime is 0.07462034225463868 minutes
2023-10-15 22:37:05,104:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:05,104:INFO:Initializing create_model()
2023-10-15 22:37:05,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:05,104:INFO:Checking exceptions
2023-10-15 22:37:05,104:INFO:Importing libraries
2023-10-15 22:37:05,104:INFO:Copying training dataset
2023-10-15 22:37:05,110:INFO:Defining folds
2023-10-15 22:37:05,111:INFO:Declaring metric variables
2023-10-15 22:37:05,113:INFO:Importing untrained model
2023-10-15 22:37:05,117:INFO:Lasso Regression Imported successfully
2023-10-15 22:37:05,125:INFO:Starting cross validation
2023-10-15 22:37:05,127:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:07,173:INFO:Calculating mean and std
2023-10-15 22:37:07,175:INFO:Creating metrics dataframe
2023-10-15 22:37:07,179:INFO:Uploading results into container
2023-10-15 22:37:07,180:INFO:Uploading model into container now
2023-10-15 22:37:07,181:INFO:_master_model_container: 2
2023-10-15 22:37:07,181:INFO:_display_container: 2
2023-10-15 22:37:07,181:INFO:Lasso(random_state=1234)
2023-10-15 22:37:07,181:INFO:create_model() successfully completed......................................
2023-10-15 22:37:07,340:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:07,340:INFO:Creating metrics dataframe
2023-10-15 22:37:07,348:INFO:Initializing Ridge Regression
2023-10-15 22:37:07,348:INFO:Total runtime is 0.11210116147994996 minutes
2023-10-15 22:37:07,351:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:07,352:INFO:Initializing create_model()
2023-10-15 22:37:07,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:07,352:INFO:Checking exceptions
2023-10-15 22:37:07,352:INFO:Importing libraries
2023-10-15 22:37:07,352:INFO:Copying training dataset
2023-10-15 22:37:07,358:INFO:Defining folds
2023-10-15 22:37:07,359:INFO:Declaring metric variables
2023-10-15 22:37:07,361:INFO:Importing untrained model
2023-10-15 22:37:07,365:INFO:Ridge Regression Imported successfully
2023-10-15 22:37:07,372:INFO:Starting cross validation
2023-10-15 22:37:07,375:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:09,192:INFO:Calculating mean and std
2023-10-15 22:37:09,194:INFO:Creating metrics dataframe
2023-10-15 22:37:09,197:INFO:Uploading results into container
2023-10-15 22:37:09,197:INFO:Uploading model into container now
2023-10-15 22:37:09,197:INFO:_master_model_container: 3
2023-10-15 22:37:09,198:INFO:_display_container: 2
2023-10-15 22:37:09,199:INFO:Ridge(random_state=1234)
2023-10-15 22:37:09,199:INFO:create_model() successfully completed......................................
2023-10-15 22:37:09,360:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:09,360:INFO:Creating metrics dataframe
2023-10-15 22:37:09,367:INFO:Initializing Elastic Net
2023-10-15 22:37:09,367:INFO:Total runtime is 0.145750363667806 minutes
2023-10-15 22:37:09,372:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:09,373:INFO:Initializing create_model()
2023-10-15 22:37:09,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:09,373:INFO:Checking exceptions
2023-10-15 22:37:09,373:INFO:Importing libraries
2023-10-15 22:37:09,373:INFO:Copying training dataset
2023-10-15 22:37:09,379:INFO:Defining folds
2023-10-15 22:37:09,379:INFO:Declaring metric variables
2023-10-15 22:37:09,382:INFO:Importing untrained model
2023-10-15 22:37:09,388:INFO:Elastic Net Imported successfully
2023-10-15 22:37:09,393:INFO:Starting cross validation
2023-10-15 22:37:09,394:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:09,530:INFO:Calculating mean and std
2023-10-15 22:37:09,532:INFO:Creating metrics dataframe
2023-10-15 22:37:09,535:INFO:Uploading results into container
2023-10-15 22:37:09,536:INFO:Uploading model into container now
2023-10-15 22:37:09,536:INFO:_master_model_container: 4
2023-10-15 22:37:09,536:INFO:_display_container: 2
2023-10-15 22:37:09,536:INFO:ElasticNet(random_state=1234)
2023-10-15 22:37:09,537:INFO:create_model() successfully completed......................................
2023-10-15 22:37:09,664:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:09,664:INFO:Creating metrics dataframe
2023-10-15 22:37:09,677:INFO:Initializing Least Angle Regression
2023-10-15 22:37:09,677:INFO:Total runtime is 0.15091119607289633 minutes
2023-10-15 22:37:09,679:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:09,680:INFO:Initializing create_model()
2023-10-15 22:37:09,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:09,680:INFO:Checking exceptions
2023-10-15 22:37:09,680:INFO:Importing libraries
2023-10-15 22:37:09,680:INFO:Copying training dataset
2023-10-15 22:37:09,687:INFO:Defining folds
2023-10-15 22:37:09,687:INFO:Declaring metric variables
2023-10-15 22:37:09,691:INFO:Importing untrained model
2023-10-15 22:37:09,695:INFO:Least Angle Regression Imported successfully
2023-10-15 22:37:09,702:INFO:Starting cross validation
2023-10-15 22:37:09,704:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:09,810:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:37:09,833:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.079e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,834:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.266e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,834:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.267e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,836:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=9.524e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,836:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.586e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,837:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=4.322e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,838:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.600e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:37:09,871:INFO:Calculating mean and std
2023-10-15 22:37:09,873:INFO:Creating metrics dataframe
2023-10-15 22:37:09,875:INFO:Uploading results into container
2023-10-15 22:37:09,875:INFO:Uploading model into container now
2023-10-15 22:37:09,876:INFO:_master_model_container: 5
2023-10-15 22:37:09,876:INFO:_display_container: 2
2023-10-15 22:37:09,876:INFO:Lars(random_state=1234)
2023-10-15 22:37:09,876:INFO:create_model() successfully completed......................................
2023-10-15 22:37:09,999:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:09,999:INFO:Creating metrics dataframe
2023-10-15 22:37:10,010:INFO:Initializing Lasso Least Angle Regression
2023-10-15 22:37:10,010:INFO:Total runtime is 0.1564685662587484 minutes
2023-10-15 22:37:10,013:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:10,014:INFO:Initializing create_model()
2023-10-15 22:37:10,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:10,014:INFO:Checking exceptions
2023-10-15 22:37:10,014:INFO:Importing libraries
2023-10-15 22:37:10,014:INFO:Copying training dataset
2023-10-15 22:37:10,021:INFO:Defining folds
2023-10-15 22:37:10,021:INFO:Declaring metric variables
2023-10-15 22:37:10,024:INFO:Importing untrained model
2023-10-15 22:37:10,029:INFO:Lasso Least Angle Regression Imported successfully
2023-10-15 22:37:10,036:INFO:Starting cross validation
2023-10-15 22:37:10,038:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:10,113:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:37:10,129:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:37:10,146:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:37:10,176:INFO:Calculating mean and std
2023-10-15 22:37:10,177:INFO:Creating metrics dataframe
2023-10-15 22:37:10,179:INFO:Uploading results into container
2023-10-15 22:37:10,180:INFO:Uploading model into container now
2023-10-15 22:37:10,180:INFO:_master_model_container: 6
2023-10-15 22:37:10,180:INFO:_display_container: 2
2023-10-15 22:37:10,181:INFO:LassoLars(random_state=1234)
2023-10-15 22:37:10,181:INFO:create_model() successfully completed......................................
2023-10-15 22:37:10,307:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:10,307:INFO:Creating metrics dataframe
2023-10-15 22:37:10,316:INFO:Initializing Orthogonal Matching Pursuit
2023-10-15 22:37:10,317:INFO:Total runtime is 0.16156431833902996 minutes
2023-10-15 22:37:10,321:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:10,321:INFO:Initializing create_model()
2023-10-15 22:37:10,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:10,322:INFO:Checking exceptions
2023-10-15 22:37:10,322:INFO:Importing libraries
2023-10-15 22:37:10,322:INFO:Copying training dataset
2023-10-15 22:37:10,327:INFO:Defining folds
2023-10-15 22:37:10,327:INFO:Declaring metric variables
2023-10-15 22:37:10,330:INFO:Importing untrained model
2023-10-15 22:37:10,335:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-15 22:37:10,341:INFO:Starting cross validation
2023-10-15 22:37:10,344:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:10,429:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:37:10,438:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:37:10,458:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:37:10,490:INFO:Calculating mean and std
2023-10-15 22:37:10,492:INFO:Creating metrics dataframe
2023-10-15 22:37:10,494:INFO:Uploading results into container
2023-10-15 22:37:10,494:INFO:Uploading model into container now
2023-10-15 22:37:10,495:INFO:_master_model_container: 7
2023-10-15 22:37:10,495:INFO:_display_container: 2
2023-10-15 22:37:10,495:INFO:OrthogonalMatchingPursuit()
2023-10-15 22:37:10,495:INFO:create_model() successfully completed......................................
2023-10-15 22:37:10,623:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:10,623:INFO:Creating metrics dataframe
2023-10-15 22:37:10,634:INFO:Initializing Bayesian Ridge
2023-10-15 22:37:10,634:INFO:Total runtime is 0.1668697158495585 minutes
2023-10-15 22:37:10,638:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:10,639:INFO:Initializing create_model()
2023-10-15 22:37:10,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:10,639:INFO:Checking exceptions
2023-10-15 22:37:10,639:INFO:Importing libraries
2023-10-15 22:37:10,639:INFO:Copying training dataset
2023-10-15 22:37:10,643:INFO:Defining folds
2023-10-15 22:37:10,643:INFO:Declaring metric variables
2023-10-15 22:37:10,646:INFO:Importing untrained model
2023-10-15 22:37:10,651:INFO:Bayesian Ridge Imported successfully
2023-10-15 22:37:10,659:INFO:Starting cross validation
2023-10-15 22:37:10,661:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:10,793:INFO:Calculating mean and std
2023-10-15 22:37:10,794:INFO:Creating metrics dataframe
2023-10-15 22:37:10,797:INFO:Uploading results into container
2023-10-15 22:37:10,798:INFO:Uploading model into container now
2023-10-15 22:37:10,798:INFO:_master_model_container: 8
2023-10-15 22:37:10,798:INFO:_display_container: 2
2023-10-15 22:37:10,798:INFO:BayesianRidge()
2023-10-15 22:37:10,798:INFO:create_model() successfully completed......................................
2023-10-15 22:37:10,922:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:10,922:INFO:Creating metrics dataframe
2023-10-15 22:37:10,930:INFO:Initializing Passive Aggressive Regressor
2023-10-15 22:37:10,930:INFO:Total runtime is 0.17180852890014647 minutes
2023-10-15 22:37:10,936:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:10,936:INFO:Initializing create_model()
2023-10-15 22:37:10,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:10,937:INFO:Checking exceptions
2023-10-15 22:37:10,937:INFO:Importing libraries
2023-10-15 22:37:10,937:INFO:Copying training dataset
2023-10-15 22:37:10,942:INFO:Defining folds
2023-10-15 22:37:10,942:INFO:Declaring metric variables
2023-10-15 22:37:10,944:INFO:Importing untrained model
2023-10-15 22:37:10,949:INFO:Passive Aggressive Regressor Imported successfully
2023-10-15 22:37:10,957:INFO:Starting cross validation
2023-10-15 22:37:10,959:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:11,131:INFO:Calculating mean and std
2023-10-15 22:37:11,134:INFO:Creating metrics dataframe
2023-10-15 22:37:11,137:INFO:Uploading results into container
2023-10-15 22:37:11,138:INFO:Uploading model into container now
2023-10-15 22:37:11,138:INFO:_master_model_container: 9
2023-10-15 22:37:11,138:INFO:_display_container: 2
2023-10-15 22:37:11,139:INFO:PassiveAggressiveRegressor(random_state=1234)
2023-10-15 22:37:11,139:INFO:create_model() successfully completed......................................
2023-10-15 22:37:11,257:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:11,258:INFO:Creating metrics dataframe
2023-10-15 22:37:11,268:INFO:Initializing Huber Regressor
2023-10-15 22:37:11,268:INFO:Total runtime is 0.17742815812428792 minutes
2023-10-15 22:37:11,270:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:11,271:INFO:Initializing create_model()
2023-10-15 22:37:11,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:11,271:INFO:Checking exceptions
2023-10-15 22:37:11,271:INFO:Importing libraries
2023-10-15 22:37:11,271:INFO:Copying training dataset
2023-10-15 22:37:11,276:INFO:Defining folds
2023-10-15 22:37:11,276:INFO:Declaring metric variables
2023-10-15 22:37:11,279:INFO:Importing untrained model
2023-10-15 22:37:11,284:INFO:Huber Regressor Imported successfully
2023-10-15 22:37:11,291:INFO:Starting cross validation
2023-10-15 22:37:11,294:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:11,461:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:37:11,474:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:37:11,508:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:37:11,534:INFO:Calculating mean and std
2023-10-15 22:37:11,536:INFO:Creating metrics dataframe
2023-10-15 22:37:11,538:INFO:Uploading results into container
2023-10-15 22:37:11,539:INFO:Uploading model into container now
2023-10-15 22:37:11,539:INFO:_master_model_container: 10
2023-10-15 22:37:11,539:INFO:_display_container: 2
2023-10-15 22:37:11,540:INFO:HuberRegressor()
2023-10-15 22:37:11,540:INFO:create_model() successfully completed......................................
2023-10-15 22:37:11,662:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:11,663:INFO:Creating metrics dataframe
2023-10-15 22:37:11,673:INFO:Initializing K Neighbors Regressor
2023-10-15 22:37:11,673:INFO:Total runtime is 0.18418877124786376 minutes
2023-10-15 22:37:11,676:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:11,676:INFO:Initializing create_model()
2023-10-15 22:37:11,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:11,676:INFO:Checking exceptions
2023-10-15 22:37:11,676:INFO:Importing libraries
2023-10-15 22:37:11,677:INFO:Copying training dataset
2023-10-15 22:37:11,683:INFO:Defining folds
2023-10-15 22:37:11,684:INFO:Declaring metric variables
2023-10-15 22:37:11,686:INFO:Importing untrained model
2023-10-15 22:37:11,691:INFO:K Neighbors Regressor Imported successfully
2023-10-15 22:37:11,697:INFO:Starting cross validation
2023-10-15 22:37:11,700:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:11,924:INFO:Calculating mean and std
2023-10-15 22:37:11,925:INFO:Creating metrics dataframe
2023-10-15 22:37:11,927:INFO:Uploading results into container
2023-10-15 22:37:11,928:INFO:Uploading model into container now
2023-10-15 22:37:11,928:INFO:_master_model_container: 11
2023-10-15 22:37:11,928:INFO:_display_container: 2
2023-10-15 22:37:11,928:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-15 22:37:11,928:INFO:create_model() successfully completed......................................
2023-10-15 22:37:12,092:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:12,092:INFO:Creating metrics dataframe
2023-10-15 22:37:12,109:INFO:Initializing Decision Tree Regressor
2023-10-15 22:37:12,109:INFO:Total runtime is 0.19145550727844238 minutes
2023-10-15 22:37:12,113:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:12,114:INFO:Initializing create_model()
2023-10-15 22:37:12,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:12,114:INFO:Checking exceptions
2023-10-15 22:37:12,114:INFO:Importing libraries
2023-10-15 22:37:12,114:INFO:Copying training dataset
2023-10-15 22:37:12,125:INFO:Defining folds
2023-10-15 22:37:12,125:INFO:Declaring metric variables
2023-10-15 22:37:12,134:INFO:Importing untrained model
2023-10-15 22:37:12,142:INFO:Decision Tree Regressor Imported successfully
2023-10-15 22:37:12,153:INFO:Starting cross validation
2023-10-15 22:37:12,154:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:12,310:INFO:Calculating mean and std
2023-10-15 22:37:12,311:INFO:Creating metrics dataframe
2023-10-15 22:37:12,314:INFO:Uploading results into container
2023-10-15 22:37:12,317:INFO:Uploading model into container now
2023-10-15 22:37:12,317:INFO:_master_model_container: 12
2023-10-15 22:37:12,317:INFO:_display_container: 2
2023-10-15 22:37:12,318:INFO:DecisionTreeRegressor(random_state=1234)
2023-10-15 22:37:12,318:INFO:create_model() successfully completed......................................
2023-10-15 22:37:12,448:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:12,448:INFO:Creating metrics dataframe
2023-10-15 22:37:12,459:INFO:Initializing Random Forest Regressor
2023-10-15 22:37:12,459:INFO:Total runtime is 0.19728094339370728 minutes
2023-10-15 22:37:12,461:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:12,461:INFO:Initializing create_model()
2023-10-15 22:37:12,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:12,462:INFO:Checking exceptions
2023-10-15 22:37:12,462:INFO:Importing libraries
2023-10-15 22:37:12,462:INFO:Copying training dataset
2023-10-15 22:37:12,469:INFO:Defining folds
2023-10-15 22:37:12,470:INFO:Declaring metric variables
2023-10-15 22:37:12,473:INFO:Importing untrained model
2023-10-15 22:37:12,477:INFO:Random Forest Regressor Imported successfully
2023-10-15 22:37:12,486:INFO:Starting cross validation
2023-10-15 22:37:12,488:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:13,494:INFO:Calculating mean and std
2023-10-15 22:37:13,496:INFO:Creating metrics dataframe
2023-10-15 22:37:13,500:INFO:Uploading results into container
2023-10-15 22:37:13,500:INFO:Uploading model into container now
2023-10-15 22:37:13,501:INFO:_master_model_container: 13
2023-10-15 22:37:13,501:INFO:_display_container: 2
2023-10-15 22:37:13,501:INFO:RandomForestRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:37:13,502:INFO:create_model() successfully completed......................................
2023-10-15 22:37:13,634:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:13,634:INFO:Creating metrics dataframe
2023-10-15 22:37:13,642:INFO:Initializing Extra Trees Regressor
2023-10-15 22:37:13,642:INFO:Total runtime is 0.2170081655184428 minutes
2023-10-15 22:37:13,644:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:13,646:INFO:Initializing create_model()
2023-10-15 22:37:13,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:13,646:INFO:Checking exceptions
2023-10-15 22:37:13,646:INFO:Importing libraries
2023-10-15 22:37:13,646:INFO:Copying training dataset
2023-10-15 22:37:13,655:INFO:Defining folds
2023-10-15 22:37:13,656:INFO:Declaring metric variables
2023-10-15 22:37:13,659:INFO:Importing untrained model
2023-10-15 22:37:13,664:INFO:Extra Trees Regressor Imported successfully
2023-10-15 22:37:13,673:INFO:Starting cross validation
2023-10-15 22:37:13,675:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:14,461:INFO:Calculating mean and std
2023-10-15 22:37:14,462:INFO:Creating metrics dataframe
2023-10-15 22:37:14,466:INFO:Uploading results into container
2023-10-15 22:37:14,468:INFO:Uploading model into container now
2023-10-15 22:37:14,468:INFO:_master_model_container: 14
2023-10-15 22:37:14,468:INFO:_display_container: 2
2023-10-15 22:37:14,469:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:37:14,469:INFO:create_model() successfully completed......................................
2023-10-15 22:37:14,593:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:14,593:INFO:Creating metrics dataframe
2023-10-15 22:37:14,603:INFO:Initializing AdaBoost Regressor
2023-10-15 22:37:14,603:INFO:Total runtime is 0.23301610151926677 minutes
2023-10-15 22:37:14,606:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:14,607:INFO:Initializing create_model()
2023-10-15 22:37:14,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:14,607:INFO:Checking exceptions
2023-10-15 22:37:14,607:INFO:Importing libraries
2023-10-15 22:37:14,607:INFO:Copying training dataset
2023-10-15 22:37:14,611:INFO:Defining folds
2023-10-15 22:37:14,612:INFO:Declaring metric variables
2023-10-15 22:37:14,617:INFO:Importing untrained model
2023-10-15 22:37:14,620:INFO:AdaBoost Regressor Imported successfully
2023-10-15 22:37:14,666:INFO:Starting cross validation
2023-10-15 22:37:14,667:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:15,099:INFO:Calculating mean and std
2023-10-15 22:37:15,101:INFO:Creating metrics dataframe
2023-10-15 22:37:15,104:INFO:Uploading results into container
2023-10-15 22:37:15,104:INFO:Uploading model into container now
2023-10-15 22:37:15,105:INFO:_master_model_container: 15
2023-10-15 22:37:15,105:INFO:_display_container: 2
2023-10-15 22:37:15,105:INFO:AdaBoostRegressor(random_state=1234)
2023-10-15 22:37:15,105:INFO:create_model() successfully completed......................................
2023-10-15 22:37:15,221:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:15,221:INFO:Creating metrics dataframe
2023-10-15 22:37:15,234:INFO:Initializing Gradient Boosting Regressor
2023-10-15 22:37:15,234:INFO:Total runtime is 0.24353086551030478 minutes
2023-10-15 22:37:15,241:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:15,241:INFO:Initializing create_model()
2023-10-15 22:37:15,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:15,242:INFO:Checking exceptions
2023-10-15 22:37:15,242:INFO:Importing libraries
2023-10-15 22:37:15,242:INFO:Copying training dataset
2023-10-15 22:37:15,246:INFO:Defining folds
2023-10-15 22:37:15,246:INFO:Declaring metric variables
2023-10-15 22:37:15,250:INFO:Importing untrained model
2023-10-15 22:37:15,253:INFO:Gradient Boosting Regressor Imported successfully
2023-10-15 22:37:15,262:INFO:Starting cross validation
2023-10-15 22:37:15,265:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:15,894:INFO:Calculating mean and std
2023-10-15 22:37:15,896:INFO:Creating metrics dataframe
2023-10-15 22:37:15,901:INFO:Uploading results into container
2023-10-15 22:37:15,901:INFO:Uploading model into container now
2023-10-15 22:37:15,902:INFO:_master_model_container: 16
2023-10-15 22:37:15,902:INFO:_display_container: 2
2023-10-15 22:37:15,902:INFO:GradientBoostingRegressor(random_state=1234)
2023-10-15 22:37:15,902:INFO:create_model() successfully completed......................................
2023-10-15 22:37:16,041:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:16,041:INFO:Creating metrics dataframe
2023-10-15 22:37:16,052:INFO:Initializing Extreme Gradient Boosting
2023-10-15 22:37:16,052:INFO:Total runtime is 0.25715949535369875 minutes
2023-10-15 22:37:16,056:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:16,056:INFO:Initializing create_model()
2023-10-15 22:37:16,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:16,056:INFO:Checking exceptions
2023-10-15 22:37:16,057:INFO:Importing libraries
2023-10-15 22:37:16,057:INFO:Copying training dataset
2023-10-15 22:37:16,061:INFO:Defining folds
2023-10-15 22:37:16,061:INFO:Declaring metric variables
2023-10-15 22:37:16,067:INFO:Importing untrained model
2023-10-15 22:37:16,073:INFO:Extreme Gradient Boosting Imported successfully
2023-10-15 22:37:16,079:INFO:Starting cross validation
2023-10-15 22:37:16,080:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:16,413:INFO:Calculating mean and std
2023-10-15 22:37:16,416:INFO:Creating metrics dataframe
2023-10-15 22:37:16,419:INFO:Uploading results into container
2023-10-15 22:37:16,419:INFO:Uploading model into container now
2023-10-15 22:37:16,420:INFO:_master_model_container: 17
2023-10-15 22:37:16,420:INFO:_display_container: 2
2023-10-15 22:37:16,421:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1234, ...)
2023-10-15 22:37:16,421:INFO:create_model() successfully completed......................................
2023-10-15 22:37:16,554:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:16,556:INFO:Creating metrics dataframe
2023-10-15 22:37:16,569:INFO:Initializing Light Gradient Boosting Machine
2023-10-15 22:37:16,569:INFO:Total runtime is 0.26579053004582726 minutes
2023-10-15 22:37:16,572:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:16,573:INFO:Initializing create_model()
2023-10-15 22:37:16,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:16,573:INFO:Checking exceptions
2023-10-15 22:37:16,573:INFO:Importing libraries
2023-10-15 22:37:16,573:INFO:Copying training dataset
2023-10-15 22:37:16,579:INFO:Defining folds
2023-10-15 22:37:16,579:INFO:Declaring metric variables
2023-10-15 22:37:16,583:INFO:Importing untrained model
2023-10-15 22:37:16,587:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:37:16,594:INFO:Starting cross validation
2023-10-15 22:37:16,597:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:17,052:INFO:Calculating mean and std
2023-10-15 22:37:17,054:INFO:Creating metrics dataframe
2023-10-15 22:37:17,061:INFO:Uploading results into container
2023-10-15 22:37:17,062:INFO:Uploading model into container now
2023-10-15 22:37:17,063:INFO:_master_model_container: 18
2023-10-15 22:37:17,063:INFO:_display_container: 2
2023-10-15 22:37:17,064:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:37:17,064:INFO:create_model() successfully completed......................................
2023-10-15 22:37:17,230:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:17,230:INFO:Creating metrics dataframe
2023-10-15 22:37:17,242:INFO:Initializing Dummy Regressor
2023-10-15 22:37:17,242:INFO:Total runtime is 0.2770030736923218 minutes
2023-10-15 22:37:17,246:INFO:SubProcess create_model() called ==================================
2023-10-15 22:37:17,248:INFO:Initializing create_model()
2023-10-15 22:37:17,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE812020>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:17,249:INFO:Checking exceptions
2023-10-15 22:37:17,249:INFO:Importing libraries
2023-10-15 22:37:17,249:INFO:Copying training dataset
2023-10-15 22:37:17,257:INFO:Defining folds
2023-10-15 22:37:17,257:INFO:Declaring metric variables
2023-10-15 22:37:17,260:INFO:Importing untrained model
2023-10-15 22:37:17,266:INFO:Dummy Regressor Imported successfully
2023-10-15 22:37:17,272:INFO:Starting cross validation
2023-10-15 22:37:17,274:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:37:17,429:INFO:Calculating mean and std
2023-10-15 22:37:17,431:INFO:Creating metrics dataframe
2023-10-15 22:37:17,437:INFO:Uploading results into container
2023-10-15 22:37:17,437:INFO:Uploading model into container now
2023-10-15 22:37:17,438:INFO:_master_model_container: 19
2023-10-15 22:37:17,438:INFO:_display_container: 2
2023-10-15 22:37:17,438:INFO:DummyRegressor()
2023-10-15 22:37:17,438:INFO:create_model() successfully completed......................................
2023-10-15 22:37:17,572:INFO:SubProcess create_model() end ==================================
2023-10-15 22:37:17,572:INFO:Creating metrics dataframe
2023-10-15 22:37:17,597:INFO:Initializing create_model()
2023-10-15 22:37:17,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:37:17,597:INFO:Checking exceptions
2023-10-15 22:37:17,600:INFO:Importing libraries
2023-10-15 22:37:17,600:INFO:Copying training dataset
2023-10-15 22:37:17,605:INFO:Defining folds
2023-10-15 22:37:17,605:INFO:Declaring metric variables
2023-10-15 22:37:17,605:INFO:Importing untrained model
2023-10-15 22:37:17,605:INFO:Declaring custom model
2023-10-15 22:37:17,606:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:37:17,607:INFO:Cross validation set to False
2023-10-15 22:37:17,607:INFO:Fitting Model
2023-10-15 22:37:17,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2023-10-15 22:37:17,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:37:17,687:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:37:17,687:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:37:17,688:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:37:17,757:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:37:17,757:INFO:create_model() successfully completed......................................
2023-10-15 22:37:17,933:INFO:_master_model_container: 19
2023-10-15 22:37:17,933:INFO:_display_container: 2
2023-10-15 22:37:17,933:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:37:17,933:INFO:compare_models() successfully completed......................................
2023-10-15 22:42:16,222:INFO:Initializing predict_model()
2023-10-15 22:42:16,222:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291B7F4BEB0>)
2023-10-15 22:42:16,222:INFO:Checking exceptions
2023-10-15 22:42:16,223:INFO:Preloading libraries
2023-10-15 22:42:55,478:INFO:Initializing predict_model()
2023-10-15 22:42:55,478:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291CF979360>)
2023-10-15 22:42:55,478:INFO:Checking exceptions
2023-10-15 22:42:55,478:INFO:Preloading libraries
2023-10-15 22:42:55,481:INFO:Set up data.
2023-10-15 22:42:55,492:INFO:Set up index.
2023-10-15 22:46:11,988:INFO:Initializing tune_model()
2023-10-15 22:46:11,988:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>)
2023-10-15 22:46:11,988:INFO:Checking exceptions
2023-10-15 22:46:12,026:INFO:Copying training dataset
2023-10-15 22:46:12,032:INFO:Checking base model
2023-10-15 22:46:12,032:INFO:Base model : Light Gradient Boosting Machine
2023-10-15 22:46:12,038:INFO:Declaring metric variables
2023-10-15 22:46:12,043:INFO:Defining Hyperparameters
2023-10-15 22:46:12,297:INFO:Tuning with n_jobs=-1
2023-10-15 22:46:12,297:INFO:Initializing RandomizedSearchCV
2023-10-15 22:46:20,886:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.7}
2023-10-15 22:46:20,888:INFO:Hyperparameter search completed
2023-10-15 22:46:20,889:INFO:SubProcess create_model() called ==================================
2023-10-15 22:46:20,889:INFO:Initializing create_model()
2023-10-15 22:46:20,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BE6482B0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.3, 'reg_alpha': 3, 'num_leaves': 30, 'n_estimators': 230, 'min_split_gain': 0.3, 'min_child_samples': 91, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 0.7})
2023-10-15 22:46:20,890:INFO:Checking exceptions
2023-10-15 22:46:20,890:INFO:Importing libraries
2023-10-15 22:46:20,890:INFO:Copying training dataset
2023-10-15 22:46:20,897:INFO:Defining folds
2023-10-15 22:46:20,898:INFO:Declaring metric variables
2023-10-15 22:46:20,903:INFO:Importing untrained model
2023-10-15 22:46:20,903:INFO:Declaring custom model
2023-10-15 22:46:20,907:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:46:20,915:INFO:Starting cross validation
2023-10-15 22:46:20,919:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:46:21,522:INFO:Calculating mean and std
2023-10-15 22:46:21,524:INFO:Creating metrics dataframe
2023-10-15 22:46:21,529:INFO:Finalizing model
2023-10-15 22:46:21,621:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:46:21,621:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:46:21,622:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:46:21,627:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:46:21,627:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:46:21,627:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:46:21,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.
2023-10-15 22:46:21,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-15 22:46:21,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-15 22:46:21,628:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:46:21,628:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:46:21,629:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:46:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:46:21,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:46:21,806:INFO:Uploading results into container
2023-10-15 22:46:21,806:INFO:Uploading model into container now
2023-10-15 22:46:21,808:INFO:_master_model_container: 20
2023-10-15 22:46:21,809:INFO:_display_container: 5
2023-10-15 22:46:21,810:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-10-15 22:46:21,810:INFO:create_model() successfully completed......................................
2023-10-15 22:46:21,986:INFO:SubProcess create_model() end ==================================
2023-10-15 22:46:21,986:INFO:choose_better activated
2023-10-15 22:46:21,990:INFO:SubProcess create_model() called ==================================
2023-10-15 22:46:21,991:INFO:Initializing create_model()
2023-10-15 22:46:21,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:46:21,991:INFO:Checking exceptions
2023-10-15 22:46:21,993:INFO:Importing libraries
2023-10-15 22:46:21,993:INFO:Copying training dataset
2023-10-15 22:46:21,996:INFO:Defining folds
2023-10-15 22:46:21,996:INFO:Declaring metric variables
2023-10-15 22:46:21,997:INFO:Importing untrained model
2023-10-15 22:46:21,997:INFO:Declaring custom model
2023-10-15 22:46:21,998:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:46:21,998:INFO:Starting cross validation
2023-10-15 22:46:21,998:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:46:22,379:INFO:Calculating mean and std
2023-10-15 22:46:22,380:INFO:Creating metrics dataframe
2023-10-15 22:46:22,383:INFO:Finalizing model
2023-10-15 22:46:22,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2023-10-15 22:46:22,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:46:22,475:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:46:22,475:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:46:22,476:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:46:22,548:INFO:Uploading results into container
2023-10-15 22:46:22,548:INFO:Uploading model into container now
2023-10-15 22:46:22,549:INFO:_master_model_container: 21
2023-10-15 22:46:22,549:INFO:_display_container: 6
2023-10-15 22:46:22,549:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:46:22,549:INFO:create_model() successfully completed......................................
2023-10-15 22:46:22,705:INFO:SubProcess create_model() end ==================================
2023-10-15 22:46:22,706:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) result for R2 is 0.5757
2023-10-15 22:46:22,707:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3) result for R2 is 0.5798
2023-10-15 22:46:22,707:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3) is best model
2023-10-15 22:46:22,707:INFO:choose_better completed
2023-10-15 22:46:22,715:INFO:_master_model_container: 21
2023-10-15 22:46:22,716:INFO:_display_container: 5
2023-10-15 22:46:22,716:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-10-15 22:46:22,716:INFO:tune_model() successfully completed......................................
2023-10-15 22:47:48,057:INFO:Initializing predict_model()
2023-10-15 22:47:48,058:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291D143DD80>)
2023-10-15 22:47:48,058:INFO:Checking exceptions
2023-10-15 22:47:48,058:INFO:Preloading libraries
2023-10-15 22:48:42,883:INFO:Initializing predict_model()
2023-10-15 22:48:42,883:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291BDED7C70>)
2023-10-15 22:48:42,883:INFO:Checking exceptions
2023-10-15 22:48:42,883:INFO:Preloading libraries
2023-10-15 22:48:42,886:INFO:Set up data.
2023-10-15 22:48:42,893:INFO:Set up index.
2023-10-15 22:49:37,951:INFO:Initializing finalize_model()
2023-10-15 22:49:37,951:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-15 22:49:37,952:INFO:Finalizing LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-10-15 22:49:37,957:INFO:Initializing create_model()
2023-10-15 22:49:37,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-15 22:49:37,957:INFO:Checking exceptions
2023-10-15 22:49:37,959:INFO:Importing libraries
2023-10-15 22:49:37,959:INFO:Copying training dataset
2023-10-15 22:49:37,959:INFO:Defining folds
2023-10-15 22:49:37,959:INFO:Declaring metric variables
2023-10-15 22:49:37,959:INFO:Importing untrained model
2023-10-15 22:49:37,959:INFO:Declaring custom model
2023-10-15 22:49:37,960:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:49:37,962:INFO:Cross validation set to False
2023-10-15 22:49:37,962:INFO:Fitting Model
2023-10-15 22:49:38,045:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:49:38,045:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:49:38,045:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:49:38,050:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:49:38,050:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:49:38,050:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:49:38,050:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000067 seconds.
2023-10-15 22:49:38,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-15 22:49:38,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-15 22:49:38,050:INFO:[LightGBM] [Info] Total Bins 1070
2023-10-15 22:49:38,050:INFO:[LightGBM] [Info] Number of data points in the train set: 6006, number of used features: 25
2023-10-15 22:49:38,051:INFO:[LightGBM] [Info] Start training from score 365.914729
2023-10-15 22:49:38,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:49:38,274:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=0,
                               feature_fraction=0.5, min_child_samples=91,
                               min_split_gain=0.3, n_estimators=230, n_jobs=-1,
                               num_leaves=30, random_state=1234, reg_alpha=3,
                               reg_lambda=0.3))])
2023-10-15 22:49:38,274:INFO:create_model() successfully completed......................................
2023-10-15 22:49:38,418:INFO:_master_model_container: 21
2023-10-15 22:49:38,418:INFO:_display_container: 7
2023-10-15 22:49:38,449:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(bagging_fraction=0.7, bagging_freq=0,
                               feature_fraction=0.5, min_child_samples=91,
                               min_split_gain=0.3, n_estimators=230, n_jobs=-1,
                               num_leaves=30, random_state=1234, reg_alpha=3,
                               reg_lambda=0.3))])
2023-10-15 22:49:38,449:INFO:finalize_model() successfully completed......................................
2023-10-15 22:56:12,248:INFO:Initializing ensemble_model()
2023-10-15 22:56:12,248:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-15 22:56:12,248:INFO:Checking exceptions
2023-10-15 22:56:12,284:INFO:Importing libraries
2023-10-15 22:56:12,284:INFO:Copying training dataset
2023-10-15 22:56:12,284:INFO:Checking base model
2023-10-15 22:56:12,284:INFO:Base model : Light Gradient Boosting Machine
2023-10-15 22:56:12,291:INFO:Importing untrained ensembler
2023-10-15 22:56:12,292:INFO:Ensemble method set to Bagging
2023-10-15 22:56:12,292:INFO:SubProcess create_model() called ==================================
2023-10-15 22:56:12,295:INFO:Initializing create_model()
2023-10-15 22:56:12,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=BaggingRegressor(base_estimator=LGBMRegressor(bagging_fraction=0.7,
                                              bagging_freq=0,
                                              feature_fraction=0.5,
                                              min_child_samples=91,
                                              min_split_gain=0.3,
                                              n_estimators=230, n_jobs=-1,
                                              num_leaves=30, random_state=1234,
                                              reg_alpha=3, reg_lambda=0.3),
                 random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291D1576590>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:56:12,295:INFO:Checking exceptions
2023-10-15 22:56:12,295:INFO:Importing libraries
2023-10-15 22:56:12,295:INFO:Copying training dataset
2023-10-15 22:56:12,301:INFO:Defining folds
2023-10-15 22:56:12,302:INFO:Declaring metric variables
2023-10-15 22:56:12,305:INFO:Importing untrained model
2023-10-15 22:56:12,305:INFO:Declaring custom model
2023-10-15 22:56:12,308:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:56:12,318:INFO:Starting cross validation
2023-10-15 22:56:12,321:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:56:19,103:INFO:Calculating mean and std
2023-10-15 22:56:19,106:INFO:Creating metrics dataframe
2023-10-15 22:56:19,115:INFO:Finalizing model
2023-10-15 22:56:19,211:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,211:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,211:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,214:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,214:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,214:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.
2023-10-15 22:56:19,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-15 22:56:19,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-15 22:56:19,215:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:19,215:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:19,215:INFO:[LightGBM] [Info] Start training from score 361.461216
2023-10-15 22:56:19,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,372:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,372:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,372:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,375:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,375:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,375:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2023-10-15 22:56:19,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:19,376:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:19,376:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:19,376:INFO:[LightGBM] [Info] Start training from score 362.048122
2023-10-15 22:56:19,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,510:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,510:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,513:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,514:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,514:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,514:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2023-10-15 22:56:19,514:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:19,514:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:19,514:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:19,515:INFO:[LightGBM] [Info] Start training from score 362.152229
2023-10-15 22:56:19,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,640:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,640:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,640:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,644:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,644:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,644:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2023-10-15 22:56:19,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:19,645:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:19,645:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:19,645:INFO:[LightGBM] [Info] Start training from score 361.120814
2023-10-15 22:56:19,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,787:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,787:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,787:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,791:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,791:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,791:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,791:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2023-10-15 22:56:19,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:19,791:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:19,791:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:19,792:INFO:[LightGBM] [Info] Start training from score 362.010807
2023-10-15 22:56:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:19,921:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,921:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,922:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,924:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:19,925:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:19,925:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:19,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2023-10-15 22:56:19,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:19,925:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:19,925:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:19,925:INFO:[LightGBM] [Info] Start training from score 361.960496
2023-10-15 22:56:19,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,068:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,068:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,068:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,071:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,071:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,071:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,073:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2023-10-15 22:56:20,073:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:20,073:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:20,073:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:20,073:INFO:[LightGBM] [Info] Start training from score 361.852436
2023-10-15 22:56:20,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,227:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,228:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,228:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,232:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,232:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,232:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2023-10-15 22:56:20,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:20,232:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:20,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:20,232:INFO:[LightGBM] [Info] Start training from score 361.515665
2023-10-15 22:56:20,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,364:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,364:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,364:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,368:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,368:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,368:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2023-10-15 22:56:20,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:20,369:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:20,369:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:20,369:INFO:[LightGBM] [Info] Start training from score 361.132447
2023-10-15 22:56:20,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,500:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,500:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,500:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,503:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:20,503:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:20,503:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:20,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2023-10-15 22:56:20,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:56:20,504:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:20,504:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:20,504:INFO:[LightGBM] [Info] Start training from score 360.648827
2023-10-15 22:56:20,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:20,639:INFO:Uploading results into container
2023-10-15 22:56:20,640:INFO:Uploading model into container now
2023-10-15 22:56:20,641:INFO:_master_model_container: 22
2023-10-15 22:56:20,641:INFO:_display_container: 8
2023-10-15 22:56:20,643:INFO:BaggingRegressor(base_estimator=LGBMRegressor(bagging_fraction=0.7,
                                              bagging_freq=0,
                                              feature_fraction=0.5,
                                              min_child_samples=91,
                                              min_split_gain=0.3,
                                              n_estimators=230, n_jobs=-1,
                                              num_leaves=30, random_state=1234,
                                              reg_alpha=3, reg_lambda=0.3),
                 random_state=1234)
2023-10-15 22:56:20,644:INFO:create_model() successfully completed......................................
2023-10-15 22:56:20,869:INFO:SubProcess create_model() end ==================================
2023-10-15 22:56:20,869:INFO:choose_better activated
2023-10-15 22:56:20,872:INFO:SubProcess create_model() called ==================================
2023-10-15 22:56:20,872:INFO:Initializing create_model()
2023-10-15 22:56:20,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291BDF99F00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:56:20,872:INFO:Checking exceptions
2023-10-15 22:56:20,874:INFO:Importing libraries
2023-10-15 22:56:20,874:INFO:Copying training dataset
2023-10-15 22:56:20,878:INFO:Defining folds
2023-10-15 22:56:20,878:INFO:Declaring metric variables
2023-10-15 22:56:20,878:INFO:Importing untrained model
2023-10-15 22:56:20,878:INFO:Declaring custom model
2023-10-15 22:56:20,879:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:56:20,879:INFO:Starting cross validation
2023-10-15 22:56:20,880:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None), n_jobs=-1
2023-10-15 22:56:23,207:INFO:Calculating mean and std
2023-10-15 22:56:23,208:INFO:Creating metrics dataframe
2023-10-15 22:56:23,211:INFO:Finalizing model
2023-10-15 22:56:23,312:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:23,312:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:23,312:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:23,316:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:56:23,317:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:56:23,317:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:56:23,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000063 seconds.
2023-10-15 22:56:23,317:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-15 22:56:23,317:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-15 22:56:23,317:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:56:23,317:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:56:23,317:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:56:23,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:23,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:56:23,481:INFO:Uploading results into container
2023-10-15 22:56:23,482:INFO:Uploading model into container now
2023-10-15 22:56:23,482:INFO:_master_model_container: 23
2023-10-15 22:56:23,482:INFO:_display_container: 9
2023-10-15 22:56:23,484:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-10-15 22:56:23,484:INFO:create_model() successfully completed......................................
2023-10-15 22:56:23,641:INFO:SubProcess create_model() end ==================================
2023-10-15 22:56:23,642:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3) result for R2 is 0.5798
2023-10-15 22:56:23,644:INFO:BaggingRegressor(base_estimator=LGBMRegressor(bagging_fraction=0.7,
                                              bagging_freq=0,
                                              feature_fraction=0.5,
                                              min_child_samples=91,
                                              min_split_gain=0.3,
                                              n_estimators=230, n_jobs=-1,
                                              num_leaves=30, random_state=1234,
                                              reg_alpha=3, reg_lambda=0.3),
                 random_state=1234) result for R2 is 0.5696
2023-10-15 22:56:23,645:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3) is best model
2023-10-15 22:56:23,645:INFO:choose_better completed
2023-10-15 22:56:23,645:INFO:Original model was better than the ensembled model, hence it will be returned. NOTE: The display metrics are for the ensembled model (not the original one).
2023-10-15 22:56:23,652:INFO:_master_model_container: 23
2023-10-15 22:56:23,652:INFO:_display_container: 8
2023-10-15 22:56:23,653:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-10-15 22:56:23,653:INFO:ensemble_model() successfully completed......................................
2023-10-15 22:56:48,722:INFO:PyCaret RegressionExperiment
2023-10-15 22:56:48,722:INFO:Logging name: reg-default-name
2023-10-15 22:56:48,722:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-15 22:56:48,722:INFO:version 3.1.0
2023-10-15 22:56:48,722:INFO:Initializing setup()
2023-10-15 22:56:48,722:INFO:self.USI: 29d3
2023-10-15 22:56:48,722:INFO:self._variable_keys: {'y_train', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'idx', 'y', 'X_test', 'n_jobs_param', '_ml_usecase', 'memory', 'fold_generator', 'transform_target_param', 'data', 'y_test', 'exp_id', 'target_param', 'fold_groups_param', 'pipeline', 'seed', 'logging_param', 'X', 'log_plots_param', '_available_plots', 'exp_name_log', 'X_train', 'html_param', 'gpu_param'}
2023-10-15 22:56:48,722:INFO:Checking environment
2023-10-15 22:56:48,722:INFO:python_version: 3.10.6
2023-10-15 22:56:48,722:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-10-15 22:56:48,722:INFO:machine: AMD64
2023-10-15 22:56:48,722:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-15 22:56:48,722:INFO:Memory: svmem(total=8273383424, available=1450422272, percent=82.5, used=6822961152, free=1450422272)
2023-10-15 22:56:48,722:INFO:Physical Core: 4
2023-10-15 22:56:48,722:INFO:Logical Core: 8
2023-10-15 22:56:48,722:INFO:Checking libraries
2023-10-15 22:56:48,724:INFO:System:
2023-10-15 22:56:48,724:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-10-15 22:56:48,724:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-10-15 22:56:48,724:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-15 22:56:48,724:INFO:PyCaret required dependencies:
2023-10-15 22:56:48,724:INFO:                 pip: 22.2.1
2023-10-15 22:56:48,724:INFO:          setuptools: 63.2.0
2023-10-15 22:56:48,724:INFO:             pycaret: 3.1.0
2023-10-15 22:56:48,724:INFO:             IPython: 8.4.0
2023-10-15 22:56:48,724:INFO:          ipywidgets: 8.1.1
2023-10-15 22:56:48,724:INFO:                tqdm: 4.66.1
2023-10-15 22:56:48,724:INFO:               numpy: 1.23.2
2023-10-15 22:56:48,724:INFO:              pandas: 1.4.3
2023-10-15 22:56:48,724:INFO:              jinja2: 3.1.2
2023-10-15 22:56:48,724:INFO:               scipy: 1.10.1
2023-10-15 22:56:48,724:INFO:              joblib: 1.2.0
2023-10-15 22:56:48,724:INFO:             sklearn: 1.1.2
2023-10-15 22:56:48,724:INFO:                pyod: 1.1.0
2023-10-15 22:56:48,724:INFO:            imblearn: 0.11.0
2023-10-15 22:56:48,724:INFO:   category_encoders: 2.6.2
2023-10-15 22:56:48,724:INFO:            lightgbm: 4.1.0
2023-10-15 22:56:48,724:INFO:               numba: 0.58.0
2023-10-15 22:56:48,724:INFO:            requests: 2.28.1
2023-10-15 22:56:48,724:INFO:          matplotlib: 3.6.0
2023-10-15 22:56:48,725:INFO:          scikitplot: 0.3.7
2023-10-15 22:56:48,725:INFO:         yellowbrick: 1.5
2023-10-15 22:56:48,725:INFO:              plotly: 5.17.0
2023-10-15 22:56:48,725:INFO:    plotly-resampler: Not installed
2023-10-15 22:56:48,725:INFO:             kaleido: 0.2.1
2023-10-15 22:56:48,725:INFO:           schemdraw: 0.15
2023-10-15 22:56:48,725:INFO:         statsmodels: 0.13.2
2023-10-15 22:56:48,725:INFO:              sktime: 0.21.1
2023-10-15 22:56:48,725:INFO:               tbats: 1.1.3
2023-10-15 22:56:48,725:INFO:            pmdarima: 2.0.3
2023-10-15 22:56:48,725:INFO:              psutil: 5.9.1
2023-10-15 22:56:48,725:INFO:          markupsafe: 2.1.1
2023-10-15 22:56:48,725:INFO:             pickle5: Not installed
2023-10-15 22:56:48,725:INFO:         cloudpickle: 2.2.1
2023-10-15 22:56:48,725:INFO:         deprecation: 2.1.0
2023-10-15 22:56:48,725:INFO:              xxhash: 3.4.1
2023-10-15 22:56:48,725:INFO:           wurlitzer: Not installed
2023-10-15 22:56:48,725:INFO:PyCaret optional dependencies:
2023-10-15 22:56:48,725:INFO:                shap: Not installed
2023-10-15 22:56:48,725:INFO:           interpret: Not installed
2023-10-15 22:56:48,725:INFO:                umap: Not installed
2023-10-15 22:56:48,725:INFO:     ydata_profiling: Not installed
2023-10-15 22:56:48,725:INFO:  explainerdashboard: Not installed
2023-10-15 22:56:48,725:INFO:             autoviz: Not installed
2023-10-15 22:56:48,725:INFO:           fairlearn: Not installed
2023-10-15 22:56:48,725:INFO:          deepchecks: Not installed
2023-10-15 22:56:48,725:INFO:             xgboost: 2.0.0
2023-10-15 22:56:48,725:INFO:            catboost: Not installed
2023-10-15 22:56:48,725:INFO:              kmodes: Not installed
2023-10-15 22:56:48,725:INFO:             mlxtend: Not installed
2023-10-15 22:56:48,725:INFO:       statsforecast: Not installed
2023-10-15 22:56:48,725:INFO:        tune_sklearn: Not installed
2023-10-15 22:56:48,726:INFO:                 ray: Not installed
2023-10-15 22:56:48,726:INFO:            hyperopt: Not installed
2023-10-15 22:56:48,726:INFO:              optuna: Not installed
2023-10-15 22:56:48,726:INFO:               skopt: Not installed
2023-10-15 22:56:48,726:INFO:              mlflow: Not installed
2023-10-15 22:56:48,726:INFO:              gradio: Not installed
2023-10-15 22:56:48,726:INFO:             fastapi: Not installed
2023-10-15 22:56:48,726:INFO:             uvicorn: Not installed
2023-10-15 22:56:48,726:INFO:              m2cgen: Not installed
2023-10-15 22:56:48,726:INFO:           evidently: Not installed
2023-10-15 22:56:48,726:INFO:               fugue: Not installed
2023-10-15 22:56:48,726:INFO:           streamlit: Not installed
2023-10-15 22:56:48,726:INFO:             prophet: 1.1.5
2023-10-15 22:56:48,726:INFO:None
2023-10-15 22:56:48,726:INFO:Set up data.
2023-10-15 22:56:48,731:INFO:Set up folding strategy.
2023-10-15 22:56:48,731:INFO:Set up train/test split.
2023-10-15 22:56:48,731:INFO:Set up data.
2023-10-15 22:56:48,736:INFO:Set up index.
2023-10-15 22:56:48,736:INFO:Assigning column types.
2023-10-15 22:56:48,739:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-15 22:56:48,739:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,743:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,796:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,837:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:48,839:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:48,840:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,843:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,847:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,943:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:48,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:48,945:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-15 22:56:48,949:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:56:48,954:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,055:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,062:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,156:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,158:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-15 22:56:49,166:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,216:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,252:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,262:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,347:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,349:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-15 22:56:49,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,444:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,537:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,539:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-15 22:56:49,598:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,638:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-15 22:56:49,736:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,739:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-15 22:56:49,833:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,932:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:49,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:49,937:INFO:Preparing preprocessing pipeline...
2023-10-15 22:56:49,937:INFO:Set up simple imputation.
2023-10-15 22:56:49,939:INFO:Set up encoding of ordinal features.
2023-10-15 22:56:49,940:INFO:Set up encoding of categorical features.
2023-10-15 22:56:50,019:INFO:Finished creating preprocessing pipeline.
2023-10-15 22:56:50,047:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='...
                 TransformerWrapper(include=['is_working'],
                                    transformer=OrdinalEncoder(cols=['is_working'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-10-15 22:56:50,047:INFO:Creating final display dataframe.
2023-10-15 22:56:50,246:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target        demand_GWh
2                   Target type        Regression
3           Original data shape         (6006, 9)
4        Transformed data shape        (6006, 26)
5   Transformed train set shape        (5506, 26)
6    Transformed test set shape         (500, 26)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   TimeSeriesSplit
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              29d3
2023-10-15 22:56:50,341:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:50,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:50,440:INFO:Soft dependency imported: xgboost: 2.0.0
2023-10-15 22:56:50,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-15 22:56:50,443:INFO:setup() successfully completed in 1.72s...............
2023-10-15 22:56:57,467:INFO:Initializing compare_models()
2023-10-15 22:56:57,467:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-15 22:56:57,467:INFO:Checking exceptions
2023-10-15 22:56:57,471:INFO:Preparing display monitor
2023-10-15 22:56:57,509:INFO:Initializing Linear Regression
2023-10-15 22:56:57,509:INFO:Total runtime is 0.0 minutes
2023-10-15 22:56:57,516:INFO:SubProcess create_model() called ==================================
2023-10-15 22:56:57,517:INFO:Initializing create_model()
2023-10-15 22:56:57,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:56:57,517:INFO:Checking exceptions
2023-10-15 22:56:57,517:INFO:Importing libraries
2023-10-15 22:56:57,517:INFO:Copying training dataset
2023-10-15 22:56:57,523:INFO:Defining folds
2023-10-15 22:56:57,523:INFO:Declaring metric variables
2023-10-15 22:56:57,527:INFO:Importing untrained model
2023-10-15 22:56:57,530:INFO:Linear Regression Imported successfully
2023-10-15 22:56:57,539:INFO:Starting cross validation
2023-10-15 22:56:57,541:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:00,092:INFO:Calculating mean and std
2023-10-15 22:57:00,095:INFO:Creating metrics dataframe
2023-10-15 22:57:00,102:INFO:Uploading results into container
2023-10-15 22:57:00,104:INFO:Uploading model into container now
2023-10-15 22:57:00,105:INFO:_master_model_container: 1
2023-10-15 22:57:00,105:INFO:_display_container: 2
2023-10-15 22:57:00,106:INFO:LinearRegression(n_jobs=-1)
2023-10-15 22:57:00,106:INFO:create_model() successfully completed......................................
2023-10-15 22:57:00,346:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:00,346:INFO:Creating metrics dataframe
2023-10-15 22:57:00,359:INFO:Initializing Lasso Regression
2023-10-15 22:57:00,359:INFO:Total runtime is 0.04749126831690471 minutes
2023-10-15 22:57:00,366:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:00,367:INFO:Initializing create_model()
2023-10-15 22:57:00,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:00,367:INFO:Checking exceptions
2023-10-15 22:57:00,367:INFO:Importing libraries
2023-10-15 22:57:00,367:INFO:Copying training dataset
2023-10-15 22:57:00,376:INFO:Defining folds
2023-10-15 22:57:00,376:INFO:Declaring metric variables
2023-10-15 22:57:00,382:INFO:Importing untrained model
2023-10-15 22:57:00,388:INFO:Lasso Regression Imported successfully
2023-10-15 22:57:00,398:INFO:Starting cross validation
2023-10-15 22:57:00,402:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:00,783:INFO:Calculating mean and std
2023-10-15 22:57:00,785:INFO:Creating metrics dataframe
2023-10-15 22:57:00,788:INFO:Uploading results into container
2023-10-15 22:57:00,789:INFO:Uploading model into container now
2023-10-15 22:57:00,789:INFO:_master_model_container: 2
2023-10-15 22:57:00,789:INFO:_display_container: 2
2023-10-15 22:57:00,789:INFO:Lasso(random_state=1234)
2023-10-15 22:57:00,789:INFO:create_model() successfully completed......................................
2023-10-15 22:57:00,979:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:00,979:INFO:Creating metrics dataframe
2023-10-15 22:57:00,991:INFO:Initializing Ridge Regression
2023-10-15 22:57:00,991:INFO:Total runtime is 0.05803474187850952 minutes
2023-10-15 22:57:00,994:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:00,994:INFO:Initializing create_model()
2023-10-15 22:57:00,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:00,994:INFO:Checking exceptions
2023-10-15 22:57:00,994:INFO:Importing libraries
2023-10-15 22:57:00,995:INFO:Copying training dataset
2023-10-15 22:57:01,002:INFO:Defining folds
2023-10-15 22:57:01,003:INFO:Declaring metric variables
2023-10-15 22:57:01,007:INFO:Importing untrained model
2023-10-15 22:57:01,009:INFO:Ridge Regression Imported successfully
2023-10-15 22:57:01,019:INFO:Starting cross validation
2023-10-15 22:57:01,021:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:01,371:INFO:Calculating mean and std
2023-10-15 22:57:01,373:INFO:Creating metrics dataframe
2023-10-15 22:57:01,376:INFO:Uploading results into container
2023-10-15 22:57:01,377:INFO:Uploading model into container now
2023-10-15 22:57:01,378:INFO:_master_model_container: 3
2023-10-15 22:57:01,378:INFO:_display_container: 2
2023-10-15 22:57:01,378:INFO:Ridge(random_state=1234)
2023-10-15 22:57:01,379:INFO:create_model() successfully completed......................................
2023-10-15 22:57:01,590:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:01,590:INFO:Creating metrics dataframe
2023-10-15 22:57:01,601:INFO:Initializing Elastic Net
2023-10-15 22:57:01,602:INFO:Total runtime is 0.06821475426355998 minutes
2023-10-15 22:57:01,606:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:01,606:INFO:Initializing create_model()
2023-10-15 22:57:01,606:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:01,607:INFO:Checking exceptions
2023-10-15 22:57:01,607:INFO:Importing libraries
2023-10-15 22:57:01,607:INFO:Copying training dataset
2023-10-15 22:57:01,613:INFO:Defining folds
2023-10-15 22:57:01,613:INFO:Declaring metric variables
2023-10-15 22:57:01,618:INFO:Importing untrained model
2023-10-15 22:57:01,624:INFO:Elastic Net Imported successfully
2023-10-15 22:57:01,632:INFO:Starting cross validation
2023-10-15 22:57:01,635:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:02,029:INFO:Calculating mean and std
2023-10-15 22:57:02,032:INFO:Creating metrics dataframe
2023-10-15 22:57:02,035:INFO:Uploading results into container
2023-10-15 22:57:02,036:INFO:Uploading model into container now
2023-10-15 22:57:02,036:INFO:_master_model_container: 4
2023-10-15 22:57:02,037:INFO:_display_container: 2
2023-10-15 22:57:02,037:INFO:ElasticNet(random_state=1234)
2023-10-15 22:57:02,038:INFO:create_model() successfully completed......................................
2023-10-15 22:57:02,209:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:02,210:INFO:Creating metrics dataframe
2023-10-15 22:57:02,220:INFO:Initializing Least Angle Regression
2023-10-15 22:57:02,220:INFO:Total runtime is 0.07851282358169556 minutes
2023-10-15 22:57:02,223:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:02,223:INFO:Initializing create_model()
2023-10-15 22:57:02,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:02,223:INFO:Checking exceptions
2023-10-15 22:57:02,224:INFO:Importing libraries
2023-10-15 22:57:02,224:INFO:Copying training dataset
2023-10-15 22:57:02,228:INFO:Defining folds
2023-10-15 22:57:02,228:INFO:Declaring metric variables
2023-10-15 22:57:02,233:INFO:Importing untrained model
2023-10-15 22:57:02,240:INFO:Least Angle Regression Imported successfully
2023-10-15 22:57:02,250:INFO:Starting cross validation
2023-10-15 22:57:02,253:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:02,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,378:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.284e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.081e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.696e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.979e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.936e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,387:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.832e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,387:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.827e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,388:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.589e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,426:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,435:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.395e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,478:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,488:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.144e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,501:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.703e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,502:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.174e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,503:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.086e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,511:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,522:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,566:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,627:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:02,633:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.432e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,633:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.056e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,634:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.154e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-15 22:57:02,686:INFO:Calculating mean and std
2023-10-15 22:57:02,688:INFO:Creating metrics dataframe
2023-10-15 22:57:02,693:INFO:Uploading results into container
2023-10-15 22:57:02,694:INFO:Uploading model into container now
2023-10-15 22:57:02,695:INFO:_master_model_container: 5
2023-10-15 22:57:02,695:INFO:_display_container: 2
2023-10-15 22:57:02,696:INFO:Lars(random_state=1234)
2023-10-15 22:57:02,697:INFO:create_model() successfully completed......................................
2023-10-15 22:57:02,899:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:02,899:INFO:Creating metrics dataframe
2023-10-15 22:57:02,908:INFO:Initializing Lasso Least Angle Regression
2023-10-15 22:57:02,908:INFO:Total runtime is 0.08997826178868612 minutes
2023-10-15 22:57:02,911:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:02,911:INFO:Initializing create_model()
2023-10-15 22:57:02,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:02,911:INFO:Checking exceptions
2023-10-15 22:57:02,911:INFO:Importing libraries
2023-10-15 22:57:02,911:INFO:Copying training dataset
2023-10-15 22:57:02,918:INFO:Defining folds
2023-10-15 22:57:02,918:INFO:Declaring metric variables
2023-10-15 22:57:02,922:INFO:Importing untrained model
2023-10-15 22:57:02,926:INFO:Lasso Least Angle Regression Imported successfully
2023-10-15 22:57:02,933:INFO:Starting cross validation
2023-10-15 22:57:02,935:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:03,048:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,058:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,071:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,076:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,093:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,111:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,121:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,144:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,212:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,218:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-15 22:57:03,249:INFO:Calculating mean and std
2023-10-15 22:57:03,250:INFO:Creating metrics dataframe
2023-10-15 22:57:03,253:INFO:Uploading results into container
2023-10-15 22:57:03,253:INFO:Uploading model into container now
2023-10-15 22:57:03,254:INFO:_master_model_container: 6
2023-10-15 22:57:03,254:INFO:_display_container: 2
2023-10-15 22:57:03,254:INFO:LassoLars(random_state=1234)
2023-10-15 22:57:03,254:INFO:create_model() successfully completed......................................
2023-10-15 22:57:03,437:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:03,437:INFO:Creating metrics dataframe
2023-10-15 22:57:03,444:INFO:Initializing Orthogonal Matching Pursuit
2023-10-15 22:57:03,445:INFO:Total runtime is 0.09893264770507813 minutes
2023-10-15 22:57:03,451:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:03,452:INFO:Initializing create_model()
2023-10-15 22:57:03,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:03,452:INFO:Checking exceptions
2023-10-15 22:57:03,452:INFO:Importing libraries
2023-10-15 22:57:03,452:INFO:Copying training dataset
2023-10-15 22:57:03,457:INFO:Defining folds
2023-10-15 22:57:03,457:INFO:Declaring metric variables
2023-10-15 22:57:03,460:INFO:Importing untrained model
2023-10-15 22:57:03,466:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-15 22:57:03,475:INFO:Starting cross validation
2023-10-15 22:57:03,477:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:03,586:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,591:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,618:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,632:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,642:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,645:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,672:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,754:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,775:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-15 22:57:03,817:INFO:Calculating mean and std
2023-10-15 22:57:03,819:INFO:Creating metrics dataframe
2023-10-15 22:57:03,821:INFO:Uploading results into container
2023-10-15 22:57:03,822:INFO:Uploading model into container now
2023-10-15 22:57:03,822:INFO:_master_model_container: 7
2023-10-15 22:57:03,823:INFO:_display_container: 2
2023-10-15 22:57:03,823:INFO:OrthogonalMatchingPursuit()
2023-10-15 22:57:03,823:INFO:create_model() successfully completed......................................
2023-10-15 22:57:03,983:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:03,983:INFO:Creating metrics dataframe
2023-10-15 22:57:03,991:INFO:Initializing Bayesian Ridge
2023-10-15 22:57:03,991:INFO:Total runtime is 0.10802905162175497 minutes
2023-10-15 22:57:03,994:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:03,994:INFO:Initializing create_model()
2023-10-15 22:57:03,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:03,995:INFO:Checking exceptions
2023-10-15 22:57:03,995:INFO:Importing libraries
2023-10-15 22:57:03,995:INFO:Copying training dataset
2023-10-15 22:57:04,004:INFO:Defining folds
2023-10-15 22:57:04,004:INFO:Declaring metric variables
2023-10-15 22:57:04,007:INFO:Importing untrained model
2023-10-15 22:57:04,010:INFO:Bayesian Ridge Imported successfully
2023-10-15 22:57:04,021:INFO:Starting cross validation
2023-10-15 22:57:04,023:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:04,335:INFO:Calculating mean and std
2023-10-15 22:57:04,336:INFO:Creating metrics dataframe
2023-10-15 22:57:04,338:INFO:Uploading results into container
2023-10-15 22:57:04,339:INFO:Uploading model into container now
2023-10-15 22:57:04,339:INFO:_master_model_container: 8
2023-10-15 22:57:04,339:INFO:_display_container: 2
2023-10-15 22:57:04,340:INFO:BayesianRidge()
2023-10-15 22:57:04,340:INFO:create_model() successfully completed......................................
2023-10-15 22:57:04,593:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:04,593:INFO:Creating metrics dataframe
2023-10-15 22:57:04,612:INFO:Initializing Passive Aggressive Regressor
2023-10-15 22:57:04,612:INFO:Total runtime is 0.11837161382039388 minutes
2023-10-15 22:57:04,618:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:04,619:INFO:Initializing create_model()
2023-10-15 22:57:04,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:04,619:INFO:Checking exceptions
2023-10-15 22:57:04,619:INFO:Importing libraries
2023-10-15 22:57:04,619:INFO:Copying training dataset
2023-10-15 22:57:04,626:INFO:Defining folds
2023-10-15 22:57:04,626:INFO:Declaring metric variables
2023-10-15 22:57:04,633:INFO:Importing untrained model
2023-10-15 22:57:04,639:INFO:Passive Aggressive Regressor Imported successfully
2023-10-15 22:57:04,649:INFO:Starting cross validation
2023-10-15 22:57:04,652:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:05,059:INFO:Calculating mean and std
2023-10-15 22:57:05,060:INFO:Creating metrics dataframe
2023-10-15 22:57:05,063:INFO:Uploading results into container
2023-10-15 22:57:05,064:INFO:Uploading model into container now
2023-10-15 22:57:05,065:INFO:_master_model_container: 9
2023-10-15 22:57:05,065:INFO:_display_container: 2
2023-10-15 22:57:05,065:INFO:PassiveAggressiveRegressor(random_state=1234)
2023-10-15 22:57:05,065:INFO:create_model() successfully completed......................................
2023-10-15 22:57:05,220:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:05,220:INFO:Creating metrics dataframe
2023-10-15 22:57:05,229:INFO:Initializing Huber Regressor
2023-10-15 22:57:05,230:INFO:Total runtime is 0.1286853313446045 minutes
2023-10-15 22:57:05,233:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:05,233:INFO:Initializing create_model()
2023-10-15 22:57:05,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:05,233:INFO:Checking exceptions
2023-10-15 22:57:05,233:INFO:Importing libraries
2023-10-15 22:57:05,233:INFO:Copying training dataset
2023-10-15 22:57:05,238:INFO:Defining folds
2023-10-15 22:57:05,238:INFO:Declaring metric variables
2023-10-15 22:57:05,241:INFO:Importing untrained model
2023-10-15 22:57:05,245:INFO:Huber Regressor Imported successfully
2023-10-15 22:57:05,254:INFO:Starting cross validation
2023-10-15 22:57:05,256:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:05,406:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,454:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,468:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,472:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,510:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,558:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,571:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,644:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,692:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,737:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-15 22:57:05,756:INFO:Calculating mean and std
2023-10-15 22:57:05,758:INFO:Creating metrics dataframe
2023-10-15 22:57:05,761:INFO:Uploading results into container
2023-10-15 22:57:05,761:INFO:Uploading model into container now
2023-10-15 22:57:05,762:INFO:_master_model_container: 10
2023-10-15 22:57:05,762:INFO:_display_container: 2
2023-10-15 22:57:05,762:INFO:HuberRegressor()
2023-10-15 22:57:05,763:INFO:create_model() successfully completed......................................
2023-10-15 22:57:05,910:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:05,910:INFO:Creating metrics dataframe
2023-10-15 22:57:05,922:INFO:Initializing K Neighbors Regressor
2023-10-15 22:57:05,922:INFO:Total runtime is 0.14020387331644696 minutes
2023-10-15 22:57:05,924:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:05,924:INFO:Initializing create_model()
2023-10-15 22:57:05,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:05,926:INFO:Checking exceptions
2023-10-15 22:57:05,926:INFO:Importing libraries
2023-10-15 22:57:05,926:INFO:Copying training dataset
2023-10-15 22:57:05,932:INFO:Defining folds
2023-10-15 22:57:05,932:INFO:Declaring metric variables
2023-10-15 22:57:05,935:INFO:Importing untrained model
2023-10-15 22:57:05,940:INFO:K Neighbors Regressor Imported successfully
2023-10-15 22:57:05,947:INFO:Starting cross validation
2023-10-15 22:57:05,950:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:06,639:INFO:Calculating mean and std
2023-10-15 22:57:06,642:INFO:Creating metrics dataframe
2023-10-15 22:57:06,648:INFO:Uploading results into container
2023-10-15 22:57:06,649:INFO:Uploading model into container now
2023-10-15 22:57:06,650:INFO:_master_model_container: 11
2023-10-15 22:57:06,650:INFO:_display_container: 2
2023-10-15 22:57:06,650:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-15 22:57:06,650:INFO:create_model() successfully completed......................................
2023-10-15 22:57:06,809:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:06,809:INFO:Creating metrics dataframe
2023-10-15 22:57:06,820:INFO:Initializing Decision Tree Regressor
2023-10-15 22:57:06,820:INFO:Total runtime is 0.15517279307047527 minutes
2023-10-15 22:57:06,822:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:06,822:INFO:Initializing create_model()
2023-10-15 22:57:06,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:06,822:INFO:Checking exceptions
2023-10-15 22:57:06,822:INFO:Importing libraries
2023-10-15 22:57:06,823:INFO:Copying training dataset
2023-10-15 22:57:06,828:INFO:Defining folds
2023-10-15 22:57:06,828:INFO:Declaring metric variables
2023-10-15 22:57:06,834:INFO:Importing untrained model
2023-10-15 22:57:06,839:INFO:Decision Tree Regressor Imported successfully
2023-10-15 22:57:06,845:INFO:Starting cross validation
2023-10-15 22:57:06,847:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:07,206:INFO:Calculating mean and std
2023-10-15 22:57:07,208:INFO:Creating metrics dataframe
2023-10-15 22:57:07,211:INFO:Uploading results into container
2023-10-15 22:57:07,212:INFO:Uploading model into container now
2023-10-15 22:57:07,214:INFO:_master_model_container: 12
2023-10-15 22:57:07,214:INFO:_display_container: 2
2023-10-15 22:57:07,214:INFO:DecisionTreeRegressor(random_state=1234)
2023-10-15 22:57:07,214:INFO:create_model() successfully completed......................................
2023-10-15 22:57:07,364:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:07,364:INFO:Creating metrics dataframe
2023-10-15 22:57:07,374:INFO:Initializing Random Forest Regressor
2023-10-15 22:57:07,374:INFO:Total runtime is 0.1644095818201701 minutes
2023-10-15 22:57:07,376:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:07,376:INFO:Initializing create_model()
2023-10-15 22:57:07,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:07,377:INFO:Checking exceptions
2023-10-15 22:57:07,377:INFO:Importing libraries
2023-10-15 22:57:07,377:INFO:Copying training dataset
2023-10-15 22:57:07,384:INFO:Defining folds
2023-10-15 22:57:07,384:INFO:Declaring metric variables
2023-10-15 22:57:07,388:INFO:Importing untrained model
2023-10-15 22:57:07,393:INFO:Random Forest Regressor Imported successfully
2023-10-15 22:57:07,402:INFO:Starting cross validation
2023-10-15 22:57:07,404:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:10,173:INFO:Calculating mean and std
2023-10-15 22:57:10,175:INFO:Creating metrics dataframe
2023-10-15 22:57:10,184:INFO:Uploading results into container
2023-10-15 22:57:10,185:INFO:Uploading model into container now
2023-10-15 22:57:10,185:INFO:_master_model_container: 13
2023-10-15 22:57:10,185:INFO:_display_container: 2
2023-10-15 22:57:10,185:INFO:RandomForestRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:57:10,186:INFO:create_model() successfully completed......................................
2023-10-15 22:57:10,428:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:10,428:INFO:Creating metrics dataframe
2023-10-15 22:57:10,440:INFO:Initializing Extra Trees Regressor
2023-10-15 22:57:10,440:INFO:Total runtime is 0.21551723877588908 minutes
2023-10-15 22:57:10,443:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:10,443:INFO:Initializing create_model()
2023-10-15 22:57:10,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:10,443:INFO:Checking exceptions
2023-10-15 22:57:10,443:INFO:Importing libraries
2023-10-15 22:57:10,443:INFO:Copying training dataset
2023-10-15 22:57:10,450:INFO:Defining folds
2023-10-15 22:57:10,451:INFO:Declaring metric variables
2023-10-15 22:57:10,455:INFO:Importing untrained model
2023-10-15 22:57:10,458:INFO:Extra Trees Regressor Imported successfully
2023-10-15 22:57:10,467:INFO:Starting cross validation
2023-10-15 22:57:10,469:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:12,804:INFO:Calculating mean and std
2023-10-15 22:57:12,805:INFO:Creating metrics dataframe
2023-10-15 22:57:12,809:INFO:Uploading results into container
2023-10-15 22:57:12,809:INFO:Uploading model into container now
2023-10-15 22:57:12,810:INFO:_master_model_container: 14
2023-10-15 22:57:12,810:INFO:_display_container: 2
2023-10-15 22:57:12,811:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:57:12,811:INFO:create_model() successfully completed......................................
2023-10-15 22:57:12,963:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:12,963:INFO:Creating metrics dataframe
2023-10-15 22:57:12,974:INFO:Initializing AdaBoost Regressor
2023-10-15 22:57:12,974:INFO:Total runtime is 0.25773853063583374 minutes
2023-10-15 22:57:12,978:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:12,978:INFO:Initializing create_model()
2023-10-15 22:57:12,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:12,979:INFO:Checking exceptions
2023-10-15 22:57:12,979:INFO:Importing libraries
2023-10-15 22:57:12,979:INFO:Copying training dataset
2023-10-15 22:57:12,984:INFO:Defining folds
2023-10-15 22:57:12,984:INFO:Declaring metric variables
2023-10-15 22:57:12,988:INFO:Importing untrained model
2023-10-15 22:57:12,992:INFO:AdaBoost Regressor Imported successfully
2023-10-15 22:57:12,998:INFO:Starting cross validation
2023-10-15 22:57:12,999:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:13,938:INFO:Calculating mean and std
2023-10-15 22:57:13,939:INFO:Creating metrics dataframe
2023-10-15 22:57:13,943:INFO:Uploading results into container
2023-10-15 22:57:13,943:INFO:Uploading model into container now
2023-10-15 22:57:13,944:INFO:_master_model_container: 15
2023-10-15 22:57:13,944:INFO:_display_container: 2
2023-10-15 22:57:13,945:INFO:AdaBoostRegressor(random_state=1234)
2023-10-15 22:57:13,945:INFO:create_model() successfully completed......................................
2023-10-15 22:57:14,165:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:14,165:INFO:Creating metrics dataframe
2023-10-15 22:57:14,179:INFO:Initializing Gradient Boosting Regressor
2023-10-15 22:57:14,179:INFO:Total runtime is 0.2778219938278198 minutes
2023-10-15 22:57:14,184:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:14,184:INFO:Initializing create_model()
2023-10-15 22:57:14,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:14,184:INFO:Checking exceptions
2023-10-15 22:57:14,184:INFO:Importing libraries
2023-10-15 22:57:14,185:INFO:Copying training dataset
2023-10-15 22:57:14,189:INFO:Defining folds
2023-10-15 22:57:14,189:INFO:Declaring metric variables
2023-10-15 22:57:14,193:INFO:Importing untrained model
2023-10-15 22:57:14,199:INFO:Gradient Boosting Regressor Imported successfully
2023-10-15 22:57:14,205:INFO:Starting cross validation
2023-10-15 22:57:14,206:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:15,482:INFO:Calculating mean and std
2023-10-15 22:57:15,483:INFO:Creating metrics dataframe
2023-10-15 22:57:15,485:INFO:Uploading results into container
2023-10-15 22:57:15,485:INFO:Uploading model into container now
2023-10-15 22:57:15,486:INFO:_master_model_container: 16
2023-10-15 22:57:15,486:INFO:_display_container: 2
2023-10-15 22:57:15,487:INFO:GradientBoostingRegressor(random_state=1234)
2023-10-15 22:57:15,487:INFO:create_model() successfully completed......................................
2023-10-15 22:57:15,631:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:15,632:INFO:Creating metrics dataframe
2023-10-15 22:57:15,643:INFO:Initializing Extreme Gradient Boosting
2023-10-15 22:57:15,644:INFO:Total runtime is 0.3022471944491068 minutes
2023-10-15 22:57:15,648:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:15,648:INFO:Initializing create_model()
2023-10-15 22:57:15,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:15,648:INFO:Checking exceptions
2023-10-15 22:57:15,649:INFO:Importing libraries
2023-10-15 22:57:15,649:INFO:Copying training dataset
2023-10-15 22:57:15,654:INFO:Defining folds
2023-10-15 22:57:15,654:INFO:Declaring metric variables
2023-10-15 22:57:15,658:INFO:Importing untrained model
2023-10-15 22:57:15,664:INFO:Extreme Gradient Boosting Imported successfully
2023-10-15 22:57:15,672:INFO:Starting cross validation
2023-10-15 22:57:15,673:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:16,669:INFO:Calculating mean and std
2023-10-15 22:57:16,672:INFO:Creating metrics dataframe
2023-10-15 22:57:16,678:INFO:Uploading results into container
2023-10-15 22:57:16,679:INFO:Uploading model into container now
2023-10-15 22:57:16,680:INFO:_master_model_container: 17
2023-10-15 22:57:16,680:INFO:_display_container: 2
2023-10-15 22:57:16,681:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1234, ...)
2023-10-15 22:57:16,681:INFO:create_model() successfully completed......................................
2023-10-15 22:57:16,884:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:16,884:INFO:Creating metrics dataframe
2023-10-15 22:57:16,894:INFO:Initializing Light Gradient Boosting Machine
2023-10-15 22:57:16,895:INFO:Total runtime is 0.32309323549270624 minutes
2023-10-15 22:57:16,898:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:16,898:INFO:Initializing create_model()
2023-10-15 22:57:16,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:16,898:INFO:Checking exceptions
2023-10-15 22:57:16,898:INFO:Importing libraries
2023-10-15 22:57:16,898:INFO:Copying training dataset
2023-10-15 22:57:16,903:INFO:Defining folds
2023-10-15 22:57:16,903:INFO:Declaring metric variables
2023-10-15 22:57:16,906:INFO:Importing untrained model
2023-10-15 22:57:16,913:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:57:16,919:INFO:Starting cross validation
2023-10-15 22:57:16,921:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:18,038:INFO:Calculating mean and std
2023-10-15 22:57:18,040:INFO:Creating metrics dataframe
2023-10-15 22:57:18,046:INFO:Uploading results into container
2023-10-15 22:57:18,047:INFO:Uploading model into container now
2023-10-15 22:57:18,048:INFO:_master_model_container: 18
2023-10-15 22:57:18,048:INFO:_display_container: 2
2023-10-15 22:57:18,048:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:57:18,048:INFO:create_model() successfully completed......................................
2023-10-15 22:57:18,206:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:18,206:INFO:Creating metrics dataframe
2023-10-15 22:57:18,218:INFO:Initializing Dummy Regressor
2023-10-15 22:57:18,218:INFO:Total runtime is 0.3451433897018432 minutes
2023-10-15 22:57:18,221:INFO:SubProcess create_model() called ==================================
2023-10-15 22:57:18,221:INFO:Initializing create_model()
2023-10-15 22:57:18,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291BED7E620>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:18,222:INFO:Checking exceptions
2023-10-15 22:57:18,222:INFO:Importing libraries
2023-10-15 22:57:18,222:INFO:Copying training dataset
2023-10-15 22:57:18,227:INFO:Defining folds
2023-10-15 22:57:18,227:INFO:Declaring metric variables
2023-10-15 22:57:18,231:INFO:Importing untrained model
2023-10-15 22:57:18,235:INFO:Dummy Regressor Imported successfully
2023-10-15 22:57:18,241:INFO:Starting cross validation
2023-10-15 22:57:18,244:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:57:18,524:INFO:Calculating mean and std
2023-10-15 22:57:18,525:INFO:Creating metrics dataframe
2023-10-15 22:57:18,530:INFO:Uploading results into container
2023-10-15 22:57:18,531:INFO:Uploading model into container now
2023-10-15 22:57:18,531:INFO:_master_model_container: 19
2023-10-15 22:57:18,531:INFO:_display_container: 2
2023-10-15 22:57:18,531:INFO:DummyRegressor()
2023-10-15 22:57:18,531:INFO:create_model() successfully completed......................................
2023-10-15 22:57:18,684:INFO:SubProcess create_model() end ==================================
2023-10-15 22:57:18,684:INFO:Creating metrics dataframe
2023-10-15 22:57:18,709:INFO:Initializing create_model()
2023-10-15 22:57:18,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:57:18,710:INFO:Checking exceptions
2023-10-15 22:57:18,713:INFO:Importing libraries
2023-10-15 22:57:18,713:INFO:Copying training dataset
2023-10-15 22:57:18,717:INFO:Defining folds
2023-10-15 22:57:18,717:INFO:Declaring metric variables
2023-10-15 22:57:18,717:INFO:Importing untrained model
2023-10-15 22:57:18,717:INFO:Declaring custom model
2023-10-15 22:57:18,717:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:57:18,718:INFO:Cross validation set to False
2023-10-15 22:57:18,718:INFO:Fitting Model
2023-10-15 22:57:18,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2023-10-15 22:57:18,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:57:18,805:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:57:18,805:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:57:18,805:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:57:18,878:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:57:18,878:INFO:create_model() successfully completed......................................
2023-10-15 22:57:19,082:INFO:_master_model_container: 19
2023-10-15 22:57:19,082:INFO:_display_container: 2
2023-10-15 22:57:19,083:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:57:19,083:INFO:compare_models() successfully completed......................................
2023-10-15 22:57:46,143:INFO:Initializing tune_model()
2023-10-15 22:57:46,143:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>)
2023-10-15 22:57:46,143:INFO:Checking exceptions
2023-10-15 22:57:46,183:INFO:Copying training dataset
2023-10-15 22:57:46,189:INFO:Checking base model
2023-10-15 22:57:46,189:INFO:Base model : Light Gradient Boosting Machine
2023-10-15 22:57:46,193:INFO:Declaring metric variables
2023-10-15 22:57:46,196:INFO:Defining Hyperparameters
2023-10-15 22:57:46,455:INFO:Tuning with n_jobs=-1
2023-10-15 22:57:46,455:INFO:Initializing RandomizedSearchCV
2023-10-15 22:58:00,491:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.7}
2023-10-15 22:58:00,493:INFO:Hyperparameter search completed
2023-10-15 22:58:00,493:INFO:SubProcess create_model() called ==================================
2023-10-15 22:58:00,494:INFO:Initializing create_model()
2023-10-15 22:58:00,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291B7F7A410>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.3, 'reg_alpha': 3, 'num_leaves': 30, 'n_estimators': 230, 'min_split_gain': 0.3, 'min_child_samples': 91, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 0.7})
2023-10-15 22:58:00,495:INFO:Checking exceptions
2023-10-15 22:58:00,495:INFO:Importing libraries
2023-10-15 22:58:00,495:INFO:Copying training dataset
2023-10-15 22:58:00,503:INFO:Defining folds
2023-10-15 22:58:00,503:INFO:Declaring metric variables
2023-10-15 22:58:00,506:INFO:Importing untrained model
2023-10-15 22:58:00,506:INFO:Declaring custom model
2023-10-15 22:58:00,512:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:58:00,521:INFO:Starting cross validation
2023-10-15 22:58:00,523:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:58:02,516:INFO:Calculating mean and std
2023-10-15 22:58:02,518:INFO:Creating metrics dataframe
2023-10-15 22:58:02,524:INFO:Finalizing model
2023-10-15 22:58:02,625:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:58:02,626:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:58:02,626:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:58:02,631:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-10-15 22:58:02,631:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-10-15 22:58:02,631:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-10-15 22:58:02,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.
2023-10-15 22:58:02,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-15 22:58:02,632:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-15 22:58:02,632:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:02,632:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:02,632:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:58:02,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:58:02,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-10-15 22:58:02,829:INFO:Uploading results into container
2023-10-15 22:58:02,830:INFO:Uploading model into container now
2023-10-15 22:58:02,831:INFO:_master_model_container: 20
2023-10-15 22:58:02,831:INFO:_display_container: 3
2023-10-15 22:58:02,832:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-10-15 22:58:02,832:INFO:create_model() successfully completed......................................
2023-10-15 22:58:03,002:INFO:SubProcess create_model() end ==================================
2023-10-15 22:58:03,002:INFO:choose_better activated
2023-10-15 22:58:03,005:INFO:SubProcess create_model() called ==================================
2023-10-15 22:58:03,005:INFO:Initializing create_model()
2023-10-15 22:58:03,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:58:03,005:INFO:Checking exceptions
2023-10-15 22:58:03,007:INFO:Importing libraries
2023-10-15 22:58:03,007:INFO:Copying training dataset
2023-10-15 22:58:03,013:INFO:Defining folds
2023-10-15 22:58:03,013:INFO:Declaring metric variables
2023-10-15 22:58:03,013:INFO:Importing untrained model
2023-10-15 22:58:03,013:INFO:Declaring custom model
2023-10-15 22:58:03,014:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:58:03,014:INFO:Starting cross validation
2023-10-15 22:58:03,015:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:58:04,280:INFO:Calculating mean and std
2023-10-15 22:58:04,281:INFO:Creating metrics dataframe
2023-10-15 22:58:04,283:INFO:Finalizing model
2023-10-15 22:58:04,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2023-10-15 22:58:04,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:04,382:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:04,383:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:04,383:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:58:04,474:INFO:Uploading results into container
2023-10-15 22:58:04,474:INFO:Uploading model into container now
2023-10-15 22:58:04,475:INFO:_master_model_container: 21
2023-10-15 22:58:04,475:INFO:_display_container: 4
2023-10-15 22:58:04,475:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:58:04,475:INFO:create_model() successfully completed......................................
2023-10-15 22:58:04,641:INFO:SubProcess create_model() end ==================================
2023-10-15 22:58:04,641:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) result for R2 is 0.7286
2023-10-15 22:58:04,642:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3) result for R2 is 0.7164
2023-10-15 22:58:04,643:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) is best model
2023-10-15 22:58:04,643:INFO:choose_better completed
2023-10-15 22:58:04,643:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-10-15 22:58:04,651:INFO:_master_model_container: 21
2023-10-15 22:58:04,651:INFO:_display_container: 3
2023-10-15 22:58:04,652:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:58:04,652:INFO:tune_model() successfully completed......................................
2023-10-15 22:58:19,234:INFO:Initializing ensemble_model()
2023-10-15 22:58:19,234:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-10-15 22:58:19,234:INFO:Checking exceptions
2023-10-15 22:58:19,265:INFO:Importing libraries
2023-10-15 22:58:19,267:INFO:Copying training dataset
2023-10-15 22:58:19,267:INFO:Checking base model
2023-10-15 22:58:19,267:INFO:Base model : Light Gradient Boosting Machine
2023-10-15 22:58:19,275:INFO:Importing untrained ensembler
2023-10-15 22:58:19,275:INFO:Ensemble method set to Bagging
2023-10-15 22:58:19,275:INFO:SubProcess create_model() called ==================================
2023-10-15 22:58:19,276:INFO:Initializing create_model()
2023-10-15 22:58:19,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000291D1C3BB80>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:58:19,277:INFO:Checking exceptions
2023-10-15 22:58:19,277:INFO:Importing libraries
2023-10-15 22:58:19,277:INFO:Copying training dataset
2023-10-15 22:58:19,282:INFO:Defining folds
2023-10-15 22:58:19,282:INFO:Declaring metric variables
2023-10-15 22:58:19,285:INFO:Importing untrained model
2023-10-15 22:58:19,287:INFO:Declaring custom model
2023-10-15 22:58:19,294:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:58:19,301:INFO:Starting cross validation
2023-10-15 22:58:19,303:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:58:29,630:INFO:Calculating mean and std
2023-10-15 22:58:29,632:INFO:Creating metrics dataframe
2023-10-15 22:58:29,642:INFO:Finalizing model
2023-10-15 22:58:29,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2023-10-15 22:58:29,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:29,744:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:29,744:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:29,744:INFO:[LightGBM] [Info] Start training from score 361.461216
2023-10-15 22:58:29,971:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2023-10-15 22:58:29,972:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:29,972:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:29,972:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:29,972:INFO:[LightGBM] [Info] Start training from score 362.048122
2023-10-15 22:58:30,057:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2023-10-15 22:58:30,057:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,057:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,058:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,058:INFO:[LightGBM] [Info] Start training from score 362.152229
2023-10-15 22:58:30,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2023-10-15 22:58:30,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,141:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,141:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,141:INFO:[LightGBM] [Info] Start training from score 361.120814
2023-10-15 22:58:30,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2023-10-15 22:58:30,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,223:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,223:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,224:INFO:[LightGBM] [Info] Start training from score 362.010807
2023-10-15 22:58:30,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2023-10-15 22:58:30,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,303:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,303:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,303:INFO:[LightGBM] [Info] Start training from score 361.960496
2023-10-15 22:58:30,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2023-10-15 22:58:30,391:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,391:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,391:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,391:INFO:[LightGBM] [Info] Start training from score 361.852436
2023-10-15 22:58:30,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2023-10-15 22:58:30,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,474:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,474:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,474:INFO:[LightGBM] [Info] Start training from score 361.515665
2023-10-15 22:58:30,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2023-10-15 22:58:30,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,559:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,559:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,559:INFO:[LightGBM] [Info] Start training from score 361.132447
2023-10-15 22:58:30,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2023-10-15 22:58:30,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:30,657:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:30,657:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:30,657:INFO:[LightGBM] [Info] Start training from score 360.648827
2023-10-15 22:58:30,741:INFO:Uploading results into container
2023-10-15 22:58:30,742:INFO:Uploading model into container now
2023-10-15 22:58:30,743:INFO:_master_model_container: 22
2023-10-15 22:58:30,743:INFO:_display_container: 4
2023-10-15 22:58:30,744:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234)
2023-10-15 22:58:30,744:INFO:create_model() successfully completed......................................
2023-10-15 22:58:30,951:INFO:SubProcess create_model() end ==================================
2023-10-15 22:58:30,951:INFO:choose_better activated
2023-10-15 22:58:30,956:INFO:SubProcess create_model() called ==================================
2023-10-15 22:58:30,957:INFO:Initializing create_model()
2023-10-15 22:58:30,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 22:58:30,958:INFO:Checking exceptions
2023-10-15 22:58:30,960:INFO:Importing libraries
2023-10-15 22:58:30,960:INFO:Copying training dataset
2023-10-15 22:58:30,963:INFO:Defining folds
2023-10-15 22:58:30,964:INFO:Declaring metric variables
2023-10-15 22:58:30,964:INFO:Importing untrained model
2023-10-15 22:58:30,964:INFO:Declaring custom model
2023-10-15 22:58:30,964:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:58:30,965:INFO:Starting cross validation
2023-10-15 22:58:30,965:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-10-15 22:58:32,365:INFO:Calculating mean and std
2023-10-15 22:58:32,365:INFO:Creating metrics dataframe
2023-10-15 22:58:32,368:INFO:Finalizing model
2023-10-15 22:58:32,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2023-10-15 22:58:32,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:58:32,466:INFO:[LightGBM] [Info] Total Bins 1069
2023-10-15 22:58:32,466:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-10-15 22:58:32,467:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-10-15 22:58:32,545:INFO:Uploading results into container
2023-10-15 22:58:32,545:INFO:Uploading model into container now
2023-10-15 22:58:32,546:INFO:_master_model_container: 23
2023-10-15 22:58:32,546:INFO:_display_container: 5
2023-10-15 22:58:32,547:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:58:32,547:INFO:create_model() successfully completed......................................
2023-10-15 22:58:32,721:INFO:SubProcess create_model() end ==================================
2023-10-15 22:58:32,721:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) result for R2 is 0.7286
2023-10-15 22:58:32,722:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234) result for R2 is 0.7301
2023-10-15 22:58:32,723:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234) is best model
2023-10-15 22:58:32,723:INFO:choose_better completed
2023-10-15 22:58:32,732:INFO:_master_model_container: 23
2023-10-15 22:58:32,732:INFO:_display_container: 4
2023-10-15 22:58:32,735:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234)
2023-10-15 22:58:32,735:INFO:ensemble_model() successfully completed......................................
2023-10-15 22:59:11,684:INFO:Initializing predict_model()
2023-10-15 22:59:11,684:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291BDD94940>)
2023-10-15 22:59:11,684:INFO:Checking exceptions
2023-10-15 22:59:11,684:INFO:Preloading libraries
2023-10-15 22:59:16,478:INFO:Initializing predict_model()
2023-10-15 22:59:16,479:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291BDD948B0>)
2023-10-15 22:59:16,479:INFO:Checking exceptions
2023-10-15 22:59:16,479:INFO:Preloading libraries
2023-10-15 22:59:21,464:INFO:Initializing predict_model()
2023-10-15 22:59:21,464:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291D143DAB0>)
2023-10-15 22:59:21,464:INFO:Checking exceptions
2023-10-15 22:59:21,464:INFO:Preloading libraries
2023-10-15 22:59:21,467:INFO:Set up data.
2023-10-15 22:59:21,475:INFO:Set up index.
2023-10-15 22:59:45,848:INFO:Initializing finalize_model()
2023-10-15 22:59:45,849:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-15 22:59:45,849:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=1234)
2023-10-15 22:59:45,854:INFO:Initializing create_model()
2023-10-15 22:59:45,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-15 22:59:45,855:INFO:Checking exceptions
2023-10-15 22:59:45,858:INFO:Importing libraries
2023-10-15 22:59:45,858:INFO:Copying training dataset
2023-10-15 22:59:45,859:INFO:Defining folds
2023-10-15 22:59:45,859:INFO:Declaring metric variables
2023-10-15 22:59:45,860:INFO:Importing untrained model
2023-10-15 22:59:45,860:INFO:Declaring custom model
2023-10-15 22:59:45,861:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 22:59:45,863:INFO:Cross validation set to False
2023-10-15 22:59:45,863:INFO:Fitting Model
2023-10-15 22:59:45,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2023-10-15 22:59:45,968:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-10-15 22:59:45,968:INFO:[LightGBM] [Info] Total Bins 1070
2023-10-15 22:59:45,968:INFO:[LightGBM] [Info] Number of data points in the train set: 6006, number of used features: 25
2023-10-15 22:59:45,969:INFO:[LightGBM] [Info] Start training from score 365.914729
2023-10-15 22:59:46,095:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))])
2023-10-15 22:59:46,095:INFO:create_model() successfully completed......................................
2023-10-15 22:59:46,265:INFO:_master_model_container: 23
2023-10-15 22:59:46,266:INFO:_display_container: 7
2023-10-15 22:59:46,291:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))])
2023-10-15 22:59:46,292:INFO:finalize_model() successfully completed......................................
2023-10-15 23:22:21,817:INFO:Initializing predict_model()
2023-10-15 23:22:21,818:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000291D1576AD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000291BDF8BC70>)
2023-10-15 23:22:21,818:INFO:Checking exceptions
2023-10-15 23:22:21,818:INFO:Preloading libraries
2023-10-15 23:22:21,823:INFO:Set up data.
2023-10-15 23:22:21,828:INFO:Set up index.
2023-11-01 09:15:39,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 09:15:39,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 09:15:39,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 09:15:39,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 09:15:39,243:INFO:PyCaret RegressionExperiment
2023-11-01 09:15:39,243:INFO:Logging name: reg-default-name
2023-11-01 09:15:39,243:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-01 09:15:39,243:INFO:version 3.1.0
2023-11-01 09:15:39,243:INFO:Initializing setup()
2023-11-01 09:15:39,243:INFO:self.USI: 9fab
2023-11-01 09:15:39,243:INFO:self._variable_keys: {'gpu_n_jobs_param', 'transform_target_param', 'target_param', 'y_test', 'y', 'X', 'exp_id', 'X_test', 'USI', '_ml_usecase', '_available_plots', 'html_param', 'y_train', 'idx', 'fold_groups_param', 'exp_name_log', 'seed', 'gpu_param', 'pipeline', 'fold_generator', 'X_train', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'logging_param', 'data'}
2023-11-01 09:15:39,243:INFO:Checking environment
2023-11-01 09:15:39,243:INFO:python_version: 3.10.6
2023-11-01 09:15:39,243:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-01 09:15:39,243:INFO:machine: AMD64
2023-11-01 09:15:39,243:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-01 09:15:39,244:INFO:Memory: svmem(total=8273383424, available=1319919616, percent=84.0, used=6953463808, free=1319919616)
2023-11-01 09:15:39,244:INFO:Physical Core: 4
2023-11-01 09:15:39,244:INFO:Logical Core: 8
2023-11-01 09:15:39,244:INFO:Checking libraries
2023-11-01 09:15:39,244:INFO:System:
2023-11-01 09:15:39,244:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-01 09:15:39,244:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-01 09:15:39,244:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-01 09:15:39,244:INFO:PyCaret required dependencies:
2023-11-01 09:15:39,303:INFO:                 pip: 22.2.1
2023-11-01 09:15:39,303:INFO:          setuptools: 63.2.0
2023-11-01 09:15:39,303:INFO:             pycaret: 3.1.0
2023-11-01 09:15:39,303:INFO:             IPython: 8.4.0
2023-11-01 09:15:39,303:INFO:          ipywidgets: 8.1.1
2023-11-01 09:15:39,303:INFO:                tqdm: 4.66.1
2023-11-01 09:15:39,303:INFO:               numpy: 1.23.2
2023-11-01 09:15:39,303:INFO:              pandas: 1.4.3
2023-11-01 09:15:39,303:INFO:              jinja2: 3.1.2
2023-11-01 09:15:39,303:INFO:               scipy: 1.10.1
2023-11-01 09:15:39,303:INFO:              joblib: 1.2.0
2023-11-01 09:15:39,303:INFO:             sklearn: 1.1.2
2023-11-01 09:15:39,303:INFO:                pyod: 1.1.0
2023-11-01 09:15:39,303:INFO:            imblearn: 0.11.0
2023-11-01 09:15:39,303:INFO:   category_encoders: 2.6.2
2023-11-01 09:15:39,303:INFO:            lightgbm: 4.1.0
2023-11-01 09:15:39,303:INFO:               numba: 0.58.0
2023-11-01 09:15:39,303:INFO:            requests: 2.28.1
2023-11-01 09:15:39,303:INFO:          matplotlib: 3.6.0
2023-11-01 09:15:39,303:INFO:          scikitplot: 0.3.7
2023-11-01 09:15:39,303:INFO:         yellowbrick: 1.5
2023-11-01 09:15:39,303:INFO:              plotly: 5.17.0
2023-11-01 09:15:39,303:INFO:    plotly-resampler: Not installed
2023-11-01 09:15:39,303:INFO:             kaleido: 0.2.1
2023-11-01 09:15:39,303:INFO:           schemdraw: 0.15
2023-11-01 09:15:39,303:INFO:         statsmodels: 0.13.2
2023-11-01 09:15:39,304:INFO:              sktime: 0.21.1
2023-11-01 09:15:39,304:INFO:               tbats: 1.1.3
2023-11-01 09:15:39,304:INFO:            pmdarima: 2.0.3
2023-11-01 09:15:39,304:INFO:              psutil: 5.9.1
2023-11-01 09:15:39,304:INFO:          markupsafe: 2.1.1
2023-11-01 09:15:39,304:INFO:             pickle5: Not installed
2023-11-01 09:15:39,304:INFO:         cloudpickle: 2.2.1
2023-11-01 09:15:39,304:INFO:         deprecation: 2.1.0
2023-11-01 09:15:39,304:INFO:              xxhash: 3.4.1
2023-11-01 09:15:39,304:INFO:           wurlitzer: Not installed
2023-11-01 09:15:39,304:INFO:PyCaret optional dependencies:
2023-11-01 09:15:39,455:INFO:                shap: Not installed
2023-11-01 09:15:39,456:INFO:           interpret: Not installed
2023-11-01 09:15:39,456:INFO:                umap: Not installed
2023-11-01 09:15:39,456:INFO:     ydata_profiling: Not installed
2023-11-01 09:15:39,456:INFO:  explainerdashboard: Not installed
2023-11-01 09:15:39,456:INFO:             autoviz: Not installed
2023-11-01 09:15:39,456:INFO:           fairlearn: Not installed
2023-11-01 09:15:39,456:INFO:          deepchecks: Not installed
2023-11-01 09:15:39,456:INFO:             xgboost: 2.0.0
2023-11-01 09:15:39,456:INFO:            catboost: Not installed
2023-11-01 09:15:39,456:INFO:              kmodes: Not installed
2023-11-01 09:15:39,456:INFO:             mlxtend: Not installed
2023-11-01 09:15:39,456:INFO:       statsforecast: Not installed
2023-11-01 09:15:39,456:INFO:        tune_sklearn: Not installed
2023-11-01 09:15:39,456:INFO:                 ray: Not installed
2023-11-01 09:15:39,456:INFO:            hyperopt: Not installed
2023-11-01 09:15:39,456:INFO:              optuna: Not installed
2023-11-01 09:15:39,456:INFO:               skopt: Not installed
2023-11-01 09:15:39,456:INFO:              mlflow: Not installed
2023-11-01 09:15:39,456:INFO:              gradio: Not installed
2023-11-01 09:15:39,456:INFO:             fastapi: Not installed
2023-11-01 09:15:39,456:INFO:             uvicorn: Not installed
2023-11-01 09:15:39,456:INFO:              m2cgen: Not installed
2023-11-01 09:15:39,456:INFO:           evidently: Not installed
2023-11-01 09:15:39,456:INFO:               fugue: Not installed
2023-11-01 09:15:39,456:INFO:           streamlit: Not installed
2023-11-01 09:15:39,456:INFO:             prophet: 1.1.5
2023-11-01 09:15:39,456:INFO:None
2023-11-01 09:15:39,456:INFO:Set up data.
2023-11-01 09:15:39,462:INFO:Set up folding strategy.
2023-11-01 09:15:39,462:INFO:Set up train/test split.
2023-11-01 09:15:39,462:INFO:Set up data.
2023-11-01 09:15:39,465:INFO:Set up index.
2023-11-01 09:15:39,465:INFO:Assigning column types.
2023-11-01 09:15:39,468:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-01 09:15:39,469:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,474:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,477:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,565:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:39,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:39,567:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,571:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,574:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,658:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:39,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:39,660:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-01 09:15:39,665:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,752:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:39,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:39,759:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,847:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:39,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:39,849:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-01 09:15:39,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:39,943:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:39,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:39,953:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,041:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,043:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-01 09:15:40,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,136:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,232:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,235:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-01 09:15:40,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,327:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:15:40,424:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,426:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-01 09:15:40,541:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,636:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:40,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:40,642:INFO:Preparing preprocessing pipeline...
2023-11-01 09:15:40,642:INFO:Set up simple imputation.
2023-11-01 09:15:40,645:INFO:Set up encoding of ordinal features.
2023-11-01 09:15:40,646:INFO:Set up encoding of categorical features.
2023-11-01 09:15:40,722:INFO:Finished creating preprocessing pipeline.
2023-11-01 09:15:40,745:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='...
                 TransformerWrapper(include=['is_working'],
                                    transformer=OrdinalEncoder(cols=['is_working'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-11-01 09:15:40,745:INFO:Creating final display dataframe.
2023-11-01 09:15:40,929:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target        demand_GWh
2                   Target type        Regression
3           Original data shape         (6006, 9)
4        Transformed data shape        (6006, 26)
5   Transformed train set shape        (5506, 26)
6    Transformed test set shape         (500, 26)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   TimeSeriesSplit
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              9fab
2023-11-01 09:15:41,020:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:41,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:41,114:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:15:41,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:15:41,116:INFO:setup() successfully completed in 1.88s...............
2023-11-01 09:15:44,915:INFO:Initializing compare_models()
2023-11-01 09:15:44,916:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 09:15:44,916:INFO:Checking exceptions
2023-11-01 09:15:44,920:INFO:Preparing display monitor
2023-11-01 09:15:44,970:INFO:Initializing Linear Regression
2023-11-01 09:15:44,970:INFO:Total runtime is 0.0 minutes
2023-11-01 09:15:44,973:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:44,974:INFO:Initializing create_model()
2023-11-01 09:15:44,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:44,974:INFO:Checking exceptions
2023-11-01 09:15:44,974:INFO:Importing libraries
2023-11-01 09:15:44,974:INFO:Copying training dataset
2023-11-01 09:15:44,978:INFO:Defining folds
2023-11-01 09:15:44,978:INFO:Declaring metric variables
2023-11-01 09:15:44,981:INFO:Importing untrained model
2023-11-01 09:15:44,984:INFO:Linear Regression Imported successfully
2023-11-01 09:15:44,991:INFO:Starting cross validation
2023-11-01 09:15:45,007:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:49,886:INFO:Calculating mean and std
2023-11-01 09:15:49,888:INFO:Creating metrics dataframe
2023-11-01 09:15:49,890:INFO:Uploading results into container
2023-11-01 09:15:49,891:INFO:Uploading model into container now
2023-11-01 09:15:49,893:INFO:_master_model_container: 1
2023-11-01 09:15:49,893:INFO:_display_container: 2
2023-11-01 09:15:49,894:INFO:LinearRegression(n_jobs=-1)
2023-11-01 09:15:49,894:INFO:create_model() successfully completed......................................
2023-11-01 09:15:49,959:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:49,959:INFO:Creating metrics dataframe
2023-11-01 09:15:49,967:INFO:Initializing Lasso Regression
2023-11-01 09:15:49,967:INFO:Total runtime is 0.08327479759852091 minutes
2023-11-01 09:15:49,970:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:49,970:INFO:Initializing create_model()
2023-11-01 09:15:49,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:49,970:INFO:Checking exceptions
2023-11-01 09:15:49,970:INFO:Importing libraries
2023-11-01 09:15:49,970:INFO:Copying training dataset
2023-11-01 09:15:49,974:INFO:Defining folds
2023-11-01 09:15:49,975:INFO:Declaring metric variables
2023-11-01 09:15:49,977:INFO:Importing untrained model
2023-11-01 09:15:49,980:INFO:Lasso Regression Imported successfully
2023-11-01 09:15:49,986:INFO:Starting cross validation
2023-11-01 09:15:49,988:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:50,274:INFO:Calculating mean and std
2023-11-01 09:15:50,275:INFO:Creating metrics dataframe
2023-11-01 09:15:50,279:INFO:Uploading results into container
2023-11-01 09:15:50,279:INFO:Uploading model into container now
2023-11-01 09:15:50,280:INFO:_master_model_container: 2
2023-11-01 09:15:50,280:INFO:_display_container: 2
2023-11-01 09:15:50,280:INFO:Lasso(random_state=1234)
2023-11-01 09:15:50,280:INFO:create_model() successfully completed......................................
2023-11-01 09:15:50,339:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:50,339:INFO:Creating metrics dataframe
2023-11-01 09:15:50,351:INFO:Initializing Ridge Regression
2023-11-01 09:15:50,351:INFO:Total runtime is 0.0896758198738098 minutes
2023-11-01 09:15:50,353:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:50,353:INFO:Initializing create_model()
2023-11-01 09:15:50,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:50,354:INFO:Checking exceptions
2023-11-01 09:15:50,354:INFO:Importing libraries
2023-11-01 09:15:50,354:INFO:Copying training dataset
2023-11-01 09:15:50,358:INFO:Defining folds
2023-11-01 09:15:50,358:INFO:Declaring metric variables
2023-11-01 09:15:50,361:INFO:Importing untrained model
2023-11-01 09:15:50,365:INFO:Ridge Regression Imported successfully
2023-11-01 09:15:50,371:INFO:Starting cross validation
2023-11-01 09:15:50,373:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:50,655:INFO:Calculating mean and std
2023-11-01 09:15:50,656:INFO:Creating metrics dataframe
2023-11-01 09:15:50,659:INFO:Uploading results into container
2023-11-01 09:15:50,659:INFO:Uploading model into container now
2023-11-01 09:15:50,659:INFO:_master_model_container: 3
2023-11-01 09:15:50,659:INFO:_display_container: 2
2023-11-01 09:15:50,659:INFO:Ridge(random_state=1234)
2023-11-01 09:15:50,659:INFO:create_model() successfully completed......................................
2023-11-01 09:15:50,719:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:50,719:INFO:Creating metrics dataframe
2023-11-01 09:15:50,726:INFO:Initializing Elastic Net
2023-11-01 09:15:50,726:INFO:Total runtime is 0.09592821598052978 minutes
2023-11-01 09:15:50,730:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:50,731:INFO:Initializing create_model()
2023-11-01 09:15:50,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:50,731:INFO:Checking exceptions
2023-11-01 09:15:50,731:INFO:Importing libraries
2023-11-01 09:15:50,731:INFO:Copying training dataset
2023-11-01 09:15:50,737:INFO:Defining folds
2023-11-01 09:15:50,737:INFO:Declaring metric variables
2023-11-01 09:15:50,741:INFO:Importing untrained model
2023-11-01 09:15:50,743:INFO:Elastic Net Imported successfully
2023-11-01 09:15:50,752:INFO:Starting cross validation
2023-11-01 09:15:50,754:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:51,045:INFO:Calculating mean and std
2023-11-01 09:15:51,046:INFO:Creating metrics dataframe
2023-11-01 09:15:51,049:INFO:Uploading results into container
2023-11-01 09:15:51,050:INFO:Uploading model into container now
2023-11-01 09:15:51,050:INFO:_master_model_container: 4
2023-11-01 09:15:51,050:INFO:_display_container: 2
2023-11-01 09:15:51,050:INFO:ElasticNet(random_state=1234)
2023-11-01 09:15:51,050:INFO:create_model() successfully completed......................................
2023-11-01 09:15:51,108:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:51,108:INFO:Creating metrics dataframe
2023-11-01 09:15:51,117:INFO:Initializing Least Angle Regression
2023-11-01 09:15:51,117:INFO:Total runtime is 0.10244756539662679 minutes
2023-11-01 09:15:51,121:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:51,121:INFO:Initializing create_model()
2023-11-01 09:15:51,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:51,122:INFO:Checking exceptions
2023-11-01 09:15:51,122:INFO:Importing libraries
2023-11-01 09:15:51,122:INFO:Copying training dataset
2023-11-01 09:15:51,126:INFO:Defining folds
2023-11-01 09:15:51,127:INFO:Declaring metric variables
2023-11-01 09:15:51,129:INFO:Importing untrained model
2023-11-01 09:15:51,135:INFO:Least Angle Regression Imported successfully
2023-11-01 09:15:51,141:INFO:Starting cross validation
2023-11-01 09:15:51,142:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:51,279:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,285:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,299:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,299:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,305:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.703e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,305:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.081e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,305:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.395e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,306:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.696e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,306:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.936e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,306:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.979e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,306:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.832e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,307:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.827e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,307:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.174e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,307:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.589e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,307:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.086e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,323:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,354:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,417:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,433:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:51,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.432e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.056e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.154e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:15:51,461:INFO:Calculating mean and std
2023-11-01 09:15:51,462:INFO:Creating metrics dataframe
2023-11-01 09:15:51,464:INFO:Uploading results into container
2023-11-01 09:15:51,465:INFO:Uploading model into container now
2023-11-01 09:15:51,465:INFO:_master_model_container: 5
2023-11-01 09:15:51,465:INFO:_display_container: 2
2023-11-01 09:15:51,466:INFO:Lars(random_state=1234)
2023-11-01 09:15:51,466:INFO:create_model() successfully completed......................................
2023-11-01 09:15:51,532:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:51,532:INFO:Creating metrics dataframe
2023-11-01 09:15:51,540:INFO:Initializing Lasso Least Angle Regression
2023-11-01 09:15:51,541:INFO:Total runtime is 0.10951821009318034 minutes
2023-11-01 09:15:51,543:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:51,544:INFO:Initializing create_model()
2023-11-01 09:15:51,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:51,544:INFO:Checking exceptions
2023-11-01 09:15:51,544:INFO:Importing libraries
2023-11-01 09:15:51,544:INFO:Copying training dataset
2023-11-01 09:15:51,549:INFO:Defining folds
2023-11-01 09:15:51,549:INFO:Declaring metric variables
2023-11-01 09:15:51,552:INFO:Importing untrained model
2023-11-01 09:15:51,555:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 09:15:51,562:INFO:Starting cross validation
2023-11-01 09:15:51,564:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:51,666:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,672:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,675:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,697:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,698:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,723:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,747:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,813:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,814:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:15:51,840:INFO:Calculating mean and std
2023-11-01 09:15:51,841:INFO:Creating metrics dataframe
2023-11-01 09:15:51,843:INFO:Uploading results into container
2023-11-01 09:15:51,843:INFO:Uploading model into container now
2023-11-01 09:15:51,843:INFO:_master_model_container: 6
2023-11-01 09:15:51,844:INFO:_display_container: 2
2023-11-01 09:15:51,844:INFO:LassoLars(random_state=1234)
2023-11-01 09:15:51,844:INFO:create_model() successfully completed......................................
2023-11-01 09:15:51,903:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:51,903:INFO:Creating metrics dataframe
2023-11-01 09:15:51,910:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 09:15:51,910:INFO:Total runtime is 0.11566255489985149 minutes
2023-11-01 09:15:51,914:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:51,914:INFO:Initializing create_model()
2023-11-01 09:15:51,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:51,914:INFO:Checking exceptions
2023-11-01 09:15:51,915:INFO:Importing libraries
2023-11-01 09:15:51,915:INFO:Copying training dataset
2023-11-01 09:15:51,920:INFO:Defining folds
2023-11-01 09:15:51,920:INFO:Declaring metric variables
2023-11-01 09:15:51,924:INFO:Importing untrained model
2023-11-01 09:15:51,926:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 09:15:51,933:INFO:Starting cross validation
2023-11-01 09:15:51,936:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:52,044:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,045:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,045:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,056:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,069:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,075:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,101:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,173:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,183:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:15:52,209:INFO:Calculating mean and std
2023-11-01 09:15:52,211:INFO:Creating metrics dataframe
2023-11-01 09:15:52,214:INFO:Uploading results into container
2023-11-01 09:15:52,216:INFO:Uploading model into container now
2023-11-01 09:15:52,216:INFO:_master_model_container: 7
2023-11-01 09:15:52,216:INFO:_display_container: 2
2023-11-01 09:15:52,216:INFO:OrthogonalMatchingPursuit()
2023-11-01 09:15:52,216:INFO:create_model() successfully completed......................................
2023-11-01 09:15:52,277:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:52,278:INFO:Creating metrics dataframe
2023-11-01 09:15:52,287:INFO:Initializing Bayesian Ridge
2023-11-01 09:15:52,287:INFO:Total runtime is 0.12193958759307862 minutes
2023-11-01 09:15:52,290:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:52,290:INFO:Initializing create_model()
2023-11-01 09:15:52,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:52,290:INFO:Checking exceptions
2023-11-01 09:15:52,290:INFO:Importing libraries
2023-11-01 09:15:52,290:INFO:Copying training dataset
2023-11-01 09:15:52,294:INFO:Defining folds
2023-11-01 09:15:52,294:INFO:Declaring metric variables
2023-11-01 09:15:52,297:INFO:Importing untrained model
2023-11-01 09:15:52,299:INFO:Bayesian Ridge Imported successfully
2023-11-01 09:15:52,307:INFO:Starting cross validation
2023-11-01 09:15:52,308:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:52,587:INFO:Calculating mean and std
2023-11-01 09:15:52,588:INFO:Creating metrics dataframe
2023-11-01 09:15:52,591:INFO:Uploading results into container
2023-11-01 09:15:52,591:INFO:Uploading model into container now
2023-11-01 09:15:52,591:INFO:_master_model_container: 8
2023-11-01 09:15:52,591:INFO:_display_container: 2
2023-11-01 09:15:52,591:INFO:BayesianRidge()
2023-11-01 09:15:52,591:INFO:create_model() successfully completed......................................
2023-11-01 09:15:52,649:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:52,650:INFO:Creating metrics dataframe
2023-11-01 09:15:52,657:INFO:Initializing Passive Aggressive Regressor
2023-11-01 09:15:52,657:INFO:Total runtime is 0.12811268170674642 minutes
2023-11-01 09:15:52,661:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:52,661:INFO:Initializing create_model()
2023-11-01 09:15:52,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:52,662:INFO:Checking exceptions
2023-11-01 09:15:52,662:INFO:Importing libraries
2023-11-01 09:15:52,662:INFO:Copying training dataset
2023-11-01 09:15:52,668:INFO:Defining folds
2023-11-01 09:15:52,668:INFO:Declaring metric variables
2023-11-01 09:15:52,671:INFO:Importing untrained model
2023-11-01 09:15:52,673:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 09:15:52,681:INFO:Starting cross validation
2023-11-01 09:15:52,683:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:52,965:INFO:Calculating mean and std
2023-11-01 09:15:52,966:INFO:Creating metrics dataframe
2023-11-01 09:15:52,970:INFO:Uploading results into container
2023-11-01 09:15:52,971:INFO:Uploading model into container now
2023-11-01 09:15:52,971:INFO:_master_model_container: 9
2023-11-01 09:15:52,971:INFO:_display_container: 2
2023-11-01 09:15:52,972:INFO:PassiveAggressiveRegressor(random_state=1234)
2023-11-01 09:15:52,972:INFO:create_model() successfully completed......................................
2023-11-01 09:15:53,036:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:53,036:INFO:Creating metrics dataframe
2023-11-01 09:15:53,044:INFO:Initializing Huber Regressor
2023-11-01 09:15:53,044:INFO:Total runtime is 0.13456448316574096 minutes
2023-11-01 09:15:53,047:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:53,047:INFO:Initializing create_model()
2023-11-01 09:15:53,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:53,048:INFO:Checking exceptions
2023-11-01 09:15:53,048:INFO:Importing libraries
2023-11-01 09:15:53,048:INFO:Copying training dataset
2023-11-01 09:15:53,053:INFO:Defining folds
2023-11-01 09:15:53,053:INFO:Declaring metric variables
2023-11-01 09:15:53,056:INFO:Importing untrained model
2023-11-01 09:15:53,059:INFO:Huber Regressor Imported successfully
2023-11-01 09:15:53,065:INFO:Starting cross validation
2023-11-01 09:15:53,067:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:53,221:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,233:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,260:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,265:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,358:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,381:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,473:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,496:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:15:53,519:INFO:Calculating mean and std
2023-11-01 09:15:53,521:INFO:Creating metrics dataframe
2023-11-01 09:15:53,523:INFO:Uploading results into container
2023-11-01 09:15:53,523:INFO:Uploading model into container now
2023-11-01 09:15:53,523:INFO:_master_model_container: 10
2023-11-01 09:15:53,523:INFO:_display_container: 2
2023-11-01 09:15:53,523:INFO:HuberRegressor()
2023-11-01 09:15:53,523:INFO:create_model() successfully completed......................................
2023-11-01 09:15:53,581:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:53,581:INFO:Creating metrics dataframe
2023-11-01 09:15:53,591:INFO:Initializing K Neighbors Regressor
2023-11-01 09:15:53,591:INFO:Total runtime is 0.14367928504943847 minutes
2023-11-01 09:15:53,593:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:53,595:INFO:Initializing create_model()
2023-11-01 09:15:53,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:53,595:INFO:Checking exceptions
2023-11-01 09:15:53,595:INFO:Importing libraries
2023-11-01 09:15:53,595:INFO:Copying training dataset
2023-11-01 09:15:53,600:INFO:Defining folds
2023-11-01 09:15:53,600:INFO:Declaring metric variables
2023-11-01 09:15:53,602:INFO:Importing untrained model
2023-11-01 09:15:53,605:INFO:K Neighbors Regressor Imported successfully
2023-11-01 09:15:53,610:INFO:Starting cross validation
2023-11-01 09:15:53,611:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:54,005:INFO:Calculating mean and std
2023-11-01 09:15:54,006:INFO:Creating metrics dataframe
2023-11-01 09:15:54,008:INFO:Uploading results into container
2023-11-01 09:15:54,009:INFO:Uploading model into container now
2023-11-01 09:15:54,009:INFO:_master_model_container: 11
2023-11-01 09:15:54,009:INFO:_display_container: 2
2023-11-01 09:15:54,009:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 09:15:54,009:INFO:create_model() successfully completed......................................
2023-11-01 09:15:54,067:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:54,067:INFO:Creating metrics dataframe
2023-11-01 09:15:54,076:INFO:Initializing Decision Tree Regressor
2023-11-01 09:15:54,076:INFO:Total runtime is 0.15176333189010618 minutes
2023-11-01 09:15:54,080:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:54,081:INFO:Initializing create_model()
2023-11-01 09:15:54,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:54,081:INFO:Checking exceptions
2023-11-01 09:15:54,082:INFO:Importing libraries
2023-11-01 09:15:54,082:INFO:Copying training dataset
2023-11-01 09:15:54,086:INFO:Defining folds
2023-11-01 09:15:54,086:INFO:Declaring metric variables
2023-11-01 09:15:54,088:INFO:Importing untrained model
2023-11-01 09:15:54,091:INFO:Decision Tree Regressor Imported successfully
2023-11-01 09:15:54,098:INFO:Starting cross validation
2023-11-01 09:15:54,100:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:54,402:INFO:Calculating mean and std
2023-11-01 09:15:54,403:INFO:Creating metrics dataframe
2023-11-01 09:15:54,406:INFO:Uploading results into container
2023-11-01 09:15:54,407:INFO:Uploading model into container now
2023-11-01 09:15:54,407:INFO:_master_model_container: 12
2023-11-01 09:15:54,407:INFO:_display_container: 2
2023-11-01 09:15:54,408:INFO:DecisionTreeRegressor(random_state=1234)
2023-11-01 09:15:54,408:INFO:create_model() successfully completed......................................
2023-11-01 09:15:54,466:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:54,466:INFO:Creating metrics dataframe
2023-11-01 09:15:54,474:INFO:Initializing Random Forest Regressor
2023-11-01 09:15:54,474:INFO:Total runtime is 0.15839951038360595 minutes
2023-11-01 09:15:54,476:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:54,476:INFO:Initializing create_model()
2023-11-01 09:15:54,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:54,476:INFO:Checking exceptions
2023-11-01 09:15:54,477:INFO:Importing libraries
2023-11-01 09:15:54,477:INFO:Copying training dataset
2023-11-01 09:15:54,483:INFO:Defining folds
2023-11-01 09:15:54,483:INFO:Declaring metric variables
2023-11-01 09:15:54,486:INFO:Importing untrained model
2023-11-01 09:15:54,488:INFO:Random Forest Regressor Imported successfully
2023-11-01 09:15:54,494:INFO:Starting cross validation
2023-11-01 09:15:54,496:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:57,008:INFO:Calculating mean and std
2023-11-01 09:15:57,010:INFO:Creating metrics dataframe
2023-11-01 09:15:57,015:INFO:Uploading results into container
2023-11-01 09:15:57,015:INFO:Uploading model into container now
2023-11-01 09:15:57,016:INFO:_master_model_container: 13
2023-11-01 09:15:57,016:INFO:_display_container: 2
2023-11-01 09:15:57,016:INFO:RandomForestRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:15:57,016:INFO:create_model() successfully completed......................................
2023-11-01 09:15:57,092:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:57,092:INFO:Creating metrics dataframe
2023-11-01 09:15:57,103:INFO:Initializing Extra Trees Regressor
2023-11-01 09:15:57,103:INFO:Total runtime is 0.2022127350171407 minutes
2023-11-01 09:15:57,106:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:57,106:INFO:Initializing create_model()
2023-11-01 09:15:57,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:57,107:INFO:Checking exceptions
2023-11-01 09:15:57,107:INFO:Importing libraries
2023-11-01 09:15:57,107:INFO:Copying training dataset
2023-11-01 09:15:57,113:INFO:Defining folds
2023-11-01 09:15:57,113:INFO:Declaring metric variables
2023-11-01 09:15:57,116:INFO:Importing untrained model
2023-11-01 09:15:57,121:INFO:Extra Trees Regressor Imported successfully
2023-11-01 09:15:57,128:INFO:Starting cross validation
2023-11-01 09:15:57,130:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:15:59,362:INFO:Calculating mean and std
2023-11-01 09:15:59,365:INFO:Creating metrics dataframe
2023-11-01 09:15:59,369:INFO:Uploading results into container
2023-11-01 09:15:59,370:INFO:Uploading model into container now
2023-11-01 09:15:59,371:INFO:_master_model_container: 14
2023-11-01 09:15:59,371:INFO:_display_container: 2
2023-11-01 09:15:59,372:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:15:59,372:INFO:create_model() successfully completed......................................
2023-11-01 09:15:59,449:INFO:SubProcess create_model() end ==================================
2023-11-01 09:15:59,449:INFO:Creating metrics dataframe
2023-11-01 09:15:59,459:INFO:Initializing AdaBoost Regressor
2023-11-01 09:15:59,459:INFO:Total runtime is 0.24148589769999187 minutes
2023-11-01 09:15:59,461:INFO:SubProcess create_model() called ==================================
2023-11-01 09:15:59,461:INFO:Initializing create_model()
2023-11-01 09:15:59,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:15:59,463:INFO:Checking exceptions
2023-11-01 09:15:59,463:INFO:Importing libraries
2023-11-01 09:15:59,463:INFO:Copying training dataset
2023-11-01 09:15:59,469:INFO:Defining folds
2023-11-01 09:15:59,469:INFO:Declaring metric variables
2023-11-01 09:15:59,472:INFO:Importing untrained model
2023-11-01 09:15:59,476:INFO:AdaBoost Regressor Imported successfully
2023-11-01 09:15:59,484:INFO:Starting cross validation
2023-11-01 09:15:59,485:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:16:00,292:INFO:Calculating mean and std
2023-11-01 09:16:00,293:INFO:Creating metrics dataframe
2023-11-01 09:16:00,297:INFO:Uploading results into container
2023-11-01 09:16:00,298:INFO:Uploading model into container now
2023-11-01 09:16:00,298:INFO:_master_model_container: 15
2023-11-01 09:16:00,298:INFO:_display_container: 2
2023-11-01 09:16:00,299:INFO:AdaBoostRegressor(random_state=1234)
2023-11-01 09:16:00,299:INFO:create_model() successfully completed......................................
2023-11-01 09:16:00,357:INFO:SubProcess create_model() end ==================================
2023-11-01 09:16:00,357:INFO:Creating metrics dataframe
2023-11-01 09:16:00,368:INFO:Initializing Gradient Boosting Regressor
2023-11-01 09:16:00,368:INFO:Total runtime is 0.25663466850916544 minutes
2023-11-01 09:16:00,371:INFO:SubProcess create_model() called ==================================
2023-11-01 09:16:00,371:INFO:Initializing create_model()
2023-11-01 09:16:00,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:16:00,371:INFO:Checking exceptions
2023-11-01 09:16:00,371:INFO:Importing libraries
2023-11-01 09:16:00,371:INFO:Copying training dataset
2023-11-01 09:16:00,377:INFO:Defining folds
2023-11-01 09:16:00,377:INFO:Declaring metric variables
2023-11-01 09:16:00,380:INFO:Importing untrained model
2023-11-01 09:16:00,383:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 09:16:00,390:INFO:Starting cross validation
2023-11-01 09:16:00,391:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:16:01,456:INFO:Calculating mean and std
2023-11-01 09:16:01,458:INFO:Creating metrics dataframe
2023-11-01 09:16:01,461:INFO:Uploading results into container
2023-11-01 09:16:01,462:INFO:Uploading model into container now
2023-11-01 09:16:01,462:INFO:_master_model_container: 16
2023-11-01 09:16:01,462:INFO:_display_container: 2
2023-11-01 09:16:01,463:INFO:GradientBoostingRegressor(random_state=1234)
2023-11-01 09:16:01,463:INFO:create_model() successfully completed......................................
2023-11-01 09:16:01,521:INFO:SubProcess create_model() end ==================================
2023-11-01 09:16:01,521:INFO:Creating metrics dataframe
2023-11-01 09:16:01,533:INFO:Initializing Extreme Gradient Boosting
2023-11-01 09:16:01,533:INFO:Total runtime is 0.2760397513707479 minutes
2023-11-01 09:16:01,536:INFO:SubProcess create_model() called ==================================
2023-11-01 09:16:01,536:INFO:Initializing create_model()
2023-11-01 09:16:01,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:16:01,536:INFO:Checking exceptions
2023-11-01 09:16:01,536:INFO:Importing libraries
2023-11-01 09:16:01,536:INFO:Copying training dataset
2023-11-01 09:16:01,541:INFO:Defining folds
2023-11-01 09:16:01,541:INFO:Declaring metric variables
2023-11-01 09:16:01,544:INFO:Importing untrained model
2023-11-01 09:16:01,548:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 09:16:01,556:INFO:Starting cross validation
2023-11-01 09:16:01,557:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:16:02,369:INFO:Calculating mean and std
2023-11-01 09:16:02,371:INFO:Creating metrics dataframe
2023-11-01 09:16:02,374:INFO:Uploading results into container
2023-11-01 09:16:02,375:INFO:Uploading model into container now
2023-11-01 09:16:02,375:INFO:_master_model_container: 17
2023-11-01 09:16:02,375:INFO:_display_container: 2
2023-11-01 09:16:02,377:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1234, ...)
2023-11-01 09:16:02,377:INFO:create_model() successfully completed......................................
2023-11-01 09:16:02,434:INFO:SubProcess create_model() end ==================================
2023-11-01 09:16:02,434:INFO:Creating metrics dataframe
2023-11-01 09:16:02,443:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 09:16:02,443:INFO:Total runtime is 0.2912122368812561 minutes
2023-11-01 09:16:02,447:INFO:SubProcess create_model() called ==================================
2023-11-01 09:16:02,447:INFO:Initializing create_model()
2023-11-01 09:16:02,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:16:02,447:INFO:Checking exceptions
2023-11-01 09:16:02,447:INFO:Importing libraries
2023-11-01 09:16:02,447:INFO:Copying training dataset
2023-11-01 09:16:02,451:INFO:Defining folds
2023-11-01 09:16:02,451:INFO:Declaring metric variables
2023-11-01 09:16:02,455:INFO:Importing untrained model
2023-11-01 09:16:02,457:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:16:02,465:INFO:Starting cross validation
2023-11-01 09:16:02,467:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:16:03,648:INFO:Calculating mean and std
2023-11-01 09:16:03,650:INFO:Creating metrics dataframe
2023-11-01 09:16:03,655:INFO:Uploading results into container
2023-11-01 09:16:03,656:INFO:Uploading model into container now
2023-11-01 09:16:03,656:INFO:_master_model_container: 18
2023-11-01 09:16:03,656:INFO:_display_container: 2
2023-11-01 09:16:03,657:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:16:03,657:INFO:create_model() successfully completed......................................
2023-11-01 09:16:03,731:INFO:SubProcess create_model() end ==================================
2023-11-01 09:16:03,733:INFO:Creating metrics dataframe
2023-11-01 09:16:03,746:INFO:Initializing Dummy Regressor
2023-11-01 09:16:03,746:INFO:Total runtime is 0.3129244049390157 minutes
2023-11-01 09:16:03,749:INFO:SubProcess create_model() called ==================================
2023-11-01 09:16:03,750:INFO:Initializing create_model()
2023-11-01 09:16:03,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D85E860>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:16:03,750:INFO:Checking exceptions
2023-11-01 09:16:03,750:INFO:Importing libraries
2023-11-01 09:16:03,750:INFO:Copying training dataset
2023-11-01 09:16:03,756:INFO:Defining folds
2023-11-01 09:16:03,757:INFO:Declaring metric variables
2023-11-01 09:16:03,761:INFO:Importing untrained model
2023-11-01 09:16:03,766:INFO:Dummy Regressor Imported successfully
2023-11-01 09:16:03,771:INFO:Starting cross validation
2023-11-01 09:16:03,774:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:16:04,035:INFO:Calculating mean and std
2023-11-01 09:16:04,036:INFO:Creating metrics dataframe
2023-11-01 09:16:04,038:INFO:Uploading results into container
2023-11-01 09:16:04,039:INFO:Uploading model into container now
2023-11-01 09:16:04,039:INFO:_master_model_container: 19
2023-11-01 09:16:04,039:INFO:_display_container: 2
2023-11-01 09:16:04,039:INFO:DummyRegressor()
2023-11-01 09:16:04,039:INFO:create_model() successfully completed......................................
2023-11-01 09:16:04,097:INFO:SubProcess create_model() end ==================================
2023-11-01 09:16:04,097:INFO:Creating metrics dataframe
2023-11-01 09:16:04,118:INFO:Initializing create_model()
2023-11-01 09:16:04,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:16:04,118:INFO:Checking exceptions
2023-11-01 09:16:04,120:INFO:Importing libraries
2023-11-01 09:16:04,120:INFO:Copying training dataset
2023-11-01 09:16:04,125:INFO:Defining folds
2023-11-01 09:16:04,125:INFO:Declaring metric variables
2023-11-01 09:16:04,125:INFO:Importing untrained model
2023-11-01 09:16:04,125:INFO:Declaring custom model
2023-11-01 09:16:04,126:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:16:04,128:INFO:Cross validation set to False
2023-11-01 09:16:04,128:INFO:Fitting Model
2023-11-01 09:16:04,215:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2023-11-01 09:16:04,215:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:16:04,215:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:16:04,215:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:16:04,216:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-11-01 09:16:04,288:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:16:04,288:INFO:create_model() successfully completed......................................
2023-11-01 09:16:04,399:INFO:_master_model_container: 19
2023-11-01 09:16:04,399:INFO:_display_container: 2
2023-11-01 09:16:04,400:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:16:04,400:INFO:compare_models() successfully completed......................................
2023-11-01 09:17:25,920:INFO:Initializing tune_model()
2023-11-01 09:17:25,920:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>)
2023-11-01 09:17:25,920:INFO:Checking exceptions
2023-11-01 09:17:25,951:INFO:Copying training dataset
2023-11-01 09:17:25,954:INFO:Checking base model
2023-11-01 09:17:25,954:INFO:Base model : Light Gradient Boosting Machine
2023-11-01 09:17:25,958:INFO:Declaring metric variables
2023-11-01 09:17:25,962:INFO:Defining Hyperparameters
2023-11-01 09:17:26,060:INFO:Tuning with n_jobs=-1
2023-11-01 09:17:26,060:INFO:Initializing RandomizedSearchCV
2023-11-01 09:17:37,561:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.7}
2023-11-01 09:17:37,564:INFO:Hyperparameter search completed
2023-11-01 09:17:37,564:INFO:SubProcess create_model() called ==================================
2023-11-01 09:17:37,565:INFO:Initializing create_model()
2023-11-01 09:17:37,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366EFF1690>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.3, 'reg_alpha': 3, 'num_leaves': 30, 'n_estimators': 230, 'min_split_gain': 0.3, 'min_child_samples': 91, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 0.7})
2023-11-01 09:17:37,565:INFO:Checking exceptions
2023-11-01 09:17:37,565:INFO:Importing libraries
2023-11-01 09:17:37,565:INFO:Copying training dataset
2023-11-01 09:17:37,570:INFO:Defining folds
2023-11-01 09:17:37,570:INFO:Declaring metric variables
2023-11-01 09:17:37,573:INFO:Importing untrained model
2023-11-01 09:17:37,573:INFO:Declaring custom model
2023-11-01 09:17:37,578:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:17:37,587:INFO:Starting cross validation
2023-11-01 09:17:37,589:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:17:39,365:INFO:Calculating mean and std
2023-11-01 09:17:39,367:INFO:Creating metrics dataframe
2023-11-01 09:17:39,374:INFO:Finalizing model
2023-11-01 09:17:39,468:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-11-01 09:17:39,469:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-11-01 09:17:39,469:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-11-01 09:17:39,473:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-11-01 09:17:39,474:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-11-01 09:17:39,474:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-11-01 09:17:39,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2023-11-01 09:17:39,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-01 09:17:39,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-01 09:17:39,475:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:17:39,475:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:17:39,475:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-11-01 09:17:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-01 09:17:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-01 09:17:39,648:INFO:Uploading results into container
2023-11-01 09:17:39,649:INFO:Uploading model into container now
2023-11-01 09:17:39,650:INFO:_master_model_container: 20
2023-11-01 09:17:39,650:INFO:_display_container: 3
2023-11-01 09:17:39,651:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3)
2023-11-01 09:17:39,652:INFO:create_model() successfully completed......................................
2023-11-01 09:17:39,730:INFO:SubProcess create_model() end ==================================
2023-11-01 09:17:39,730:INFO:choose_better activated
2023-11-01 09:17:39,734:INFO:SubProcess create_model() called ==================================
2023-11-01 09:17:39,735:INFO:Initializing create_model()
2023-11-01 09:17:39,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001365DB57A90>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:17:39,735:INFO:Checking exceptions
2023-11-01 09:17:39,737:INFO:Importing libraries
2023-11-01 09:17:39,737:INFO:Copying training dataset
2023-11-01 09:17:39,741:INFO:Defining folds
2023-11-01 09:17:39,741:INFO:Declaring metric variables
2023-11-01 09:17:39,741:INFO:Importing untrained model
2023-11-01 09:17:39,741:INFO:Declaring custom model
2023-11-01 09:17:39,742:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:17:39,742:INFO:Starting cross validation
2023-11-01 09:17:39,744:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:17:40,757:INFO:Calculating mean and std
2023-11-01 09:17:40,758:INFO:Creating metrics dataframe
2023-11-01 09:17:40,760:INFO:Finalizing model
2023-11-01 09:17:40,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2023-11-01 09:17:40,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:17:40,882:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:17:40,882:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:17:40,882:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-11-01 09:17:40,945:INFO:Uploading results into container
2023-11-01 09:17:40,945:INFO:Uploading model into container now
2023-11-01 09:17:40,946:INFO:_master_model_container: 21
2023-11-01 09:17:40,946:INFO:_display_container: 4
2023-11-01 09:17:40,946:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:17:40,946:INFO:create_model() successfully completed......................................
2023-11-01 09:17:41,016:INFO:SubProcess create_model() end ==================================
2023-11-01 09:17:41,017:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) result for R2 is 0.7286
2023-11-01 09:17:41,018:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.5,
              min_child_samples=91, min_split_gain=0.3, n_estimators=230,
              n_jobs=-1, num_leaves=30, random_state=1234, reg_alpha=3,
              reg_lambda=0.3) result for R2 is 0.7164
2023-11-01 09:17:41,018:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) is best model
2023-11-01 09:17:41,018:INFO:choose_better completed
2023-11-01 09:17:41,018:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-11-01 09:17:41,028:INFO:_master_model_container: 21
2023-11-01 09:17:41,028:INFO:_display_container: 3
2023-11-01 09:17:41,028:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:17:41,029:INFO:tune_model() successfully completed......................................
2023-11-01 09:18:47,473:INFO:PyCaret RegressionExperiment
2023-11-01 09:18:47,473:INFO:Logging name: reg-default-name
2023-11-01 09:18:47,473:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-01 09:18:47,473:INFO:version 3.1.0
2023-11-01 09:18:47,473:INFO:Initializing setup()
2023-11-01 09:18:47,474:INFO:self.USI: 737c
2023-11-01 09:18:47,474:INFO:self._variable_keys: {'gpu_n_jobs_param', 'transform_target_param', 'target_param', 'y_test', 'y', 'X', 'exp_id', 'X_test', 'USI', '_ml_usecase', '_available_plots', 'html_param', 'y_train', 'idx', 'fold_groups_param', 'exp_name_log', 'seed', 'gpu_param', 'pipeline', 'fold_generator', 'X_train', 'memory', 'fold_shuffle_param', 'log_plots_param', 'n_jobs_param', 'logging_param', 'data'}
2023-11-01 09:18:47,474:INFO:Checking environment
2023-11-01 09:18:47,474:INFO:python_version: 3.10.6
2023-11-01 09:18:47,474:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-01 09:18:47,474:INFO:machine: AMD64
2023-11-01 09:18:47,474:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-01 09:18:47,474:INFO:Memory: svmem(total=8273383424, available=822427648, percent=90.1, used=7450955776, free=822427648)
2023-11-01 09:18:47,474:INFO:Physical Core: 4
2023-11-01 09:18:47,474:INFO:Logical Core: 8
2023-11-01 09:18:47,475:INFO:Checking libraries
2023-11-01 09:18:47,475:INFO:System:
2023-11-01 09:18:47,475:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-01 09:18:47,475:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-01 09:18:47,475:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-01 09:18:47,475:INFO:PyCaret required dependencies:
2023-11-01 09:18:47,475:INFO:                 pip: 22.2.1
2023-11-01 09:18:47,475:INFO:          setuptools: 63.2.0
2023-11-01 09:18:47,475:INFO:             pycaret: 3.1.0
2023-11-01 09:18:47,475:INFO:             IPython: 8.4.0
2023-11-01 09:18:47,475:INFO:          ipywidgets: 8.1.1
2023-11-01 09:18:47,475:INFO:                tqdm: 4.66.1
2023-11-01 09:18:47,475:INFO:               numpy: 1.23.2
2023-11-01 09:18:47,475:INFO:              pandas: 1.4.3
2023-11-01 09:18:47,475:INFO:              jinja2: 3.1.2
2023-11-01 09:18:47,475:INFO:               scipy: 1.10.1
2023-11-01 09:18:47,475:INFO:              joblib: 1.2.0
2023-11-01 09:18:47,475:INFO:             sklearn: 1.1.2
2023-11-01 09:18:47,475:INFO:                pyod: 1.1.0
2023-11-01 09:18:47,475:INFO:            imblearn: 0.11.0
2023-11-01 09:18:47,475:INFO:   category_encoders: 2.6.2
2023-11-01 09:18:47,475:INFO:            lightgbm: 4.1.0
2023-11-01 09:18:47,475:INFO:               numba: 0.58.0
2023-11-01 09:18:47,475:INFO:            requests: 2.28.1
2023-11-01 09:18:47,476:INFO:          matplotlib: 3.6.0
2023-11-01 09:18:47,476:INFO:          scikitplot: 0.3.7
2023-11-01 09:18:47,476:INFO:         yellowbrick: 1.5
2023-11-01 09:18:47,476:INFO:              plotly: 5.17.0
2023-11-01 09:18:47,476:INFO:    plotly-resampler: Not installed
2023-11-01 09:18:47,476:INFO:             kaleido: 0.2.1
2023-11-01 09:18:47,476:INFO:           schemdraw: 0.15
2023-11-01 09:18:47,476:INFO:         statsmodels: 0.13.2
2023-11-01 09:18:47,476:INFO:              sktime: 0.21.1
2023-11-01 09:18:47,476:INFO:               tbats: 1.1.3
2023-11-01 09:18:47,476:INFO:            pmdarima: 2.0.3
2023-11-01 09:18:47,476:INFO:              psutil: 5.9.1
2023-11-01 09:18:47,476:INFO:          markupsafe: 2.1.1
2023-11-01 09:18:47,476:INFO:             pickle5: Not installed
2023-11-01 09:18:47,476:INFO:         cloudpickle: 2.2.1
2023-11-01 09:18:47,476:INFO:         deprecation: 2.1.0
2023-11-01 09:18:47,476:INFO:              xxhash: 3.4.1
2023-11-01 09:18:47,476:INFO:           wurlitzer: Not installed
2023-11-01 09:18:47,476:INFO:PyCaret optional dependencies:
2023-11-01 09:18:47,476:INFO:                shap: Not installed
2023-11-01 09:18:47,476:INFO:           interpret: Not installed
2023-11-01 09:18:47,476:INFO:                umap: Not installed
2023-11-01 09:18:47,476:INFO:     ydata_profiling: Not installed
2023-11-01 09:18:47,476:INFO:  explainerdashboard: Not installed
2023-11-01 09:18:47,476:INFO:             autoviz: Not installed
2023-11-01 09:18:47,476:INFO:           fairlearn: Not installed
2023-11-01 09:18:47,476:INFO:          deepchecks: Not installed
2023-11-01 09:18:47,476:INFO:             xgboost: 2.0.0
2023-11-01 09:18:47,477:INFO:            catboost: Not installed
2023-11-01 09:18:47,477:INFO:              kmodes: Not installed
2023-11-01 09:18:47,477:INFO:             mlxtend: Not installed
2023-11-01 09:18:47,477:INFO:       statsforecast: Not installed
2023-11-01 09:18:47,477:INFO:        tune_sklearn: Not installed
2023-11-01 09:18:47,477:INFO:                 ray: Not installed
2023-11-01 09:18:47,477:INFO:            hyperopt: Not installed
2023-11-01 09:18:47,477:INFO:              optuna: Not installed
2023-11-01 09:18:47,477:INFO:               skopt: Not installed
2023-11-01 09:18:47,477:INFO:              mlflow: Not installed
2023-11-01 09:18:47,477:INFO:              gradio: Not installed
2023-11-01 09:18:47,477:INFO:             fastapi: Not installed
2023-11-01 09:18:47,477:INFO:             uvicorn: Not installed
2023-11-01 09:18:47,477:INFO:              m2cgen: Not installed
2023-11-01 09:18:47,477:INFO:           evidently: Not installed
2023-11-01 09:18:47,477:INFO:               fugue: Not installed
2023-11-01 09:18:47,477:INFO:           streamlit: Not installed
2023-11-01 09:18:47,477:INFO:             prophet: 1.1.5
2023-11-01 09:18:47,477:INFO:None
2023-11-01 09:18:47,477:INFO:Set up data.
2023-11-01 09:18:47,483:INFO:Set up folding strategy.
2023-11-01 09:18:47,483:INFO:Set up train/test split.
2023-11-01 09:18:47,483:INFO:Set up data.
2023-11-01 09:18:47,490:INFO:Set up index.
2023-11-01 09:18:47,490:INFO:Assigning column types.
2023-11-01 09:18:47,495:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-01 09:18:47,495:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,500:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,505:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,613:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:47,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:47,616:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,619:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,624:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,712:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:47,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:47,715:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-01 09:18:47,720:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,724:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,820:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:47,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:47,826:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,830:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,879:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,917:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:47,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:47,920:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-01 09:18:47,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:18:47,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,013:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,108:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,110:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-01 09:18:48,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,203:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,261:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,298:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,301:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-01 09:18:48,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,391:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 09:18:48,487:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,490:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-01 09:18:48,582:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,676:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:48,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:48,679:INFO:Preparing preprocessing pipeline...
2023-11-01 09:18:48,679:INFO:Set up simple imputation.
2023-11-01 09:18:48,681:INFO:Set up encoding of ordinal features.
2023-11-01 09:18:48,682:INFO:Set up encoding of categorical features.
2023-11-01 09:18:48,751:INFO:Finished creating preprocessing pipeline.
2023-11-01 09:18:48,778:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='...
                 TransformerWrapper(include=['is_working'],
                                    transformer=OrdinalEncoder(cols=['is_working'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-11-01 09:18:48,778:INFO:Creating final display dataframe.
2023-11-01 09:18:49,020:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target        demand_GWh
2                   Target type        Regression
3           Original data shape         (6006, 9)
4        Transformed data shape        (6006, 26)
5   Transformed train set shape        (5506, 26)
6    Transformed test set shape         (500, 26)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   TimeSeriesSplit
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              737c
2023-11-01 09:18:49,111:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:49,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:49,204:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 09:18:49,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 09:18:49,207:INFO:setup() successfully completed in 1.74s...............
2023-11-01 09:18:51,177:INFO:Initializing compare_models()
2023-11-01 09:18:51,177:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 09:18:51,177:INFO:Checking exceptions
2023-11-01 09:18:51,180:INFO:Preparing display monitor
2023-11-01 09:18:51,220:INFO:Initializing Linear Regression
2023-11-01 09:18:51,220:INFO:Total runtime is 0.0 minutes
2023-11-01 09:18:51,226:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:51,226:INFO:Initializing create_model()
2023-11-01 09:18:51,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:51,227:INFO:Checking exceptions
2023-11-01 09:18:51,227:INFO:Importing libraries
2023-11-01 09:18:51,227:INFO:Copying training dataset
2023-11-01 09:18:51,231:INFO:Defining folds
2023-11-01 09:18:51,231:INFO:Declaring metric variables
2023-11-01 09:18:51,234:INFO:Importing untrained model
2023-11-01 09:18:51,240:INFO:Linear Regression Imported successfully
2023-11-01 09:18:51,248:INFO:Starting cross validation
2023-11-01 09:18:51,250:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:51,663:INFO:Calculating mean and std
2023-11-01 09:18:51,664:INFO:Creating metrics dataframe
2023-11-01 09:18:51,666:INFO:Uploading results into container
2023-11-01 09:18:51,667:INFO:Uploading model into container now
2023-11-01 09:18:51,667:INFO:_master_model_container: 1
2023-11-01 09:18:51,667:INFO:_display_container: 2
2023-11-01 09:18:51,667:INFO:LinearRegression(n_jobs=-1)
2023-11-01 09:18:51,667:INFO:create_model() successfully completed......................................
2023-11-01 09:18:51,747:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:51,747:INFO:Creating metrics dataframe
2023-11-01 09:18:51,756:INFO:Initializing Lasso Regression
2023-11-01 09:18:51,756:INFO:Total runtime is 0.008929010232289631 minutes
2023-11-01 09:18:51,760:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:51,760:INFO:Initializing create_model()
2023-11-01 09:18:51,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:51,760:INFO:Checking exceptions
2023-11-01 09:18:51,760:INFO:Importing libraries
2023-11-01 09:18:51,760:INFO:Copying training dataset
2023-11-01 09:18:51,765:INFO:Defining folds
2023-11-01 09:18:51,765:INFO:Declaring metric variables
2023-11-01 09:18:51,768:INFO:Importing untrained model
2023-11-01 09:18:51,771:INFO:Lasso Regression Imported successfully
2023-11-01 09:18:51,779:INFO:Starting cross validation
2023-11-01 09:18:51,780:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:52,106:INFO:Calculating mean and std
2023-11-01 09:18:52,106:INFO:Creating metrics dataframe
2023-11-01 09:18:52,108:INFO:Uploading results into container
2023-11-01 09:18:52,109:INFO:Uploading model into container now
2023-11-01 09:18:52,109:INFO:_master_model_container: 2
2023-11-01 09:18:52,109:INFO:_display_container: 2
2023-11-01 09:18:52,109:INFO:Lasso(random_state=1234)
2023-11-01 09:18:52,109:INFO:create_model() successfully completed......................................
2023-11-01 09:18:52,171:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:52,171:INFO:Creating metrics dataframe
2023-11-01 09:18:52,179:INFO:Initializing Ridge Regression
2023-11-01 09:18:52,179:INFO:Total runtime is 0.01597460905710856 minutes
2023-11-01 09:18:52,181:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:52,181:INFO:Initializing create_model()
2023-11-01 09:18:52,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:52,182:INFO:Checking exceptions
2023-11-01 09:18:52,182:INFO:Importing libraries
2023-11-01 09:18:52,182:INFO:Copying training dataset
2023-11-01 09:18:52,186:INFO:Defining folds
2023-11-01 09:18:52,186:INFO:Declaring metric variables
2023-11-01 09:18:52,189:INFO:Importing untrained model
2023-11-01 09:18:52,191:INFO:Ridge Regression Imported successfully
2023-11-01 09:18:52,199:INFO:Starting cross validation
2023-11-01 09:18:52,202:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:52,458:INFO:Calculating mean and std
2023-11-01 09:18:52,459:INFO:Creating metrics dataframe
2023-11-01 09:18:52,461:INFO:Uploading results into container
2023-11-01 09:18:52,463:INFO:Uploading model into container now
2023-11-01 09:18:52,463:INFO:_master_model_container: 3
2023-11-01 09:18:52,463:INFO:_display_container: 2
2023-11-01 09:18:52,464:INFO:Ridge(random_state=1234)
2023-11-01 09:18:52,464:INFO:create_model() successfully completed......................................
2023-11-01 09:18:52,524:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:52,524:INFO:Creating metrics dataframe
2023-11-01 09:18:52,532:INFO:Initializing Elastic Net
2023-11-01 09:18:52,532:INFO:Total runtime is 0.02185462713241577 minutes
2023-11-01 09:18:52,535:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:52,535:INFO:Initializing create_model()
2023-11-01 09:18:52,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:52,535:INFO:Checking exceptions
2023-11-01 09:18:52,536:INFO:Importing libraries
2023-11-01 09:18:52,536:INFO:Copying training dataset
2023-11-01 09:18:52,540:INFO:Defining folds
2023-11-01 09:18:52,540:INFO:Declaring metric variables
2023-11-01 09:18:52,543:INFO:Importing untrained model
2023-11-01 09:18:52,545:INFO:Elastic Net Imported successfully
2023-11-01 09:18:52,553:INFO:Starting cross validation
2023-11-01 09:18:52,554:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:52,814:INFO:Calculating mean and std
2023-11-01 09:18:52,815:INFO:Creating metrics dataframe
2023-11-01 09:18:52,818:INFO:Uploading results into container
2023-11-01 09:18:52,819:INFO:Uploading model into container now
2023-11-01 09:18:52,819:INFO:_master_model_container: 4
2023-11-01 09:18:52,819:INFO:_display_container: 2
2023-11-01 09:18:52,820:INFO:ElasticNet(random_state=1234)
2023-11-01 09:18:52,820:INFO:create_model() successfully completed......................................
2023-11-01 09:18:52,879:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:52,880:INFO:Creating metrics dataframe
2023-11-01 09:18:52,889:INFO:Initializing Least Angle Regression
2023-11-01 09:18:52,889:INFO:Total runtime is 0.027811030546824135 minutes
2023-11-01 09:18:52,891:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:52,892:INFO:Initializing create_model()
2023-11-01 09:18:52,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:52,892:INFO:Checking exceptions
2023-11-01 09:18:52,892:INFO:Importing libraries
2023-11-01 09:18:52,892:INFO:Copying training dataset
2023-11-01 09:18:52,897:INFO:Defining folds
2023-11-01 09:18:52,897:INFO:Declaring metric variables
2023-11-01 09:18:52,899:INFO:Importing untrained model
2023-11-01 09:18:52,902:INFO:Least Angle Regression Imported successfully
2023-11-01 09:18:52,910:INFO:Starting cross validation
2023-11-01 09:18:52,911:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:53,001:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,007:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.284e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,008:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.696e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,008:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.979e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,008:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.832e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,020:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,020:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,025:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.081e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,026:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.936e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,027:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.827e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,027:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.589e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,030:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,037:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.144e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,039:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,046:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,048:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.395e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,058:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.703e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,060:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.174e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,060:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.086e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,061:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,077:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,141:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,148:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,153:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.432e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,153:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.056e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,153:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.154e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:18:53,177:INFO:Calculating mean and std
2023-11-01 09:18:53,178:INFO:Creating metrics dataframe
2023-11-01 09:18:53,181:INFO:Uploading results into container
2023-11-01 09:18:53,181:INFO:Uploading model into container now
2023-11-01 09:18:53,181:INFO:_master_model_container: 5
2023-11-01 09:18:53,183:INFO:_display_container: 2
2023-11-01 09:18:53,183:INFO:Lars(random_state=1234)
2023-11-01 09:18:53,183:INFO:create_model() successfully completed......................................
2023-11-01 09:18:53,251:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:53,251:INFO:Creating metrics dataframe
2023-11-01 09:18:53,259:INFO:Initializing Lasso Least Angle Regression
2023-11-01 09:18:53,259:INFO:Total runtime is 0.03398563861846923 minutes
2023-11-01 09:18:53,261:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:53,261:INFO:Initializing create_model()
2023-11-01 09:18:53,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:53,261:INFO:Checking exceptions
2023-11-01 09:18:53,261:INFO:Importing libraries
2023-11-01 09:18:53,261:INFO:Copying training dataset
2023-11-01 09:18:53,267:INFO:Defining folds
2023-11-01 09:18:53,267:INFO:Declaring metric variables
2023-11-01 09:18:53,271:INFO:Importing untrained model
2023-11-01 09:18:53,273:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 09:18:53,280:INFO:Starting cross validation
2023-11-01 09:18:53,281:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:53,392:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,392:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,399:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,406:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,414:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,422:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,455:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,521:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,525:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:18:53,551:INFO:Calculating mean and std
2023-11-01 09:18:53,553:INFO:Creating metrics dataframe
2023-11-01 09:18:53,556:INFO:Uploading results into container
2023-11-01 09:18:53,556:INFO:Uploading model into container now
2023-11-01 09:18:53,557:INFO:_master_model_container: 6
2023-11-01 09:18:53,557:INFO:_display_container: 2
2023-11-01 09:18:53,557:INFO:LassoLars(random_state=1234)
2023-11-01 09:18:53,557:INFO:create_model() successfully completed......................................
2023-11-01 09:18:53,617:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:53,618:INFO:Creating metrics dataframe
2023-11-01 09:18:53,627:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 09:18:53,627:INFO:Total runtime is 0.040114227930704745 minutes
2023-11-01 09:18:53,630:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:53,630:INFO:Initializing create_model()
2023-11-01 09:18:53,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:53,631:INFO:Checking exceptions
2023-11-01 09:18:53,631:INFO:Importing libraries
2023-11-01 09:18:53,631:INFO:Copying training dataset
2023-11-01 09:18:53,635:INFO:Defining folds
2023-11-01 09:18:53,635:INFO:Declaring metric variables
2023-11-01 09:18:53,638:INFO:Importing untrained model
2023-11-01 09:18:53,641:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 09:18:53,647:INFO:Starting cross validation
2023-11-01 09:18:53,649:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:53,739:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,753:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,769:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,772:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,772:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,788:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,793:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,814:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,872:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,878:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:18:53,905:INFO:Calculating mean and std
2023-11-01 09:18:53,906:INFO:Creating metrics dataframe
2023-11-01 09:18:53,909:INFO:Uploading results into container
2023-11-01 09:18:53,910:INFO:Uploading model into container now
2023-11-01 09:18:53,910:INFO:_master_model_container: 7
2023-11-01 09:18:53,910:INFO:_display_container: 2
2023-11-01 09:18:53,910:INFO:OrthogonalMatchingPursuit()
2023-11-01 09:18:53,911:INFO:create_model() successfully completed......................................
2023-11-01 09:18:53,977:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:53,978:INFO:Creating metrics dataframe
2023-11-01 09:18:53,986:INFO:Initializing Bayesian Ridge
2023-11-01 09:18:53,986:INFO:Total runtime is 0.046097071965535474 minutes
2023-11-01 09:18:53,990:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:53,990:INFO:Initializing create_model()
2023-11-01 09:18:53,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:53,990:INFO:Checking exceptions
2023-11-01 09:18:53,990:INFO:Importing libraries
2023-11-01 09:18:53,990:INFO:Copying training dataset
2023-11-01 09:18:53,994:INFO:Defining folds
2023-11-01 09:18:53,994:INFO:Declaring metric variables
2023-11-01 09:18:53,997:INFO:Importing untrained model
2023-11-01 09:18:54,000:INFO:Bayesian Ridge Imported successfully
2023-11-01 09:18:54,006:INFO:Starting cross validation
2023-11-01 09:18:54,008:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:54,269:INFO:Calculating mean and std
2023-11-01 09:18:54,270:INFO:Creating metrics dataframe
2023-11-01 09:18:54,273:INFO:Uploading results into container
2023-11-01 09:18:54,273:INFO:Uploading model into container now
2023-11-01 09:18:54,274:INFO:_master_model_container: 8
2023-11-01 09:18:54,274:INFO:_display_container: 2
2023-11-01 09:18:54,274:INFO:BayesianRidge()
2023-11-01 09:18:54,274:INFO:create_model() successfully completed......................................
2023-11-01 09:18:54,334:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:54,335:INFO:Creating metrics dataframe
2023-11-01 09:18:54,344:INFO:Initializing Passive Aggressive Regressor
2023-11-01 09:18:54,345:INFO:Total runtime is 0.05207125743230183 minutes
2023-11-01 09:18:54,346:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:54,347:INFO:Initializing create_model()
2023-11-01 09:18:54,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:54,347:INFO:Checking exceptions
2023-11-01 09:18:54,347:INFO:Importing libraries
2023-11-01 09:18:54,347:INFO:Copying training dataset
2023-11-01 09:18:54,351:INFO:Defining folds
2023-11-01 09:18:54,351:INFO:Declaring metric variables
2023-11-01 09:18:54,355:INFO:Importing untrained model
2023-11-01 09:18:54,359:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 09:18:54,365:INFO:Starting cross validation
2023-11-01 09:18:54,367:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:54,648:INFO:Calculating mean and std
2023-11-01 09:18:54,648:INFO:Creating metrics dataframe
2023-11-01 09:18:54,651:INFO:Uploading results into container
2023-11-01 09:18:54,653:INFO:Uploading model into container now
2023-11-01 09:18:54,653:INFO:_master_model_container: 9
2023-11-01 09:18:54,653:INFO:_display_container: 2
2023-11-01 09:18:54,654:INFO:PassiveAggressiveRegressor(random_state=1234)
2023-11-01 09:18:54,654:INFO:create_model() successfully completed......................................
2023-11-01 09:18:54,715:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:54,715:INFO:Creating metrics dataframe
2023-11-01 09:18:54,723:INFO:Initializing Huber Regressor
2023-11-01 09:18:54,723:INFO:Total runtime is 0.058386433124542225 minutes
2023-11-01 09:18:54,726:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:54,727:INFO:Initializing create_model()
2023-11-01 09:18:54,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:54,727:INFO:Checking exceptions
2023-11-01 09:18:54,727:INFO:Importing libraries
2023-11-01 09:18:54,727:INFO:Copying training dataset
2023-11-01 09:18:54,731:INFO:Defining folds
2023-11-01 09:18:54,731:INFO:Declaring metric variables
2023-11-01 09:18:54,734:INFO:Importing untrained model
2023-11-01 09:18:54,739:INFO:Huber Regressor Imported successfully
2023-11-01 09:18:54,745:INFO:Starting cross validation
2023-11-01 09:18:54,746:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:54,875:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:54,897:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:54,915:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:54,942:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:54,966:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:54,970:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:55,025:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:55,059:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:55,184:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:55,211:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:18:55,237:INFO:Calculating mean and std
2023-11-01 09:18:55,238:INFO:Creating metrics dataframe
2023-11-01 09:18:55,241:INFO:Uploading results into container
2023-11-01 09:18:55,241:INFO:Uploading model into container now
2023-11-01 09:18:55,241:INFO:_master_model_container: 10
2023-11-01 09:18:55,241:INFO:_display_container: 2
2023-11-01 09:18:55,242:INFO:HuberRegressor()
2023-11-01 09:18:55,242:INFO:create_model() successfully completed......................................
2023-11-01 09:18:55,335:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:55,335:INFO:Creating metrics dataframe
2023-11-01 09:18:55,344:INFO:Initializing K Neighbors Regressor
2023-11-01 09:18:55,345:INFO:Total runtime is 0.06875292857487995 minutes
2023-11-01 09:18:55,348:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:55,349:INFO:Initializing create_model()
2023-11-01 09:18:55,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:55,349:INFO:Checking exceptions
2023-11-01 09:18:55,349:INFO:Importing libraries
2023-11-01 09:18:55,349:INFO:Copying training dataset
2023-11-01 09:18:55,353:INFO:Defining folds
2023-11-01 09:18:55,353:INFO:Declaring metric variables
2023-11-01 09:18:55,357:INFO:Importing untrained model
2023-11-01 09:18:55,360:INFO:K Neighbors Regressor Imported successfully
2023-11-01 09:18:55,366:INFO:Starting cross validation
2023-11-01 09:18:55,367:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:55,712:INFO:Calculating mean and std
2023-11-01 09:18:55,714:INFO:Creating metrics dataframe
2023-11-01 09:18:55,719:INFO:Uploading results into container
2023-11-01 09:18:55,720:INFO:Uploading model into container now
2023-11-01 09:18:55,721:INFO:_master_model_container: 11
2023-11-01 09:18:55,721:INFO:_display_container: 2
2023-11-01 09:18:55,721:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 09:18:55,721:INFO:create_model() successfully completed......................................
2023-11-01 09:18:55,797:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:55,797:INFO:Creating metrics dataframe
2023-11-01 09:18:55,808:INFO:Initializing Decision Tree Regressor
2023-11-01 09:18:55,809:INFO:Total runtime is 0.07648277680079141 minutes
2023-11-01 09:18:55,811:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:55,813:INFO:Initializing create_model()
2023-11-01 09:18:55,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:55,813:INFO:Checking exceptions
2023-11-01 09:18:55,813:INFO:Importing libraries
2023-11-01 09:18:55,813:INFO:Copying training dataset
2023-11-01 09:18:55,818:INFO:Defining folds
2023-11-01 09:18:55,818:INFO:Declaring metric variables
2023-11-01 09:18:55,822:INFO:Importing untrained model
2023-11-01 09:18:55,825:INFO:Decision Tree Regressor Imported successfully
2023-11-01 09:18:55,831:INFO:Starting cross validation
2023-11-01 09:18:55,832:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:56,154:INFO:Calculating mean and std
2023-11-01 09:18:56,156:INFO:Creating metrics dataframe
2023-11-01 09:18:56,159:INFO:Uploading results into container
2023-11-01 09:18:56,159:INFO:Uploading model into container now
2023-11-01 09:18:56,160:INFO:_master_model_container: 12
2023-11-01 09:18:56,160:INFO:_display_container: 2
2023-11-01 09:18:56,160:INFO:DecisionTreeRegressor(random_state=1234)
2023-11-01 09:18:56,161:INFO:create_model() successfully completed......................................
2023-11-01 09:18:56,228:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:56,228:INFO:Creating metrics dataframe
2023-11-01 09:18:56,237:INFO:Initializing Random Forest Regressor
2023-11-01 09:18:56,239:INFO:Total runtime is 0.08363985220591226 minutes
2023-11-01 09:18:56,242:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:56,242:INFO:Initializing create_model()
2023-11-01 09:18:56,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:56,242:INFO:Checking exceptions
2023-11-01 09:18:56,242:INFO:Importing libraries
2023-11-01 09:18:56,242:INFO:Copying training dataset
2023-11-01 09:18:56,246:INFO:Defining folds
2023-11-01 09:18:56,246:INFO:Declaring metric variables
2023-11-01 09:18:56,248:INFO:Importing untrained model
2023-11-01 09:18:56,251:INFO:Random Forest Regressor Imported successfully
2023-11-01 09:18:56,259:INFO:Starting cross validation
2023-11-01 09:18:56,260:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:18:58,573:INFO:Calculating mean and std
2023-11-01 09:18:58,574:INFO:Creating metrics dataframe
2023-11-01 09:18:58,577:INFO:Uploading results into container
2023-11-01 09:18:58,578:INFO:Uploading model into container now
2023-11-01 09:18:58,578:INFO:_master_model_container: 13
2023-11-01 09:18:58,578:INFO:_display_container: 2
2023-11-01 09:18:58,578:INFO:RandomForestRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:18:58,578:INFO:create_model() successfully completed......................................
2023-11-01 09:18:58,640:INFO:SubProcess create_model() end ==================================
2023-11-01 09:18:58,640:INFO:Creating metrics dataframe
2023-11-01 09:18:58,650:INFO:Initializing Extra Trees Regressor
2023-11-01 09:18:58,651:INFO:Total runtime is 0.12383956511815389 minutes
2023-11-01 09:18:58,654:INFO:SubProcess create_model() called ==================================
2023-11-01 09:18:58,654:INFO:Initializing create_model()
2023-11-01 09:18:58,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:18:58,654:INFO:Checking exceptions
2023-11-01 09:18:58,654:INFO:Importing libraries
2023-11-01 09:18:58,655:INFO:Copying training dataset
2023-11-01 09:18:58,658:INFO:Defining folds
2023-11-01 09:18:58,658:INFO:Declaring metric variables
2023-11-01 09:18:58,661:INFO:Importing untrained model
2023-11-01 09:18:58,664:INFO:Extra Trees Regressor Imported successfully
2023-11-01 09:18:58,671:INFO:Starting cross validation
2023-11-01 09:18:58,673:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:00,777:INFO:Calculating mean and std
2023-11-01 09:19:00,778:INFO:Creating metrics dataframe
2023-11-01 09:19:00,781:INFO:Uploading results into container
2023-11-01 09:19:00,781:INFO:Uploading model into container now
2023-11-01 09:19:00,781:INFO:_master_model_container: 14
2023-11-01 09:19:00,781:INFO:_display_container: 2
2023-11-01 09:19:00,781:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:00,783:INFO:create_model() successfully completed......................................
2023-11-01 09:19:00,844:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:00,845:INFO:Creating metrics dataframe
2023-11-01 09:19:00,854:INFO:Initializing AdaBoost Regressor
2023-11-01 09:19:00,854:INFO:Total runtime is 0.16055463155110677 minutes
2023-11-01 09:19:00,857:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:00,857:INFO:Initializing create_model()
2023-11-01 09:19:00,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:00,857:INFO:Checking exceptions
2023-11-01 09:19:00,858:INFO:Importing libraries
2023-11-01 09:19:00,858:INFO:Copying training dataset
2023-11-01 09:19:00,862:INFO:Defining folds
2023-11-01 09:19:00,862:INFO:Declaring metric variables
2023-11-01 09:19:00,864:INFO:Importing untrained model
2023-11-01 09:19:00,869:INFO:AdaBoost Regressor Imported successfully
2023-11-01 09:19:00,875:INFO:Starting cross validation
2023-11-01 09:19:00,876:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:01,701:INFO:Calculating mean and std
2023-11-01 09:19:01,702:INFO:Creating metrics dataframe
2023-11-01 09:19:01,705:INFO:Uploading results into container
2023-11-01 09:19:01,706:INFO:Uploading model into container now
2023-11-01 09:19:01,706:INFO:_master_model_container: 15
2023-11-01 09:19:01,707:INFO:_display_container: 2
2023-11-01 09:19:01,707:INFO:AdaBoostRegressor(random_state=1234)
2023-11-01 09:19:01,707:INFO:create_model() successfully completed......................................
2023-11-01 09:19:01,769:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:01,769:INFO:Creating metrics dataframe
2023-11-01 09:19:01,779:INFO:Initializing Gradient Boosting Regressor
2023-11-01 09:19:01,779:INFO:Total runtime is 0.1759830911954244 minutes
2023-11-01 09:19:01,783:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:01,783:INFO:Initializing create_model()
2023-11-01 09:19:01,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:01,783:INFO:Checking exceptions
2023-11-01 09:19:01,783:INFO:Importing libraries
2023-11-01 09:19:01,783:INFO:Copying training dataset
2023-11-01 09:19:01,788:INFO:Defining folds
2023-11-01 09:19:01,788:INFO:Declaring metric variables
2023-11-01 09:19:01,791:INFO:Importing untrained model
2023-11-01 09:19:01,793:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 09:19:01,800:INFO:Starting cross validation
2023-11-01 09:19:01,801:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:02,800:INFO:Calculating mean and std
2023-11-01 09:19:02,801:INFO:Creating metrics dataframe
2023-11-01 09:19:02,803:INFO:Uploading results into container
2023-11-01 09:19:02,804:INFO:Uploading model into container now
2023-11-01 09:19:02,804:INFO:_master_model_container: 16
2023-11-01 09:19:02,804:INFO:_display_container: 2
2023-11-01 09:19:02,804:INFO:GradientBoostingRegressor(random_state=1234)
2023-11-01 09:19:02,805:INFO:create_model() successfully completed......................................
2023-11-01 09:19:02,887:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:02,887:INFO:Creating metrics dataframe
2023-11-01 09:19:02,905:INFO:Initializing Extreme Gradient Boosting
2023-11-01 09:19:02,905:INFO:Total runtime is 0.19474713802337648 minutes
2023-11-01 09:19:02,911:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:02,911:INFO:Initializing create_model()
2023-11-01 09:19:02,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:02,911:INFO:Checking exceptions
2023-11-01 09:19:02,911:INFO:Importing libraries
2023-11-01 09:19:02,911:INFO:Copying training dataset
2023-11-01 09:19:02,918:INFO:Defining folds
2023-11-01 09:19:02,918:INFO:Declaring metric variables
2023-11-01 09:19:02,921:INFO:Importing untrained model
2023-11-01 09:19:02,926:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 09:19:02,932:INFO:Starting cross validation
2023-11-01 09:19:02,935:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:03,813:INFO:Calculating mean and std
2023-11-01 09:19:03,815:INFO:Creating metrics dataframe
2023-11-01 09:19:03,819:INFO:Uploading results into container
2023-11-01 09:19:03,820:INFO:Uploading model into container now
2023-11-01 09:19:03,820:INFO:_master_model_container: 17
2023-11-01 09:19:03,821:INFO:_display_container: 2
2023-11-01 09:19:03,822:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1234, ...)
2023-11-01 09:19:03,822:INFO:create_model() successfully completed......................................
2023-11-01 09:19:03,897:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:03,897:INFO:Creating metrics dataframe
2023-11-01 09:19:03,911:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 09:19:03,911:INFO:Total runtime is 0.21151407957077029 minutes
2023-11-01 09:19:03,916:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:03,917:INFO:Initializing create_model()
2023-11-01 09:19:03,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:03,917:INFO:Checking exceptions
2023-11-01 09:19:03,917:INFO:Importing libraries
2023-11-01 09:19:03,917:INFO:Copying training dataset
2023-11-01 09:19:03,922:INFO:Defining folds
2023-11-01 09:19:03,922:INFO:Declaring metric variables
2023-11-01 09:19:03,924:INFO:Importing untrained model
2023-11-01 09:19:03,928:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:19:03,937:INFO:Starting cross validation
2023-11-01 09:19:03,938:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:04,992:INFO:Calculating mean and std
2023-11-01 09:19:04,994:INFO:Creating metrics dataframe
2023-11-01 09:19:04,998:INFO:Uploading results into container
2023-11-01 09:19:04,998:INFO:Uploading model into container now
2023-11-01 09:19:04,999:INFO:_master_model_container: 18
2023-11-01 09:19:04,999:INFO:_display_container: 2
2023-11-01 09:19:05,000:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:05,000:INFO:create_model() successfully completed......................................
2023-11-01 09:19:05,103:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:05,103:INFO:Creating metrics dataframe
2023-11-01 09:19:05,115:INFO:Initializing Dummy Regressor
2023-11-01 09:19:05,116:INFO:Total runtime is 0.23158926169077557 minutes
2023-11-01 09:19:05,119:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:05,119:INFO:Initializing create_model()
2023-11-01 09:19:05,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366E5ECC10>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:05,119:INFO:Checking exceptions
2023-11-01 09:19:05,119:INFO:Importing libraries
2023-11-01 09:19:05,119:INFO:Copying training dataset
2023-11-01 09:19:05,123:INFO:Defining folds
2023-11-01 09:19:05,123:INFO:Declaring metric variables
2023-11-01 09:19:05,126:INFO:Importing untrained model
2023-11-01 09:19:05,130:INFO:Dummy Regressor Imported successfully
2023-11-01 09:19:05,138:INFO:Starting cross validation
2023-11-01 09:19:05,139:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:05,400:INFO:Calculating mean and std
2023-11-01 09:19:05,401:INFO:Creating metrics dataframe
2023-11-01 09:19:05,403:INFO:Uploading results into container
2023-11-01 09:19:05,403:INFO:Uploading model into container now
2023-11-01 09:19:05,403:INFO:_master_model_container: 19
2023-11-01 09:19:05,405:INFO:_display_container: 2
2023-11-01 09:19:05,405:INFO:DummyRegressor()
2023-11-01 09:19:05,405:INFO:create_model() successfully completed......................................
2023-11-01 09:19:05,462:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:05,462:INFO:Creating metrics dataframe
2023-11-01 09:19:05,483:INFO:Initializing create_model()
2023-11-01 09:19:05,483:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:05,483:INFO:Checking exceptions
2023-11-01 09:19:05,485:INFO:Importing libraries
2023-11-01 09:19:05,485:INFO:Copying training dataset
2023-11-01 09:19:05,489:INFO:Defining folds
2023-11-01 09:19:05,489:INFO:Declaring metric variables
2023-11-01 09:19:05,489:INFO:Importing untrained model
2023-11-01 09:19:05,489:INFO:Declaring custom model
2023-11-01 09:19:05,490:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:19:05,491:INFO:Cross validation set to False
2023-11-01 09:19:05,491:INFO:Fitting Model
2023-11-01 09:19:05,560:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2023-11-01 09:19:05,560:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:19:05,561:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:19:05,561:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:19:05,561:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-11-01 09:19:05,625:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:05,625:INFO:create_model() successfully completed......................................
2023-11-01 09:19:05,735:INFO:_master_model_container: 19
2023-11-01 09:19:05,735:INFO:_display_container: 2
2023-11-01 09:19:05,735:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:05,735:INFO:compare_models() successfully completed......................................
2023-11-01 09:19:14,925:INFO:Initializing compare_models()
2023-11-01 09:19:14,925:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 09:19:14,925:INFO:Checking exceptions
2023-11-01 09:19:14,928:INFO:Preparing display monitor
2023-11-01 09:19:14,966:INFO:Initializing Linear Regression
2023-11-01 09:19:14,968:INFO:Total runtime is 2.5125344594319663e-05 minutes
2023-11-01 09:19:14,971:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:14,972:INFO:Initializing create_model()
2023-11-01 09:19:14,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:14,972:INFO:Checking exceptions
2023-11-01 09:19:14,972:INFO:Importing libraries
2023-11-01 09:19:14,972:INFO:Copying training dataset
2023-11-01 09:19:14,978:INFO:Defining folds
2023-11-01 09:19:14,979:INFO:Declaring metric variables
2023-11-01 09:19:14,984:INFO:Importing untrained model
2023-11-01 09:19:14,988:INFO:Linear Regression Imported successfully
2023-11-01 09:19:14,996:INFO:Starting cross validation
2023-11-01 09:19:14,999:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:15,349:INFO:Calculating mean and std
2023-11-01 09:19:15,349:INFO:Creating metrics dataframe
2023-11-01 09:19:15,351:INFO:Uploading results into container
2023-11-01 09:19:15,352:INFO:Uploading model into container now
2023-11-01 09:19:15,352:INFO:_master_model_container: 20
2023-11-01 09:19:15,352:INFO:_display_container: 3
2023-11-01 09:19:15,352:INFO:LinearRegression(n_jobs=-1)
2023-11-01 09:19:15,352:INFO:create_model() successfully completed......................................
2023-11-01 09:19:15,410:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:15,410:INFO:Creating metrics dataframe
2023-11-01 09:19:15,417:INFO:Initializing Lasso Regression
2023-11-01 09:19:15,417:INFO:Total runtime is 0.007508500417073568 minutes
2023-11-01 09:19:15,420:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:15,420:INFO:Initializing create_model()
2023-11-01 09:19:15,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:15,420:INFO:Checking exceptions
2023-11-01 09:19:15,420:INFO:Importing libraries
2023-11-01 09:19:15,420:INFO:Copying training dataset
2023-11-01 09:19:15,423:INFO:Defining folds
2023-11-01 09:19:15,423:INFO:Declaring metric variables
2023-11-01 09:19:15,426:INFO:Importing untrained model
2023-11-01 09:19:15,430:INFO:Lasso Regression Imported successfully
2023-11-01 09:19:15,458:INFO:Starting cross validation
2023-11-01 09:19:15,461:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:15,749:INFO:Calculating mean and std
2023-11-01 09:19:15,750:INFO:Creating metrics dataframe
2023-11-01 09:19:15,751:INFO:Uploading results into container
2023-11-01 09:19:15,753:INFO:Uploading model into container now
2023-11-01 09:19:15,753:INFO:_master_model_container: 21
2023-11-01 09:19:15,753:INFO:_display_container: 3
2023-11-01 09:19:15,753:INFO:Lasso(random_state=1234)
2023-11-01 09:19:15,753:INFO:create_model() successfully completed......................................
2023-11-01 09:19:15,813:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:15,813:INFO:Creating metrics dataframe
2023-11-01 09:19:15,821:INFO:Initializing Ridge Regression
2023-11-01 09:19:15,821:INFO:Total runtime is 0.014249404271443685 minutes
2023-11-01 09:19:15,824:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:15,825:INFO:Initializing create_model()
2023-11-01 09:19:15,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:15,825:INFO:Checking exceptions
2023-11-01 09:19:15,825:INFO:Importing libraries
2023-11-01 09:19:15,825:INFO:Copying training dataset
2023-11-01 09:19:15,830:INFO:Defining folds
2023-11-01 09:19:15,830:INFO:Declaring metric variables
2023-11-01 09:19:15,833:INFO:Importing untrained model
2023-11-01 09:19:15,835:INFO:Ridge Regression Imported successfully
2023-11-01 09:19:15,841:INFO:Starting cross validation
2023-11-01 09:19:15,843:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:16,109:INFO:Calculating mean and std
2023-11-01 09:19:16,110:INFO:Creating metrics dataframe
2023-11-01 09:19:16,113:INFO:Uploading results into container
2023-11-01 09:19:16,113:INFO:Uploading model into container now
2023-11-01 09:19:16,113:INFO:_master_model_container: 22
2023-11-01 09:19:16,113:INFO:_display_container: 3
2023-11-01 09:19:16,114:INFO:Ridge(random_state=1234)
2023-11-01 09:19:16,114:INFO:create_model() successfully completed......................................
2023-11-01 09:19:16,174:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:16,174:INFO:Creating metrics dataframe
2023-11-01 09:19:16,181:INFO:Initializing Elastic Net
2023-11-01 09:19:16,181:INFO:Total runtime is 0.0202489177385966 minutes
2023-11-01 09:19:16,186:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:16,186:INFO:Initializing create_model()
2023-11-01 09:19:16,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:16,186:INFO:Checking exceptions
2023-11-01 09:19:16,186:INFO:Importing libraries
2023-11-01 09:19:16,186:INFO:Copying training dataset
2023-11-01 09:19:16,190:INFO:Defining folds
2023-11-01 09:19:16,190:INFO:Declaring metric variables
2023-11-01 09:19:16,193:INFO:Importing untrained model
2023-11-01 09:19:16,196:INFO:Elastic Net Imported successfully
2023-11-01 09:19:16,202:INFO:Starting cross validation
2023-11-01 09:19:16,204:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:16,486:INFO:Calculating mean and std
2023-11-01 09:19:16,487:INFO:Creating metrics dataframe
2023-11-01 09:19:16,489:INFO:Uploading results into container
2023-11-01 09:19:16,489:INFO:Uploading model into container now
2023-11-01 09:19:16,489:INFO:_master_model_container: 23
2023-11-01 09:19:16,489:INFO:_display_container: 3
2023-11-01 09:19:16,490:INFO:ElasticNet(random_state=1234)
2023-11-01 09:19:16,490:INFO:create_model() successfully completed......................................
2023-11-01 09:19:16,549:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:16,549:INFO:Creating metrics dataframe
2023-11-01 09:19:16,556:INFO:Initializing Least Angle Regression
2023-11-01 09:19:16,556:INFO:Total runtime is 0.02648993730545044 minutes
2023-11-01 09:19:16,560:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:16,560:INFO:Initializing create_model()
2023-11-01 09:19:16,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:16,560:INFO:Checking exceptions
2023-11-01 09:19:16,561:INFO:Importing libraries
2023-11-01 09:19:16,561:INFO:Copying training dataset
2023-11-01 09:19:16,567:INFO:Defining folds
2023-11-01 09:19:16,567:INFO:Declaring metric variables
2023-11-01 09:19:16,570:INFO:Importing untrained model
2023-11-01 09:19:16,572:INFO:Least Angle Regression Imported successfully
2023-11-01 09:19:16,579:INFO:Starting cross validation
2023-11-01 09:19:16,581:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:16,695:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,700:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.284e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.696e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.979e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.832e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.081e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.936e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.827e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.589e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,714:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.144e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,723:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,731:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.395e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,740:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,746:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,747:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.703e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,748:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.174e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,749:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.086e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,762:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,827:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,835:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:16,839:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.432e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,839:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.056e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,839:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.154e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 09:19:16,860:INFO:Calculating mean and std
2023-11-01 09:19:16,861:INFO:Creating metrics dataframe
2023-11-01 09:19:16,865:INFO:Uploading results into container
2023-11-01 09:19:16,865:INFO:Uploading model into container now
2023-11-01 09:19:16,866:INFO:_master_model_container: 24
2023-11-01 09:19:16,866:INFO:_display_container: 3
2023-11-01 09:19:16,867:INFO:Lars(random_state=1234)
2023-11-01 09:19:16,867:INFO:create_model() successfully completed......................................
2023-11-01 09:19:16,929:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:16,929:INFO:Creating metrics dataframe
2023-11-01 09:19:16,938:INFO:Initializing Lasso Least Angle Regression
2023-11-01 09:19:16,938:INFO:Total runtime is 0.032857322692871095 minutes
2023-11-01 09:19:16,940:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:16,941:INFO:Initializing create_model()
2023-11-01 09:19:16,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:16,941:INFO:Checking exceptions
2023-11-01 09:19:16,941:INFO:Importing libraries
2023-11-01 09:19:16,941:INFO:Copying training dataset
2023-11-01 09:19:16,945:INFO:Defining folds
2023-11-01 09:19:16,945:INFO:Declaring metric variables
2023-11-01 09:19:16,948:INFO:Importing untrained model
2023-11-01 09:19:16,951:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 09:19:16,958:INFO:Starting cross validation
2023-11-01 09:19:16,960:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:17,065:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,072:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,091:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,095:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,099:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,106:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,136:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,147:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,200:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,211:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 09:19:17,237:INFO:Calculating mean and std
2023-11-01 09:19:17,238:INFO:Creating metrics dataframe
2023-11-01 09:19:17,241:INFO:Uploading results into container
2023-11-01 09:19:17,243:INFO:Uploading model into container now
2023-11-01 09:19:17,244:INFO:_master_model_container: 25
2023-11-01 09:19:17,244:INFO:_display_container: 3
2023-11-01 09:19:17,244:INFO:LassoLars(random_state=1234)
2023-11-01 09:19:17,244:INFO:create_model() successfully completed......................................
2023-11-01 09:19:17,305:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:17,305:INFO:Creating metrics dataframe
2023-11-01 09:19:17,314:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 09:19:17,314:INFO:Total runtime is 0.03912180264790853 minutes
2023-11-01 09:19:17,316:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:17,316:INFO:Initializing create_model()
2023-11-01 09:19:17,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:17,318:INFO:Checking exceptions
2023-11-01 09:19:17,318:INFO:Importing libraries
2023-11-01 09:19:17,318:INFO:Copying training dataset
2023-11-01 09:19:17,322:INFO:Defining folds
2023-11-01 09:19:17,322:INFO:Declaring metric variables
2023-11-01 09:19:17,324:INFO:Importing untrained model
2023-11-01 09:19:17,326:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 09:19:17,333:INFO:Starting cross validation
2023-11-01 09:19:17,335:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:17,448:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,450:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,471:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,471:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,498:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,507:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,517:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,524:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,596:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,597:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 09:19:17,627:INFO:Calculating mean and std
2023-11-01 09:19:17,628:INFO:Creating metrics dataframe
2023-11-01 09:19:17,631:INFO:Uploading results into container
2023-11-01 09:19:17,631:INFO:Uploading model into container now
2023-11-01 09:19:17,631:INFO:_master_model_container: 26
2023-11-01 09:19:17,632:INFO:_display_container: 3
2023-11-01 09:19:17,632:INFO:OrthogonalMatchingPursuit()
2023-11-01 09:19:17,632:INFO:create_model() successfully completed......................................
2023-11-01 09:19:17,700:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:17,700:INFO:Creating metrics dataframe
2023-11-01 09:19:17,707:INFO:Initializing Bayesian Ridge
2023-11-01 09:19:17,707:INFO:Total runtime is 0.04568057854970296 minutes
2023-11-01 09:19:17,711:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:17,711:INFO:Initializing create_model()
2023-11-01 09:19:17,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:17,713:INFO:Checking exceptions
2023-11-01 09:19:17,713:INFO:Importing libraries
2023-11-01 09:19:17,713:INFO:Copying training dataset
2023-11-01 09:19:17,717:INFO:Defining folds
2023-11-01 09:19:17,717:INFO:Declaring metric variables
2023-11-01 09:19:17,721:INFO:Importing untrained model
2023-11-01 09:19:17,724:INFO:Bayesian Ridge Imported successfully
2023-11-01 09:19:17,733:INFO:Starting cross validation
2023-11-01 09:19:17,735:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:18,019:INFO:Calculating mean and std
2023-11-01 09:19:18,020:INFO:Creating metrics dataframe
2023-11-01 09:19:18,022:INFO:Uploading results into container
2023-11-01 09:19:18,023:INFO:Uploading model into container now
2023-11-01 09:19:18,023:INFO:_master_model_container: 27
2023-11-01 09:19:18,023:INFO:_display_container: 3
2023-11-01 09:19:18,023:INFO:BayesianRidge()
2023-11-01 09:19:18,023:INFO:create_model() successfully completed......................................
2023-11-01 09:19:18,083:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:18,083:INFO:Creating metrics dataframe
2023-11-01 09:19:18,093:INFO:Initializing Passive Aggressive Regressor
2023-11-01 09:19:18,093:INFO:Total runtime is 0.05211221774419149 minutes
2023-11-01 09:19:18,097:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:18,098:INFO:Initializing create_model()
2023-11-01 09:19:18,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:18,098:INFO:Checking exceptions
2023-11-01 09:19:18,098:INFO:Importing libraries
2023-11-01 09:19:18,098:INFO:Copying training dataset
2023-11-01 09:19:18,102:INFO:Defining folds
2023-11-01 09:19:18,102:INFO:Declaring metric variables
2023-11-01 09:19:18,105:INFO:Importing untrained model
2023-11-01 09:19:18,109:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 09:19:18,116:INFO:Starting cross validation
2023-11-01 09:19:18,118:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:18,391:INFO:Calculating mean and std
2023-11-01 09:19:18,393:INFO:Creating metrics dataframe
2023-11-01 09:19:18,396:INFO:Uploading results into container
2023-11-01 09:19:18,396:INFO:Uploading model into container now
2023-11-01 09:19:18,396:INFO:_master_model_container: 28
2023-11-01 09:19:18,396:INFO:_display_container: 3
2023-11-01 09:19:18,397:INFO:PassiveAggressiveRegressor(random_state=1234)
2023-11-01 09:19:18,397:INFO:create_model() successfully completed......................................
2023-11-01 09:19:18,457:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:18,458:INFO:Creating metrics dataframe
2023-11-01 09:19:18,470:INFO:Initializing Huber Regressor
2023-11-01 09:19:18,470:INFO:Total runtime is 0.05839192867279053 minutes
2023-11-01 09:19:18,475:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:18,475:INFO:Initializing create_model()
2023-11-01 09:19:18,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:18,476:INFO:Checking exceptions
2023-11-01 09:19:18,476:INFO:Importing libraries
2023-11-01 09:19:18,476:INFO:Copying training dataset
2023-11-01 09:19:18,483:INFO:Defining folds
2023-11-01 09:19:18,483:INFO:Declaring metric variables
2023-11-01 09:19:18,486:INFO:Importing untrained model
2023-11-01 09:19:18,488:INFO:Huber Regressor Imported successfully
2023-11-01 09:19:18,496:INFO:Starting cross validation
2023-11-01 09:19:18,498:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:18,638:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,661:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,668:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,691:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,724:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,745:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,774:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,886:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,909:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-01 09:19:18,932:INFO:Calculating mean and std
2023-11-01 09:19:18,933:INFO:Creating metrics dataframe
2023-11-01 09:19:18,936:INFO:Uploading results into container
2023-11-01 09:19:18,936:INFO:Uploading model into container now
2023-11-01 09:19:18,937:INFO:_master_model_container: 29
2023-11-01 09:19:18,937:INFO:_display_container: 3
2023-11-01 09:19:18,937:INFO:HuberRegressor()
2023-11-01 09:19:18,937:INFO:create_model() successfully completed......................................
2023-11-01 09:19:18,997:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:18,997:INFO:Creating metrics dataframe
2023-11-01 09:19:19,007:INFO:Initializing K Neighbors Regressor
2023-11-01 09:19:19,007:INFO:Total runtime is 0.06733955939610799 minutes
2023-11-01 09:19:19,011:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:19,012:INFO:Initializing create_model()
2023-11-01 09:19:19,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:19,012:INFO:Checking exceptions
2023-11-01 09:19:19,012:INFO:Importing libraries
2023-11-01 09:19:19,012:INFO:Copying training dataset
2023-11-01 09:19:19,017:INFO:Defining folds
2023-11-01 09:19:19,017:INFO:Declaring metric variables
2023-11-01 09:19:19,020:INFO:Importing untrained model
2023-11-01 09:19:19,023:INFO:K Neighbors Regressor Imported successfully
2023-11-01 09:19:19,031:INFO:Starting cross validation
2023-11-01 09:19:19,033:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:19,388:INFO:Calculating mean and std
2023-11-01 09:19:19,389:INFO:Creating metrics dataframe
2023-11-01 09:19:19,395:INFO:Uploading results into container
2023-11-01 09:19:19,396:INFO:Uploading model into container now
2023-11-01 09:19:19,396:INFO:_master_model_container: 30
2023-11-01 09:19:19,396:INFO:_display_container: 3
2023-11-01 09:19:19,397:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 09:19:19,397:INFO:create_model() successfully completed......................................
2023-11-01 09:19:19,472:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:19,472:INFO:Creating metrics dataframe
2023-11-01 09:19:19,483:INFO:Initializing Decision Tree Regressor
2023-11-01 09:19:19,483:INFO:Total runtime is 0.07527987957000731 minutes
2023-11-01 09:19:19,486:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:19,486:INFO:Initializing create_model()
2023-11-01 09:19:19,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:19,486:INFO:Checking exceptions
2023-11-01 09:19:19,486:INFO:Importing libraries
2023-11-01 09:19:19,486:INFO:Copying training dataset
2023-11-01 09:19:19,491:INFO:Defining folds
2023-11-01 09:19:19,491:INFO:Declaring metric variables
2023-11-01 09:19:19,494:INFO:Importing untrained model
2023-11-01 09:19:19,500:INFO:Decision Tree Regressor Imported successfully
2023-11-01 09:19:19,505:INFO:Starting cross validation
2023-11-01 09:19:19,507:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:19,808:INFO:Calculating mean and std
2023-11-01 09:19:19,809:INFO:Creating metrics dataframe
2023-11-01 09:19:19,811:INFO:Uploading results into container
2023-11-01 09:19:19,811:INFO:Uploading model into container now
2023-11-01 09:19:19,813:INFO:_master_model_container: 31
2023-11-01 09:19:19,813:INFO:_display_container: 3
2023-11-01 09:19:19,813:INFO:DecisionTreeRegressor(random_state=1234)
2023-11-01 09:19:19,813:INFO:create_model() successfully completed......................................
2023-11-01 09:19:19,877:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:19,877:INFO:Creating metrics dataframe
2023-11-01 09:19:19,887:INFO:Initializing Random Forest Regressor
2023-11-01 09:19:19,887:INFO:Total runtime is 0.08200823465983072 minutes
2023-11-01 09:19:19,890:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:19,890:INFO:Initializing create_model()
2023-11-01 09:19:19,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:19,890:INFO:Checking exceptions
2023-11-01 09:19:19,890:INFO:Importing libraries
2023-11-01 09:19:19,890:INFO:Copying training dataset
2023-11-01 09:19:19,895:INFO:Defining folds
2023-11-01 09:19:19,895:INFO:Declaring metric variables
2023-11-01 09:19:19,897:INFO:Importing untrained model
2023-11-01 09:19:19,900:INFO:Random Forest Regressor Imported successfully
2023-11-01 09:19:19,906:INFO:Starting cross validation
2023-11-01 09:19:19,908:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:22,252:INFO:Calculating mean and std
2023-11-01 09:19:22,253:INFO:Creating metrics dataframe
2023-11-01 09:19:22,255:INFO:Uploading results into container
2023-11-01 09:19:22,256:INFO:Uploading model into container now
2023-11-01 09:19:22,256:INFO:_master_model_container: 32
2023-11-01 09:19:22,256:INFO:_display_container: 3
2023-11-01 09:19:22,257:INFO:RandomForestRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:22,257:INFO:create_model() successfully completed......................................
2023-11-01 09:19:22,321:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:22,321:INFO:Creating metrics dataframe
2023-11-01 09:19:22,331:INFO:Initializing Extra Trees Regressor
2023-11-01 09:19:22,331:INFO:Total runtime is 0.12274636824925739 minutes
2023-11-01 09:19:22,334:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:22,334:INFO:Initializing create_model()
2023-11-01 09:19:22,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:22,334:INFO:Checking exceptions
2023-11-01 09:19:22,334:INFO:Importing libraries
2023-11-01 09:19:22,334:INFO:Copying training dataset
2023-11-01 09:19:22,339:INFO:Defining folds
2023-11-01 09:19:22,339:INFO:Declaring metric variables
2023-11-01 09:19:22,343:INFO:Importing untrained model
2023-11-01 09:19:22,346:INFO:Extra Trees Regressor Imported successfully
2023-11-01 09:19:22,353:INFO:Starting cross validation
2023-11-01 09:19:22,355:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:24,410:INFO:Calculating mean and std
2023-11-01 09:19:24,412:INFO:Creating metrics dataframe
2023-11-01 09:19:24,416:INFO:Uploading results into container
2023-11-01 09:19:24,417:INFO:Uploading model into container now
2023-11-01 09:19:24,418:INFO:_master_model_container: 33
2023-11-01 09:19:24,418:INFO:_display_container: 3
2023-11-01 09:19:24,418:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:24,419:INFO:create_model() successfully completed......................................
2023-11-01 09:19:24,499:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:24,499:INFO:Creating metrics dataframe
2023-11-01 09:19:24,510:INFO:Initializing AdaBoost Regressor
2023-11-01 09:19:24,511:INFO:Total runtime is 0.15907251040140785 minutes
2023-11-01 09:19:24,513:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:24,513:INFO:Initializing create_model()
2023-11-01 09:19:24,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:24,513:INFO:Checking exceptions
2023-11-01 09:19:24,513:INFO:Importing libraries
2023-11-01 09:19:24,513:INFO:Copying training dataset
2023-11-01 09:19:24,519:INFO:Defining folds
2023-11-01 09:19:24,519:INFO:Declaring metric variables
2023-11-01 09:19:24,522:INFO:Importing untrained model
2023-11-01 09:19:24,527:INFO:AdaBoost Regressor Imported successfully
2023-11-01 09:19:24,534:INFO:Starting cross validation
2023-11-01 09:19:24,535:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:25,338:INFO:Calculating mean and std
2023-11-01 09:19:25,339:INFO:Creating metrics dataframe
2023-11-01 09:19:25,341:INFO:Uploading results into container
2023-11-01 09:19:25,343:INFO:Uploading model into container now
2023-11-01 09:19:25,343:INFO:_master_model_container: 34
2023-11-01 09:19:25,343:INFO:_display_container: 3
2023-11-01 09:19:25,344:INFO:AdaBoostRegressor(random_state=1234)
2023-11-01 09:19:25,344:INFO:create_model() successfully completed......................................
2023-11-01 09:19:25,404:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:25,404:INFO:Creating metrics dataframe
2023-11-01 09:19:25,415:INFO:Initializing Gradient Boosting Regressor
2023-11-01 09:19:25,415:INFO:Total runtime is 0.17414461771647133 minutes
2023-11-01 09:19:25,417:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:25,418:INFO:Initializing create_model()
2023-11-01 09:19:25,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:25,418:INFO:Checking exceptions
2023-11-01 09:19:25,418:INFO:Importing libraries
2023-11-01 09:19:25,418:INFO:Copying training dataset
2023-11-01 09:19:25,422:INFO:Defining folds
2023-11-01 09:19:25,423:INFO:Declaring metric variables
2023-11-01 09:19:25,425:INFO:Importing untrained model
2023-11-01 09:19:25,429:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 09:19:25,435:INFO:Starting cross validation
2023-11-01 09:19:25,436:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:26,470:INFO:Calculating mean and std
2023-11-01 09:19:26,472:INFO:Creating metrics dataframe
2023-11-01 09:19:26,474:INFO:Uploading results into container
2023-11-01 09:19:26,475:INFO:Uploading model into container now
2023-11-01 09:19:26,475:INFO:_master_model_container: 35
2023-11-01 09:19:26,476:INFO:_display_container: 3
2023-11-01 09:19:26,476:INFO:GradientBoostingRegressor(random_state=1234)
2023-11-01 09:19:26,476:INFO:create_model() successfully completed......................................
2023-11-01 09:19:26,549:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:26,549:INFO:Creating metrics dataframe
2023-11-01 09:19:26,560:INFO:Initializing Extreme Gradient Boosting
2023-11-01 09:19:26,560:INFO:Total runtime is 0.1932361602783203 minutes
2023-11-01 09:19:26,564:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:26,564:INFO:Initializing create_model()
2023-11-01 09:19:26,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:26,564:INFO:Checking exceptions
2023-11-01 09:19:26,564:INFO:Importing libraries
2023-11-01 09:19:26,565:INFO:Copying training dataset
2023-11-01 09:19:26,568:INFO:Defining folds
2023-11-01 09:19:26,568:INFO:Declaring metric variables
2023-11-01 09:19:26,570:INFO:Importing untrained model
2023-11-01 09:19:26,573:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 09:19:26,582:INFO:Starting cross validation
2023-11-01 09:19:26,584:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:27,475:INFO:Calculating mean and std
2023-11-01 09:19:27,475:INFO:Creating metrics dataframe
2023-11-01 09:19:27,480:INFO:Uploading results into container
2023-11-01 09:19:27,481:INFO:Uploading model into container now
2023-11-01 09:19:27,481:INFO:_master_model_container: 36
2023-11-01 09:19:27,481:INFO:_display_container: 3
2023-11-01 09:19:27,483:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1234, ...)
2023-11-01 09:19:27,484:INFO:create_model() successfully completed......................................
2023-11-01 09:19:27,561:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:27,561:INFO:Creating metrics dataframe
2023-11-01 09:19:27,575:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 09:19:27,576:INFO:Total runtime is 0.21015624602635702 minutes
2023-11-01 09:19:27,579:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:27,579:INFO:Initializing create_model()
2023-11-01 09:19:27,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:27,579:INFO:Checking exceptions
2023-11-01 09:19:27,579:INFO:Importing libraries
2023-11-01 09:19:27,579:INFO:Copying training dataset
2023-11-01 09:19:27,584:INFO:Defining folds
2023-11-01 09:19:27,584:INFO:Declaring metric variables
2023-11-01 09:19:27,587:INFO:Importing untrained model
2023-11-01 09:19:27,593:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:19:27,601:INFO:Starting cross validation
2023-11-01 09:19:27,603:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:28,653:INFO:Calculating mean and std
2023-11-01 09:19:28,655:INFO:Creating metrics dataframe
2023-11-01 09:19:28,659:INFO:Uploading results into container
2023-11-01 09:19:28,660:INFO:Uploading model into container now
2023-11-01 09:19:28,660:INFO:_master_model_container: 37
2023-11-01 09:19:28,661:INFO:_display_container: 3
2023-11-01 09:19:28,661:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:28,661:INFO:create_model() successfully completed......................................
2023-11-01 09:19:28,768:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:28,768:INFO:Creating metrics dataframe
2023-11-01 09:19:28,780:INFO:Initializing Dummy Regressor
2023-11-01 09:19:28,780:INFO:Total runtime is 0.23022811412811278 minutes
2023-11-01 09:19:28,783:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:28,783:INFO:Initializing create_model()
2023-11-01 09:19:28,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001366F3C8190>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:28,783:INFO:Checking exceptions
2023-11-01 09:19:28,784:INFO:Importing libraries
2023-11-01 09:19:28,784:INFO:Copying training dataset
2023-11-01 09:19:28,792:INFO:Defining folds
2023-11-01 09:19:28,793:INFO:Declaring metric variables
2023-11-01 09:19:28,798:INFO:Importing untrained model
2023-11-01 09:19:28,802:INFO:Dummy Regressor Imported successfully
2023-11-01 09:19:28,811:INFO:Starting cross validation
2023-11-01 09:19:28,813:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:29,101:INFO:Calculating mean and std
2023-11-01 09:19:29,102:INFO:Creating metrics dataframe
2023-11-01 09:19:29,104:INFO:Uploading results into container
2023-11-01 09:19:29,105:INFO:Uploading model into container now
2023-11-01 09:19:29,105:INFO:_master_model_container: 38
2023-11-01 09:19:29,105:INFO:_display_container: 3
2023-11-01 09:19:29,105:INFO:DummyRegressor()
2023-11-01 09:19:29,105:INFO:create_model() successfully completed......................................
2023-11-01 09:19:29,164:INFO:SubProcess create_model() end ==================================
2023-11-01 09:19:29,164:INFO:Creating metrics dataframe
2023-11-01 09:19:29,183:INFO:Initializing create_model()
2023-11-01 09:19:29,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:29,183:INFO:Checking exceptions
2023-11-01 09:19:29,184:INFO:Importing libraries
2023-11-01 09:19:29,184:INFO:Copying training dataset
2023-11-01 09:19:29,188:INFO:Defining folds
2023-11-01 09:19:29,188:INFO:Declaring metric variables
2023-11-01 09:19:29,188:INFO:Importing untrained model
2023-11-01 09:19:29,189:INFO:Declaring custom model
2023-11-01 09:19:29,189:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:19:29,191:INFO:Cross validation set to False
2023-11-01 09:19:29,191:INFO:Fitting Model
2023-11-01 09:19:29,269:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2023-11-01 09:19:29,269:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:19:29,269:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:19:29,269:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:19:29,269:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-11-01 09:19:29,332:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:29,332:INFO:create_model() successfully completed......................................
2023-11-01 09:19:29,445:INFO:_master_model_container: 38
2023-11-01 09:19:29,445:INFO:_display_container: 3
2023-11-01 09:19:29,446:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:19:29,446:INFO:compare_models() successfully completed......................................
2023-11-01 09:19:52,276:INFO:Initializing ensemble_model()
2023-11-01 09:19:52,276:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-01 09:19:52,276:INFO:Checking exceptions
2023-11-01 09:19:52,308:INFO:Importing libraries
2023-11-01 09:19:52,309:INFO:Copying training dataset
2023-11-01 09:19:52,309:INFO:Checking base model
2023-11-01 09:19:52,309:INFO:Base model : Light Gradient Boosting Machine
2023-11-01 09:19:52,320:INFO:Importing untrained ensembler
2023-11-01 09:19:52,320:INFO:Ensemble method set to Bagging
2023-11-01 09:19:52,320:INFO:SubProcess create_model() called ==================================
2023-11-01 09:19:52,321:INFO:Initializing create_model()
2023-11-01 09:19:52,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001365D876890>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:19:52,321:INFO:Checking exceptions
2023-11-01 09:19:52,321:INFO:Importing libraries
2023-11-01 09:19:52,321:INFO:Copying training dataset
2023-11-01 09:19:52,327:INFO:Defining folds
2023-11-01 09:19:52,327:INFO:Declaring metric variables
2023-11-01 09:19:52,330:INFO:Importing untrained model
2023-11-01 09:19:52,330:INFO:Declaring custom model
2023-11-01 09:19:52,337:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:19:52,344:INFO:Starting cross validation
2023-11-01 09:19:52,345:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:19:59,993:INFO:Calculating mean and std
2023-11-01 09:19:59,995:INFO:Creating metrics dataframe
2023-11-01 09:20:00,002:INFO:Finalizing model
2023-11-01 09:20:00,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2023-11-01 09:20:00,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,096:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,096:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,097:INFO:[LightGBM] [Info] Start training from score 361.461216
2023-11-01 09:20:00,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2023-11-01 09:20:00,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,164:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,164:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,164:INFO:[LightGBM] [Info] Start training from score 362.048122
2023-11-01 09:20:00,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2023-11-01 09:20:00,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,232:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,232:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,232:INFO:[LightGBM] [Info] Start training from score 362.152229
2023-11-01 09:20:00,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2023-11-01 09:20:00,300:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,300:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,300:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,301:INFO:[LightGBM] [Info] Start training from score 361.120814
2023-11-01 09:20:00,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2023-11-01 09:20:00,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,368:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,368:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,368:INFO:[LightGBM] [Info] Start training from score 362.010807
2023-11-01 09:20:00,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.
2023-11-01 09:20:00,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,438:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,439:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,439:INFO:[LightGBM] [Info] Start training from score 361.960496
2023-11-01 09:20:00,511:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2023-11-01 09:20:00,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,511:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,511:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,512:INFO:[LightGBM] [Info] Start training from score 361.852436
2023-11-01 09:20:00,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.
2023-11-01 09:20:00,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,580:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,580:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,581:INFO:[LightGBM] [Info] Start training from score 361.515665
2023-11-01 09:20:00,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2023-11-01 09:20:00,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,652:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,653:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,653:INFO:[LightGBM] [Info] Start training from score 361.132447
2023-11-01 09:20:00,723:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2023-11-01 09:20:00,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:00,724:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:00,724:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:00,724:INFO:[LightGBM] [Info] Start training from score 360.648827
2023-11-01 09:20:00,795:INFO:Uploading results into container
2023-11-01 09:20:00,797:INFO:Uploading model into container now
2023-11-01 09:20:00,797:INFO:_master_model_container: 39
2023-11-01 09:20:00,798:INFO:_display_container: 4
2023-11-01 09:20:00,799:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234)
2023-11-01 09:20:00,799:INFO:create_model() successfully completed......................................
2023-11-01 09:20:00,887:INFO:SubProcess create_model() end ==================================
2023-11-01 09:20:00,887:INFO:choose_better activated
2023-11-01 09:20:00,890:INFO:SubProcess create_model() called ==================================
2023-11-01 09:20:00,890:INFO:Initializing create_model()
2023-11-01 09:20:00,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 09:20:00,890:INFO:Checking exceptions
2023-11-01 09:20:00,892:INFO:Importing libraries
2023-11-01 09:20:00,892:INFO:Copying training dataset
2023-11-01 09:20:00,894:INFO:Defining folds
2023-11-01 09:20:00,895:INFO:Declaring metric variables
2023-11-01 09:20:00,895:INFO:Importing untrained model
2023-11-01 09:20:00,895:INFO:Declaring custom model
2023-11-01 09:20:00,896:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:20:00,896:INFO:Starting cross validation
2023-11-01 09:20:00,897:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 09:20:01,897:INFO:Calculating mean and std
2023-11-01 09:20:01,898:INFO:Creating metrics dataframe
2023-11-01 09:20:01,900:INFO:Finalizing model
2023-11-01 09:20:02,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2023-11-01 09:20:02,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:20:02,024:INFO:[LightGBM] [Info] Total Bins 1069
2023-11-01 09:20:02,024:INFO:[LightGBM] [Info] Number of data points in the train set: 5506, number of used features: 25
2023-11-01 09:20:02,024:INFO:[LightGBM] [Info] Start training from score 361.942261
2023-11-01 09:20:02,090:INFO:Uploading results into container
2023-11-01 09:20:02,090:INFO:Uploading model into container now
2023-11-01 09:20:02,091:INFO:_master_model_container: 40
2023-11-01 09:20:02,091:INFO:_display_container: 5
2023-11-01 09:20:02,091:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:20:02,091:INFO:create_model() successfully completed......................................
2023-11-01 09:20:02,161:INFO:SubProcess create_model() end ==================================
2023-11-01 09:20:02,163:INFO:LGBMRegressor(n_jobs=-1, random_state=1234) result for R2 is 0.7286
2023-11-01 09:20:02,164:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234) result for R2 is 0.7301
2023-11-01 09:20:02,165:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234) is best model
2023-11-01 09:20:02,165:INFO:choose_better completed
2023-11-01 09:20:02,173:INFO:_master_model_container: 40
2023-11-01 09:20:02,174:INFO:_display_container: 4
2023-11-01 09:20:02,175:INFO:BaggingRegressor(base_estimator=LGBMRegressor(n_jobs=-1, random_state=1234),
                 random_state=1234)
2023-11-01 09:20:02,175:INFO:ensemble_model() successfully completed......................................
2023-11-01 09:20:39,048:INFO:Initializing predict_model()
2023-11-01 09:20:39,048:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001364B213250>)
2023-11-01 09:20:39,048:INFO:Checking exceptions
2023-11-01 09:20:39,049:INFO:Preloading libraries
2023-11-01 09:20:39,052:INFO:Set up data.
2023-11-01 09:20:39,058:INFO:Set up index.
2023-11-01 09:21:20,661:INFO:Initializing finalize_model()
2023-11-01 09:21:20,663:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-01 09:21:20,663:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 09:21:20,668:INFO:Initializing create_model()
2023-11-01 09:21:20,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=LGBMRegressor(n_jobs=-1, random_state=1234), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-11-01 09:21:20,668:INFO:Checking exceptions
2023-11-01 09:21:20,672:INFO:Importing libraries
2023-11-01 09:21:20,672:INFO:Copying training dataset
2023-11-01 09:21:20,672:INFO:Defining folds
2023-11-01 09:21:20,672:INFO:Declaring metric variables
2023-11-01 09:21:20,672:INFO:Importing untrained model
2023-11-01 09:21:20,672:INFO:Declaring custom model
2023-11-01 09:21:20,674:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 09:21:20,676:INFO:Cross validation set to False
2023-11-01 09:21:20,676:INFO:Fitting Model
2023-11-01 09:21:20,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.
2023-11-01 09:21:20,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-01 09:21:20,760:INFO:[LightGBM] [Info] Total Bins 1070
2023-11-01 09:21:20,760:INFO:[LightGBM] [Info] Number of data points in the train set: 6006, number of used features: 25
2023-11-01 09:21:20,760:INFO:[LightGBM] [Info] Start training from score 365.914729
2023-11-01 09:21:20,961:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))])
2023-11-01 09:21:20,962:INFO:create_model() successfully completed......................................
2023-11-01 09:21:21,037:INFO:_master_model_container: 40
2023-11-01 09:21:21,037:INFO:_display_container: 5
2023-11-01 09:21:21,068:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))])
2023-11-01 09:21:21,068:INFO:finalize_model() successfully completed......................................
2023-11-01 10:40:40,860:WARNING:C:\Users\manue\AppData\Local\Temp\ipykernel_4564\3344577448.py:7: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy


2023-11-01 10:41:27,696:INFO:Initializing predict_model()
2023-11-01 10:41:27,697:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000013677F71870>)
2023-11-01 10:41:27,698:INFO:Checking exceptions
2023-11-01 10:41:27,698:INFO:Preloading libraries
2023-11-01 10:41:27,703:INFO:Set up data.
2023-11-01 10:41:27,709:INFO:Set up index.
2023-11-01 10:43:54,884:INFO:Initializing predict_model()
2023-11-01 10:43:54,884:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001367B8B2200>)
2023-11-01 10:43:54,884:INFO:Checking exceptions
2023-11-01 10:43:54,884:INFO:Preloading libraries
2023-11-01 10:43:54,887:INFO:Set up data.
2023-11-01 10:43:54,894:INFO:Set up index.
2023-11-01 10:46:57,839:INFO:Initializing predict_model()
2023-11-01 10:46:57,839:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001366F49D870>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['year', 'Series', 'day_of_year',
                                             'dolar_oficial', 'temperature_C'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['month', 'day_of_week',
                                             'is_working'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Tr...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'is_working',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['month', 'day_of_week'],
                                    transformer=OneHotEncoder(cols=['month',
                                                                    'day_of_week'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=1234))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001367A4F37F0>)
2023-11-01 10:46:57,839:INFO:Checking exceptions
2023-11-01 10:46:57,839:INFO:Preloading libraries
2023-11-01 10:46:57,842:INFO:Set up data.
2023-11-01 10:46:57,847:INFO:Set up index.
2023-11-01 23:47:36,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 23:47:36,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 23:47:36,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 23:47:36,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-01 23:47:36,257:INFO:PyCaret RegressionExperiment
2023-11-01 23:47:36,257:INFO:Logging name: reg-default-name
2023-11-01 23:47:36,257:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-01 23:47:36,257:INFO:version 3.1.0
2023-11-01 23:47:36,257:INFO:Initializing setup()
2023-11-01 23:47:36,257:INFO:self.USI: 9d30
2023-11-01 23:47:36,257:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-01 23:47:36,257:INFO:Checking environment
2023-11-01 23:47:36,258:INFO:python_version: 3.10.6
2023-11-01 23:47:36,258:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-01 23:47:36,258:INFO:machine: AMD64
2023-11-01 23:47:36,258:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-01 23:47:36,258:INFO:Memory: svmem(total=8273383424, available=1194958848, percent=85.6, used=7078424576, free=1194958848)
2023-11-01 23:47:36,258:INFO:Physical Core: 4
2023-11-01 23:47:36,258:INFO:Logical Core: 8
2023-11-01 23:47:36,258:INFO:Checking libraries
2023-11-01 23:47:36,258:INFO:System:
2023-11-01 23:47:36,258:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-01 23:47:36,258:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-01 23:47:36,258:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-01 23:47:36,259:INFO:PyCaret required dependencies:
2023-11-01 23:47:36,348:INFO:                 pip: 22.2.1
2023-11-01 23:47:36,348:INFO:          setuptools: 63.2.0
2023-11-01 23:47:36,348:INFO:             pycaret: 3.1.0
2023-11-01 23:47:36,348:INFO:             IPython: 8.4.0
2023-11-01 23:47:36,348:INFO:          ipywidgets: 8.1.1
2023-11-01 23:47:36,348:INFO:                tqdm: 4.66.1
2023-11-01 23:47:36,348:INFO:               numpy: 1.23.2
2023-11-01 23:47:36,348:INFO:              pandas: 1.4.3
2023-11-01 23:47:36,348:INFO:              jinja2: 3.1.2
2023-11-01 23:47:36,348:INFO:               scipy: 1.10.1
2023-11-01 23:47:36,348:INFO:              joblib: 1.2.0
2023-11-01 23:47:36,348:INFO:             sklearn: 1.1.2
2023-11-01 23:47:36,348:INFO:                pyod: 1.1.0
2023-11-01 23:47:36,348:INFO:            imblearn: 0.11.0
2023-11-01 23:47:36,348:INFO:   category_encoders: 2.6.2
2023-11-01 23:47:36,348:INFO:            lightgbm: 4.1.0
2023-11-01 23:47:36,348:INFO:               numba: 0.58.0
2023-11-01 23:47:36,348:INFO:            requests: 2.28.1
2023-11-01 23:47:36,348:INFO:          matplotlib: 3.6.0
2023-11-01 23:47:36,348:INFO:          scikitplot: 0.3.7
2023-11-01 23:47:36,348:INFO:         yellowbrick: 1.5
2023-11-01 23:47:36,348:INFO:              plotly: 5.17.0
2023-11-01 23:47:36,348:INFO:    plotly-resampler: Not installed
2023-11-01 23:47:36,348:INFO:             kaleido: 0.2.1
2023-11-01 23:47:36,348:INFO:           schemdraw: 0.15
2023-11-01 23:47:36,348:INFO:         statsmodels: 0.13.2
2023-11-01 23:47:36,348:INFO:              sktime: 0.21.1
2023-11-01 23:47:36,348:INFO:               tbats: 1.1.3
2023-11-01 23:47:36,348:INFO:            pmdarima: 2.0.3
2023-11-01 23:47:36,348:INFO:              psutil: 5.9.1
2023-11-01 23:47:36,348:INFO:          markupsafe: 2.1.1
2023-11-01 23:47:36,349:INFO:             pickle5: Not installed
2023-11-01 23:47:36,349:INFO:         cloudpickle: 2.2.1
2023-11-01 23:47:36,349:INFO:         deprecation: 2.1.0
2023-11-01 23:47:36,349:INFO:              xxhash: 3.4.1
2023-11-01 23:47:36,349:INFO:           wurlitzer: Not installed
2023-11-01 23:47:36,349:INFO:PyCaret optional dependencies:
2023-11-01 23:47:36,442:INFO:                shap: Not installed
2023-11-01 23:47:36,442:INFO:           interpret: Not installed
2023-11-01 23:47:36,442:INFO:                umap: Not installed
2023-11-01 23:47:36,442:INFO:     ydata_profiling: Not installed
2023-11-01 23:47:36,442:INFO:  explainerdashboard: Not installed
2023-11-01 23:47:36,442:INFO:             autoviz: Not installed
2023-11-01 23:47:36,442:INFO:           fairlearn: Not installed
2023-11-01 23:47:36,442:INFO:          deepchecks: Not installed
2023-11-01 23:47:36,442:INFO:             xgboost: 2.0.0
2023-11-01 23:47:36,442:INFO:            catboost: Not installed
2023-11-01 23:47:36,442:INFO:              kmodes: Not installed
2023-11-01 23:47:36,442:INFO:             mlxtend: Not installed
2023-11-01 23:47:36,442:INFO:       statsforecast: Not installed
2023-11-01 23:47:36,442:INFO:        tune_sklearn: Not installed
2023-11-01 23:47:36,442:INFO:                 ray: Not installed
2023-11-01 23:47:36,442:INFO:            hyperopt: Not installed
2023-11-01 23:47:36,442:INFO:              optuna: Not installed
2023-11-01 23:47:36,442:INFO:               skopt: Not installed
2023-11-01 23:47:36,442:INFO:              mlflow: Not installed
2023-11-01 23:47:36,442:INFO:              gradio: Not installed
2023-11-01 23:47:36,442:INFO:             fastapi: Not installed
2023-11-01 23:47:36,442:INFO:             uvicorn: Not installed
2023-11-01 23:47:36,442:INFO:              m2cgen: Not installed
2023-11-01 23:47:36,442:INFO:           evidently: Not installed
2023-11-01 23:47:36,442:INFO:               fugue: Not installed
2023-11-01 23:47:36,443:INFO:           streamlit: Not installed
2023-11-01 23:47:36,443:INFO:             prophet: 1.1.5
2023-11-01 23:47:36,443:INFO:None
2023-11-01 23:47:36,443:INFO:Set up data.
2023-11-01 23:47:36,449:INFO:Set up folding strategy.
2023-11-01 23:47:36,449:INFO:Set up train/test split.
2023-11-01 23:47:36,449:INFO:Set up data.
2023-11-01 23:47:36,454:INFO:Set up index.
2023-11-01 23:47:36,454:INFO:Assigning column types.
2023-11-01 23:47:36,457:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-01 23:47:36,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,461:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,555:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:36,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:36,557:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,561:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,649:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:36,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:36,653:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-01 23:47:36,657:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,746:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:36,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:36,753:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,842:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:36,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:36,844:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-01 23:47:36,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,937:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:36,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:36,947:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:47:36,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,032:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,034:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-01 23:47:37,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,127:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,184:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,222:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,224:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-01 23:47:37,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,318:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:47:37,412:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,416:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-01 23:47:37,507:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,601:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:37,608:INFO:Preparing preprocessing pipeline...
2023-11-01 23:47:37,608:INFO:Set up simple imputation.
2023-11-01 23:47:37,611:INFO:Set up encoding of categorical features.
2023-11-01 23:47:37,611:INFO:Set up column name cleaning.
2023-11-01 23:47:37,687:INFO:Finished creating preprocessing pipeline.
2023-11-01 23:47:37,694:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'ao', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'ao', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'ao',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-01 23:47:37,694:INFO:Creating final display dataframe.
2023-11-01 23:47:37,846:INFO:Setup _display_container:                     Description             Value
0                    Session id              1234
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (140, 12)
4        Transformed data shape         (140, 35)
5   Transformed train set shape         (128, 35)
6    Transformed test set shape          (12, 35)
7               Ignore features                 5
8              Numeric features                 7
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   TimeSeriesSplit
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              9d30
2023-11-01 23:47:37,942:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:37,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:38,037:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:47:38,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:47:38,039:INFO:setup() successfully completed in 1.78s...............
2023-11-01 23:48:40,695:INFO:Initializing compare_models()
2023-11-01 23:48:40,695:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 23:48:40,695:INFO:Checking exceptions
2023-11-01 23:48:40,697:INFO:Preparing display monitor
2023-11-01 23:48:40,740:INFO:Initializing Linear Regression
2023-11-01 23:48:40,741:INFO:Total runtime is 1.6645590464274088e-05 minutes
2023-11-01 23:48:40,746:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:40,746:INFO:Initializing create_model()
2023-11-01 23:48:40,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:40,746:INFO:Checking exceptions
2023-11-01 23:48:40,746:INFO:Importing libraries
2023-11-01 23:48:40,747:INFO:Copying training dataset
2023-11-01 23:48:40,752:INFO:Defining folds
2023-11-01 23:48:40,752:INFO:Declaring metric variables
2023-11-01 23:48:40,756:INFO:Importing untrained model
2023-11-01 23:48:40,760:INFO:Linear Regression Imported successfully
2023-11-01 23:48:40,768:INFO:Starting cross validation
2023-11-01 23:48:40,781:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:49,241:INFO:Calculating mean and std
2023-11-01 23:48:49,243:INFO:Creating metrics dataframe
2023-11-01 23:48:49,246:INFO:Uploading results into container
2023-11-01 23:48:49,246:INFO:Uploading model into container now
2023-11-01 23:48:49,247:INFO:_master_model_container: 1
2023-11-01 23:48:49,247:INFO:_display_container: 2
2023-11-01 23:48:49,248:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:48:49,248:INFO:create_model() successfully completed......................................
2023-11-01 23:48:49,876:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:49,876:INFO:Creating metrics dataframe
2023-11-01 23:48:49,884:INFO:Initializing Lasso Regression
2023-11-01 23:48:49,885:INFO:Total runtime is 0.15240699450174966 minutes
2023-11-01 23:48:49,888:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:49,888:INFO:Initializing create_model()
2023-11-01 23:48:49,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:49,888:INFO:Checking exceptions
2023-11-01 23:48:49,888:INFO:Importing libraries
2023-11-01 23:48:49,888:INFO:Copying training dataset
2023-11-01 23:48:49,896:INFO:Defining folds
2023-11-01 23:48:49,896:INFO:Declaring metric variables
2023-11-01 23:48:49,903:INFO:Importing untrained model
2023-11-01 23:48:49,908:INFO:Lasso Regression Imported successfully
2023-11-01 23:48:49,917:INFO:Starting cross validation
2023-11-01 23:48:49,920:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:50,213:INFO:Calculating mean and std
2023-11-01 23:48:50,214:INFO:Creating metrics dataframe
2023-11-01 23:48:50,217:INFO:Uploading results into container
2023-11-01 23:48:50,217:INFO:Uploading model into container now
2023-11-01 23:48:50,217:INFO:_master_model_container: 2
2023-11-01 23:48:50,217:INFO:_display_container: 2
2023-11-01 23:48:50,218:INFO:Lasso(random_state=1234)
2023-11-01 23:48:50,218:INFO:create_model() successfully completed......................................
2023-11-01 23:48:50,488:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:50,488:INFO:Creating metrics dataframe
2023-11-01 23:48:50,497:INFO:Initializing Ridge Regression
2023-11-01 23:48:50,498:INFO:Total runtime is 0.16262961228688558 minutes
2023-11-01 23:48:50,501:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:50,502:INFO:Initializing create_model()
2023-11-01 23:48:50,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:50,502:INFO:Checking exceptions
2023-11-01 23:48:50,502:INFO:Importing libraries
2023-11-01 23:48:50,502:INFO:Copying training dataset
2023-11-01 23:48:50,507:INFO:Defining folds
2023-11-01 23:48:50,507:INFO:Declaring metric variables
2023-11-01 23:48:50,511:INFO:Importing untrained model
2023-11-01 23:48:50,516:INFO:Ridge Regression Imported successfully
2023-11-01 23:48:50,522:INFO:Starting cross validation
2023-11-01 23:48:50,524:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:50,742:INFO:Calculating mean and std
2023-11-01 23:48:50,743:INFO:Creating metrics dataframe
2023-11-01 23:48:50,747:INFO:Uploading results into container
2023-11-01 23:48:50,748:INFO:Uploading model into container now
2023-11-01 23:48:50,748:INFO:_master_model_container: 3
2023-11-01 23:48:50,748:INFO:_display_container: 2
2023-11-01 23:48:50,749:INFO:Ridge(random_state=1234)
2023-11-01 23:48:50,749:INFO:create_model() successfully completed......................................
2023-11-01 23:48:51,009:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:51,009:INFO:Creating metrics dataframe
2023-11-01 23:48:51,017:INFO:Initializing Elastic Net
2023-11-01 23:48:51,017:INFO:Total runtime is 0.17128296295801798 minutes
2023-11-01 23:48:51,019:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:51,021:INFO:Initializing create_model()
2023-11-01 23:48:51,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:51,021:INFO:Checking exceptions
2023-11-01 23:48:51,021:INFO:Importing libraries
2023-11-01 23:48:51,021:INFO:Copying training dataset
2023-11-01 23:48:51,026:INFO:Defining folds
2023-11-01 23:48:51,026:INFO:Declaring metric variables
2023-11-01 23:48:51,029:INFO:Importing untrained model
2023-11-01 23:48:51,033:INFO:Elastic Net Imported successfully
2023-11-01 23:48:51,041:INFO:Starting cross validation
2023-11-01 23:48:51,044:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:51,275:INFO:Calculating mean and std
2023-11-01 23:48:51,277:INFO:Creating metrics dataframe
2023-11-01 23:48:51,279:INFO:Uploading results into container
2023-11-01 23:48:51,280:INFO:Uploading model into container now
2023-11-01 23:48:51,280:INFO:_master_model_container: 4
2023-11-01 23:48:51,280:INFO:_display_container: 2
2023-11-01 23:48:51,280:INFO:ElasticNet(random_state=1234)
2023-11-01 23:48:51,280:INFO:create_model() successfully completed......................................
2023-11-01 23:48:51,529:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:51,529:INFO:Creating metrics dataframe
2023-11-01 23:48:51,536:INFO:Initializing Least Angle Regression
2023-11-01 23:48:51,537:INFO:Total runtime is 0.17994802792867023 minutes
2023-11-01 23:48:51,542:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:51,542:INFO:Initializing create_model()
2023-11-01 23:48:51,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:51,542:INFO:Checking exceptions
2023-11-01 23:48:51,542:INFO:Importing libraries
2023-11-01 23:48:51,542:INFO:Copying training dataset
2023-11-01 23:48:51,547:INFO:Defining folds
2023-11-01 23:48:51,547:INFO:Declaring metric variables
2023-11-01 23:48:51,550:INFO:Importing untrained model
2023-11-01 23:48:51,554:INFO:Least Angle Regression Imported successfully
2023-11-01 23:48:51,562:INFO:Starting cross validation
2023-11-01 23:48:51,564:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:51,684:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,684:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,685:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.331e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.689e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.407e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.774e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.270e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.358e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.300e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.525e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.172e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.345e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.910e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.382e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.464e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.767e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.689e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.434e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.196e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.534e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.346e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.304e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.333e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.688e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.296e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.089e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.140e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.271e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.846e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.208e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.242e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.523e-07, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=8.053e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.293e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.027e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,708:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.121e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.484e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.704e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.037e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.010e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.844e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=9.902e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.869e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=7.653e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.503e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.251e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.562e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.200e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,712:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.966e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,718:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.023e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,718:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.938e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,719:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.746e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,719:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.585e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,783:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,786:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.556e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,787:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.858e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,787:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.657e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,787:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=9.068e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,787:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.721e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,788:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.804e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,788:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.289e-04, with an active set of 29 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,788:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.101e-04, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,788:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.518e-05, with an active set of 29 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,795:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:51,798:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.125e-02, with an active set of 26 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,798:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.478e-02, with an active set of 26 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=9.752e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=7.571e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.257e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.251e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.278e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.084e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=8.939e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:48:51,821:INFO:Calculating mean and std
2023-11-01 23:48:51,822:INFO:Creating metrics dataframe
2023-11-01 23:48:51,825:INFO:Uploading results into container
2023-11-01 23:48:51,825:INFO:Uploading model into container now
2023-11-01 23:48:51,826:INFO:_master_model_container: 5
2023-11-01 23:48:51,826:INFO:_display_container: 2
2023-11-01 23:48:51,827:INFO:Lars(random_state=1234)
2023-11-01 23:48:51,827:INFO:create_model() successfully completed......................................
2023-11-01 23:48:52,084:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:52,084:INFO:Creating metrics dataframe
2023-11-01 23:48:52,091:INFO:Initializing Lasso Least Angle Regression
2023-11-01 23:48:52,091:INFO:Total runtime is 0.18918211062749227 minutes
2023-11-01 23:48:52,095:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:52,095:INFO:Initializing create_model()
2023-11-01 23:48:52,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:52,095:INFO:Checking exceptions
2023-11-01 23:48:52,095:INFO:Importing libraries
2023-11-01 23:48:52,095:INFO:Copying training dataset
2023-11-01 23:48:52,099:INFO:Defining folds
2023-11-01 23:48:52,099:INFO:Declaring metric variables
2023-11-01 23:48:52,103:INFO:Importing untrained model
2023-11-01 23:48:52,107:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:48:52,114:INFO:Starting cross validation
2023-11-01 23:48:52,116:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:52,204:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,219:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,219:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,230:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,249:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,256:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,261:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,267:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,313:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,319:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:48:52,342:INFO:Calculating mean and std
2023-11-01 23:48:52,343:INFO:Creating metrics dataframe
2023-11-01 23:48:52,347:INFO:Uploading results into container
2023-11-01 23:48:52,348:INFO:Uploading model into container now
2023-11-01 23:48:52,348:INFO:_master_model_container: 6
2023-11-01 23:48:52,348:INFO:_display_container: 2
2023-11-01 23:48:52,348:INFO:LassoLars(random_state=1234)
2023-11-01 23:48:52,348:INFO:create_model() successfully completed......................................
2023-11-01 23:48:52,605:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:52,605:INFO:Creating metrics dataframe
2023-11-01 23:48:52,615:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 23:48:52,615:INFO:Total runtime is 0.19791138172149658 minutes
2023-11-01 23:48:52,617:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:52,618:INFO:Initializing create_model()
2023-11-01 23:48:52,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:52,618:INFO:Checking exceptions
2023-11-01 23:48:52,618:INFO:Importing libraries
2023-11-01 23:48:52,618:INFO:Copying training dataset
2023-11-01 23:48:52,621:INFO:Defining folds
2023-11-01 23:48:52,621:INFO:Declaring metric variables
2023-11-01 23:48:52,626:INFO:Importing untrained model
2023-11-01 23:48:52,630:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:48:52,637:INFO:Starting cross validation
2023-11-01 23:48:52,638:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:52,724:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,729:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,759:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,765:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,767:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,782:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,789:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,879:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,885:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:48:52,914:INFO:Calculating mean and std
2023-11-01 23:48:52,915:INFO:Creating metrics dataframe
2023-11-01 23:48:52,918:INFO:Uploading results into container
2023-11-01 23:48:52,918:INFO:Uploading model into container now
2023-11-01 23:48:52,919:INFO:_master_model_container: 7
2023-11-01 23:48:52,919:INFO:_display_container: 2
2023-11-01 23:48:52,919:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:48:52,919:INFO:create_model() successfully completed......................................
2023-11-01 23:48:53,201:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:53,201:INFO:Creating metrics dataframe
2023-11-01 23:48:53,212:INFO:Initializing Bayesian Ridge
2023-11-01 23:48:53,212:INFO:Total runtime is 0.20785748958587646 minutes
2023-11-01 23:48:53,214:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:53,215:INFO:Initializing create_model()
2023-11-01 23:48:53,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:53,215:INFO:Checking exceptions
2023-11-01 23:48:53,215:INFO:Importing libraries
2023-11-01 23:48:53,215:INFO:Copying training dataset
2023-11-01 23:48:53,219:INFO:Defining folds
2023-11-01 23:48:53,219:INFO:Declaring metric variables
2023-11-01 23:48:53,221:INFO:Importing untrained model
2023-11-01 23:48:53,227:INFO:Bayesian Ridge Imported successfully
2023-11-01 23:48:53,235:INFO:Starting cross validation
2023-11-01 23:48:53,236:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:53,460:INFO:Calculating mean and std
2023-11-01 23:48:53,461:INFO:Creating metrics dataframe
2023-11-01 23:48:53,465:INFO:Uploading results into container
2023-11-01 23:48:53,466:INFO:Uploading model into container now
2023-11-01 23:48:53,466:INFO:_master_model_container: 8
2023-11-01 23:48:53,466:INFO:_display_container: 2
2023-11-01 23:48:53,467:INFO:BayesianRidge()
2023-11-01 23:48:53,467:INFO:create_model() successfully completed......................................
2023-11-01 23:48:53,718:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:53,718:INFO:Creating metrics dataframe
2023-11-01 23:48:53,726:INFO:Initializing Passive Aggressive Regressor
2023-11-01 23:48:53,727:INFO:Total runtime is 0.2164493719736735 minutes
2023-11-01 23:48:53,730:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:53,731:INFO:Initializing create_model()
2023-11-01 23:48:53,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:53,731:INFO:Checking exceptions
2023-11-01 23:48:53,731:INFO:Importing libraries
2023-11-01 23:48:53,731:INFO:Copying training dataset
2023-11-01 23:48:53,735:INFO:Defining folds
2023-11-01 23:48:53,736:INFO:Declaring metric variables
2023-11-01 23:48:53,738:INFO:Importing untrained model
2023-11-01 23:48:53,742:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 23:48:53,750:INFO:Starting cross validation
2023-11-01 23:48:53,753:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:54,041:INFO:Calculating mean and std
2023-11-01 23:48:54,042:INFO:Creating metrics dataframe
2023-11-01 23:48:54,045:INFO:Uploading results into container
2023-11-01 23:48:54,045:INFO:Uploading model into container now
2023-11-01 23:48:54,046:INFO:_master_model_container: 9
2023-11-01 23:48:54,046:INFO:_display_container: 2
2023-11-01 23:48:54,047:INFO:PassiveAggressiveRegressor(random_state=1234)
2023-11-01 23:48:54,047:INFO:create_model() successfully completed......................................
2023-11-01 23:48:54,327:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:54,327:INFO:Creating metrics dataframe
2023-11-01 23:48:54,335:INFO:Initializing Huber Regressor
2023-11-01 23:48:54,335:INFO:Total runtime is 0.22657254536946614 minutes
2023-11-01 23:48:54,339:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:54,339:INFO:Initializing create_model()
2023-11-01 23:48:54,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:54,339:INFO:Checking exceptions
2023-11-01 23:48:54,339:INFO:Importing libraries
2023-11-01 23:48:54,339:INFO:Copying training dataset
2023-11-01 23:48:54,342:INFO:Defining folds
2023-11-01 23:48:54,343:INFO:Declaring metric variables
2023-11-01 23:48:54,346:INFO:Importing untrained model
2023-11-01 23:48:54,351:INFO:Huber Regressor Imported successfully
2023-11-01 23:48:54,357:INFO:Starting cross validation
2023-11-01 23:48:54,359:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:54,663:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\manue\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py", line 331, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-11-01 23:48:54,663:INFO:Calculating mean and std
2023-11-01 23:48:54,665:INFO:Creating metrics dataframe
2023-11-01 23:48:54,667:INFO:Uploading results into container
2023-11-01 23:48:54,667:INFO:Uploading model into container now
2023-11-01 23:48:54,668:INFO:_master_model_container: 10
2023-11-01 23:48:54,668:INFO:_display_container: 2
2023-11-01 23:48:54,668:INFO:HuberRegressor()
2023-11-01 23:48:54,668:INFO:create_model() successfully completed......................................
2023-11-01 23:48:54,944:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:54,944:INFO:Creating metrics dataframe
2023-11-01 23:48:54,957:INFO:Initializing K Neighbors Regressor
2023-11-01 23:48:54,957:INFO:Total runtime is 0.23693935871124266 minutes
2023-11-01 23:48:54,961:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:54,962:INFO:Initializing create_model()
2023-11-01 23:48:54,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:54,962:INFO:Checking exceptions
2023-11-01 23:48:54,962:INFO:Importing libraries
2023-11-01 23:48:54,962:INFO:Copying training dataset
2023-11-01 23:48:54,967:INFO:Defining folds
2023-11-01 23:48:54,968:INFO:Declaring metric variables
2023-11-01 23:48:54,973:INFO:Importing untrained model
2023-11-01 23:48:54,978:INFO:K Neighbors Regressor Imported successfully
2023-11-01 23:48:54,985:INFO:Starting cross validation
2023-11-01 23:48:54,986:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:55,464:INFO:Calculating mean and std
2023-11-01 23:48:55,467:INFO:Creating metrics dataframe
2023-11-01 23:48:55,469:INFO:Uploading results into container
2023-11-01 23:48:55,470:INFO:Uploading model into container now
2023-11-01 23:48:55,470:INFO:_master_model_container: 11
2023-11-01 23:48:55,470:INFO:_display_container: 2
2023-11-01 23:48:55,470:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 23:48:55,470:INFO:create_model() successfully completed......................................
2023-11-01 23:48:55,729:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:55,729:INFO:Creating metrics dataframe
2023-11-01 23:48:55,740:INFO:Initializing Decision Tree Regressor
2023-11-01 23:48:55,740:INFO:Total runtime is 0.24999294281005857 minutes
2023-11-01 23:48:55,744:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:55,745:INFO:Initializing create_model()
2023-11-01 23:48:55,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:55,745:INFO:Checking exceptions
2023-11-01 23:48:55,745:INFO:Importing libraries
2023-11-01 23:48:55,745:INFO:Copying training dataset
2023-11-01 23:48:55,749:INFO:Defining folds
2023-11-01 23:48:55,749:INFO:Declaring metric variables
2023-11-01 23:48:55,751:INFO:Importing untrained model
2023-11-01 23:48:55,756:INFO:Decision Tree Regressor Imported successfully
2023-11-01 23:48:55,765:INFO:Starting cross validation
2023-11-01 23:48:55,766:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:56,124:INFO:Calculating mean and std
2023-11-01 23:48:56,126:INFO:Creating metrics dataframe
2023-11-01 23:48:56,130:INFO:Uploading results into container
2023-11-01 23:48:56,131:INFO:Uploading model into container now
2023-11-01 23:48:56,132:INFO:_master_model_container: 12
2023-11-01 23:48:56,132:INFO:_display_container: 2
2023-11-01 23:48:56,132:INFO:DecisionTreeRegressor(random_state=1234)
2023-11-01 23:48:56,132:INFO:create_model() successfully completed......................................
2023-11-01 23:48:56,401:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:56,401:INFO:Creating metrics dataframe
2023-11-01 23:48:56,411:INFO:Initializing Random Forest Regressor
2023-11-01 23:48:56,413:INFO:Total runtime is 0.2612116058667501 minutes
2023-11-01 23:48:56,416:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:56,416:INFO:Initializing create_model()
2023-11-01 23:48:56,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:56,416:INFO:Checking exceptions
2023-11-01 23:48:56,416:INFO:Importing libraries
2023-11-01 23:48:56,416:INFO:Copying training dataset
2023-11-01 23:48:56,420:INFO:Defining folds
2023-11-01 23:48:56,420:INFO:Declaring metric variables
2023-11-01 23:48:56,423:INFO:Importing untrained model
2023-11-01 23:48:56,429:INFO:Random Forest Regressor Imported successfully
2023-11-01 23:48:56,436:INFO:Starting cross validation
2023-11-01 23:48:56,437:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:57,000:INFO:Calculating mean and std
2023-11-01 23:48:57,001:INFO:Creating metrics dataframe
2023-11-01 23:48:57,004:INFO:Uploading results into container
2023-11-01 23:48:57,005:INFO:Uploading model into container now
2023-11-01 23:48:57,005:INFO:_master_model_container: 13
2023-11-01 23:48:57,005:INFO:_display_container: 2
2023-11-01 23:48:57,006:INFO:RandomForestRegressor(n_jobs=-1, random_state=1234)
2023-11-01 23:48:57,006:INFO:create_model() successfully completed......................................
2023-11-01 23:48:57,260:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:57,260:INFO:Creating metrics dataframe
2023-11-01 23:48:57,269:INFO:Initializing Extra Trees Regressor
2023-11-01 23:48:57,269:INFO:Total runtime is 0.27548598051071166 minutes
2023-11-01 23:48:57,273:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:57,273:INFO:Initializing create_model()
2023-11-01 23:48:57,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:57,274:INFO:Checking exceptions
2023-11-01 23:48:57,274:INFO:Importing libraries
2023-11-01 23:48:57,274:INFO:Copying training dataset
2023-11-01 23:48:57,278:INFO:Defining folds
2023-11-01 23:48:57,278:INFO:Declaring metric variables
2023-11-01 23:48:57,281:INFO:Importing untrained model
2023-11-01 23:48:57,285:INFO:Extra Trees Regressor Imported successfully
2023-11-01 23:48:57,294:INFO:Starting cross validation
2023-11-01 23:48:57,296:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:57,814:INFO:Calculating mean and std
2023-11-01 23:48:57,815:INFO:Creating metrics dataframe
2023-11-01 23:48:57,818:INFO:Uploading results into container
2023-11-01 23:48:57,818:INFO:Uploading model into container now
2023-11-01 23:48:57,819:INFO:_master_model_container: 14
2023-11-01 23:48:57,819:INFO:_display_container: 2
2023-11-01 23:48:57,819:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1234)
2023-11-01 23:48:57,819:INFO:create_model() successfully completed......................................
2023-11-01 23:48:58,085:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:58,085:INFO:Creating metrics dataframe
2023-11-01 23:48:58,095:INFO:Initializing AdaBoost Regressor
2023-11-01 23:48:58,095:INFO:Total runtime is 0.2892468214035034 minutes
2023-11-01 23:48:58,098:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:58,098:INFO:Initializing create_model()
2023-11-01 23:48:58,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:58,098:INFO:Checking exceptions
2023-11-01 23:48:58,098:INFO:Importing libraries
2023-11-01 23:48:58,099:INFO:Copying training dataset
2023-11-01 23:48:58,103:INFO:Defining folds
2023-11-01 23:48:58,103:INFO:Declaring metric variables
2023-11-01 23:48:58,107:INFO:Importing untrained model
2023-11-01 23:48:58,111:INFO:AdaBoost Regressor Imported successfully
2023-11-01 23:48:58,118:INFO:Starting cross validation
2023-11-01 23:48:58,119:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:58,471:INFO:Calculating mean and std
2023-11-01 23:48:58,473:INFO:Creating metrics dataframe
2023-11-01 23:48:58,475:INFO:Uploading results into container
2023-11-01 23:48:58,475:INFO:Uploading model into container now
2023-11-01 23:48:58,476:INFO:_master_model_container: 15
2023-11-01 23:48:58,476:INFO:_display_container: 2
2023-11-01 23:48:58,476:INFO:AdaBoostRegressor(random_state=1234)
2023-11-01 23:48:58,476:INFO:create_model() successfully completed......................................
2023-11-01 23:48:58,722:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:58,722:INFO:Creating metrics dataframe
2023-11-01 23:48:58,734:INFO:Initializing Gradient Boosting Regressor
2023-11-01 23:48:58,734:INFO:Total runtime is 0.2999033331871032 minutes
2023-11-01 23:48:58,738:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:58,738:INFO:Initializing create_model()
2023-11-01 23:48:58,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:58,740:INFO:Checking exceptions
2023-11-01 23:48:58,740:INFO:Importing libraries
2023-11-01 23:48:58,740:INFO:Copying training dataset
2023-11-01 23:48:58,744:INFO:Defining folds
2023-11-01 23:48:58,745:INFO:Declaring metric variables
2023-11-01 23:48:58,747:INFO:Importing untrained model
2023-11-01 23:48:58,752:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 23:48:58,761:INFO:Starting cross validation
2023-11-01 23:48:58,762:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:59,036:INFO:Calculating mean and std
2023-11-01 23:48:59,037:INFO:Creating metrics dataframe
2023-11-01 23:48:59,040:INFO:Uploading results into container
2023-11-01 23:48:59,041:INFO:Uploading model into container now
2023-11-01 23:48:59,041:INFO:_master_model_container: 16
2023-11-01 23:48:59,041:INFO:_display_container: 2
2023-11-01 23:48:59,042:INFO:GradientBoostingRegressor(random_state=1234)
2023-11-01 23:48:59,042:INFO:create_model() successfully completed......................................
2023-11-01 23:48:59,288:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:59,289:INFO:Creating metrics dataframe
2023-11-01 23:48:59,299:INFO:Initializing Extreme Gradient Boosting
2023-11-01 23:48:59,299:INFO:Total runtime is 0.30931778351465855 minutes
2023-11-01 23:48:59,301:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:59,301:INFO:Initializing create_model()
2023-11-01 23:48:59,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:59,301:INFO:Checking exceptions
2023-11-01 23:48:59,301:INFO:Importing libraries
2023-11-01 23:48:59,301:INFO:Copying training dataset
2023-11-01 23:48:59,307:INFO:Defining folds
2023-11-01 23:48:59,307:INFO:Declaring metric variables
2023-11-01 23:48:59,311:INFO:Importing untrained model
2023-11-01 23:48:59,315:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 23:48:59,322:INFO:Starting cross validation
2023-11-01 23:48:59,324:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:48:59,719:INFO:Calculating mean and std
2023-11-01 23:48:59,720:INFO:Creating metrics dataframe
2023-11-01 23:48:59,723:INFO:Uploading results into container
2023-11-01 23:48:59,723:INFO:Uploading model into container now
2023-11-01 23:48:59,724:INFO:_master_model_container: 17
2023-11-01 23:48:59,724:INFO:_display_container: 2
2023-11-01 23:48:59,725:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1234, ...)
2023-11-01 23:48:59,725:INFO:create_model() successfully completed......................................
2023-11-01 23:48:59,975:INFO:SubProcess create_model() end ==================================
2023-11-01 23:48:59,975:INFO:Creating metrics dataframe
2023-11-01 23:48:59,989:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 23:48:59,989:INFO:Total runtime is 0.32081025044123324 minutes
2023-11-01 23:48:59,992:INFO:SubProcess create_model() called ==================================
2023-11-01 23:48:59,992:INFO:Initializing create_model()
2023-11-01 23:48:59,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:48:59,992:INFO:Checking exceptions
2023-11-01 23:48:59,992:INFO:Importing libraries
2023-11-01 23:48:59,992:INFO:Copying training dataset
2023-11-01 23:48:59,997:INFO:Defining folds
2023-11-01 23:48:59,997:INFO:Declaring metric variables
2023-11-01 23:49:00,000:INFO:Importing untrained model
2023-11-01 23:49:00,005:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 23:49:00,012:INFO:Starting cross validation
2023-11-01 23:49:00,015:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:49:00,391:INFO:Calculating mean and std
2023-11-01 23:49:00,393:INFO:Creating metrics dataframe
2023-11-01 23:49:00,397:INFO:Uploading results into container
2023-11-01 23:49:00,398:INFO:Uploading model into container now
2023-11-01 23:49:00,399:INFO:_master_model_container: 18
2023-11-01 23:49:00,399:INFO:_display_container: 2
2023-11-01 23:49:00,399:INFO:LGBMRegressor(n_jobs=-1, random_state=1234)
2023-11-01 23:49:00,400:INFO:create_model() successfully completed......................................
2023-11-01 23:49:00,666:INFO:SubProcess create_model() end ==================================
2023-11-01 23:49:00,666:INFO:Creating metrics dataframe
2023-11-01 23:49:00,676:INFO:Initializing Dummy Regressor
2023-11-01 23:49:00,676:INFO:Total runtime is 0.33226799567540477 minutes
2023-11-01 23:49:00,679:INFO:SubProcess create_model() called ==================================
2023-11-01 23:49:00,680:INFO:Initializing create_model()
2023-11-01 23:49:00,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCDEF730>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:49:00,680:INFO:Checking exceptions
2023-11-01 23:49:00,680:INFO:Importing libraries
2023-11-01 23:49:00,680:INFO:Copying training dataset
2023-11-01 23:49:00,684:INFO:Defining folds
2023-11-01 23:49:00,684:INFO:Declaring metric variables
2023-11-01 23:49:00,688:INFO:Importing untrained model
2023-11-01 23:49:00,692:INFO:Dummy Regressor Imported successfully
2023-11-01 23:49:00,700:INFO:Starting cross validation
2023-11-01 23:49:00,702:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:49:00,915:INFO:Calculating mean and std
2023-11-01 23:49:00,916:INFO:Creating metrics dataframe
2023-11-01 23:49:00,920:INFO:Uploading results into container
2023-11-01 23:49:00,921:INFO:Uploading model into container now
2023-11-01 23:49:00,921:INFO:_master_model_container: 19
2023-11-01 23:49:00,921:INFO:_display_container: 2
2023-11-01 23:49:00,921:INFO:DummyRegressor()
2023-11-01 23:49:00,921:INFO:create_model() successfully completed......................................
2023-11-01 23:49:01,177:INFO:SubProcess create_model() end ==================================
2023-11-01 23:49:01,177:INFO:Creating metrics dataframe
2023-11-01 23:49:01,197:INFO:Initializing create_model()
2023-11-01 23:49:01,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DBA0C5870>, estimator=LinearRegression(n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:49:01,198:INFO:Checking exceptions
2023-11-01 23:49:01,200:INFO:Importing libraries
2023-11-01 23:49:01,200:INFO:Copying training dataset
2023-11-01 23:49:01,202:INFO:Defining folds
2023-11-01 23:49:01,203:INFO:Declaring metric variables
2023-11-01 23:49:01,203:INFO:Importing untrained model
2023-11-01 23:49:01,203:INFO:Declaring custom model
2023-11-01 23:49:01,203:INFO:Linear Regression Imported successfully
2023-11-01 23:49:01,205:INFO:Cross validation set to False
2023-11-01 23:49:01,205:INFO:Fitting Model
2023-11-01 23:49:01,260:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:49:01,260:INFO:create_model() successfully completed......................................
2023-11-01 23:49:01,546:INFO:_master_model_container: 19
2023-11-01 23:49:01,546:INFO:_display_container: 2
2023-11-01 23:49:01,546:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:49:01,546:INFO:compare_models() successfully completed......................................
2023-11-01 23:53:33,469:INFO:PyCaret RegressionExperiment
2023-11-01 23:53:33,469:INFO:Logging name: reg-default-name
2023-11-01 23:53:33,469:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-01 23:53:33,469:INFO:version 3.1.0
2023-11-01 23:53:33,469:INFO:Initializing setup()
2023-11-01 23:53:33,469:INFO:self.USI: 4963
2023-11-01 23:53:33,469:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-01 23:53:33,469:INFO:Checking environment
2023-11-01 23:53:33,469:INFO:python_version: 3.10.6
2023-11-01 23:53:33,469:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-01 23:53:33,469:INFO:machine: AMD64
2023-11-01 23:53:33,469:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-01 23:53:33,470:INFO:Memory: svmem(total=8273383424, available=536678400, percent=93.5, used=7736705024, free=536678400)
2023-11-01 23:53:33,470:INFO:Physical Core: 4
2023-11-01 23:53:33,470:INFO:Logical Core: 8
2023-11-01 23:53:33,470:INFO:Checking libraries
2023-11-01 23:53:33,470:INFO:System:
2023-11-01 23:53:33,471:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-01 23:53:33,471:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-01 23:53:33,471:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-01 23:53:33,471:INFO:PyCaret required dependencies:
2023-11-01 23:53:33,471:INFO:                 pip: 22.2.1
2023-11-01 23:53:33,471:INFO:          setuptools: 63.2.0
2023-11-01 23:53:33,471:INFO:             pycaret: 3.1.0
2023-11-01 23:53:33,471:INFO:             IPython: 8.4.0
2023-11-01 23:53:33,471:INFO:          ipywidgets: 8.1.1
2023-11-01 23:53:33,471:INFO:                tqdm: 4.66.1
2023-11-01 23:53:33,471:INFO:               numpy: 1.23.2
2023-11-01 23:53:33,471:INFO:              pandas: 1.4.3
2023-11-01 23:53:33,471:INFO:              jinja2: 3.1.2
2023-11-01 23:53:33,471:INFO:               scipy: 1.10.1
2023-11-01 23:53:33,471:INFO:              joblib: 1.2.0
2023-11-01 23:53:33,471:INFO:             sklearn: 1.1.2
2023-11-01 23:53:33,471:INFO:                pyod: 1.1.0
2023-11-01 23:53:33,471:INFO:            imblearn: 0.11.0
2023-11-01 23:53:33,471:INFO:   category_encoders: 2.6.2
2023-11-01 23:53:33,471:INFO:            lightgbm: 4.1.0
2023-11-01 23:53:33,471:INFO:               numba: 0.58.0
2023-11-01 23:53:33,471:INFO:            requests: 2.28.1
2023-11-01 23:53:33,471:INFO:          matplotlib: 3.6.0
2023-11-01 23:53:33,471:INFO:          scikitplot: 0.3.7
2023-11-01 23:53:33,471:INFO:         yellowbrick: 1.5
2023-11-01 23:53:33,471:INFO:              plotly: 5.17.0
2023-11-01 23:53:33,471:INFO:    plotly-resampler: Not installed
2023-11-01 23:53:33,472:INFO:             kaleido: 0.2.1
2023-11-01 23:53:33,472:INFO:           schemdraw: 0.15
2023-11-01 23:53:33,472:INFO:         statsmodels: 0.13.2
2023-11-01 23:53:33,472:INFO:              sktime: 0.21.1
2023-11-01 23:53:33,472:INFO:               tbats: 1.1.3
2023-11-01 23:53:33,472:INFO:            pmdarima: 2.0.3
2023-11-01 23:53:33,472:INFO:              psutil: 5.9.1
2023-11-01 23:53:33,472:INFO:          markupsafe: 2.1.1
2023-11-01 23:53:33,472:INFO:             pickle5: Not installed
2023-11-01 23:53:33,472:INFO:         cloudpickle: 2.2.1
2023-11-01 23:53:33,472:INFO:         deprecation: 2.1.0
2023-11-01 23:53:33,472:INFO:              xxhash: 3.4.1
2023-11-01 23:53:33,472:INFO:           wurlitzer: Not installed
2023-11-01 23:53:33,472:INFO:PyCaret optional dependencies:
2023-11-01 23:53:33,472:INFO:                shap: Not installed
2023-11-01 23:53:33,472:INFO:           interpret: Not installed
2023-11-01 23:53:33,472:INFO:                umap: Not installed
2023-11-01 23:53:33,472:INFO:     ydata_profiling: Not installed
2023-11-01 23:53:33,472:INFO:  explainerdashboard: Not installed
2023-11-01 23:53:33,472:INFO:             autoviz: Not installed
2023-11-01 23:53:33,472:INFO:           fairlearn: Not installed
2023-11-01 23:53:33,472:INFO:          deepchecks: Not installed
2023-11-01 23:53:33,472:INFO:             xgboost: 2.0.0
2023-11-01 23:53:33,472:INFO:            catboost: Not installed
2023-11-01 23:53:33,472:INFO:              kmodes: Not installed
2023-11-01 23:53:33,472:INFO:             mlxtend: Not installed
2023-11-01 23:53:33,472:INFO:       statsforecast: Not installed
2023-11-01 23:53:33,472:INFO:        tune_sklearn: Not installed
2023-11-01 23:53:33,472:INFO:                 ray: Not installed
2023-11-01 23:53:33,472:INFO:            hyperopt: Not installed
2023-11-01 23:53:33,472:INFO:              optuna: Not installed
2023-11-01 23:53:33,472:INFO:               skopt: Not installed
2023-11-01 23:53:33,472:INFO:              mlflow: Not installed
2023-11-01 23:53:33,472:INFO:              gradio: Not installed
2023-11-01 23:53:33,472:INFO:             fastapi: Not installed
2023-11-01 23:53:33,472:INFO:             uvicorn: Not installed
2023-11-01 23:53:33,472:INFO:              m2cgen: Not installed
2023-11-01 23:53:33,472:INFO:           evidently: Not installed
2023-11-01 23:53:33,472:INFO:               fugue: Not installed
2023-11-01 23:53:33,472:INFO:           streamlit: Not installed
2023-11-01 23:53:33,472:INFO:             prophet: 1.1.5
2023-11-01 23:53:33,473:INFO:None
2023-11-01 23:53:33,473:INFO:Set up data.
2023-11-01 23:53:33,489:INFO:Set up folding strategy.
2023-11-01 23:53:33,489:INFO:Set up train/test split.
2023-11-01 23:53:33,489:INFO:Set up data.
2023-11-01 23:53:33,497:INFO:Set up index.
2023-11-01 23:53:33,497:INFO:Assigning column types.
2023-11-01 23:53:33,499:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-01 23:53:33,500:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,509:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,630:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:33,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:33,633:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,638:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,758:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:33,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:33,760:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-01 23:53:33,768:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,772:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,881:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:33,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:33,888:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,892:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:53:33,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,011:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,015:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-01 23:53:34,025:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,172:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,186:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,295:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,299:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-01 23:53:34,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,408:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,510:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,510:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,513:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-01 23:53:34,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,666:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,740:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-01 23:53:34,781:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,785:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-01 23:53:34,887:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,986:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:34,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:34,990:INFO:Preparing preprocessing pipeline...
2023-11-01 23:53:34,990:INFO:Set up simple imputation.
2023-11-01 23:53:34,995:INFO:Set up encoding of categorical features.
2023-11-01 23:53:34,995:INFO:Set up feature normalization.
2023-11-01 23:53:34,996:INFO:Set up column name cleaning.
2023-11-01 23:53:35,076:INFO:Finished creating preprocessing pipeline.
2023-11-01 23:53:35,082:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'ao', 'trimestre'],
                                    transforme...uter(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'ao', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'ao',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-01 23:53:35,082:INFO:Creating final display dataframe.
2023-11-01 23:53:35,236:INFO:Setup _display_container:                     Description             Value
0                    Session id              1122
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (140, 12)
4        Transformed data shape         (140, 35)
5   Transformed train set shape         (128, 35)
6    Transformed test set shape          (12, 35)
7               Ignore features                 5
8              Numeric features                 7
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   TimeSeriesSplit
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              4963
2023-11-01 23:53:35,326:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:35,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:35,422:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-01 23:53:35,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-01 23:53:35,425:INFO:setup() successfully completed in 1.96s...............
2023-11-01 23:53:47,749:INFO:Initializing compare_models()
2023-11-01 23:53:47,749:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 23:53:47,749:INFO:Checking exceptions
2023-11-01 23:53:47,752:INFO:Preparing display monitor
2023-11-01 23:53:47,796:INFO:Initializing Linear Regression
2023-11-01 23:53:47,796:INFO:Total runtime is 0.0 minutes
2023-11-01 23:53:47,800:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:47,801:INFO:Initializing create_model()
2023-11-01 23:53:47,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:47,802:INFO:Checking exceptions
2023-11-01 23:53:47,802:INFO:Importing libraries
2023-11-01 23:53:47,802:INFO:Copying training dataset
2023-11-01 23:53:47,808:INFO:Defining folds
2023-11-01 23:53:47,808:INFO:Declaring metric variables
2023-11-01 23:53:47,812:INFO:Importing untrained model
2023-11-01 23:53:47,818:INFO:Linear Regression Imported successfully
2023-11-01 23:53:47,825:INFO:Starting cross validation
2023-11-01 23:53:47,828:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:48,109:INFO:Calculating mean and std
2023-11-01 23:53:48,110:INFO:Creating metrics dataframe
2023-11-01 23:53:48,112:INFO:Uploading results into container
2023-11-01 23:53:48,113:INFO:Uploading model into container now
2023-11-01 23:53:48,113:INFO:_master_model_container: 1
2023-11-01 23:53:48,113:INFO:_display_container: 2
2023-11-01 23:53:48,113:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:53:48,113:INFO:create_model() successfully completed......................................
2023-11-01 23:53:48,494:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:48,495:INFO:Creating metrics dataframe
2023-11-01 23:53:48,502:INFO:Initializing Lasso Regression
2023-11-01 23:53:48,502:INFO:Total runtime is 0.011772068341573079 minutes
2023-11-01 23:53:48,505:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:48,505:INFO:Initializing create_model()
2023-11-01 23:53:48,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:48,505:INFO:Checking exceptions
2023-11-01 23:53:48,505:INFO:Importing libraries
2023-11-01 23:53:48,505:INFO:Copying training dataset
2023-11-01 23:53:48,509:INFO:Defining folds
2023-11-01 23:53:48,510:INFO:Declaring metric variables
2023-11-01 23:53:48,512:INFO:Importing untrained model
2023-11-01 23:53:48,516:INFO:Lasso Regression Imported successfully
2023-11-01 23:53:48,524:INFO:Starting cross validation
2023-11-01 23:53:48,526:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:48,756:INFO:Calculating mean and std
2023-11-01 23:53:48,757:INFO:Creating metrics dataframe
2023-11-01 23:53:48,759:INFO:Uploading results into container
2023-11-01 23:53:48,760:INFO:Uploading model into container now
2023-11-01 23:53:48,760:INFO:_master_model_container: 2
2023-11-01 23:53:48,760:INFO:_display_container: 2
2023-11-01 23:53:48,760:INFO:Lasso(random_state=1122)
2023-11-01 23:53:48,760:INFO:create_model() successfully completed......................................
2023-11-01 23:53:49,040:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:49,040:INFO:Creating metrics dataframe
2023-11-01 23:53:49,049:INFO:Initializing Ridge Regression
2023-11-01 23:53:49,050:INFO:Total runtime is 0.020909889539082845 minutes
2023-11-01 23:53:49,053:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:49,053:INFO:Initializing create_model()
2023-11-01 23:53:49,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:49,054:INFO:Checking exceptions
2023-11-01 23:53:49,054:INFO:Importing libraries
2023-11-01 23:53:49,054:INFO:Copying training dataset
2023-11-01 23:53:49,059:INFO:Defining folds
2023-11-01 23:53:49,059:INFO:Declaring metric variables
2023-11-01 23:53:49,063:INFO:Importing untrained model
2023-11-01 23:53:49,068:INFO:Ridge Regression Imported successfully
2023-11-01 23:53:49,078:INFO:Starting cross validation
2023-11-01 23:53:49,080:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:49,343:INFO:Calculating mean and std
2023-11-01 23:53:49,345:INFO:Creating metrics dataframe
2023-11-01 23:53:49,347:INFO:Uploading results into container
2023-11-01 23:53:49,348:INFO:Uploading model into container now
2023-11-01 23:53:49,348:INFO:_master_model_container: 3
2023-11-01 23:53:49,348:INFO:_display_container: 2
2023-11-01 23:53:49,349:INFO:Ridge(random_state=1122)
2023-11-01 23:53:49,349:INFO:create_model() successfully completed......................................
2023-11-01 23:53:49,649:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:49,649:INFO:Creating metrics dataframe
2023-11-01 23:53:49,657:INFO:Initializing Elastic Net
2023-11-01 23:53:49,657:INFO:Total runtime is 0.03102331558863322 minutes
2023-11-01 23:53:49,660:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:49,660:INFO:Initializing create_model()
2023-11-01 23:53:49,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:49,660:INFO:Checking exceptions
2023-11-01 23:53:49,660:INFO:Importing libraries
2023-11-01 23:53:49,660:INFO:Copying training dataset
2023-11-01 23:53:49,666:INFO:Defining folds
2023-11-01 23:53:49,666:INFO:Declaring metric variables
2023-11-01 23:53:49,668:INFO:Importing untrained model
2023-11-01 23:53:49,673:INFO:Elastic Net Imported successfully
2023-11-01 23:53:49,680:INFO:Starting cross validation
2023-11-01 23:53:49,682:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:49,916:INFO:Calculating mean and std
2023-11-01 23:53:49,917:INFO:Creating metrics dataframe
2023-11-01 23:53:49,920:INFO:Uploading results into container
2023-11-01 23:53:49,920:INFO:Uploading model into container now
2023-11-01 23:53:49,921:INFO:_master_model_container: 4
2023-11-01 23:53:49,921:INFO:_display_container: 2
2023-11-01 23:53:49,921:INFO:ElasticNet(random_state=1122)
2023-11-01 23:53:49,921:INFO:create_model() successfully completed......................................
2023-11-01 23:53:50,216:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:50,216:INFO:Creating metrics dataframe
2023-11-01 23:53:50,226:INFO:Initializing Least Angle Regression
2023-11-01 23:53:50,226:INFO:Total runtime is 0.04051209688186646 minutes
2023-11-01 23:53:50,230:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:50,230:INFO:Initializing create_model()
2023-11-01 23:53:50,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:50,230:INFO:Checking exceptions
2023-11-01 23:53:50,230:INFO:Importing libraries
2023-11-01 23:53:50,230:INFO:Copying training dataset
2023-11-01 23:53:50,236:INFO:Defining folds
2023-11-01 23:53:50,236:INFO:Declaring metric variables
2023-11-01 23:53:50,240:INFO:Importing untrained model
2023-11-01 23:53:50,245:INFO:Least Angle Regression Imported successfully
2023-11-01 23:53:50,253:INFO:Starting cross validation
2023-11-01 23:53:50,256:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:50,354:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,371:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,375:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.689e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,375:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,375:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.270e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.106e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.345e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.910e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.464e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.343e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.196e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.346e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.688e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.140e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=7.144e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.213e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,378:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.523e-07, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,378:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,378:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.331e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,379:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.172e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,380:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.434e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,380:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.304e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,381:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.296e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,381:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.293e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,381:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.121e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,382:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.704e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,382:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.089e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,382:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.037e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,382:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.869e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,382:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.774e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,383:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.525e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,384:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.767e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.478e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.242e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.005e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.027e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.484e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.019e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.813e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,391:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.407e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,391:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.300e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,392:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.382e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,392:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.689e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,393:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.534e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,393:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.333e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.089e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.271e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.208e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=8.053e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,398:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,400:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,404:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.496e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,404:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.058e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,404:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.417e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,404:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.713e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,404:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.162e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,404:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.200e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,405:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.465e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,405:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.846e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,405:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,405:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,405:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,406:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,408:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.097e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,409:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.162e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,471:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,475:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.556e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,476:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.741e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,476:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.670e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,476:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.981e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,477:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.615e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,477:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.929e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,477:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.701e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,477:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.066e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,487:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:50,490:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.555e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,491:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.672e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,491:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.425e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,491:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.340e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,491:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.267e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,491:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.172e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,492:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.382e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,492:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.318e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,492:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.790e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,492:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.732e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,492:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.421e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.732e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.097e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.209e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.673e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.842e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,493:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.351e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:53:50,516:INFO:Calculating mean and std
2023-11-01 23:53:50,518:INFO:Creating metrics dataframe
2023-11-01 23:53:50,521:INFO:Uploading results into container
2023-11-01 23:53:50,522:INFO:Uploading model into container now
2023-11-01 23:53:50,522:INFO:_master_model_container: 5
2023-11-01 23:53:50,522:INFO:_display_container: 2
2023-11-01 23:53:50,523:INFO:Lars(random_state=1122)
2023-11-01 23:53:50,523:INFO:create_model() successfully completed......................................
2023-11-01 23:53:50,861:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:50,862:INFO:Creating metrics dataframe
2023-11-01 23:53:50,870:INFO:Initializing Lasso Least Angle Regression
2023-11-01 23:53:50,870:INFO:Total runtime is 0.051243154207865405 minutes
2023-11-01 23:53:50,873:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:50,874:INFO:Initializing create_model()
2023-11-01 23:53:50,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:50,874:INFO:Checking exceptions
2023-11-01 23:53:50,874:INFO:Importing libraries
2023-11-01 23:53:50,874:INFO:Copying training dataset
2023-11-01 23:53:50,879:INFO:Defining folds
2023-11-01 23:53:50,879:INFO:Declaring metric variables
2023-11-01 23:53:50,882:INFO:Importing untrained model
2023-11-01 23:53:50,886:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:53:50,895:INFO:Starting cross validation
2023-11-01 23:53:50,897:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:50,986:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,004:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,007:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,010:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,016:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,029:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,034:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,092:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,102:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:53:51,125:INFO:Calculating mean and std
2023-11-01 23:53:51,126:INFO:Creating metrics dataframe
2023-11-01 23:53:51,129:INFO:Uploading results into container
2023-11-01 23:53:51,129:INFO:Uploading model into container now
2023-11-01 23:53:51,129:INFO:_master_model_container: 6
2023-11-01 23:53:51,129:INFO:_display_container: 2
2023-11-01 23:53:51,130:INFO:LassoLars(random_state=1122)
2023-11-01 23:53:51,130:INFO:create_model() successfully completed......................................
2023-11-01 23:53:51,409:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:51,409:INFO:Creating metrics dataframe
2023-11-01 23:53:51,417:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 23:53:51,417:INFO:Total runtime is 0.060360916455586756 minutes
2023-11-01 23:53:51,421:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:51,421:INFO:Initializing create_model()
2023-11-01 23:53:51,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:51,422:INFO:Checking exceptions
2023-11-01 23:53:51,422:INFO:Importing libraries
2023-11-01 23:53:51,422:INFO:Copying training dataset
2023-11-01 23:53:51,428:INFO:Defining folds
2023-11-01 23:53:51,428:INFO:Declaring metric variables
2023-11-01 23:53:51,431:INFO:Importing untrained model
2023-11-01 23:53:51,436:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:53:51,444:INFO:Starting cross validation
2023-11-01 23:53:51,445:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:51,527:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,540:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,545:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,548:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,552:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,557:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,570:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,585:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,631:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,645:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:53:51,668:INFO:Calculating mean and std
2023-11-01 23:53:51,669:INFO:Creating metrics dataframe
2023-11-01 23:53:51,673:INFO:Uploading results into container
2023-11-01 23:53:51,674:INFO:Uploading model into container now
2023-11-01 23:53:51,675:INFO:_master_model_container: 7
2023-11-01 23:53:51,675:INFO:_display_container: 2
2023-11-01 23:53:51,675:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:53:51,675:INFO:create_model() successfully completed......................................
2023-11-01 23:53:51,953:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:51,953:INFO:Creating metrics dataframe
2023-11-01 23:53:51,963:INFO:Initializing Bayesian Ridge
2023-11-01 23:53:51,963:INFO:Total runtime is 0.06946506500244141 minutes
2023-11-01 23:53:51,966:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:51,967:INFO:Initializing create_model()
2023-11-01 23:53:51,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:51,967:INFO:Checking exceptions
2023-11-01 23:53:51,967:INFO:Importing libraries
2023-11-01 23:53:51,967:INFO:Copying training dataset
2023-11-01 23:53:51,970:INFO:Defining folds
2023-11-01 23:53:51,971:INFO:Declaring metric variables
2023-11-01 23:53:51,973:INFO:Importing untrained model
2023-11-01 23:53:51,978:INFO:Bayesian Ridge Imported successfully
2023-11-01 23:53:51,985:INFO:Starting cross validation
2023-11-01 23:53:51,986:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:52,219:INFO:Calculating mean and std
2023-11-01 23:53:52,221:INFO:Creating metrics dataframe
2023-11-01 23:53:52,223:INFO:Uploading results into container
2023-11-01 23:53:52,224:INFO:Uploading model into container now
2023-11-01 23:53:52,224:INFO:_master_model_container: 8
2023-11-01 23:53:52,225:INFO:_display_container: 2
2023-11-01 23:53:52,225:INFO:BayesianRidge()
2023-11-01 23:53:52,225:INFO:create_model() successfully completed......................................
2023-11-01 23:53:52,510:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:52,510:INFO:Creating metrics dataframe
2023-11-01 23:53:52,518:INFO:Initializing Passive Aggressive Regressor
2023-11-01 23:53:52,518:INFO:Total runtime is 0.07870141665140788 minutes
2023-11-01 23:53:52,520:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:52,521:INFO:Initializing create_model()
2023-11-01 23:53:52,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:52,521:INFO:Checking exceptions
2023-11-01 23:53:52,521:INFO:Importing libraries
2023-11-01 23:53:52,521:INFO:Copying training dataset
2023-11-01 23:53:52,526:INFO:Defining folds
2023-11-01 23:53:52,526:INFO:Declaring metric variables
2023-11-01 23:53:52,530:INFO:Importing untrained model
2023-11-01 23:53:52,533:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 23:53:52,541:INFO:Starting cross validation
2023-11-01 23:53:52,543:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:52,657:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,658:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,659:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,664:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,668:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,679:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,694:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,762:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,772:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:53:52,797:INFO:Calculating mean and std
2023-11-01 23:53:52,798:INFO:Creating metrics dataframe
2023-11-01 23:53:52,800:INFO:Uploading results into container
2023-11-01 23:53:52,801:INFO:Uploading model into container now
2023-11-01 23:53:52,801:INFO:_master_model_container: 9
2023-11-01 23:53:52,801:INFO:_display_container: 2
2023-11-01 23:53:52,801:INFO:PassiveAggressiveRegressor(random_state=1122)
2023-11-01 23:53:52,801:INFO:create_model() successfully completed......................................
2023-11-01 23:53:53,081:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:53,081:INFO:Creating metrics dataframe
2023-11-01 23:53:53,093:INFO:Initializing Huber Regressor
2023-11-01 23:53:53,093:INFO:Total runtime is 0.08829100529352825 minutes
2023-11-01 23:53:53,096:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:53,096:INFO:Initializing create_model()
2023-11-01 23:53:53,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:53,096:INFO:Checking exceptions
2023-11-01 23:53:53,096:INFO:Importing libraries
2023-11-01 23:53:53,096:INFO:Copying training dataset
2023-11-01 23:53:53,100:INFO:Defining folds
2023-11-01 23:53:53,100:INFO:Declaring metric variables
2023-11-01 23:53:53,103:INFO:Importing untrained model
2023-11-01 23:53:53,109:INFO:Huber Regressor Imported successfully
2023-11-01 23:53:53,115:INFO:Starting cross validation
2023-11-01 23:53:53,116:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:53,362:INFO:Calculating mean and std
2023-11-01 23:53:53,363:INFO:Creating metrics dataframe
2023-11-01 23:53:53,367:INFO:Uploading results into container
2023-11-01 23:53:53,368:INFO:Uploading model into container now
2023-11-01 23:53:53,368:INFO:_master_model_container: 10
2023-11-01 23:53:53,368:INFO:_display_container: 2
2023-11-01 23:53:53,369:INFO:HuberRegressor()
2023-11-01 23:53:53,369:INFO:create_model() successfully completed......................................
2023-11-01 23:53:53,643:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:53,644:INFO:Creating metrics dataframe
2023-11-01 23:53:53,652:INFO:Initializing K Neighbors Regressor
2023-11-01 23:53:53,652:INFO:Total runtime is 0.09760351975758871 minutes
2023-11-01 23:53:53,656:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:53,656:INFO:Initializing create_model()
2023-11-01 23:53:53,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:53,657:INFO:Checking exceptions
2023-11-01 23:53:53,657:INFO:Importing libraries
2023-11-01 23:53:53,657:INFO:Copying training dataset
2023-11-01 23:53:53,661:INFO:Defining folds
2023-11-01 23:53:53,661:INFO:Declaring metric variables
2023-11-01 23:53:53,664:INFO:Importing untrained model
2023-11-01 23:53:53,668:INFO:K Neighbors Regressor Imported successfully
2023-11-01 23:53:53,676:INFO:Starting cross validation
2023-11-01 23:53:53,677:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:53,923:INFO:Calculating mean and std
2023-11-01 23:53:53,924:INFO:Creating metrics dataframe
2023-11-01 23:53:53,926:INFO:Uploading results into container
2023-11-01 23:53:53,927:INFO:Uploading model into container now
2023-11-01 23:53:53,927:INFO:_master_model_container: 11
2023-11-01 23:53:53,927:INFO:_display_container: 2
2023-11-01 23:53:53,927:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 23:53:53,928:INFO:create_model() successfully completed......................................
2023-11-01 23:53:54,206:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:54,206:INFO:Creating metrics dataframe
2023-11-01 23:53:54,215:INFO:Initializing Decision Tree Regressor
2023-11-01 23:53:54,216:INFO:Total runtime is 0.10701091686884563 minutes
2023-11-01 23:53:54,220:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:54,220:INFO:Initializing create_model()
2023-11-01 23:53:54,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:54,220:INFO:Checking exceptions
2023-11-01 23:53:54,220:INFO:Importing libraries
2023-11-01 23:53:54,221:INFO:Copying training dataset
2023-11-01 23:53:54,227:INFO:Defining folds
2023-11-01 23:53:54,227:INFO:Declaring metric variables
2023-11-01 23:53:54,230:INFO:Importing untrained model
2023-11-01 23:53:54,232:INFO:Decision Tree Regressor Imported successfully
2023-11-01 23:53:54,239:INFO:Starting cross validation
2023-11-01 23:53:54,241:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:54,469:INFO:Calculating mean and std
2023-11-01 23:53:54,470:INFO:Creating metrics dataframe
2023-11-01 23:53:54,474:INFO:Uploading results into container
2023-11-01 23:53:54,475:INFO:Uploading model into container now
2023-11-01 23:53:54,475:INFO:_master_model_container: 12
2023-11-01 23:53:54,475:INFO:_display_container: 2
2023-11-01 23:53:54,476:INFO:DecisionTreeRegressor(random_state=1122)
2023-11-01 23:53:54,476:INFO:create_model() successfully completed......................................
2023-11-01 23:53:54,747:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:54,747:INFO:Creating metrics dataframe
2023-11-01 23:53:54,756:INFO:Initializing Random Forest Regressor
2023-11-01 23:53:54,756:INFO:Total runtime is 0.11601390441258749 minutes
2023-11-01 23:53:54,760:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:54,761:INFO:Initializing create_model()
2023-11-01 23:53:54,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:54,761:INFO:Checking exceptions
2023-11-01 23:53:54,761:INFO:Importing libraries
2023-11-01 23:53:54,761:INFO:Copying training dataset
2023-11-01 23:53:54,766:INFO:Defining folds
2023-11-01 23:53:54,766:INFO:Declaring metric variables
2023-11-01 23:53:54,769:INFO:Importing untrained model
2023-11-01 23:53:54,774:INFO:Random Forest Regressor Imported successfully
2023-11-01 23:53:54,781:INFO:Starting cross validation
2023-11-01 23:53:54,782:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:55,349:INFO:Calculating mean and std
2023-11-01 23:53:55,350:INFO:Creating metrics dataframe
2023-11-01 23:53:55,352:INFO:Uploading results into container
2023-11-01 23:53:55,353:INFO:Uploading model into container now
2023-11-01 23:53:55,353:INFO:_master_model_container: 13
2023-11-01 23:53:55,353:INFO:_display_container: 2
2023-11-01 23:53:55,353:INFO:RandomForestRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:53:55,353:INFO:create_model() successfully completed......................................
2023-11-01 23:53:55,640:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:55,640:INFO:Creating metrics dataframe
2023-11-01 23:53:55,648:INFO:Initializing Extra Trees Regressor
2023-11-01 23:53:55,648:INFO:Total runtime is 0.13087172508239747 minutes
2023-11-01 23:53:55,651:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:55,651:INFO:Initializing create_model()
2023-11-01 23:53:55,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:55,651:INFO:Checking exceptions
2023-11-01 23:53:55,651:INFO:Importing libraries
2023-11-01 23:53:55,651:INFO:Copying training dataset
2023-11-01 23:53:55,656:INFO:Defining folds
2023-11-01 23:53:55,656:INFO:Declaring metric variables
2023-11-01 23:53:55,659:INFO:Importing untrained model
2023-11-01 23:53:55,663:INFO:Extra Trees Regressor Imported successfully
2023-11-01 23:53:55,670:INFO:Starting cross validation
2023-11-01 23:53:55,673:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:56,166:INFO:Calculating mean and std
2023-11-01 23:53:56,167:INFO:Creating metrics dataframe
2023-11-01 23:53:56,169:INFO:Uploading results into container
2023-11-01 23:53:56,170:INFO:Uploading model into container now
2023-11-01 23:53:56,171:INFO:_master_model_container: 14
2023-11-01 23:53:56,171:INFO:_display_container: 2
2023-11-01 23:53:56,171:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:53:56,172:INFO:create_model() successfully completed......................................
2023-11-01 23:53:56,455:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:56,455:INFO:Creating metrics dataframe
2023-11-01 23:53:56,465:INFO:Initializing AdaBoost Regressor
2023-11-01 23:53:56,465:INFO:Total runtime is 0.14449642101923627 minutes
2023-11-01 23:53:56,468:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:56,468:INFO:Initializing create_model()
2023-11-01 23:53:56,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:56,468:INFO:Checking exceptions
2023-11-01 23:53:56,469:INFO:Importing libraries
2023-11-01 23:53:56,469:INFO:Copying training dataset
2023-11-01 23:53:56,473:INFO:Defining folds
2023-11-01 23:53:56,474:INFO:Declaring metric variables
2023-11-01 23:53:56,477:INFO:Importing untrained model
2023-11-01 23:53:56,481:INFO:AdaBoost Regressor Imported successfully
2023-11-01 23:53:56,487:INFO:Starting cross validation
2023-11-01 23:53:56,490:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:56,839:INFO:Calculating mean and std
2023-11-01 23:53:56,840:INFO:Creating metrics dataframe
2023-11-01 23:53:56,844:INFO:Uploading results into container
2023-11-01 23:53:56,845:INFO:Uploading model into container now
2023-11-01 23:53:56,845:INFO:_master_model_container: 15
2023-11-01 23:53:56,845:INFO:_display_container: 2
2023-11-01 23:53:56,845:INFO:AdaBoostRegressor(random_state=1122)
2023-11-01 23:53:56,845:INFO:create_model() successfully completed......................................
2023-11-01 23:53:57,117:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:57,117:INFO:Creating metrics dataframe
2023-11-01 23:53:57,129:INFO:Initializing Gradient Boosting Regressor
2023-11-01 23:53:57,129:INFO:Total runtime is 0.15555835564931236 minutes
2023-11-01 23:53:57,131:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:57,132:INFO:Initializing create_model()
2023-11-01 23:53:57,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:57,133:INFO:Checking exceptions
2023-11-01 23:53:57,133:INFO:Importing libraries
2023-11-01 23:53:57,133:INFO:Copying training dataset
2023-11-01 23:53:57,137:INFO:Defining folds
2023-11-01 23:53:57,138:INFO:Declaring metric variables
2023-11-01 23:53:57,141:INFO:Importing untrained model
2023-11-01 23:53:57,145:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 23:53:57,151:INFO:Starting cross validation
2023-11-01 23:53:57,153:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:57,501:INFO:Calculating mean and std
2023-11-01 23:53:57,502:INFO:Creating metrics dataframe
2023-11-01 23:53:57,506:INFO:Uploading results into container
2023-11-01 23:53:57,506:INFO:Uploading model into container now
2023-11-01 23:53:57,507:INFO:_master_model_container: 16
2023-11-01 23:53:57,507:INFO:_display_container: 2
2023-11-01 23:53:57,507:INFO:GradientBoostingRegressor(random_state=1122)
2023-11-01 23:53:57,507:INFO:create_model() successfully completed......................................
2023-11-01 23:53:57,782:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:57,782:INFO:Creating metrics dataframe
2023-11-01 23:53:57,794:INFO:Initializing Extreme Gradient Boosting
2023-11-01 23:53:57,794:INFO:Total runtime is 0.1666475852330526 minutes
2023-11-01 23:53:57,798:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:57,798:INFO:Initializing create_model()
2023-11-01 23:53:57,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:57,798:INFO:Checking exceptions
2023-11-01 23:53:57,798:INFO:Importing libraries
2023-11-01 23:53:57,798:INFO:Copying training dataset
2023-11-01 23:53:57,805:INFO:Defining folds
2023-11-01 23:53:57,805:INFO:Declaring metric variables
2023-11-01 23:53:57,809:INFO:Importing untrained model
2023-11-01 23:53:57,813:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 23:53:57,818:INFO:Starting cross validation
2023-11-01 23:53:57,821:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:58,416:INFO:Calculating mean and std
2023-11-01 23:53:58,418:INFO:Creating metrics dataframe
2023-11-01 23:53:58,422:INFO:Uploading results into container
2023-11-01 23:53:58,424:INFO:Uploading model into container now
2023-11-01 23:53:58,425:INFO:_master_model_container: 17
2023-11-01 23:53:58,425:INFO:_display_container: 2
2023-11-01 23:53:58,426:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1122, ...)
2023-11-01 23:53:58,426:INFO:create_model() successfully completed......................................
2023-11-01 23:53:58,745:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:58,745:INFO:Creating metrics dataframe
2023-11-01 23:53:58,757:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 23:53:58,757:INFO:Total runtime is 0.18269811471303307 minutes
2023-11-01 23:53:58,761:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:58,761:INFO:Initializing create_model()
2023-11-01 23:53:58,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:58,763:INFO:Checking exceptions
2023-11-01 23:53:58,763:INFO:Importing libraries
2023-11-01 23:53:58,763:INFO:Copying training dataset
2023-11-01 23:53:58,768:INFO:Defining folds
2023-11-01 23:53:58,768:INFO:Declaring metric variables
2023-11-01 23:53:58,773:INFO:Importing untrained model
2023-11-01 23:53:58,779:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 23:53:58,791:INFO:Starting cross validation
2023-11-01 23:53:58,793:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:59,266:INFO:Calculating mean and std
2023-11-01 23:53:59,268:INFO:Creating metrics dataframe
2023-11-01 23:53:59,273:INFO:Uploading results into container
2023-11-01 23:53:59,275:INFO:Uploading model into container now
2023-11-01 23:53:59,275:INFO:_master_model_container: 18
2023-11-01 23:53:59,276:INFO:_display_container: 2
2023-11-01 23:53:59,276:INFO:LGBMRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:53:59,276:INFO:create_model() successfully completed......................................
2023-11-01 23:53:59,740:INFO:SubProcess create_model() end ==================================
2023-11-01 23:53:59,740:INFO:Creating metrics dataframe
2023-11-01 23:53:59,749:INFO:Initializing Dummy Regressor
2023-11-01 23:53:59,749:INFO:Total runtime is 0.19922850529352826 minutes
2023-11-01 23:53:59,751:INFO:SubProcess create_model() called ==================================
2023-11-01 23:53:59,753:INFO:Initializing create_model()
2023-11-01 23:53:59,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB82EFE80>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:53:59,753:INFO:Checking exceptions
2023-11-01 23:53:59,753:INFO:Importing libraries
2023-11-01 23:53:59,753:INFO:Copying training dataset
2023-11-01 23:53:59,758:INFO:Defining folds
2023-11-01 23:53:59,759:INFO:Declaring metric variables
2023-11-01 23:53:59,762:INFO:Importing untrained model
2023-11-01 23:53:59,765:INFO:Dummy Regressor Imported successfully
2023-11-01 23:53:59,770:INFO:Starting cross validation
2023-11-01 23:53:59,771:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:53:59,985:INFO:Calculating mean and std
2023-11-01 23:53:59,987:INFO:Creating metrics dataframe
2023-11-01 23:53:59,990:INFO:Uploading results into container
2023-11-01 23:53:59,990:INFO:Uploading model into container now
2023-11-01 23:53:59,991:INFO:_master_model_container: 19
2023-11-01 23:53:59,991:INFO:_display_container: 2
2023-11-01 23:53:59,991:INFO:DummyRegressor()
2023-11-01 23:53:59,991:INFO:create_model() successfully completed......................................
2023-11-01 23:54:00,341:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:00,342:INFO:Creating metrics dataframe
2023-11-01 23:54:00,375:INFO:Initializing create_model()
2023-11-01 23:54:00,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=LassoLars(random_state=1122), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:00,375:INFO:Checking exceptions
2023-11-01 23:54:00,378:INFO:Importing libraries
2023-11-01 23:54:00,379:INFO:Copying training dataset
2023-11-01 23:54:00,383:INFO:Defining folds
2023-11-01 23:54:00,383:INFO:Declaring metric variables
2023-11-01 23:54:00,383:INFO:Importing untrained model
2023-11-01 23:54:00,385:INFO:Declaring custom model
2023-11-01 23:54:00,385:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:54:00,387:INFO:Cross validation set to False
2023-11-01 23:54:00,388:INFO:Fitting Model
2023-11-01 23:54:00,468:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:00,473:INFO:LassoLars(random_state=1122)
2023-11-01 23:54:00,473:INFO:create_model() successfully completed......................................
2023-11-01 23:54:00,808:INFO:_master_model_container: 19
2023-11-01 23:54:00,808:INFO:_display_container: 2
2023-11-01 23:54:00,809:INFO:LassoLars(random_state=1122)
2023-11-01 23:54:00,809:INFO:compare_models() successfully completed......................................
2023-11-01 23:54:09,185:INFO:Initializing compare_models()
2023-11-01 23:54:09,185:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 23:54:09,185:INFO:Checking exceptions
2023-11-01 23:54:09,188:INFO:Preparing display monitor
2023-11-01 23:54:09,231:INFO:Initializing Linear Regression
2023-11-01 23:54:09,231:INFO:Total runtime is 0.0 minutes
2023-11-01 23:54:09,235:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:09,235:INFO:Initializing create_model()
2023-11-01 23:54:09,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:09,235:INFO:Checking exceptions
2023-11-01 23:54:09,236:INFO:Importing libraries
2023-11-01 23:54:09,236:INFO:Copying training dataset
2023-11-01 23:54:09,240:INFO:Defining folds
2023-11-01 23:54:09,240:INFO:Declaring metric variables
2023-11-01 23:54:09,244:INFO:Importing untrained model
2023-11-01 23:54:09,250:INFO:Linear Regression Imported successfully
2023-11-01 23:54:09,259:INFO:Starting cross validation
2023-11-01 23:54:09,262:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:09,625:INFO:Calculating mean and std
2023-11-01 23:54:09,625:INFO:Creating metrics dataframe
2023-11-01 23:54:09,628:INFO:Uploading results into container
2023-11-01 23:54:09,628:INFO:Uploading model into container now
2023-11-01 23:54:09,628:INFO:_master_model_container: 20
2023-11-01 23:54:09,628:INFO:_display_container: 3
2023-11-01 23:54:09,629:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:54:09,629:INFO:create_model() successfully completed......................................
2023-11-01 23:54:09,908:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:09,908:INFO:Creating metrics dataframe
2023-11-01 23:54:09,915:INFO:Initializing Lasso Regression
2023-11-01 23:54:09,915:INFO:Total runtime is 0.011406397819519043 minutes
2023-11-01 23:54:09,918:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:09,918:INFO:Initializing create_model()
2023-11-01 23:54:09,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:09,919:INFO:Checking exceptions
2023-11-01 23:54:09,919:INFO:Importing libraries
2023-11-01 23:54:09,919:INFO:Copying training dataset
2023-11-01 23:54:09,922:INFO:Defining folds
2023-11-01 23:54:09,922:INFO:Declaring metric variables
2023-11-01 23:54:09,925:INFO:Importing untrained model
2023-11-01 23:54:09,927:INFO:Lasso Regression Imported successfully
2023-11-01 23:54:09,933:INFO:Starting cross validation
2023-11-01 23:54:09,935:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:10,173:INFO:Calculating mean and std
2023-11-01 23:54:10,173:INFO:Creating metrics dataframe
2023-11-01 23:54:10,175:INFO:Uploading results into container
2023-11-01 23:54:10,176:INFO:Uploading model into container now
2023-11-01 23:54:10,176:INFO:_master_model_container: 21
2023-11-01 23:54:10,176:INFO:_display_container: 3
2023-11-01 23:54:10,176:INFO:Lasso(random_state=1122)
2023-11-01 23:54:10,176:INFO:create_model() successfully completed......................................
2023-11-01 23:54:10,457:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:10,457:INFO:Creating metrics dataframe
2023-11-01 23:54:10,465:INFO:Initializing Ridge Regression
2023-11-01 23:54:10,465:INFO:Total runtime is 0.02056779464085897 minutes
2023-11-01 23:54:10,468:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:10,468:INFO:Initializing create_model()
2023-11-01 23:54:10,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:10,468:INFO:Checking exceptions
2023-11-01 23:54:10,469:INFO:Importing libraries
2023-11-01 23:54:10,469:INFO:Copying training dataset
2023-11-01 23:54:10,472:INFO:Defining folds
2023-11-01 23:54:10,472:INFO:Declaring metric variables
2023-11-01 23:54:10,475:INFO:Importing untrained model
2023-11-01 23:54:10,479:INFO:Ridge Regression Imported successfully
2023-11-01 23:54:10,487:INFO:Starting cross validation
2023-11-01 23:54:10,489:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:10,724:INFO:Calculating mean and std
2023-11-01 23:54:10,725:INFO:Creating metrics dataframe
2023-11-01 23:54:10,728:INFO:Uploading results into container
2023-11-01 23:54:10,728:INFO:Uploading model into container now
2023-11-01 23:54:10,728:INFO:_master_model_container: 22
2023-11-01 23:54:10,728:INFO:_display_container: 3
2023-11-01 23:54:10,728:INFO:Ridge(random_state=1122)
2023-11-01 23:54:10,728:INFO:create_model() successfully completed......................................
2023-11-01 23:54:11,007:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:11,007:INFO:Creating metrics dataframe
2023-11-01 23:54:11,015:INFO:Initializing Elastic Net
2023-11-01 23:54:11,016:INFO:Total runtime is 0.029762752850850425 minutes
2023-11-01 23:54:11,021:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:11,021:INFO:Initializing create_model()
2023-11-01 23:54:11,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:11,021:INFO:Checking exceptions
2023-11-01 23:54:11,021:INFO:Importing libraries
2023-11-01 23:54:11,021:INFO:Copying training dataset
2023-11-01 23:54:11,026:INFO:Defining folds
2023-11-01 23:54:11,026:INFO:Declaring metric variables
2023-11-01 23:54:11,029:INFO:Importing untrained model
2023-11-01 23:54:11,034:INFO:Elastic Net Imported successfully
2023-11-01 23:54:11,040:INFO:Starting cross validation
2023-11-01 23:54:11,041:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:11,269:INFO:Calculating mean and std
2023-11-01 23:54:11,271:INFO:Creating metrics dataframe
2023-11-01 23:54:11,274:INFO:Uploading results into container
2023-11-01 23:54:11,274:INFO:Uploading model into container now
2023-11-01 23:54:11,275:INFO:_master_model_container: 23
2023-11-01 23:54:11,275:INFO:_display_container: 3
2023-11-01 23:54:11,276:INFO:ElasticNet(random_state=1122)
2023-11-01 23:54:11,276:INFO:create_model() successfully completed......................................
2023-11-01 23:54:11,554:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:11,554:INFO:Creating metrics dataframe
2023-11-01 23:54:11,561:INFO:Initializing Least Angle Regression
2023-11-01 23:54:11,561:INFO:Total runtime is 0.03884777625401815 minutes
2023-11-01 23:54:11,564:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:11,564:INFO:Initializing create_model()
2023-11-01 23:54:11,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:11,564:INFO:Checking exceptions
2023-11-01 23:54:11,564:INFO:Importing libraries
2023-11-01 23:54:11,565:INFO:Copying training dataset
2023-11-01 23:54:11,569:INFO:Defining folds
2023-11-01 23:54:11,570:INFO:Declaring metric variables
2023-11-01 23:54:11,573:INFO:Importing untrained model
2023-11-01 23:54:11,577:INFO:Least Angle Regression Imported successfully
2023-11-01 23:54:11,585:INFO:Starting cross validation
2023-11-01 23:54:11,587:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:11,696:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,696:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,699:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.331e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,700:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.172e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,700:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.774e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.434e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.304e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.525e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.296e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.767e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.293e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.121e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.704e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.089e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.037e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.478e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.689e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.869e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.270e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.106e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.345e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.910e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.242e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.464e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.005e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.343e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.027e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.484e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.346e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.019e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.688e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.813e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=7.144e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.213e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.523e-07, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,707:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.496e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.417e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.200e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.097e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.162e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,713:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.407e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,713:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.300e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,713:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.382e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,714:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.689e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,714:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.534e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,715:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.333e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,715:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.089e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,715:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.271e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,715:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.208e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,715:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=8.053e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,729:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,733:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,735:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.846e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,735:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,736:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,736:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,736:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,738:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.058e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,738:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.713e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,739:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.162e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,739:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.465e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,813:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,816:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.555e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,816:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.672e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,817:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.425e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,817:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.340e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,817:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.267e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,817:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.172e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.382e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.318e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.790e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.732e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.421e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,818:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.732e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,819:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.097e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,819:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.209e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,819:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.673e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,819:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.842e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,819:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.351e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,820:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.556e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,821:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.741e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,821:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.670e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,821:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.981e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,822:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.615e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,822:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.929e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,822:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.701e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,822:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.066e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:54:11,848:INFO:Calculating mean and std
2023-11-01 23:54:11,850:INFO:Creating metrics dataframe
2023-11-01 23:54:11,854:INFO:Uploading results into container
2023-11-01 23:54:11,854:INFO:Uploading model into container now
2023-11-01 23:54:11,855:INFO:_master_model_container: 24
2023-11-01 23:54:11,855:INFO:_display_container: 3
2023-11-01 23:54:11,855:INFO:Lars(random_state=1122)
2023-11-01 23:54:11,855:INFO:create_model() successfully completed......................................
2023-11-01 23:54:12,129:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:12,130:INFO:Creating metrics dataframe
2023-11-01 23:54:12,139:INFO:Initializing Lasso Least Angle Regression
2023-11-01 23:54:12,139:INFO:Total runtime is 0.048466130097707116 minutes
2023-11-01 23:54:12,141:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:12,142:INFO:Initializing create_model()
2023-11-01 23:54:12,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:12,142:INFO:Checking exceptions
2023-11-01 23:54:12,142:INFO:Importing libraries
2023-11-01 23:54:12,142:INFO:Copying training dataset
2023-11-01 23:54:12,146:INFO:Defining folds
2023-11-01 23:54:12,146:INFO:Declaring metric variables
2023-11-01 23:54:12,149:INFO:Importing untrained model
2023-11-01 23:54:12,154:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:54:12,161:INFO:Starting cross validation
2023-11-01 23:54:12,163:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:12,265:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,272:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,277:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,279:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,280:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,295:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,300:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,309:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,366:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:12,392:INFO:Calculating mean and std
2023-11-01 23:54:12,393:INFO:Creating metrics dataframe
2023-11-01 23:54:12,395:INFO:Uploading results into container
2023-11-01 23:54:12,396:INFO:Uploading model into container now
2023-11-01 23:54:12,396:INFO:_master_model_container: 25
2023-11-01 23:54:12,396:INFO:_display_container: 3
2023-11-01 23:54:12,397:INFO:LassoLars(random_state=1122)
2023-11-01 23:54:12,397:INFO:create_model() successfully completed......................................
2023-11-01 23:54:12,678:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:12,678:INFO:Creating metrics dataframe
2023-11-01 23:54:12,688:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 23:54:12,688:INFO:Total runtime is 0.057620799541473394 minutes
2023-11-01 23:54:12,691:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:12,691:INFO:Initializing create_model()
2023-11-01 23:54:12,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:12,691:INFO:Checking exceptions
2023-11-01 23:54:12,691:INFO:Importing libraries
2023-11-01 23:54:12,691:INFO:Copying training dataset
2023-11-01 23:54:12,696:INFO:Defining folds
2023-11-01 23:54:12,696:INFO:Declaring metric variables
2023-11-01 23:54:12,700:INFO:Importing untrained model
2023-11-01 23:54:12,705:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:54:12,712:INFO:Starting cross validation
2023-11-01 23:54:12,714:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:12,801:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,820:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,836:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,905:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,907:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,921:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,947:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,964:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:54:12,989:INFO:Calculating mean and std
2023-11-01 23:54:12,990:INFO:Creating metrics dataframe
2023-11-01 23:54:12,993:INFO:Uploading results into container
2023-11-01 23:54:12,994:INFO:Uploading model into container now
2023-11-01 23:54:12,994:INFO:_master_model_container: 26
2023-11-01 23:54:12,994:INFO:_display_container: 3
2023-11-01 23:54:12,994:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:54:12,994:INFO:create_model() successfully completed......................................
2023-11-01 23:54:13,276:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:13,276:INFO:Creating metrics dataframe
2023-11-01 23:54:13,286:INFO:Initializing Bayesian Ridge
2023-11-01 23:54:13,286:INFO:Total runtime is 0.0675898313522339 minutes
2023-11-01 23:54:13,289:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:13,289:INFO:Initializing create_model()
2023-11-01 23:54:13,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:13,289:INFO:Checking exceptions
2023-11-01 23:54:13,289:INFO:Importing libraries
2023-11-01 23:54:13,289:INFO:Copying training dataset
2023-11-01 23:54:13,293:INFO:Defining folds
2023-11-01 23:54:13,295:INFO:Declaring metric variables
2023-11-01 23:54:13,299:INFO:Importing untrained model
2023-11-01 23:54:13,301:INFO:Bayesian Ridge Imported successfully
2023-11-01 23:54:13,309:INFO:Starting cross validation
2023-11-01 23:54:13,310:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:13,544:INFO:Calculating mean and std
2023-11-01 23:54:13,545:INFO:Creating metrics dataframe
2023-11-01 23:54:13,548:INFO:Uploading results into container
2023-11-01 23:54:13,549:INFO:Uploading model into container now
2023-11-01 23:54:13,549:INFO:_master_model_container: 27
2023-11-01 23:54:13,549:INFO:_display_container: 3
2023-11-01 23:54:13,550:INFO:BayesianRidge()
2023-11-01 23:54:13,550:INFO:create_model() successfully completed......................................
2023-11-01 23:54:13,829:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:13,829:INFO:Creating metrics dataframe
2023-11-01 23:54:13,838:INFO:Initializing Passive Aggressive Regressor
2023-11-01 23:54:13,838:INFO:Total runtime is 0.07679659922917685 minutes
2023-11-01 23:54:13,841:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:13,841:INFO:Initializing create_model()
2023-11-01 23:54:13,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:13,843:INFO:Checking exceptions
2023-11-01 23:54:13,843:INFO:Importing libraries
2023-11-01 23:54:13,843:INFO:Copying training dataset
2023-11-01 23:54:13,847:INFO:Defining folds
2023-11-01 23:54:13,847:INFO:Declaring metric variables
2023-11-01 23:54:13,851:INFO:Importing untrained model
2023-11-01 23:54:13,856:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 23:54:13,863:INFO:Starting cross validation
2023-11-01 23:54:13,865:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:13,984:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:13,992:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:13,997:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,017:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,024:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,037:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,057:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,070:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,156:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:54:14,213:INFO:Calculating mean and std
2023-11-01 23:54:14,215:INFO:Creating metrics dataframe
2023-11-01 23:54:14,217:INFO:Uploading results into container
2023-11-01 23:54:14,218:INFO:Uploading model into container now
2023-11-01 23:54:14,218:INFO:_master_model_container: 28
2023-11-01 23:54:14,218:INFO:_display_container: 3
2023-11-01 23:54:14,218:INFO:PassiveAggressiveRegressor(random_state=1122)
2023-11-01 23:54:14,218:INFO:create_model() successfully completed......................................
2023-11-01 23:54:14,508:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:14,508:INFO:Creating metrics dataframe
2023-11-01 23:54:14,520:INFO:Initializing Huber Regressor
2023-11-01 23:54:14,520:INFO:Total runtime is 0.08816069761912029 minutes
2023-11-01 23:54:14,523:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:14,525:INFO:Initializing create_model()
2023-11-01 23:54:14,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:14,525:INFO:Checking exceptions
2023-11-01 23:54:14,525:INFO:Importing libraries
2023-11-01 23:54:14,525:INFO:Copying training dataset
2023-11-01 23:54:14,529:INFO:Defining folds
2023-11-01 23:54:14,529:INFO:Declaring metric variables
2023-11-01 23:54:14,533:INFO:Importing untrained model
2023-11-01 23:54:14,537:INFO:Huber Regressor Imported successfully
2023-11-01 23:54:14,543:INFO:Starting cross validation
2023-11-01 23:54:14,546:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:14,835:INFO:Calculating mean and std
2023-11-01 23:54:14,836:INFO:Creating metrics dataframe
2023-11-01 23:54:14,839:INFO:Uploading results into container
2023-11-01 23:54:14,840:INFO:Uploading model into container now
2023-11-01 23:54:14,840:INFO:_master_model_container: 29
2023-11-01 23:54:14,840:INFO:_display_container: 3
2023-11-01 23:54:14,840:INFO:HuberRegressor()
2023-11-01 23:54:14,840:INFO:create_model() successfully completed......................................
2023-11-01 23:54:15,140:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:15,141:INFO:Creating metrics dataframe
2023-11-01 23:54:15,153:INFO:Initializing K Neighbors Regressor
2023-11-01 23:54:15,153:INFO:Total runtime is 0.098715078830719 minutes
2023-11-01 23:54:15,156:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:15,157:INFO:Initializing create_model()
2023-11-01 23:54:15,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:15,157:INFO:Checking exceptions
2023-11-01 23:54:15,157:INFO:Importing libraries
2023-11-01 23:54:15,157:INFO:Copying training dataset
2023-11-01 23:54:15,161:INFO:Defining folds
2023-11-01 23:54:15,162:INFO:Declaring metric variables
2023-11-01 23:54:15,166:INFO:Importing untrained model
2023-11-01 23:54:15,171:INFO:K Neighbors Regressor Imported successfully
2023-11-01 23:54:15,178:INFO:Starting cross validation
2023-11-01 23:54:15,180:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:15,443:INFO:Calculating mean and std
2023-11-01 23:54:15,444:INFO:Creating metrics dataframe
2023-11-01 23:54:15,447:INFO:Uploading results into container
2023-11-01 23:54:15,448:INFO:Uploading model into container now
2023-11-01 23:54:15,448:INFO:_master_model_container: 30
2023-11-01 23:54:15,448:INFO:_display_container: 3
2023-11-01 23:54:15,448:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 23:54:15,448:INFO:create_model() successfully completed......................................
2023-11-01 23:54:15,731:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:15,731:INFO:Creating metrics dataframe
2023-11-01 23:54:15,744:INFO:Initializing Decision Tree Regressor
2023-11-01 23:54:15,744:INFO:Total runtime is 0.10855531692504884 minutes
2023-11-01 23:54:15,749:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:15,749:INFO:Initializing create_model()
2023-11-01 23:54:15,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:15,750:INFO:Checking exceptions
2023-11-01 23:54:15,750:INFO:Importing libraries
2023-11-01 23:54:15,750:INFO:Copying training dataset
2023-11-01 23:54:15,754:INFO:Defining folds
2023-11-01 23:54:15,754:INFO:Declaring metric variables
2023-11-01 23:54:15,758:INFO:Importing untrained model
2023-11-01 23:54:15,761:INFO:Decision Tree Regressor Imported successfully
2023-11-01 23:54:15,771:INFO:Starting cross validation
2023-11-01 23:54:15,773:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:16,026:INFO:Calculating mean and std
2023-11-01 23:54:16,027:INFO:Creating metrics dataframe
2023-11-01 23:54:16,029:INFO:Uploading results into container
2023-11-01 23:54:16,030:INFO:Uploading model into container now
2023-11-01 23:54:16,031:INFO:_master_model_container: 31
2023-11-01 23:54:16,031:INFO:_display_container: 3
2023-11-01 23:54:16,031:INFO:DecisionTreeRegressor(random_state=1122)
2023-11-01 23:54:16,031:INFO:create_model() successfully completed......................................
2023-11-01 23:54:16,309:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:16,309:INFO:Creating metrics dataframe
2023-11-01 23:54:16,322:INFO:Initializing Random Forest Regressor
2023-11-01 23:54:16,322:INFO:Total runtime is 0.11818326314290366 minutes
2023-11-01 23:54:16,327:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:16,327:INFO:Initializing create_model()
2023-11-01 23:54:16,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:16,328:INFO:Checking exceptions
2023-11-01 23:54:16,328:INFO:Importing libraries
2023-11-01 23:54:16,328:INFO:Copying training dataset
2023-11-01 23:54:16,333:INFO:Defining folds
2023-11-01 23:54:16,335:INFO:Declaring metric variables
2023-11-01 23:54:16,339:INFO:Importing untrained model
2023-11-01 23:54:16,342:INFO:Random Forest Regressor Imported successfully
2023-11-01 23:54:16,350:INFO:Starting cross validation
2023-11-01 23:54:16,352:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:16,952:INFO:Calculating mean and std
2023-11-01 23:54:16,954:INFO:Creating metrics dataframe
2023-11-01 23:54:16,956:INFO:Uploading results into container
2023-11-01 23:54:16,957:INFO:Uploading model into container now
2023-11-01 23:54:16,957:INFO:_master_model_container: 32
2023-11-01 23:54:16,957:INFO:_display_container: 3
2023-11-01 23:54:16,957:INFO:RandomForestRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:54:16,957:INFO:create_model() successfully completed......................................
2023-11-01 23:54:17,234:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:17,235:INFO:Creating metrics dataframe
2023-11-01 23:54:17,244:INFO:Initializing Extra Trees Regressor
2023-11-01 23:54:17,244:INFO:Total runtime is 0.1335575302441915 minutes
2023-11-01 23:54:17,248:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:17,249:INFO:Initializing create_model()
2023-11-01 23:54:17,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:17,249:INFO:Checking exceptions
2023-11-01 23:54:17,249:INFO:Importing libraries
2023-11-01 23:54:17,249:INFO:Copying training dataset
2023-11-01 23:54:17,253:INFO:Defining folds
2023-11-01 23:54:17,253:INFO:Declaring metric variables
2023-11-01 23:54:17,256:INFO:Importing untrained model
2023-11-01 23:54:17,261:INFO:Extra Trees Regressor Imported successfully
2023-11-01 23:54:17,268:INFO:Starting cross validation
2023-11-01 23:54:17,270:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:17,771:INFO:Calculating mean and std
2023-11-01 23:54:17,773:INFO:Creating metrics dataframe
2023-11-01 23:54:17,775:INFO:Uploading results into container
2023-11-01 23:54:17,776:INFO:Uploading model into container now
2023-11-01 23:54:17,776:INFO:_master_model_container: 33
2023-11-01 23:54:17,776:INFO:_display_container: 3
2023-11-01 23:54:17,777:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:54:17,777:INFO:create_model() successfully completed......................................
2023-11-01 23:54:18,069:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:18,069:INFO:Creating metrics dataframe
2023-11-01 23:54:18,078:INFO:Initializing AdaBoost Regressor
2023-11-01 23:54:18,078:INFO:Total runtime is 0.1474507729212443 minutes
2023-11-01 23:54:18,082:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:18,082:INFO:Initializing create_model()
2023-11-01 23:54:18,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:18,082:INFO:Checking exceptions
2023-11-01 23:54:18,082:INFO:Importing libraries
2023-11-01 23:54:18,082:INFO:Copying training dataset
2023-11-01 23:54:18,086:INFO:Defining folds
2023-11-01 23:54:18,086:INFO:Declaring metric variables
2023-11-01 23:54:18,088:INFO:Importing untrained model
2023-11-01 23:54:18,092:INFO:AdaBoost Regressor Imported successfully
2023-11-01 23:54:18,101:INFO:Starting cross validation
2023-11-01 23:54:18,103:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:18,482:INFO:Calculating mean and std
2023-11-01 23:54:18,482:INFO:Creating metrics dataframe
2023-11-01 23:54:18,485:INFO:Uploading results into container
2023-11-01 23:54:18,486:INFO:Uploading model into container now
2023-11-01 23:54:18,486:INFO:_master_model_container: 34
2023-11-01 23:54:18,486:INFO:_display_container: 3
2023-11-01 23:54:18,486:INFO:AdaBoostRegressor(random_state=1122)
2023-11-01 23:54:18,486:INFO:create_model() successfully completed......................................
2023-11-01 23:54:18,771:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:18,771:INFO:Creating metrics dataframe
2023-11-01 23:54:18,784:INFO:Initializing Gradient Boosting Regressor
2023-11-01 23:54:18,784:INFO:Total runtime is 0.15922036170959472 minutes
2023-11-01 23:54:18,787:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:18,788:INFO:Initializing create_model()
2023-11-01 23:54:18,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:18,788:INFO:Checking exceptions
2023-11-01 23:54:18,788:INFO:Importing libraries
2023-11-01 23:54:18,788:INFO:Copying training dataset
2023-11-01 23:54:18,792:INFO:Defining folds
2023-11-01 23:54:18,792:INFO:Declaring metric variables
2023-11-01 23:54:18,795:INFO:Importing untrained model
2023-11-01 23:54:18,800:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 23:54:18,807:INFO:Starting cross validation
2023-11-01 23:54:18,809:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:19,125:INFO:Calculating mean and std
2023-11-01 23:54:19,126:INFO:Creating metrics dataframe
2023-11-01 23:54:19,130:INFO:Uploading results into container
2023-11-01 23:54:19,130:INFO:Uploading model into container now
2023-11-01 23:54:19,131:INFO:_master_model_container: 35
2023-11-01 23:54:19,131:INFO:_display_container: 3
2023-11-01 23:54:19,131:INFO:GradientBoostingRegressor(random_state=1122)
2023-11-01 23:54:19,131:INFO:create_model() successfully completed......................................
2023-11-01 23:54:19,411:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:19,411:INFO:Creating metrics dataframe
2023-11-01 23:54:19,423:INFO:Initializing Extreme Gradient Boosting
2023-11-01 23:54:19,424:INFO:Total runtime is 0.16989625295003255 minutes
2023-11-01 23:54:19,428:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:19,428:INFO:Initializing create_model()
2023-11-01 23:54:19,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:19,428:INFO:Checking exceptions
2023-11-01 23:54:19,428:INFO:Importing libraries
2023-11-01 23:54:19,428:INFO:Copying training dataset
2023-11-01 23:54:19,434:INFO:Defining folds
2023-11-01 23:54:19,435:INFO:Declaring metric variables
2023-11-01 23:54:19,439:INFO:Importing untrained model
2023-11-01 23:54:19,443:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 23:54:19,450:INFO:Starting cross validation
2023-11-01 23:54:19,453:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:20,114:INFO:Calculating mean and std
2023-11-01 23:54:20,116:INFO:Creating metrics dataframe
2023-11-01 23:54:20,120:INFO:Uploading results into container
2023-11-01 23:54:20,121:INFO:Uploading model into container now
2023-11-01 23:54:20,121:INFO:_master_model_container: 36
2023-11-01 23:54:20,121:INFO:_display_container: 3
2023-11-01 23:54:20,122:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1122, ...)
2023-11-01 23:54:20,123:INFO:create_model() successfully completed......................................
2023-11-01 23:54:20,413:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:20,413:INFO:Creating metrics dataframe
2023-11-01 23:54:20,424:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 23:54:20,424:INFO:Total runtime is 0.18655860424041748 minutes
2023-11-01 23:54:20,428:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:20,428:INFO:Initializing create_model()
2023-11-01 23:54:20,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:20,429:INFO:Checking exceptions
2023-11-01 23:54:20,429:INFO:Importing libraries
2023-11-01 23:54:20,429:INFO:Copying training dataset
2023-11-01 23:54:20,433:INFO:Defining folds
2023-11-01 23:54:20,434:INFO:Declaring metric variables
2023-11-01 23:54:20,436:INFO:Importing untrained model
2023-11-01 23:54:20,441:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 23:54:20,446:INFO:Starting cross validation
2023-11-01 23:54:20,448:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:20,917:INFO:Calculating mean and std
2023-11-01 23:54:20,918:INFO:Creating metrics dataframe
2023-11-01 23:54:20,921:INFO:Uploading results into container
2023-11-01 23:54:20,922:INFO:Uploading model into container now
2023-11-01 23:54:20,922:INFO:_master_model_container: 37
2023-11-01 23:54:20,922:INFO:_display_container: 3
2023-11-01 23:54:20,923:INFO:LGBMRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:54:20,923:INFO:create_model() successfully completed......................................
2023-11-01 23:54:21,218:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:21,218:INFO:Creating metrics dataframe
2023-11-01 23:54:21,227:INFO:Initializing Dummy Regressor
2023-11-01 23:54:21,227:INFO:Total runtime is 0.19994048277537027 minutes
2023-11-01 23:54:21,231:INFO:SubProcess create_model() called ==================================
2023-11-01 23:54:21,231:INFO:Initializing create_model()
2023-11-01 23:54:21,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB7138DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:21,232:INFO:Checking exceptions
2023-11-01 23:54:21,232:INFO:Importing libraries
2023-11-01 23:54:21,232:INFO:Copying training dataset
2023-11-01 23:54:21,235:INFO:Defining folds
2023-11-01 23:54:21,236:INFO:Declaring metric variables
2023-11-01 23:54:21,238:INFO:Importing untrained model
2023-11-01 23:54:21,242:INFO:Dummy Regressor Imported successfully
2023-11-01 23:54:21,249:INFO:Starting cross validation
2023-11-01 23:54:21,250:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:54:21,534:INFO:Calculating mean and std
2023-11-01 23:54:21,536:INFO:Creating metrics dataframe
2023-11-01 23:54:21,538:INFO:Uploading results into container
2023-11-01 23:54:21,538:INFO:Uploading model into container now
2023-11-01 23:54:21,539:INFO:_master_model_container: 38
2023-11-01 23:54:21,539:INFO:_display_container: 3
2023-11-01 23:54:21,539:INFO:DummyRegressor()
2023-11-01 23:54:21,539:INFO:create_model() successfully completed......................................
2023-11-01 23:54:21,818:INFO:SubProcess create_model() end ==================================
2023-11-01 23:54:21,818:INFO:Creating metrics dataframe
2023-11-01 23:54:21,838:INFO:Initializing create_model()
2023-11-01 23:54:21,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=LassoLars(random_state=1122), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:54:21,839:INFO:Checking exceptions
2023-11-01 23:54:21,840:INFO:Importing libraries
2023-11-01 23:54:21,840:INFO:Copying training dataset
2023-11-01 23:54:21,843:INFO:Defining folds
2023-11-01 23:54:21,843:INFO:Declaring metric variables
2023-11-01 23:54:21,843:INFO:Importing untrained model
2023-11-01 23:54:21,843:INFO:Declaring custom model
2023-11-01 23:54:21,843:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:54:21,845:INFO:Cross validation set to False
2023-11-01 23:54:21,845:INFO:Fitting Model
2023-11-01 23:54:21,904:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:54:21,907:INFO:LassoLars(random_state=1122)
2023-11-01 23:54:21,907:INFO:create_model() successfully completed......................................
2023-11-01 23:54:22,238:INFO:_master_model_container: 38
2023-11-01 23:54:22,238:INFO:_display_container: 3
2023-11-01 23:54:22,238:INFO:LassoLars(random_state=1122)
2023-11-01 23:54:22,238:INFO:compare_models() successfully completed......................................
2023-11-01 23:55:14,746:INFO:Initializing compare_models()
2023-11-01 23:55:14,746:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 23:55:14,746:INFO:Checking exceptions
2023-11-01 23:55:14,748:INFO:Preparing display monitor
2023-11-01 23:55:14,788:INFO:Initializing Linear Regression
2023-11-01 23:55:14,788:INFO:Total runtime is 0.0 minutes
2023-11-01 23:55:14,792:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:14,792:INFO:Initializing create_model()
2023-11-01 23:55:14,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:14,792:INFO:Checking exceptions
2023-11-01 23:55:14,792:INFO:Importing libraries
2023-11-01 23:55:14,792:INFO:Copying training dataset
2023-11-01 23:55:14,798:INFO:Defining folds
2023-11-01 23:55:14,799:INFO:Declaring metric variables
2023-11-01 23:55:14,802:INFO:Importing untrained model
2023-11-01 23:55:14,807:INFO:Linear Regression Imported successfully
2023-11-01 23:55:14,817:INFO:Starting cross validation
2023-11-01 23:55:14,820:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:15,116:INFO:Calculating mean and std
2023-11-01 23:55:15,117:INFO:Creating metrics dataframe
2023-11-01 23:55:15,119:INFO:Uploading results into container
2023-11-01 23:55:15,119:INFO:Uploading model into container now
2023-11-01 23:55:15,120:INFO:_master_model_container: 39
2023-11-01 23:55:15,120:INFO:_display_container: 4
2023-11-01 23:55:15,120:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:55:15,120:INFO:create_model() successfully completed......................................
2023-11-01 23:55:15,400:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:15,400:INFO:Creating metrics dataframe
2023-11-01 23:55:15,406:INFO:Initializing Lasso Regression
2023-11-01 23:55:15,406:INFO:Total runtime is 0.01030498743057251 minutes
2023-11-01 23:55:15,409:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:15,410:INFO:Initializing create_model()
2023-11-01 23:55:15,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:15,410:INFO:Checking exceptions
2023-11-01 23:55:15,410:INFO:Importing libraries
2023-11-01 23:55:15,410:INFO:Copying training dataset
2023-11-01 23:55:15,414:INFO:Defining folds
2023-11-01 23:55:15,414:INFO:Declaring metric variables
2023-11-01 23:55:15,418:INFO:Importing untrained model
2023-11-01 23:55:15,421:INFO:Lasso Regression Imported successfully
2023-11-01 23:55:15,427:INFO:Starting cross validation
2023-11-01 23:55:15,430:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:15,666:INFO:Calculating mean and std
2023-11-01 23:55:15,666:INFO:Creating metrics dataframe
2023-11-01 23:55:15,668:INFO:Uploading results into container
2023-11-01 23:55:15,669:INFO:Uploading model into container now
2023-11-01 23:55:15,669:INFO:_master_model_container: 40
2023-11-01 23:55:15,669:INFO:_display_container: 4
2023-11-01 23:55:15,669:INFO:Lasso(random_state=1122)
2023-11-01 23:55:15,669:INFO:create_model() successfully completed......................................
2023-11-01 23:55:15,943:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:15,943:INFO:Creating metrics dataframe
2023-11-01 23:55:15,950:INFO:Initializing Ridge Regression
2023-11-01 23:55:15,950:INFO:Total runtime is 0.019378066062927246 minutes
2023-11-01 23:55:15,954:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:15,955:INFO:Initializing create_model()
2023-11-01 23:55:15,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:15,955:INFO:Checking exceptions
2023-11-01 23:55:15,955:INFO:Importing libraries
2023-11-01 23:55:15,955:INFO:Copying training dataset
2023-11-01 23:55:15,959:INFO:Defining folds
2023-11-01 23:55:15,959:INFO:Declaring metric variables
2023-11-01 23:55:15,962:INFO:Importing untrained model
2023-11-01 23:55:15,966:INFO:Ridge Regression Imported successfully
2023-11-01 23:55:15,973:INFO:Starting cross validation
2023-11-01 23:55:15,975:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:16,209:INFO:Calculating mean and std
2023-11-01 23:55:16,211:INFO:Creating metrics dataframe
2023-11-01 23:55:16,213:INFO:Uploading results into container
2023-11-01 23:55:16,214:INFO:Uploading model into container now
2023-11-01 23:55:16,214:INFO:_master_model_container: 41
2023-11-01 23:55:16,214:INFO:_display_container: 4
2023-11-01 23:55:16,215:INFO:Ridge(random_state=1122)
2023-11-01 23:55:16,215:INFO:create_model() successfully completed......................................
2023-11-01 23:55:16,491:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:16,491:INFO:Creating metrics dataframe
2023-11-01 23:55:16,500:INFO:Initializing Elastic Net
2023-11-01 23:55:16,500:INFO:Total runtime is 0.028530597686767578 minutes
2023-11-01 23:55:16,502:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:16,503:INFO:Initializing create_model()
2023-11-01 23:55:16,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:16,503:INFO:Checking exceptions
2023-11-01 23:55:16,503:INFO:Importing libraries
2023-11-01 23:55:16,503:INFO:Copying training dataset
2023-11-01 23:55:16,508:INFO:Defining folds
2023-11-01 23:55:16,509:INFO:Declaring metric variables
2023-11-01 23:55:16,512:INFO:Importing untrained model
2023-11-01 23:55:16,518:INFO:Elastic Net Imported successfully
2023-11-01 23:55:16,524:INFO:Starting cross validation
2023-11-01 23:55:16,526:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:16,766:INFO:Calculating mean and std
2023-11-01 23:55:16,767:INFO:Creating metrics dataframe
2023-11-01 23:55:16,770:INFO:Uploading results into container
2023-11-01 23:55:16,770:INFO:Uploading model into container now
2023-11-01 23:55:16,770:INFO:_master_model_container: 42
2023-11-01 23:55:16,770:INFO:_display_container: 4
2023-11-01 23:55:16,771:INFO:ElasticNet(random_state=1122)
2023-11-01 23:55:16,771:INFO:create_model() successfully completed......................................
2023-11-01 23:55:17,051:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:17,051:INFO:Creating metrics dataframe
2023-11-01 23:55:17,060:INFO:Initializing Least Angle Regression
2023-11-01 23:55:17,061:INFO:Total runtime is 0.037879443168640135 minutes
2023-11-01 23:55:17,064:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:17,065:INFO:Initializing create_model()
2023-11-01 23:55:17,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:17,065:INFO:Checking exceptions
2023-11-01 23:55:17,065:INFO:Importing libraries
2023-11-01 23:55:17,065:INFO:Copying training dataset
2023-11-01 23:55:17,069:INFO:Defining folds
2023-11-01 23:55:17,069:INFO:Declaring metric variables
2023-11-01 23:55:17,071:INFO:Importing untrained model
2023-11-01 23:55:17,076:INFO:Least Angle Regression Imported successfully
2023-11-01 23:55:17,084:INFO:Starting cross validation
2023-11-01 23:55:17,086:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:17,181:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,184:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,185:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,188:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.331e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,189:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.689e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,189:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.172e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,189:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.270e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,189:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.106e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,189:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.345e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.910e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.434e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.464e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.343e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.304e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.196e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,190:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.296e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.346e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.688e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.140e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.293e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=7.144e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.121e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.213e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.704e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.523e-07, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.089e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.037e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.869e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,197:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,202:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,203:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.496e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,203:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,203:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.417e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,203:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.200e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,204:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.097e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,204:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.162e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,205:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.774e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,206:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.525e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,206:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.767e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,207:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.407e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,207:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.478e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,207:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.300e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.382e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.242e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.005e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.689e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.027e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.484e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.019e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,208:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.534e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,209:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.333e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,209:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.089e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,209:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.271e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,209:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.208e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,210:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=8.053e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,222:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,229:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.846e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,229:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,230:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,230:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,230:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,240:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,245:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.058e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,246:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.713e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,246:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.162e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,246:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.465e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,293:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,296:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.556e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,297:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.741e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,297:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.670e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,298:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.981e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,298:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.615e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,298:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.929e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,298:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.701e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,298:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.066e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,300:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:17,302:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.555e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,302:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.672e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,302:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.425e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,302:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.340e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.267e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.172e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.382e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.318e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.790e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.732e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.421e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,303:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.732e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,304:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.097e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,304:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.209e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,304:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.673e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,304:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.842e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,304:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.351e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:17,327:INFO:Calculating mean and std
2023-11-01 23:55:17,329:INFO:Creating metrics dataframe
2023-11-01 23:55:17,331:INFO:Uploading results into container
2023-11-01 23:55:17,332:INFO:Uploading model into container now
2023-11-01 23:55:17,332:INFO:_master_model_container: 43
2023-11-01 23:55:17,332:INFO:_display_container: 4
2023-11-01 23:55:17,332:INFO:Lars(random_state=1122)
2023-11-01 23:55:17,332:INFO:create_model() successfully completed......................................
2023-11-01 23:55:17,614:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:17,614:INFO:Creating metrics dataframe
2023-11-01 23:55:17,624:INFO:Initializing Lasso Least Angle Regression
2023-11-01 23:55:17,624:INFO:Total runtime is 0.04726616144180298 minutes
2023-11-01 23:55:17,627:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:17,627:INFO:Initializing create_model()
2023-11-01 23:55:17,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:17,628:INFO:Checking exceptions
2023-11-01 23:55:17,628:INFO:Importing libraries
2023-11-01 23:55:17,628:INFO:Copying training dataset
2023-11-01 23:55:17,635:INFO:Defining folds
2023-11-01 23:55:17,664:INFO:Declaring metric variables
2023-11-01 23:55:17,669:INFO:Importing untrained model
2023-11-01 23:55:17,675:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:55:17,684:INFO:Starting cross validation
2023-11-01 23:55:17,687:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:17,783:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,794:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,801:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,819:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,836:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,837:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,851:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,871:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,905:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,907:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:17,929:INFO:Calculating mean and std
2023-11-01 23:55:17,930:INFO:Creating metrics dataframe
2023-11-01 23:55:17,933:INFO:Uploading results into container
2023-11-01 23:55:17,934:INFO:Uploading model into container now
2023-11-01 23:55:17,934:INFO:_master_model_container: 44
2023-11-01 23:55:17,934:INFO:_display_container: 4
2023-11-01 23:55:17,935:INFO:LassoLars(random_state=1122)
2023-11-01 23:55:17,935:INFO:create_model() successfully completed......................................
2023-11-01 23:55:18,225:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:18,225:INFO:Creating metrics dataframe
2023-11-01 23:55:18,237:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 23:55:18,237:INFO:Total runtime is 0.05748205582300822 minutes
2023-11-01 23:55:18,239:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:18,240:INFO:Initializing create_model()
2023-11-01 23:55:18,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:18,240:INFO:Checking exceptions
2023-11-01 23:55:18,240:INFO:Importing libraries
2023-11-01 23:55:18,240:INFO:Copying training dataset
2023-11-01 23:55:18,248:INFO:Defining folds
2023-11-01 23:55:18,248:INFO:Declaring metric variables
2023-11-01 23:55:18,252:INFO:Importing untrained model
2023-11-01 23:55:18,254:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:55:18,261:INFO:Starting cross validation
2023-11-01 23:55:18,263:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:18,362:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,370:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,375:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,384:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,386:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,399:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,408:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,481:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,490:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:18,516:INFO:Calculating mean and std
2023-11-01 23:55:18,518:INFO:Creating metrics dataframe
2023-11-01 23:55:18,520:INFO:Uploading results into container
2023-11-01 23:55:18,521:INFO:Uploading model into container now
2023-11-01 23:55:18,521:INFO:_master_model_container: 45
2023-11-01 23:55:18,521:INFO:_display_container: 4
2023-11-01 23:55:18,522:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:55:18,522:INFO:create_model() successfully completed......................................
2023-11-01 23:55:18,825:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:18,825:INFO:Creating metrics dataframe
2023-11-01 23:55:18,836:INFO:Initializing Bayesian Ridge
2023-11-01 23:55:18,836:INFO:Total runtime is 0.06747049887975057 minutes
2023-11-01 23:55:18,840:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:18,840:INFO:Initializing create_model()
2023-11-01 23:55:18,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:18,840:INFO:Checking exceptions
2023-11-01 23:55:18,840:INFO:Importing libraries
2023-11-01 23:55:18,840:INFO:Copying training dataset
2023-11-01 23:55:18,847:INFO:Defining folds
2023-11-01 23:55:18,847:INFO:Declaring metric variables
2023-11-01 23:55:18,849:INFO:Importing untrained model
2023-11-01 23:55:18,854:INFO:Bayesian Ridge Imported successfully
2023-11-01 23:55:18,863:INFO:Starting cross validation
2023-11-01 23:55:18,865:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:19,101:INFO:Calculating mean and std
2023-11-01 23:55:19,102:INFO:Creating metrics dataframe
2023-11-01 23:55:19,105:INFO:Uploading results into container
2023-11-01 23:55:19,106:INFO:Uploading model into container now
2023-11-01 23:55:19,106:INFO:_master_model_container: 46
2023-11-01 23:55:19,106:INFO:_display_container: 4
2023-11-01 23:55:19,107:INFO:BayesianRidge()
2023-11-01 23:55:19,107:INFO:create_model() successfully completed......................................
2023-11-01 23:55:19,408:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:19,408:INFO:Creating metrics dataframe
2023-11-01 23:55:19,419:INFO:Initializing Passive Aggressive Regressor
2023-11-01 23:55:19,419:INFO:Total runtime is 0.07719098726908366 minutes
2023-11-01 23:55:19,421:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:19,422:INFO:Initializing create_model()
2023-11-01 23:55:19,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:19,422:INFO:Checking exceptions
2023-11-01 23:55:19,422:INFO:Importing libraries
2023-11-01 23:55:19,422:INFO:Copying training dataset
2023-11-01 23:55:19,427:INFO:Defining folds
2023-11-01 23:55:19,427:INFO:Declaring metric variables
2023-11-01 23:55:19,431:INFO:Importing untrained model
2023-11-01 23:55:19,435:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 23:55:19,442:INFO:Starting cross validation
2023-11-01 23:55:19,445:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:19,550:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,561:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,567:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,574:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,579:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,584:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,599:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,613:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,677:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,678:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:19,701:INFO:Calculating mean and std
2023-11-01 23:55:19,702:INFO:Creating metrics dataframe
2023-11-01 23:55:19,705:INFO:Uploading results into container
2023-11-01 23:55:19,705:INFO:Uploading model into container now
2023-11-01 23:55:19,705:INFO:_master_model_container: 47
2023-11-01 23:55:19,705:INFO:_display_container: 4
2023-11-01 23:55:19,706:INFO:PassiveAggressiveRegressor(random_state=1122)
2023-11-01 23:55:19,706:INFO:create_model() successfully completed......................................
2023-11-01 23:55:20,004:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:20,005:INFO:Creating metrics dataframe
2023-11-01 23:55:20,017:INFO:Initializing Huber Regressor
2023-11-01 23:55:20,017:INFO:Total runtime is 0.08715602556864421 minutes
2023-11-01 23:55:20,020:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:20,020:INFO:Initializing create_model()
2023-11-01 23:55:20,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB71A5D50>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:20,021:INFO:Checking exceptions
2023-11-01 23:55:20,021:INFO:Importing libraries
2023-11-01 23:55:20,021:INFO:Copying training dataset
2023-11-01 23:55:20,026:INFO:Defining folds
2023-11-01 23:55:20,027:INFO:Declaring metric variables
2023-11-01 23:55:20,030:INFO:Importing untrained model
2023-11-01 23:55:20,034:INFO:Huber Regressor Imported successfully
2023-11-01 23:55:20,041:INFO:Starting cross validation
2023-11-01 23:55:20,044:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:20,363:INFO:Calculating mean and std
2023-11-01 23:55:20,365:INFO:Creating metrics dataframe
2023-11-01 23:55:20,367:INFO:Uploading results into container
2023-11-01 23:55:20,367:INFO:Uploading model into container now
2023-11-01 23:55:20,368:INFO:_master_model_container: 48
2023-11-01 23:55:20,368:INFO:_display_container: 4
2023-11-01 23:55:20,368:INFO:HuberRegressor()
2023-11-01 23:55:20,368:INFO:create_model() successfully completed......................................
2023-11-01 23:55:25,756:INFO:Initializing compare_models()
2023-11-01 23:55:25,756:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-01 23:55:25,756:INFO:Checking exceptions
2023-11-01 23:55:25,759:INFO:Preparing display monitor
2023-11-01 23:55:25,795:INFO:Initializing Linear Regression
2023-11-01 23:55:25,795:INFO:Total runtime is 0.0 minutes
2023-11-01 23:55:25,798:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:25,799:INFO:Initializing create_model()
2023-11-01 23:55:25,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:25,799:INFO:Checking exceptions
2023-11-01 23:55:25,799:INFO:Importing libraries
2023-11-01 23:55:25,799:INFO:Copying training dataset
2023-11-01 23:55:25,802:INFO:Defining folds
2023-11-01 23:55:25,802:INFO:Declaring metric variables
2023-11-01 23:55:25,806:INFO:Importing untrained model
2023-11-01 23:55:25,812:INFO:Linear Regression Imported successfully
2023-11-01 23:55:25,819:INFO:Starting cross validation
2023-11-01 23:55:25,820:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:26,115:INFO:Calculating mean and std
2023-11-01 23:55:26,115:INFO:Creating metrics dataframe
2023-11-01 23:55:26,118:INFO:Uploading results into container
2023-11-01 23:55:26,118:INFO:Uploading model into container now
2023-11-01 23:55:26,118:INFO:_master_model_container: 49
2023-11-01 23:55:26,118:INFO:_display_container: 5
2023-11-01 23:55:26,119:INFO:LinearRegression(n_jobs=-1)
2023-11-01 23:55:26,119:INFO:create_model() successfully completed......................................
2023-11-01 23:55:26,425:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:26,425:INFO:Creating metrics dataframe
2023-11-01 23:55:26,431:INFO:Initializing Lasso Regression
2023-11-01 23:55:26,431:INFO:Total runtime is 0.010603153705596923 minutes
2023-11-01 23:55:26,434:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:26,435:INFO:Initializing create_model()
2023-11-01 23:55:26,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:26,435:INFO:Checking exceptions
2023-11-01 23:55:26,435:INFO:Importing libraries
2023-11-01 23:55:26,435:INFO:Copying training dataset
2023-11-01 23:55:26,439:INFO:Defining folds
2023-11-01 23:55:26,439:INFO:Declaring metric variables
2023-11-01 23:55:26,442:INFO:Importing untrained model
2023-11-01 23:55:26,445:INFO:Lasso Regression Imported successfully
2023-11-01 23:55:26,451:INFO:Starting cross validation
2023-11-01 23:55:26,453:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:26,706:INFO:Calculating mean and std
2023-11-01 23:55:26,707:INFO:Creating metrics dataframe
2023-11-01 23:55:26,711:INFO:Uploading results into container
2023-11-01 23:55:26,711:INFO:Uploading model into container now
2023-11-01 23:55:26,711:INFO:_master_model_container: 50
2023-11-01 23:55:26,711:INFO:_display_container: 5
2023-11-01 23:55:26,711:INFO:Lasso(random_state=1122)
2023-11-01 23:55:26,711:INFO:create_model() successfully completed......................................
2023-11-01 23:55:27,011:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:27,011:INFO:Creating metrics dataframe
2023-11-01 23:55:27,019:INFO:Initializing Ridge Regression
2023-11-01 23:55:27,019:INFO:Total runtime is 0.020401465892791747 minutes
2023-11-01 23:55:27,022:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:27,023:INFO:Initializing create_model()
2023-11-01 23:55:27,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:27,023:INFO:Checking exceptions
2023-11-01 23:55:27,023:INFO:Importing libraries
2023-11-01 23:55:27,023:INFO:Copying training dataset
2023-11-01 23:55:27,027:INFO:Defining folds
2023-11-01 23:55:27,027:INFO:Declaring metric variables
2023-11-01 23:55:27,030:INFO:Importing untrained model
2023-11-01 23:55:27,033:INFO:Ridge Regression Imported successfully
2023-11-01 23:55:27,041:INFO:Starting cross validation
2023-11-01 23:55:27,043:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:27,344:INFO:Calculating mean and std
2023-11-01 23:55:27,345:INFO:Creating metrics dataframe
2023-11-01 23:55:27,348:INFO:Uploading results into container
2023-11-01 23:55:27,349:INFO:Uploading model into container now
2023-11-01 23:55:27,349:INFO:_master_model_container: 51
2023-11-01 23:55:27,350:INFO:_display_container: 5
2023-11-01 23:55:27,350:INFO:Ridge(random_state=1122)
2023-11-01 23:55:27,350:INFO:create_model() successfully completed......................................
2023-11-01 23:55:27,646:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:27,646:INFO:Creating metrics dataframe
2023-11-01 23:55:27,653:INFO:Initializing Elastic Net
2023-11-01 23:55:27,655:INFO:Total runtime is 0.030995515982309978 minutes
2023-11-01 23:55:27,658:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:27,659:INFO:Initializing create_model()
2023-11-01 23:55:27,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:27,659:INFO:Checking exceptions
2023-11-01 23:55:27,659:INFO:Importing libraries
2023-11-01 23:55:27,659:INFO:Copying training dataset
2023-11-01 23:55:27,662:INFO:Defining folds
2023-11-01 23:55:27,663:INFO:Declaring metric variables
2023-11-01 23:55:27,666:INFO:Importing untrained model
2023-11-01 23:55:27,670:INFO:Elastic Net Imported successfully
2023-11-01 23:55:27,677:INFO:Starting cross validation
2023-11-01 23:55:27,679:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:27,907:INFO:Calculating mean and std
2023-11-01 23:55:27,909:INFO:Creating metrics dataframe
2023-11-01 23:55:27,912:INFO:Uploading results into container
2023-11-01 23:55:27,913:INFO:Uploading model into container now
2023-11-01 23:55:27,913:INFO:_master_model_container: 52
2023-11-01 23:55:27,914:INFO:_display_container: 5
2023-11-01 23:55:27,914:INFO:ElasticNet(random_state=1122)
2023-11-01 23:55:27,914:INFO:create_model() successfully completed......................................
2023-11-01 23:55:28,209:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:28,209:INFO:Creating metrics dataframe
2023-11-01 23:55:28,217:INFO:Initializing Least Angle Regression
2023-11-01 23:55:28,217:INFO:Total runtime is 0.04037241935729981 minutes
2023-11-01 23:55:28,219:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:28,220:INFO:Initializing create_model()
2023-11-01 23:55:28,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:28,220:INFO:Checking exceptions
2023-11-01 23:55:28,220:INFO:Importing libraries
2023-11-01 23:55:28,220:INFO:Copying training dataset
2023-11-01 23:55:28,224:INFO:Defining folds
2023-11-01 23:55:28,224:INFO:Declaring metric variables
2023-11-01 23:55:28,228:INFO:Importing untrained model
2023-11-01 23:55:28,231:INFO:Least Angle Regression Imported successfully
2023-11-01 23:55:28,238:INFO:Starting cross validation
2023-11-01 23:55:28,241:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:28,350:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,353:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,354:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,355:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,355:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.496e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,356:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.417e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,356:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.200e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,356:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.097e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,356:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.162e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,357:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.774e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,358:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.525e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,359:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.767e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,359:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.478e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,360:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.242e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,360:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.005e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,360:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.027e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,360:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.484e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,361:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.019e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,361:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.813e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,363:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,363:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.689e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,363:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.270e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,364:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.106e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,364:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.345e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,364:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.910e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,364:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.464e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,364:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.343e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.196e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.346e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.688e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.140e-05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,365:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=7.144e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,366:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.213e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,366:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.523e-07, with an active set of 21 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,366:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.172e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,367:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.434e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,368:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.304e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,368:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.296e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,368:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.407e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,368:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.293e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.121e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.704e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.300e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=4.089e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.037e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.382e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,369:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.869e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,370:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.689e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,370:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.534e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,370:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.333e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,370:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.089e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,371:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.271e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,371:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.208e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,371:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=8.053e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,387:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,391:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,393:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.846e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.370e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,394:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.776e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,397:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.058e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,397:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.713e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,397:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.162e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,397:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.465e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,448:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,451:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.556e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,452:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.741e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,452:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.670e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,452:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.981e-03, with an active set of 27 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,452:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.615e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,453:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.929e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,453:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.701e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,453:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.066e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,453:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:28,456:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.555e-03, with an active set of 21 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,457:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.672e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,457:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.425e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,457:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.340e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,457:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.267e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,457:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.172e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,458:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.382e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,458:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.318e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,459:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.790e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,459:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.732e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,459:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.421e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,459:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.732e-03, with an active set of 26 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,459:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.097e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,459:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=6.209e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,460:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.673e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,460:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.842e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,460:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.351e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-01 23:55:28,484:INFO:Calculating mean and std
2023-11-01 23:55:28,485:INFO:Creating metrics dataframe
2023-11-01 23:55:28,488:INFO:Uploading results into container
2023-11-01 23:55:28,488:INFO:Uploading model into container now
2023-11-01 23:55:28,488:INFO:_master_model_container: 53
2023-11-01 23:55:28,488:INFO:_display_container: 5
2023-11-01 23:55:28,489:INFO:Lars(random_state=1122)
2023-11-01 23:55:28,489:INFO:create_model() successfully completed......................................
2023-11-01 23:55:28,810:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:28,810:INFO:Creating metrics dataframe
2023-11-01 23:55:28,820:INFO:Initializing Lasso Least Angle Regression
2023-11-01 23:55:28,820:INFO:Total runtime is 0.05041513840357463 minutes
2023-11-01 23:55:28,822:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:28,822:INFO:Initializing create_model()
2023-11-01 23:55:28,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:28,822:INFO:Checking exceptions
2023-11-01 23:55:28,823:INFO:Importing libraries
2023-11-01 23:55:28,823:INFO:Copying training dataset
2023-11-01 23:55:28,828:INFO:Defining folds
2023-11-01 23:55:28,828:INFO:Declaring metric variables
2023-11-01 23:55:28,831:INFO:Importing untrained model
2023-11-01 23:55:28,836:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:55:28,843:INFO:Starting cross validation
2023-11-01 23:55:28,845:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:28,960:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,960:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,962:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,963:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,967:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,970:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,988:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:28,997:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:29,061:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:29,064:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:29,089:INFO:Calculating mean and std
2023-11-01 23:55:29,091:INFO:Creating metrics dataframe
2023-11-01 23:55:29,094:INFO:Uploading results into container
2023-11-01 23:55:29,095:INFO:Uploading model into container now
2023-11-01 23:55:29,095:INFO:_master_model_container: 54
2023-11-01 23:55:29,096:INFO:_display_container: 5
2023-11-01 23:55:29,096:INFO:LassoLars(random_state=1122)
2023-11-01 23:55:29,096:INFO:create_model() successfully completed......................................
2023-11-01 23:55:29,394:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:29,394:INFO:Creating metrics dataframe
2023-11-01 23:55:29,402:INFO:Initializing Orthogonal Matching Pursuit
2023-11-01 23:55:29,402:INFO:Total runtime is 0.060115977128346765 minutes
2023-11-01 23:55:29,404:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:29,405:INFO:Initializing create_model()
2023-11-01 23:55:29,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:29,405:INFO:Checking exceptions
2023-11-01 23:55:29,405:INFO:Importing libraries
2023-11-01 23:55:29,405:INFO:Copying training dataset
2023-11-01 23:55:29,411:INFO:Defining folds
2023-11-01 23:55:29,411:INFO:Declaring metric variables
2023-11-01 23:55:29,415:INFO:Importing untrained model
2023-11-01 23:55:29,419:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:55:29,428:INFO:Starting cross validation
2023-11-01 23:55:29,429:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:29,531:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,540:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,553:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,553:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,555:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,563:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,580:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,582:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,648:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,653:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:29,678:INFO:Calculating mean and std
2023-11-01 23:55:29,680:INFO:Creating metrics dataframe
2023-11-01 23:55:29,682:INFO:Uploading results into container
2023-11-01 23:55:29,682:INFO:Uploading model into container now
2023-11-01 23:55:29,683:INFO:_master_model_container: 55
2023-11-01 23:55:29,683:INFO:_display_container: 5
2023-11-01 23:55:29,683:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:55:29,683:INFO:create_model() successfully completed......................................
2023-11-01 23:55:29,990:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:29,990:INFO:Creating metrics dataframe
2023-11-01 23:55:29,999:INFO:Initializing Bayesian Ridge
2023-11-01 23:55:29,999:INFO:Total runtime is 0.07007685502370199 minutes
2023-11-01 23:55:30,004:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:30,004:INFO:Initializing create_model()
2023-11-01 23:55:30,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:30,005:INFO:Checking exceptions
2023-11-01 23:55:30,005:INFO:Importing libraries
2023-11-01 23:55:30,005:INFO:Copying training dataset
2023-11-01 23:55:30,010:INFO:Defining folds
2023-11-01 23:55:30,010:INFO:Declaring metric variables
2023-11-01 23:55:30,015:INFO:Importing untrained model
2023-11-01 23:55:30,017:INFO:Bayesian Ridge Imported successfully
2023-11-01 23:55:30,025:INFO:Starting cross validation
2023-11-01 23:55:30,027:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:30,286:INFO:Calculating mean and std
2023-11-01 23:55:30,288:INFO:Creating metrics dataframe
2023-11-01 23:55:30,291:INFO:Uploading results into container
2023-11-01 23:55:30,291:INFO:Uploading model into container now
2023-11-01 23:55:30,293:INFO:_master_model_container: 56
2023-11-01 23:55:30,293:INFO:_display_container: 5
2023-11-01 23:55:30,293:INFO:BayesianRidge()
2023-11-01 23:55:30,293:INFO:create_model() successfully completed......................................
2023-11-01 23:55:30,618:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:30,618:INFO:Creating metrics dataframe
2023-11-01 23:55:30,629:INFO:Initializing Passive Aggressive Regressor
2023-11-01 23:55:30,629:INFO:Total runtime is 0.08057124614715577 minutes
2023-11-01 23:55:30,633:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:30,633:INFO:Initializing create_model()
2023-11-01 23:55:30,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:30,634:INFO:Checking exceptions
2023-11-01 23:55:30,634:INFO:Importing libraries
2023-11-01 23:55:30,634:INFO:Copying training dataset
2023-11-01 23:55:30,639:INFO:Defining folds
2023-11-01 23:55:30,639:INFO:Declaring metric variables
2023-11-01 23:55:30,642:INFO:Importing untrained model
2023-11-01 23:55:30,646:INFO:Passive Aggressive Regressor Imported successfully
2023-11-01 23:55:30,653:INFO:Starting cross validation
2023-11-01 23:55:30,655:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:30,770:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,780:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,785:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,789:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,791:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,799:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,822:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,841:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,905:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,913:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-01 23:55:30,941:INFO:Calculating mean and std
2023-11-01 23:55:30,942:INFO:Creating metrics dataframe
2023-11-01 23:55:30,945:INFO:Uploading results into container
2023-11-01 23:55:30,946:INFO:Uploading model into container now
2023-11-01 23:55:30,947:INFO:_master_model_container: 57
2023-11-01 23:55:30,947:INFO:_display_container: 5
2023-11-01 23:55:30,947:INFO:PassiveAggressiveRegressor(random_state=1122)
2023-11-01 23:55:30,948:INFO:create_model() successfully completed......................................
2023-11-01 23:55:31,275:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:31,275:INFO:Creating metrics dataframe
2023-11-01 23:55:31,284:INFO:Initializing Huber Regressor
2023-11-01 23:55:31,284:INFO:Total runtime is 0.09148023923238119 minutes
2023-11-01 23:55:31,287:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:31,287:INFO:Initializing create_model()
2023-11-01 23:55:31,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:31,288:INFO:Checking exceptions
2023-11-01 23:55:31,288:INFO:Importing libraries
2023-11-01 23:55:31,288:INFO:Copying training dataset
2023-11-01 23:55:31,293:INFO:Defining folds
2023-11-01 23:55:31,293:INFO:Declaring metric variables
2023-11-01 23:55:31,296:INFO:Importing untrained model
2023-11-01 23:55:31,300:INFO:Huber Regressor Imported successfully
2023-11-01 23:55:31,309:INFO:Starting cross validation
2023-11-01 23:55:31,311:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:31,563:INFO:Calculating mean and std
2023-11-01 23:55:31,564:INFO:Creating metrics dataframe
2023-11-01 23:55:31,567:INFO:Uploading results into container
2023-11-01 23:55:31,568:INFO:Uploading model into container now
2023-11-01 23:55:31,568:INFO:_master_model_container: 58
2023-11-01 23:55:31,568:INFO:_display_container: 5
2023-11-01 23:55:31,569:INFO:HuberRegressor()
2023-11-01 23:55:31,569:INFO:create_model() successfully completed......................................
2023-11-01 23:55:31,907:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:31,908:INFO:Creating metrics dataframe
2023-11-01 23:55:31,918:INFO:Initializing K Neighbors Regressor
2023-11-01 23:55:31,918:INFO:Total runtime is 0.10205583572387696 minutes
2023-11-01 23:55:31,921:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:31,922:INFO:Initializing create_model()
2023-11-01 23:55:31,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:31,922:INFO:Checking exceptions
2023-11-01 23:55:31,922:INFO:Importing libraries
2023-11-01 23:55:31,922:INFO:Copying training dataset
2023-11-01 23:55:31,927:INFO:Defining folds
2023-11-01 23:55:31,928:INFO:Declaring metric variables
2023-11-01 23:55:31,930:INFO:Importing untrained model
2023-11-01 23:55:31,934:INFO:K Neighbors Regressor Imported successfully
2023-11-01 23:55:31,941:INFO:Starting cross validation
2023-11-01 23:55:31,942:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:32,191:INFO:Calculating mean and std
2023-11-01 23:55:32,194:INFO:Creating metrics dataframe
2023-11-01 23:55:32,196:INFO:Uploading results into container
2023-11-01 23:55:32,197:INFO:Uploading model into container now
2023-11-01 23:55:32,198:INFO:_master_model_container: 59
2023-11-01 23:55:32,198:INFO:_display_container: 5
2023-11-01 23:55:32,198:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-01 23:55:32,198:INFO:create_model() successfully completed......................................
2023-11-01 23:55:32,501:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:32,501:INFO:Creating metrics dataframe
2023-11-01 23:55:32,513:INFO:Initializing Decision Tree Regressor
2023-11-01 23:55:32,513:INFO:Total runtime is 0.1119675358136495 minutes
2023-11-01 23:55:32,515:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:32,516:INFO:Initializing create_model()
2023-11-01 23:55:32,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:32,516:INFO:Checking exceptions
2023-11-01 23:55:32,516:INFO:Importing libraries
2023-11-01 23:55:32,516:INFO:Copying training dataset
2023-11-01 23:55:32,521:INFO:Defining folds
2023-11-01 23:55:32,521:INFO:Declaring metric variables
2023-11-01 23:55:32,526:INFO:Importing untrained model
2023-11-01 23:55:32,531:INFO:Decision Tree Regressor Imported successfully
2023-11-01 23:55:32,537:INFO:Starting cross validation
2023-11-01 23:55:32,540:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:32,786:INFO:Calculating mean and std
2023-11-01 23:55:32,787:INFO:Creating metrics dataframe
2023-11-01 23:55:32,791:INFO:Uploading results into container
2023-11-01 23:55:32,791:INFO:Uploading model into container now
2023-11-01 23:55:32,792:INFO:_master_model_container: 60
2023-11-01 23:55:32,792:INFO:_display_container: 5
2023-11-01 23:55:32,792:INFO:DecisionTreeRegressor(random_state=1122)
2023-11-01 23:55:32,792:INFO:create_model() successfully completed......................................
2023-11-01 23:55:33,104:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:33,104:INFO:Creating metrics dataframe
2023-11-01 23:55:33,116:INFO:Initializing Random Forest Regressor
2023-11-01 23:55:33,116:INFO:Total runtime is 0.12201588948567708 minutes
2023-11-01 23:55:33,121:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:33,122:INFO:Initializing create_model()
2023-11-01 23:55:33,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:33,122:INFO:Checking exceptions
2023-11-01 23:55:33,122:INFO:Importing libraries
2023-11-01 23:55:33,122:INFO:Copying training dataset
2023-11-01 23:55:33,126:INFO:Defining folds
2023-11-01 23:55:33,126:INFO:Declaring metric variables
2023-11-01 23:55:33,129:INFO:Importing untrained model
2023-11-01 23:55:33,133:INFO:Random Forest Regressor Imported successfully
2023-11-01 23:55:33,140:INFO:Starting cross validation
2023-11-01 23:55:33,143:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:33,818:INFO:Calculating mean and std
2023-11-01 23:55:33,819:INFO:Creating metrics dataframe
2023-11-01 23:55:33,822:INFO:Uploading results into container
2023-11-01 23:55:33,823:INFO:Uploading model into container now
2023-11-01 23:55:33,823:INFO:_master_model_container: 61
2023-11-01 23:55:33,823:INFO:_display_container: 5
2023-11-01 23:55:33,823:INFO:RandomForestRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:55:33,823:INFO:create_model() successfully completed......................................
2023-11-01 23:55:34,133:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:34,133:INFO:Creating metrics dataframe
2023-11-01 23:55:34,144:INFO:Initializing Extra Trees Regressor
2023-11-01 23:55:34,144:INFO:Total runtime is 0.13914981683095295 minutes
2023-11-01 23:55:34,147:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:34,147:INFO:Initializing create_model()
2023-11-01 23:55:34,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:34,147:INFO:Checking exceptions
2023-11-01 23:55:34,147:INFO:Importing libraries
2023-11-01 23:55:34,147:INFO:Copying training dataset
2023-11-01 23:55:34,151:INFO:Defining folds
2023-11-01 23:55:34,152:INFO:Declaring metric variables
2023-11-01 23:55:34,155:INFO:Importing untrained model
2023-11-01 23:55:34,160:INFO:Extra Trees Regressor Imported successfully
2023-11-01 23:55:34,167:INFO:Starting cross validation
2023-11-01 23:55:34,169:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:34,748:INFO:Calculating mean and std
2023-11-01 23:55:34,749:INFO:Creating metrics dataframe
2023-11-01 23:55:34,751:INFO:Uploading results into container
2023-11-01 23:55:34,751:INFO:Uploading model into container now
2023-11-01 23:55:34,753:INFO:_master_model_container: 62
2023-11-01 23:55:34,753:INFO:_display_container: 5
2023-11-01 23:55:34,753:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:55:34,754:INFO:create_model() successfully completed......................................
2023-11-01 23:55:35,054:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:35,055:INFO:Creating metrics dataframe
2023-11-01 23:55:35,066:INFO:Initializing AdaBoost Regressor
2023-11-01 23:55:35,066:INFO:Total runtime is 0.15452307860056558 minutes
2023-11-01 23:55:35,069:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:35,069:INFO:Initializing create_model()
2023-11-01 23:55:35,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:35,070:INFO:Checking exceptions
2023-11-01 23:55:35,070:INFO:Importing libraries
2023-11-01 23:55:35,070:INFO:Copying training dataset
2023-11-01 23:55:35,075:INFO:Defining folds
2023-11-01 23:55:35,075:INFO:Declaring metric variables
2023-11-01 23:55:35,078:INFO:Importing untrained model
2023-11-01 23:55:35,081:INFO:AdaBoost Regressor Imported successfully
2023-11-01 23:55:35,090:INFO:Starting cross validation
2023-11-01 23:55:35,092:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:35,472:INFO:Calculating mean and std
2023-11-01 23:55:35,473:INFO:Creating metrics dataframe
2023-11-01 23:55:35,476:INFO:Uploading results into container
2023-11-01 23:55:35,476:INFO:Uploading model into container now
2023-11-01 23:55:35,477:INFO:_master_model_container: 63
2023-11-01 23:55:35,477:INFO:_display_container: 5
2023-11-01 23:55:35,477:INFO:AdaBoostRegressor(random_state=1122)
2023-11-01 23:55:35,477:INFO:create_model() successfully completed......................................
2023-11-01 23:55:35,773:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:35,773:INFO:Creating metrics dataframe
2023-11-01 23:55:35,783:INFO:Initializing Gradient Boosting Regressor
2023-11-01 23:55:35,785:INFO:Total runtime is 0.16649504899978637 minutes
2023-11-01 23:55:35,790:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:35,790:INFO:Initializing create_model()
2023-11-01 23:55:35,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:35,791:INFO:Checking exceptions
2023-11-01 23:55:35,791:INFO:Importing libraries
2023-11-01 23:55:35,791:INFO:Copying training dataset
2023-11-01 23:55:35,795:INFO:Defining folds
2023-11-01 23:55:35,795:INFO:Declaring metric variables
2023-11-01 23:55:35,797:INFO:Importing untrained model
2023-11-01 23:55:35,801:INFO:Gradient Boosting Regressor Imported successfully
2023-11-01 23:55:35,807:INFO:Starting cross validation
2023-11-01 23:55:35,809:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:36,114:INFO:Calculating mean and std
2023-11-01 23:55:36,116:INFO:Creating metrics dataframe
2023-11-01 23:55:36,120:INFO:Uploading results into container
2023-11-01 23:55:36,121:INFO:Uploading model into container now
2023-11-01 23:55:36,121:INFO:_master_model_container: 64
2023-11-01 23:55:36,122:INFO:_display_container: 5
2023-11-01 23:55:36,122:INFO:GradientBoostingRegressor(random_state=1122)
2023-11-01 23:55:36,122:INFO:create_model() successfully completed......................................
2023-11-01 23:55:36,418:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:36,418:INFO:Creating metrics dataframe
2023-11-01 23:55:36,431:INFO:Initializing Extreme Gradient Boosting
2023-11-01 23:55:36,431:INFO:Total runtime is 0.177266259988149 minutes
2023-11-01 23:55:36,433:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:36,433:INFO:Initializing create_model()
2023-11-01 23:55:36,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:36,434:INFO:Checking exceptions
2023-11-01 23:55:36,434:INFO:Importing libraries
2023-11-01 23:55:36,434:INFO:Copying training dataset
2023-11-01 23:55:36,440:INFO:Defining folds
2023-11-01 23:55:36,440:INFO:Declaring metric variables
2023-11-01 23:55:36,443:INFO:Importing untrained model
2023-11-01 23:55:36,448:INFO:Extreme Gradient Boosting Imported successfully
2023-11-01 23:55:36,454:INFO:Starting cross validation
2023-11-01 23:55:36,456:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:37,099:INFO:Calculating mean and std
2023-11-01 23:55:37,101:INFO:Creating metrics dataframe
2023-11-01 23:55:37,104:INFO:Uploading results into container
2023-11-01 23:55:37,105:INFO:Uploading model into container now
2023-11-01 23:55:37,106:INFO:_master_model_container: 65
2023-11-01 23:55:37,106:INFO:_display_container: 5
2023-11-01 23:55:37,107:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1122, ...)
2023-11-01 23:55:37,107:INFO:create_model() successfully completed......................................
2023-11-01 23:55:37,431:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:37,431:INFO:Creating metrics dataframe
2023-11-01 23:55:37,443:INFO:Initializing Light Gradient Boosting Machine
2023-11-01 23:55:37,444:INFO:Total runtime is 0.1941518505414327 minutes
2023-11-01 23:55:37,448:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:37,448:INFO:Initializing create_model()
2023-11-01 23:55:37,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:37,449:INFO:Checking exceptions
2023-11-01 23:55:37,449:INFO:Importing libraries
2023-11-01 23:55:37,449:INFO:Copying training dataset
2023-11-01 23:55:37,454:INFO:Defining folds
2023-11-01 23:55:37,454:INFO:Declaring metric variables
2023-11-01 23:55:37,458:INFO:Importing untrained model
2023-11-01 23:55:37,463:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-01 23:55:37,471:INFO:Starting cross validation
2023-11-01 23:55:37,475:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:37,980:INFO:Calculating mean and std
2023-11-01 23:55:37,982:INFO:Creating metrics dataframe
2023-11-01 23:55:37,987:INFO:Uploading results into container
2023-11-01 23:55:37,987:INFO:Uploading model into container now
2023-11-01 23:55:37,988:INFO:_master_model_container: 66
2023-11-01 23:55:37,988:INFO:_display_container: 5
2023-11-01 23:55:37,989:INFO:LGBMRegressor(n_jobs=-1, random_state=1122)
2023-11-01 23:55:37,989:INFO:create_model() successfully completed......................................
2023-11-01 23:55:38,295:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:38,295:INFO:Creating metrics dataframe
2023-11-01 23:55:38,304:INFO:Initializing Dummy Regressor
2023-11-01 23:55:38,304:INFO:Total runtime is 0.20848293701807658 minutes
2023-11-01 23:55:38,307:INFO:SubProcess create_model() called ==================================
2023-11-01 23:55:38,307:INFO:Initializing create_model()
2023-11-01 23:55:38,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DBCBA2830>, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:38,307:INFO:Checking exceptions
2023-11-01 23:55:38,308:INFO:Importing libraries
2023-11-01 23:55:38,308:INFO:Copying training dataset
2023-11-01 23:55:38,311:INFO:Defining folds
2023-11-01 23:55:38,311:INFO:Declaring metric variables
2023-11-01 23:55:38,315:INFO:Importing untrained model
2023-11-01 23:55:38,319:INFO:Dummy Regressor Imported successfully
2023-11-01 23:55:38,327:INFO:Starting cross validation
2023-11-01 23:55:38,329:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:55:38,566:INFO:Calculating mean and std
2023-11-01 23:55:38,567:INFO:Creating metrics dataframe
2023-11-01 23:55:38,570:INFO:Uploading results into container
2023-11-01 23:55:38,570:INFO:Uploading model into container now
2023-11-01 23:55:38,571:INFO:_master_model_container: 67
2023-11-01 23:55:38,571:INFO:_display_container: 5
2023-11-01 23:55:38,571:INFO:DummyRegressor()
2023-11-01 23:55:38,571:INFO:create_model() successfully completed......................................
2023-11-01 23:55:38,860:INFO:SubProcess create_model() end ==================================
2023-11-01 23:55:38,860:INFO:Creating metrics dataframe
2023-11-01 23:55:38,881:INFO:Initializing create_model()
2023-11-01 23:55:38,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=OrthogonalMatchingPursuit(), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:38,882:INFO:Checking exceptions
2023-11-01 23:55:38,883:INFO:Importing libraries
2023-11-01 23:55:38,883:INFO:Copying training dataset
2023-11-01 23:55:38,886:INFO:Defining folds
2023-11-01 23:55:38,886:INFO:Declaring metric variables
2023-11-01 23:55:38,886:INFO:Importing untrained model
2023-11-01 23:55:38,886:INFO:Declaring custom model
2023-11-01 23:55:38,887:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:55:38,888:INFO:Cross validation set to False
2023-11-01 23:55:38,888:INFO:Fitting Model
2023-11-01 23:55:38,945:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:55:38,947:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:55:38,947:INFO:create_model() successfully completed......................................
2023-11-01 23:55:39,262:INFO:Initializing create_model()
2023-11-01 23:55:39,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=LassoLars(random_state=1122), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:39,262:INFO:Checking exceptions
2023-11-01 23:55:39,264:INFO:Importing libraries
2023-11-01 23:55:39,264:INFO:Copying training dataset
2023-11-01 23:55:39,267:INFO:Defining folds
2023-11-01 23:55:39,267:INFO:Declaring metric variables
2023-11-01 23:55:39,268:INFO:Importing untrained model
2023-11-01 23:55:39,268:INFO:Declaring custom model
2023-11-01 23:55:39,268:INFO:Lasso Least Angle Regression Imported successfully
2023-11-01 23:55:39,270:INFO:Cross validation set to False
2023-11-01 23:55:39,270:INFO:Fitting Model
2023-11-01 23:55:39,316:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-01 23:55:39,316:INFO:LassoLars(random_state=1122)
2023-11-01 23:55:39,316:INFO:create_model() successfully completed......................................
2023-11-01 23:55:39,623:INFO:Initializing create_model()
2023-11-01 23:55:39,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=Lasso(random_state=1122), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:55:39,624:INFO:Checking exceptions
2023-11-01 23:55:39,626:INFO:Importing libraries
2023-11-01 23:55:39,626:INFO:Copying training dataset
2023-11-01 23:55:39,630:INFO:Defining folds
2023-11-01 23:55:39,630:INFO:Declaring metric variables
2023-11-01 23:55:39,631:INFO:Importing untrained model
2023-11-01 23:55:39,631:INFO:Declaring custom model
2023-11-01 23:55:39,631:INFO:Lasso Regression Imported successfully
2023-11-01 23:55:39,632:INFO:Cross validation set to False
2023-11-01 23:55:39,632:INFO:Fitting Model
2023-11-01 23:55:39,688:INFO:Lasso(random_state=1122)
2023-11-01 23:55:39,688:INFO:create_model() successfully completed......................................
2023-11-01 23:55:40,010:INFO:_master_model_container: 67
2023-11-01 23:55:40,010:INFO:_display_container: 5
2023-11-01 23:55:40,011:INFO:[OrthogonalMatchingPursuit(), LassoLars(random_state=1122), Lasso(random_state=1122)]
2023-11-01 23:55:40,011:INFO:compare_models() successfully completed......................................
2023-11-01 23:56:47,251:INFO:Initializing create_model()
2023-11-01 23:56:47,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-01 23:56:47,252:INFO:Checking exceptions
2023-11-01 23:56:47,284:INFO:Importing libraries
2023-11-01 23:56:47,284:INFO:Copying training dataset
2023-11-01 23:56:47,287:INFO:Defining folds
2023-11-01 23:56:47,288:INFO:Declaring metric variables
2023-11-01 23:56:47,292:INFO:Importing untrained model
2023-11-01 23:56:47,296:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-01 23:56:47,303:INFO:Starting cross validation
2023-11-01 23:56:47,305:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-01 23:56:47,410:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,418:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,432:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,440:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,453:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,489:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,502:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,521:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,573:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,578:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,603:INFO:Calculating mean and std
2023-11-01 23:56:47,603:INFO:Creating metrics dataframe
2023-11-01 23:56:47,608:INFO:Finalizing model
2023-11-01 23:56:47,652:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-01 23:56:47,658:INFO:Uploading results into container
2023-11-01 23:56:47,659:INFO:Uploading model into container now
2023-11-01 23:56:47,667:INFO:_master_model_container: 68
2023-11-01 23:56:47,667:INFO:_display_container: 6
2023-11-01 23:56:47,667:INFO:OrthogonalMatchingPursuit()
2023-11-01 23:56:47,668:INFO:create_model() successfully completed......................................
2023-11-01 23:57:27,247:INFO:Initializing plot_model()
2023-11-01 23:57:27,247:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB71A5900>, system=True)
2023-11-01 23:57:27,247:INFO:Checking exceptions
2023-11-01 23:57:27,251:INFO:Preloading libraries
2023-11-01 23:57:27,252:INFO:Copying training dataset
2023-11-01 23:57:27,252:INFO:Plot type: feature
2023-11-01 23:57:27,530:INFO:Visual Rendered Successfully
2023-11-01 23:57:27,850:INFO:plot_model() successfully completed......................................
2023-11-02 00:00:01,171:INFO:PyCaret RegressionExperiment
2023-11-02 00:00:01,171:INFO:Logging name: reg-default-name
2023-11-02 00:00:01,171:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 00:00:01,171:INFO:version 3.1.0
2023-11-02 00:00:01,171:INFO:Initializing setup()
2023-11-02 00:00:01,171:INFO:self.USI: 5237
2023-11-02 00:00:01,171:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-02 00:00:01,171:INFO:Checking environment
2023-11-02 00:00:01,171:INFO:python_version: 3.10.6
2023-11-02 00:00:01,171:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-02 00:00:01,171:INFO:machine: AMD64
2023-11-02 00:00:01,171:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-02 00:00:01,171:INFO:Memory: svmem(total=8273383424, available=630177792, percent=92.4, used=7643205632, free=630177792)
2023-11-02 00:00:01,171:INFO:Physical Core: 4
2023-11-02 00:00:01,171:INFO:Logical Core: 8
2023-11-02 00:00:01,172:INFO:Checking libraries
2023-11-02 00:00:01,172:INFO:System:
2023-11-02 00:00:01,172:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-02 00:00:01,172:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-02 00:00:01,172:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-02 00:00:01,172:INFO:PyCaret required dependencies:
2023-11-02 00:00:01,172:INFO:                 pip: 22.2.1
2023-11-02 00:00:01,172:INFO:          setuptools: 63.2.0
2023-11-02 00:00:01,172:INFO:             pycaret: 3.1.0
2023-11-02 00:00:01,172:INFO:             IPython: 8.4.0
2023-11-02 00:00:01,172:INFO:          ipywidgets: 8.1.1
2023-11-02 00:00:01,172:INFO:                tqdm: 4.66.1
2023-11-02 00:00:01,172:INFO:               numpy: 1.23.2
2023-11-02 00:00:01,172:INFO:              pandas: 1.4.3
2023-11-02 00:00:01,172:INFO:              jinja2: 3.1.2
2023-11-02 00:00:01,172:INFO:               scipy: 1.10.1
2023-11-02 00:00:01,172:INFO:              joblib: 1.2.0
2023-11-02 00:00:01,172:INFO:             sklearn: 1.1.2
2023-11-02 00:00:01,172:INFO:                pyod: 1.1.0
2023-11-02 00:00:01,172:INFO:            imblearn: 0.11.0
2023-11-02 00:00:01,172:INFO:   category_encoders: 2.6.2
2023-11-02 00:00:01,172:INFO:            lightgbm: 4.1.0
2023-11-02 00:00:01,172:INFO:               numba: 0.58.0
2023-11-02 00:00:01,172:INFO:            requests: 2.28.1
2023-11-02 00:00:01,172:INFO:          matplotlib: 3.6.0
2023-11-02 00:00:01,173:INFO:          scikitplot: 0.3.7
2023-11-02 00:00:01,173:INFO:         yellowbrick: 1.5
2023-11-02 00:00:01,173:INFO:              plotly: 5.17.0
2023-11-02 00:00:01,173:INFO:    plotly-resampler: Not installed
2023-11-02 00:00:01,173:INFO:             kaleido: 0.2.1
2023-11-02 00:00:01,173:INFO:           schemdraw: 0.15
2023-11-02 00:00:01,173:INFO:         statsmodels: 0.13.2
2023-11-02 00:00:01,173:INFO:              sktime: 0.21.1
2023-11-02 00:00:01,173:INFO:               tbats: 1.1.3
2023-11-02 00:00:01,173:INFO:            pmdarima: 2.0.3
2023-11-02 00:00:01,173:INFO:              psutil: 5.9.1
2023-11-02 00:00:01,173:INFO:          markupsafe: 2.1.1
2023-11-02 00:00:01,173:INFO:             pickle5: Not installed
2023-11-02 00:00:01,173:INFO:         cloudpickle: 2.2.1
2023-11-02 00:00:01,173:INFO:         deprecation: 2.1.0
2023-11-02 00:00:01,173:INFO:              xxhash: 3.4.1
2023-11-02 00:00:01,173:INFO:           wurlitzer: Not installed
2023-11-02 00:00:01,173:INFO:PyCaret optional dependencies:
2023-11-02 00:00:01,173:INFO:                shap: Not installed
2023-11-02 00:00:01,173:INFO:           interpret: Not installed
2023-11-02 00:00:01,173:INFO:                umap: Not installed
2023-11-02 00:00:01,173:INFO:     ydata_profiling: Not installed
2023-11-02 00:00:01,173:INFO:  explainerdashboard: Not installed
2023-11-02 00:00:01,173:INFO:             autoviz: Not installed
2023-11-02 00:00:01,174:INFO:           fairlearn: Not installed
2023-11-02 00:00:01,174:INFO:          deepchecks: Not installed
2023-11-02 00:00:01,174:INFO:             xgboost: 2.0.0
2023-11-02 00:00:01,174:INFO:            catboost: Not installed
2023-11-02 00:00:01,174:INFO:              kmodes: Not installed
2023-11-02 00:00:01,174:INFO:             mlxtend: Not installed
2023-11-02 00:00:01,174:INFO:       statsforecast: Not installed
2023-11-02 00:00:01,174:INFO:        tune_sklearn: Not installed
2023-11-02 00:00:01,174:INFO:                 ray: Not installed
2023-11-02 00:00:01,174:INFO:            hyperopt: Not installed
2023-11-02 00:00:01,174:INFO:              optuna: Not installed
2023-11-02 00:00:01,174:INFO:               skopt: Not installed
2023-11-02 00:00:01,174:INFO:              mlflow: Not installed
2023-11-02 00:00:01,174:INFO:              gradio: Not installed
2023-11-02 00:00:01,174:INFO:             fastapi: Not installed
2023-11-02 00:00:01,174:INFO:             uvicorn: Not installed
2023-11-02 00:00:01,174:INFO:              m2cgen: Not installed
2023-11-02 00:00:01,174:INFO:           evidently: Not installed
2023-11-02 00:00:01,174:INFO:               fugue: Not installed
2023-11-02 00:00:01,174:INFO:           streamlit: Not installed
2023-11-02 00:00:01,174:INFO:             prophet: 1.1.5
2023-11-02 00:00:01,174:INFO:None
2023-11-02 00:00:01,174:INFO:Set up data.
2023-11-02 00:00:01,183:INFO:Set up folding strategy.
2023-11-02 00:00:01,183:INFO:Set up train/test split.
2023-11-02 00:00:01,188:INFO:Set up index.
2023-11-02 00:00:01,188:INFO:Assigning column types.
2023-11-02 00:00:01,191:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 00:00:01,192:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,197:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,201:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,300:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:01,303:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,309:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,313:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,410:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:01,414:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 00:00:01,419:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,423:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,519:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:01,529:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,534:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,624:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:01,628:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 00:00:01,636:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,737:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:01,749:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,801:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,842:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:01,845:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 00:00:01,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,961:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:01,962:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:01,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:02,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:02,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:00:02,071:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:02,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:02,074:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 00:00:02,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:02,178:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:02,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:02,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:00:02,302:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:02,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:02,307:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 00:00:02,415:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:02,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:02,523:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:02,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:02,527:INFO:Preparing preprocessing pipeline...
2023-11-02 00:00:02,527:INFO:Set up simple imputation.
2023-11-02 00:00:02,529:INFO:Set up encoding of categorical features.
2023-11-02 00:00:02,529:INFO:Set up feature normalization.
2023-11-02 00:00:02,530:INFO:Set up column name cleaning.
2023-11-02 00:00:02,611:INFO:Finished creating preprocessing pipeline.
2023-11-02 00:00:02,622:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'ao'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 00:00:02,622:INFO:Creating final display dataframe.
2023-11-02 00:00:02,830:INFO:Setup _display_container:                     Description             Value
0                    Session id             11222
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (128, 12)
4        Transformed data shape         (128, 25)
5   Transformed train set shape          (89, 25)
6    Transformed test set shape          (39, 25)
7               Ignore features                 5
8              Numeric features                 8
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              5237
2023-11-02 00:00:02,948:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:02,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:03,067:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:00:03,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:00:03,071:INFO:setup() successfully completed in 1.9s...............
2023-11-02 00:00:22,531:INFO:Initializing compare_models()
2023-11-02 00:00:22,531:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-02 00:00:22,532:INFO:Checking exceptions
2023-11-02 00:00:22,533:INFO:Preparing display monitor
2023-11-02 00:00:22,568:INFO:Initializing Linear Regression
2023-11-02 00:00:22,568:INFO:Total runtime is 0.0 minutes
2023-11-02 00:00:22,571:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:22,571:INFO:Initializing create_model()
2023-11-02 00:00:22,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:22,571:INFO:Checking exceptions
2023-11-02 00:00:22,571:INFO:Importing libraries
2023-11-02 00:00:22,572:INFO:Copying training dataset
2023-11-02 00:00:22,575:INFO:Defining folds
2023-11-02 00:00:22,575:INFO:Declaring metric variables
2023-11-02 00:00:22,580:INFO:Importing untrained model
2023-11-02 00:00:22,585:INFO:Linear Regression Imported successfully
2023-11-02 00:00:22,594:INFO:Starting cross validation
2023-11-02 00:00:22,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:22,904:INFO:Calculating mean and std
2023-11-02 00:00:22,904:INFO:Creating metrics dataframe
2023-11-02 00:00:22,911:INFO:Uploading results into container
2023-11-02 00:00:22,912:INFO:Uploading model into container now
2023-11-02 00:00:22,912:INFO:_master_model_container: 1
2023-11-02 00:00:22,912:INFO:_display_container: 2
2023-11-02 00:00:22,913:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:00:22,913:INFO:create_model() successfully completed......................................
2023-11-02 00:00:23,288:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:23,288:INFO:Creating metrics dataframe
2023-11-02 00:00:23,299:INFO:Initializing Lasso Regression
2023-11-02 00:00:23,299:INFO:Total runtime is 0.012192058563232421 minutes
2023-11-02 00:00:23,302:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:23,303:INFO:Initializing create_model()
2023-11-02 00:00:23,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:23,303:INFO:Checking exceptions
2023-11-02 00:00:23,303:INFO:Importing libraries
2023-11-02 00:00:23,303:INFO:Copying training dataset
2023-11-02 00:00:23,307:INFO:Defining folds
2023-11-02 00:00:23,307:INFO:Declaring metric variables
2023-11-02 00:00:23,311:INFO:Importing untrained model
2023-11-02 00:00:23,314:INFO:Lasso Regression Imported successfully
2023-11-02 00:00:23,323:INFO:Starting cross validation
2023-11-02 00:00:23,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:23,589:INFO:Calculating mean and std
2023-11-02 00:00:23,590:INFO:Creating metrics dataframe
2023-11-02 00:00:23,594:INFO:Uploading results into container
2023-11-02 00:00:23,594:INFO:Uploading model into container now
2023-11-02 00:00:23,595:INFO:_master_model_container: 2
2023-11-02 00:00:23,595:INFO:_display_container: 2
2023-11-02 00:00:23,595:INFO:Lasso(random_state=11222)
2023-11-02 00:00:23,595:INFO:create_model() successfully completed......................................
2023-11-02 00:00:24,002:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:24,002:INFO:Creating metrics dataframe
2023-11-02 00:00:24,014:INFO:Initializing Ridge Regression
2023-11-02 00:00:24,015:INFO:Total runtime is 0.024112343788146973 minutes
2023-11-02 00:00:24,016:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:24,016:INFO:Initializing create_model()
2023-11-02 00:00:24,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:24,017:INFO:Checking exceptions
2023-11-02 00:00:24,017:INFO:Importing libraries
2023-11-02 00:00:24,017:INFO:Copying training dataset
2023-11-02 00:00:24,021:INFO:Defining folds
2023-11-02 00:00:24,021:INFO:Declaring metric variables
2023-11-02 00:00:24,025:INFO:Importing untrained model
2023-11-02 00:00:24,031:INFO:Ridge Regression Imported successfully
2023-11-02 00:00:24,037:INFO:Starting cross validation
2023-11-02 00:00:24,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:24,245:INFO:Calculating mean and std
2023-11-02 00:00:24,247:INFO:Creating metrics dataframe
2023-11-02 00:00:24,249:INFO:Uploading results into container
2023-11-02 00:00:24,250:INFO:Uploading model into container now
2023-11-02 00:00:24,250:INFO:_master_model_container: 3
2023-11-02 00:00:24,250:INFO:_display_container: 2
2023-11-02 00:00:24,251:INFO:Ridge(random_state=11222)
2023-11-02 00:00:24,251:INFO:create_model() successfully completed......................................
2023-11-02 00:00:24,560:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:24,560:INFO:Creating metrics dataframe
2023-11-02 00:00:24,568:INFO:Initializing Elastic Net
2023-11-02 00:00:24,568:INFO:Total runtime is 0.03332753181457519 minutes
2023-11-02 00:00:24,572:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:24,572:INFO:Initializing create_model()
2023-11-02 00:00:24,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:24,572:INFO:Checking exceptions
2023-11-02 00:00:24,573:INFO:Importing libraries
2023-11-02 00:00:24,573:INFO:Copying training dataset
2023-11-02 00:00:24,577:INFO:Defining folds
2023-11-02 00:00:24,577:INFO:Declaring metric variables
2023-11-02 00:00:24,580:INFO:Importing untrained model
2023-11-02 00:00:24,585:INFO:Elastic Net Imported successfully
2023-11-02 00:00:24,593:INFO:Starting cross validation
2023-11-02 00:00:24,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:24,780:INFO:Calculating mean and std
2023-11-02 00:00:24,781:INFO:Creating metrics dataframe
2023-11-02 00:00:24,785:INFO:Uploading results into container
2023-11-02 00:00:24,785:INFO:Uploading model into container now
2023-11-02 00:00:24,786:INFO:_master_model_container: 4
2023-11-02 00:00:24,786:INFO:_display_container: 2
2023-11-02 00:00:24,786:INFO:ElasticNet(random_state=11222)
2023-11-02 00:00:24,786:INFO:create_model() successfully completed......................................
2023-11-02 00:00:25,115:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:25,115:INFO:Creating metrics dataframe
2023-11-02 00:00:25,123:INFO:Initializing Least Angle Regression
2023-11-02 00:00:25,123:INFO:Total runtime is 0.042591921488444005 minutes
2023-11-02 00:00:25,127:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:25,127:INFO:Initializing create_model()
2023-11-02 00:00:25,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:25,127:INFO:Checking exceptions
2023-11-02 00:00:25,127:INFO:Importing libraries
2023-11-02 00:00:25,127:INFO:Copying training dataset
2023-11-02 00:00:25,131:INFO:Defining folds
2023-11-02 00:00:25,131:INFO:Declaring metric variables
2023-11-02 00:00:25,134:INFO:Importing untrained model
2023-11-02 00:00:25,139:INFO:Least Angle Regression Imported successfully
2023-11-02 00:00:25,146:INFO:Starting cross validation
2023-11-02 00:00:25,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:25,230:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,233:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,235:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.034e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,236:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.202e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,236:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.271e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,236:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.769e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,236:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.349e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,236:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.500e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.001e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.528e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.585e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.459e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.457e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.411e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.006e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.974e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,238:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.880e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,238:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.935e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,238:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.138e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,237:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.273e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,240:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.241e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,241:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.788e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,242:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.992e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,243:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.498e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,243:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.694e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,243:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.997e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,243:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=6.157e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,247:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,249:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,250:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.876e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,251:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.009e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,251:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.808e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,251:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.287e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,251:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.209e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,251:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.164e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,252:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.255e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,252:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.754e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,252:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.788e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,252:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.679e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,252:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.927e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,253:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,253:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.725e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,254:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.003e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,254:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.728e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,254:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.930e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,254:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.510e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,257:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.763e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,257:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.430e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,257:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.623e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,257:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.352e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,257:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.855e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,267:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,270:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,270:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.581e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,271:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.253e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,271:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.419e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,271:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.104e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,272:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.084e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,273:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.405e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,273:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.610e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,273:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.803e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.307e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.153e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.925e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.942e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.790e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.008e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,274:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.187e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,275:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.245e-07, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,275:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.784e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,275:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.680e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,275:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.250e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,275:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.521e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,322:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,325:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=8.424e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.991e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.939e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.849e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.546e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.508e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.306e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.490e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,326:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.191e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,327:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.042e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,327:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.480e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,327:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.187e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,327:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.671e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,327:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.432e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,327:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.815e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,328:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.108e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,328:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.536e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:00:25,348:INFO:Calculating mean and std
2023-11-02 00:00:25,349:INFO:Creating metrics dataframe
2023-11-02 00:00:25,352:INFO:Uploading results into container
2023-11-02 00:00:25,353:INFO:Uploading model into container now
2023-11-02 00:00:25,353:INFO:_master_model_container: 5
2023-11-02 00:00:25,353:INFO:_display_container: 2
2023-11-02 00:00:25,353:INFO:Lars(random_state=11222)
2023-11-02 00:00:25,353:INFO:create_model() successfully completed......................................
2023-11-02 00:00:25,649:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:25,649:INFO:Creating metrics dataframe
2023-11-02 00:00:25,658:INFO:Initializing Lasso Least Angle Regression
2023-11-02 00:00:25,658:INFO:Total runtime is 0.05150326093037923 minutes
2023-11-02 00:00:25,661:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:25,661:INFO:Initializing create_model()
2023-11-02 00:00:25,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:25,661:INFO:Checking exceptions
2023-11-02 00:00:25,661:INFO:Importing libraries
2023-11-02 00:00:25,661:INFO:Copying training dataset
2023-11-02 00:00:25,665:INFO:Defining folds
2023-11-02 00:00:25,665:INFO:Declaring metric variables
2023-11-02 00:00:25,667:INFO:Importing untrained model
2023-11-02 00:00:25,671:INFO:Lasso Least Angle Regression Imported successfully
2023-11-02 00:00:25,679:INFO:Starting cross validation
2023-11-02 00:00:25,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:25,761:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,775:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,780:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,780:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,783:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,789:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,796:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,811:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,851:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,862:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:00:25,884:INFO:Calculating mean and std
2023-11-02 00:00:25,885:INFO:Creating metrics dataframe
2023-11-02 00:00:25,889:INFO:Uploading results into container
2023-11-02 00:00:25,890:INFO:Uploading model into container now
2023-11-02 00:00:25,890:INFO:_master_model_container: 6
2023-11-02 00:00:25,890:INFO:_display_container: 2
2023-11-02 00:00:25,891:INFO:LassoLars(random_state=11222)
2023-11-02 00:00:25,891:INFO:create_model() successfully completed......................................
2023-11-02 00:00:26,218:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:26,218:INFO:Creating metrics dataframe
2023-11-02 00:00:26,229:INFO:Initializing Orthogonal Matching Pursuit
2023-11-02 00:00:26,229:INFO:Total runtime is 0.06101744174957275 minutes
2023-11-02 00:00:26,231:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:26,232:INFO:Initializing create_model()
2023-11-02 00:00:26,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:26,232:INFO:Checking exceptions
2023-11-02 00:00:26,232:INFO:Importing libraries
2023-11-02 00:00:26,232:INFO:Copying training dataset
2023-11-02 00:00:26,236:INFO:Defining folds
2023-11-02 00:00:26,236:INFO:Declaring metric variables
2023-11-02 00:00:26,240:INFO:Importing untrained model
2023-11-02 00:00:26,246:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:00:26,251:INFO:Starting cross validation
2023-11-02 00:00:26,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:26,339:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,345:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,348:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,349:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,355:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,356:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,360:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,376:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,428:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,430:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:26,452:INFO:Calculating mean and std
2023-11-02 00:00:26,453:INFO:Creating metrics dataframe
2023-11-02 00:00:26,458:INFO:Uploading results into container
2023-11-02 00:00:26,458:INFO:Uploading model into container now
2023-11-02 00:00:26,459:INFO:_master_model_container: 7
2023-11-02 00:00:26,459:INFO:_display_container: 2
2023-11-02 00:00:26,459:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:00:26,459:INFO:create_model() successfully completed......................................
2023-11-02 00:00:26,752:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:26,752:INFO:Creating metrics dataframe
2023-11-02 00:00:26,763:INFO:Initializing Bayesian Ridge
2023-11-02 00:00:26,763:INFO:Total runtime is 0.06991607348124186 minutes
2023-11-02 00:00:26,766:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:26,766:INFO:Initializing create_model()
2023-11-02 00:00:26,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:26,766:INFO:Checking exceptions
2023-11-02 00:00:26,766:INFO:Importing libraries
2023-11-02 00:00:26,767:INFO:Copying training dataset
2023-11-02 00:00:26,770:INFO:Defining folds
2023-11-02 00:00:26,771:INFO:Declaring metric variables
2023-11-02 00:00:26,775:INFO:Importing untrained model
2023-11-02 00:00:26,781:INFO:Bayesian Ridge Imported successfully
2023-11-02 00:00:26,788:INFO:Starting cross validation
2023-11-02 00:00:26,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:26,991:INFO:Calculating mean and std
2023-11-02 00:00:26,992:INFO:Creating metrics dataframe
2023-11-02 00:00:26,994:INFO:Uploading results into container
2023-11-02 00:00:26,995:INFO:Uploading model into container now
2023-11-02 00:00:26,995:INFO:_master_model_container: 8
2023-11-02 00:00:26,995:INFO:_display_container: 2
2023-11-02 00:00:26,995:INFO:BayesianRidge()
2023-11-02 00:00:26,995:INFO:create_model() successfully completed......................................
2023-11-02 00:00:27,299:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:27,299:INFO:Creating metrics dataframe
2023-11-02 00:00:27,308:INFO:Initializing Passive Aggressive Regressor
2023-11-02 00:00:27,308:INFO:Total runtime is 0.07900213797887166 minutes
2023-11-02 00:00:27,312:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:27,312:INFO:Initializing create_model()
2023-11-02 00:00:27,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:27,312:INFO:Checking exceptions
2023-11-02 00:00:27,312:INFO:Importing libraries
2023-11-02 00:00:27,312:INFO:Copying training dataset
2023-11-02 00:00:27,316:INFO:Defining folds
2023-11-02 00:00:27,317:INFO:Declaring metric variables
2023-11-02 00:00:27,319:INFO:Importing untrained model
2023-11-02 00:00:27,324:INFO:Passive Aggressive Regressor Imported successfully
2023-11-02 00:00:27,332:INFO:Starting cross validation
2023-11-02 00:00:27,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:27,424:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,433:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,439:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,440:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,445:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,450:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,452:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,472:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,518:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,518:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:00:27,539:INFO:Calculating mean and std
2023-11-02 00:00:27,540:INFO:Creating metrics dataframe
2023-11-02 00:00:27,543:INFO:Uploading results into container
2023-11-02 00:00:27,543:INFO:Uploading model into container now
2023-11-02 00:00:27,543:INFO:_master_model_container: 9
2023-11-02 00:00:27,544:INFO:_display_container: 2
2023-11-02 00:00:27,544:INFO:PassiveAggressiveRegressor(random_state=11222)
2023-11-02 00:00:27,544:INFO:create_model() successfully completed......................................
2023-11-02 00:00:27,832:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:27,832:INFO:Creating metrics dataframe
2023-11-02 00:00:27,840:INFO:Initializing Huber Regressor
2023-11-02 00:00:27,840:INFO:Total runtime is 0.08787306547164916 minutes
2023-11-02 00:00:27,843:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:27,843:INFO:Initializing create_model()
2023-11-02 00:00:27,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:27,843:INFO:Checking exceptions
2023-11-02 00:00:27,843:INFO:Importing libraries
2023-11-02 00:00:27,844:INFO:Copying training dataset
2023-11-02 00:00:27,848:INFO:Defining folds
2023-11-02 00:00:27,848:INFO:Declaring metric variables
2023-11-02 00:00:27,851:INFO:Importing untrained model
2023-11-02 00:00:27,856:INFO:Huber Regressor Imported successfully
2023-11-02 00:00:27,863:INFO:Starting cross validation
2023-11-02 00:00:27,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:28,159:INFO:Calculating mean and std
2023-11-02 00:00:28,160:INFO:Creating metrics dataframe
2023-11-02 00:00:28,162:INFO:Uploading results into container
2023-11-02 00:00:28,163:INFO:Uploading model into container now
2023-11-02 00:00:28,164:INFO:_master_model_container: 10
2023-11-02 00:00:28,164:INFO:_display_container: 2
2023-11-02 00:00:28,165:INFO:HuberRegressor()
2023-11-02 00:00:28,165:INFO:create_model() successfully completed......................................
2023-11-02 00:00:28,459:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:28,459:INFO:Creating metrics dataframe
2023-11-02 00:00:28,469:INFO:Initializing K Neighbors Regressor
2023-11-02 00:00:28,469:INFO:Total runtime is 0.09835541248321533 minutes
2023-11-02 00:00:28,472:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:28,472:INFO:Initializing create_model()
2023-11-02 00:00:28,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:28,472:INFO:Checking exceptions
2023-11-02 00:00:28,472:INFO:Importing libraries
2023-11-02 00:00:28,473:INFO:Copying training dataset
2023-11-02 00:00:28,477:INFO:Defining folds
2023-11-02 00:00:28,477:INFO:Declaring metric variables
2023-11-02 00:00:28,480:INFO:Importing untrained model
2023-11-02 00:00:28,484:INFO:K Neighbors Regressor Imported successfully
2023-11-02 00:00:28,493:INFO:Starting cross validation
2023-11-02 00:00:28,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:28,702:INFO:Calculating mean and std
2023-11-02 00:00:28,703:INFO:Creating metrics dataframe
2023-11-02 00:00:28,708:INFO:Uploading results into container
2023-11-02 00:00:28,709:INFO:Uploading model into container now
2023-11-02 00:00:28,710:INFO:_master_model_container: 11
2023-11-02 00:00:28,710:INFO:_display_container: 2
2023-11-02 00:00:28,710:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-02 00:00:28,710:INFO:create_model() successfully completed......................................
2023-11-02 00:00:29,064:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:29,065:INFO:Creating metrics dataframe
2023-11-02 00:00:29,073:INFO:Initializing Decision Tree Regressor
2023-11-02 00:00:29,074:INFO:Total runtime is 0.1084388534228007 minutes
2023-11-02 00:00:29,078:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:29,078:INFO:Initializing create_model()
2023-11-02 00:00:29,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:29,079:INFO:Checking exceptions
2023-11-02 00:00:29,079:INFO:Importing libraries
2023-11-02 00:00:29,079:INFO:Copying training dataset
2023-11-02 00:00:29,082:INFO:Defining folds
2023-11-02 00:00:29,083:INFO:Declaring metric variables
2023-11-02 00:00:29,085:INFO:Importing untrained model
2023-11-02 00:00:29,091:INFO:Decision Tree Regressor Imported successfully
2023-11-02 00:00:29,101:INFO:Starting cross validation
2023-11-02 00:00:29,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:29,394:INFO:Calculating mean and std
2023-11-02 00:00:29,395:INFO:Creating metrics dataframe
2023-11-02 00:00:29,397:INFO:Uploading results into container
2023-11-02 00:00:29,397:INFO:Uploading model into container now
2023-11-02 00:00:29,398:INFO:_master_model_container: 12
2023-11-02 00:00:29,398:INFO:_display_container: 2
2023-11-02 00:00:29,398:INFO:DecisionTreeRegressor(random_state=11222)
2023-11-02 00:00:29,399:INFO:create_model() successfully completed......................................
2023-11-02 00:00:29,763:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:29,763:INFO:Creating metrics dataframe
2023-11-02 00:00:29,773:INFO:Initializing Random Forest Regressor
2023-11-02 00:00:29,773:INFO:Total runtime is 0.12009055217107137 minutes
2023-11-02 00:00:29,775:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:29,775:INFO:Initializing create_model()
2023-11-02 00:00:29,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:29,775:INFO:Checking exceptions
2023-11-02 00:00:29,775:INFO:Importing libraries
2023-11-02 00:00:29,777:INFO:Copying training dataset
2023-11-02 00:00:29,780:INFO:Defining folds
2023-11-02 00:00:29,780:INFO:Declaring metric variables
2023-11-02 00:00:29,783:INFO:Importing untrained model
2023-11-02 00:00:29,787:INFO:Random Forest Regressor Imported successfully
2023-11-02 00:00:29,795:INFO:Starting cross validation
2023-11-02 00:00:29,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:30,338:INFO:Calculating mean and std
2023-11-02 00:00:30,339:INFO:Creating metrics dataframe
2023-11-02 00:00:30,342:INFO:Uploading results into container
2023-11-02 00:00:30,343:INFO:Uploading model into container now
2023-11-02 00:00:30,343:INFO:_master_model_container: 13
2023-11-02 00:00:30,343:INFO:_display_container: 2
2023-11-02 00:00:30,344:INFO:RandomForestRegressor(n_jobs=-1, random_state=11222)
2023-11-02 00:00:30,344:INFO:create_model() successfully completed......................................
2023-11-02 00:00:30,630:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:30,630:INFO:Creating metrics dataframe
2023-11-02 00:00:30,644:INFO:Initializing Extra Trees Regressor
2023-11-02 00:00:30,644:INFO:Total runtime is 0.13460113207499186 minutes
2023-11-02 00:00:30,647:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:30,647:INFO:Initializing create_model()
2023-11-02 00:00:30,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:30,647:INFO:Checking exceptions
2023-11-02 00:00:30,647:INFO:Importing libraries
2023-11-02 00:00:30,647:INFO:Copying training dataset
2023-11-02 00:00:30,652:INFO:Defining folds
2023-11-02 00:00:30,652:INFO:Declaring metric variables
2023-11-02 00:00:30,655:INFO:Importing untrained model
2023-11-02 00:00:30,660:INFO:Extra Trees Regressor Imported successfully
2023-11-02 00:00:30,666:INFO:Starting cross validation
2023-11-02 00:00:30,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:31,184:INFO:Calculating mean and std
2023-11-02 00:00:31,185:INFO:Creating metrics dataframe
2023-11-02 00:00:31,188:INFO:Uploading results into container
2023-11-02 00:00:31,189:INFO:Uploading model into container now
2023-11-02 00:00:31,189:INFO:_master_model_container: 14
2023-11-02 00:00:31,189:INFO:_display_container: 2
2023-11-02 00:00:31,190:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=11222)
2023-11-02 00:00:31,190:INFO:create_model() successfully completed......................................
2023-11-02 00:00:31,480:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:31,480:INFO:Creating metrics dataframe
2023-11-02 00:00:31,489:INFO:Initializing AdaBoost Regressor
2023-11-02 00:00:31,490:INFO:Total runtime is 0.1486780047416687 minutes
2023-11-02 00:00:31,493:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:31,493:INFO:Initializing create_model()
2023-11-02 00:00:31,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:31,493:INFO:Checking exceptions
2023-11-02 00:00:31,493:INFO:Importing libraries
2023-11-02 00:00:31,493:INFO:Copying training dataset
2023-11-02 00:00:31,497:INFO:Defining folds
2023-11-02 00:00:31,497:INFO:Declaring metric variables
2023-11-02 00:00:31,500:INFO:Importing untrained model
2023-11-02 00:00:31,505:INFO:AdaBoost Regressor Imported successfully
2023-11-02 00:00:31,513:INFO:Starting cross validation
2023-11-02 00:00:31,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:31,851:INFO:Calculating mean and std
2023-11-02 00:00:31,852:INFO:Creating metrics dataframe
2023-11-02 00:00:31,856:INFO:Uploading results into container
2023-11-02 00:00:31,857:INFO:Uploading model into container now
2023-11-02 00:00:31,858:INFO:_master_model_container: 15
2023-11-02 00:00:31,858:INFO:_display_container: 2
2023-11-02 00:00:31,858:INFO:AdaBoostRegressor(random_state=11222)
2023-11-02 00:00:31,858:INFO:create_model() successfully completed......................................
2023-11-02 00:00:32,149:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:32,149:INFO:Creating metrics dataframe
2023-11-02 00:00:32,160:INFO:Initializing Gradient Boosting Regressor
2023-11-02 00:00:32,160:INFO:Total runtime is 0.1598714868227641 minutes
2023-11-02 00:00:32,163:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:32,163:INFO:Initializing create_model()
2023-11-02 00:00:32,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:32,163:INFO:Checking exceptions
2023-11-02 00:00:32,163:INFO:Importing libraries
2023-11-02 00:00:32,163:INFO:Copying training dataset
2023-11-02 00:00:32,168:INFO:Defining folds
2023-11-02 00:00:32,168:INFO:Declaring metric variables
2023-11-02 00:00:32,172:INFO:Importing untrained model
2023-11-02 00:00:32,175:INFO:Gradient Boosting Regressor Imported successfully
2023-11-02 00:00:32,182:INFO:Starting cross validation
2023-11-02 00:00:32,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:32,456:INFO:Calculating mean and std
2023-11-02 00:00:32,457:INFO:Creating metrics dataframe
2023-11-02 00:00:32,459:INFO:Uploading results into container
2023-11-02 00:00:32,460:INFO:Uploading model into container now
2023-11-02 00:00:32,460:INFO:_master_model_container: 16
2023-11-02 00:00:32,460:INFO:_display_container: 2
2023-11-02 00:00:32,460:INFO:GradientBoostingRegressor(random_state=11222)
2023-11-02 00:00:32,460:INFO:create_model() successfully completed......................................
2023-11-02 00:00:32,746:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:32,746:INFO:Creating metrics dataframe
2023-11-02 00:00:32,757:INFO:Initializing Extreme Gradient Boosting
2023-11-02 00:00:32,759:INFO:Total runtime is 0.16982182661692302 minutes
2023-11-02 00:00:32,762:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:32,762:INFO:Initializing create_model()
2023-11-02 00:00:32,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:32,763:INFO:Checking exceptions
2023-11-02 00:00:32,763:INFO:Importing libraries
2023-11-02 00:00:32,763:INFO:Copying training dataset
2023-11-02 00:00:32,766:INFO:Defining folds
2023-11-02 00:00:32,766:INFO:Declaring metric variables
2023-11-02 00:00:32,769:INFO:Importing untrained model
2023-11-02 00:00:32,775:INFO:Extreme Gradient Boosting Imported successfully
2023-11-02 00:00:32,783:INFO:Starting cross validation
2023-11-02 00:00:32,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:33,364:INFO:Calculating mean and std
2023-11-02 00:00:33,365:INFO:Creating metrics dataframe
2023-11-02 00:00:33,371:INFO:Uploading results into container
2023-11-02 00:00:33,371:INFO:Uploading model into container now
2023-11-02 00:00:33,372:INFO:_master_model_container: 17
2023-11-02 00:00:33,372:INFO:_display_container: 2
2023-11-02 00:00:33,373:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=11222, ...)
2023-11-02 00:00:33,373:INFO:create_model() successfully completed......................................
2023-11-02 00:00:33,729:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:33,729:INFO:Creating metrics dataframe
2023-11-02 00:00:33,739:INFO:Initializing Light Gradient Boosting Machine
2023-11-02 00:00:33,739:INFO:Total runtime is 0.18618548313776653 minutes
2023-11-02 00:00:33,742:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:33,742:INFO:Initializing create_model()
2023-11-02 00:00:33,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:33,742:INFO:Checking exceptions
2023-11-02 00:00:33,742:INFO:Importing libraries
2023-11-02 00:00:33,742:INFO:Copying training dataset
2023-11-02 00:00:33,748:INFO:Defining folds
2023-11-02 00:00:33,748:INFO:Declaring metric variables
2023-11-02 00:00:33,751:INFO:Importing untrained model
2023-11-02 00:00:33,755:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 00:00:33,762:INFO:Starting cross validation
2023-11-02 00:00:33,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:34,188:INFO:Calculating mean and std
2023-11-02 00:00:34,190:INFO:Creating metrics dataframe
2023-11-02 00:00:34,194:INFO:Uploading results into container
2023-11-02 00:00:34,194:INFO:Uploading model into container now
2023-11-02 00:00:34,195:INFO:_master_model_container: 18
2023-11-02 00:00:34,195:INFO:_display_container: 2
2023-11-02 00:00:34,195:INFO:LGBMRegressor(n_jobs=-1, random_state=11222)
2023-11-02 00:00:34,196:INFO:create_model() successfully completed......................................
2023-11-02 00:00:34,499:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:34,499:INFO:Creating metrics dataframe
2023-11-02 00:00:34,509:INFO:Initializing Dummy Regressor
2023-11-02 00:00:34,509:INFO:Total runtime is 0.1990216056505839 minutes
2023-11-02 00:00:34,512:INFO:SubProcess create_model() called ==================================
2023-11-02 00:00:34,512:INFO:Initializing create_model()
2023-11-02 00:00:34,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DB8B16590>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:34,512:INFO:Checking exceptions
2023-11-02 00:00:34,512:INFO:Importing libraries
2023-11-02 00:00:34,512:INFO:Copying training dataset
2023-11-02 00:00:34,515:INFO:Defining folds
2023-11-02 00:00:34,515:INFO:Declaring metric variables
2023-11-02 00:00:34,519:INFO:Importing untrained model
2023-11-02 00:00:34,523:INFO:Dummy Regressor Imported successfully
2023-11-02 00:00:34,533:INFO:Starting cross validation
2023-11-02 00:00:34,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:34,725:INFO:Calculating mean and std
2023-11-02 00:00:34,726:INFO:Creating metrics dataframe
2023-11-02 00:00:34,730:INFO:Uploading results into container
2023-11-02 00:00:34,730:INFO:Uploading model into container now
2023-11-02 00:00:34,731:INFO:_master_model_container: 19
2023-11-02 00:00:34,731:INFO:_display_container: 2
2023-11-02 00:00:34,731:INFO:DummyRegressor()
2023-11-02 00:00:34,731:INFO:create_model() successfully completed......................................
2023-11-02 00:00:35,016:INFO:SubProcess create_model() end ==================================
2023-11-02 00:00:35,016:INFO:Creating metrics dataframe
2023-11-02 00:00:35,037:INFO:Initializing create_model()
2023-11-02 00:00:35,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:35,038:INFO:Checking exceptions
2023-11-02 00:00:35,040:INFO:Importing libraries
2023-11-02 00:00:35,041:INFO:Copying training dataset
2023-11-02 00:00:35,045:INFO:Defining folds
2023-11-02 00:00:35,045:INFO:Declaring metric variables
2023-11-02 00:00:35,045:INFO:Importing untrained model
2023-11-02 00:00:35,045:INFO:Declaring custom model
2023-11-02 00:00:35,046:INFO:Linear Regression Imported successfully
2023-11-02 00:00:35,047:INFO:Cross validation set to False
2023-11-02 00:00:35,047:INFO:Fitting Model
2023-11-02 00:00:35,094:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:00:35,094:INFO:create_model() successfully completed......................................
2023-11-02 00:00:35,419:INFO:_master_model_container: 19
2023-11-02 00:00:35,420:INFO:_display_container: 2
2023-11-02 00:00:35,420:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:00:35,420:INFO:compare_models() successfully completed......................................
2023-11-02 00:00:55,925:INFO:Initializing create_model()
2023-11-02 00:00:55,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:00:55,926:INFO:Checking exceptions
2023-11-02 00:00:55,955:INFO:Importing libraries
2023-11-02 00:00:55,955:INFO:Copying training dataset
2023-11-02 00:00:55,958:INFO:Defining folds
2023-11-02 00:00:55,959:INFO:Declaring metric variables
2023-11-02 00:00:55,962:INFO:Importing untrained model
2023-11-02 00:00:55,965:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:00:55,972:INFO:Starting cross validation
2023-11-02 00:00:55,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:00:56,072:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,124:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,132:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,152:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,160:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,177:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,186:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,200:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,231:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,241:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,275:INFO:Calculating mean and std
2023-11-02 00:00:56,275:INFO:Creating metrics dataframe
2023-11-02 00:00:56,283:INFO:Finalizing model
2023-11-02 00:00:56,344:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:00:56,353:INFO:Uploading results into container
2023-11-02 00:00:56,354:INFO:Uploading model into container now
2023-11-02 00:00:56,365:INFO:_master_model_container: 20
2023-11-02 00:00:56,365:INFO:_display_container: 3
2023-11-02 00:00:56,365:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:00:56,367:INFO:create_model() successfully completed......................................
2023-11-02 00:01:03,895:INFO:Initializing plot_model()
2023-11-02 00:01:03,895:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, system=True)
2023-11-02 00:01:03,895:INFO:Checking exceptions
2023-11-02 00:01:03,899:INFO:Preloading libraries
2023-11-02 00:01:03,900:INFO:Copying training dataset
2023-11-02 00:01:03,900:INFO:Plot type: feature
2023-11-02 00:01:04,111:INFO:Visual Rendered Successfully
2023-11-02 00:01:04,438:INFO:plot_model() successfully completed......................................
2023-11-02 00:02:31,842:INFO:Initializing predict_model()
2023-11-02 00:02:31,842:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=OrthogonalMatchingPursuit(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DC2524700>)
2023-11-02 00:02:31,842:INFO:Checking exceptions
2023-11-02 00:02:31,842:INFO:Preloading libraries
2023-11-02 00:05:02,956:INFO:Initializing ensemble_model()
2023-11-02 00:05:02,956:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=OrthogonalMatchingPursuit(), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-02 00:05:02,956:INFO:Checking exceptions
2023-11-02 00:05:02,991:INFO:Importing libraries
2023-11-02 00:05:02,991:INFO:Copying training dataset
2023-11-02 00:05:02,991:INFO:Checking base model
2023-11-02 00:05:02,992:INFO:Base model : Orthogonal Matching Pursuit
2023-11-02 00:05:03,001:INFO:Importing untrained ensembler
2023-11-02 00:05:03,002:INFO:Ensemble method set to Bagging
2023-11-02 00:05:03,002:INFO:SubProcess create_model() called ==================================
2023-11-02 00:05:03,003:INFO:Initializing create_model()
2023-11-02 00:05:03,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=BaggingRegressor(base_estimator=OrthogonalMatchingPursuit(), random_state=11222), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC2ACB370>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:05:03,003:INFO:Checking exceptions
2023-11-02 00:05:03,003:INFO:Importing libraries
2023-11-02 00:05:03,003:INFO:Copying training dataset
2023-11-02 00:05:03,008:INFO:Defining folds
2023-11-02 00:05:03,008:INFO:Declaring metric variables
2023-11-02 00:05:03,012:INFO:Importing untrained model
2023-11-02 00:05:03,013:INFO:Declaring custom model
2023-11-02 00:05:03,022:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:05:03,031:INFO:Starting cross validation
2023-11-02 00:05:03,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:05:03,151:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,154:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,155:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,156:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,158:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,160:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,161:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,162:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,162:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,165:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,165:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,165:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,167:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,167:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,167:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,168:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,169:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,169:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,170:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,171:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,171:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,172:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,172:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,173:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,174:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,174:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,175:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,176:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,176:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,178:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,179:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,179:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,180:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,181:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,181:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,182:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,183:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,184:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,184:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,187:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,187:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,192:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,196:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,194:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,199:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,199:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,201:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,202:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,203:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,205:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,207:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,209:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,210:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,212:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,212:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,212:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,214:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,214:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,215:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,217:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,218:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,219:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,220:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,221:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,221:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,223:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,224:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,224:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,225:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,226:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,228:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,231:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,231:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,234:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,236:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,240:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,243:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,333:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,334:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,336:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,338:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,339:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,339:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,340:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,341:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,341:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,342:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,342:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,342:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,344:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,344:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,345:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,346:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,347:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,349:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,350:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,374:INFO:Calculating mean and std
2023-11-02 00:05:03,374:INFO:Creating metrics dataframe
2023-11-02 00:05:03,378:INFO:Finalizing model
2023-11-02 00:05:03,418:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,419:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,420:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,421:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,421:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,422:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,424:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,424:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,425:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,426:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:05:03,432:INFO:Uploading results into container
2023-11-02 00:05:03,433:INFO:Uploading model into container now
2023-11-02 00:05:03,433:INFO:_master_model_container: 21
2023-11-02 00:05:03,433:INFO:_display_container: 5
2023-11-02 00:05:03,434:INFO:BaggingRegressor(base_estimator=OrthogonalMatchingPursuit(), random_state=11222)
2023-11-02 00:05:03,434:INFO:create_model() successfully completed......................................
2023-11-02 00:05:03,745:INFO:SubProcess create_model() end ==================================
2023-11-02 00:05:03,752:INFO:_master_model_container: 21
2023-11-02 00:05:03,752:INFO:_display_container: 5
2023-11-02 00:05:03,752:INFO:BaggingRegressor(base_estimator=OrthogonalMatchingPursuit(), random_state=11222)
2023-11-02 00:05:03,753:INFO:ensemble_model() successfully completed......................................
2023-11-02 00:06:34,524:INFO:Initializing predict_model()
2023-11-02 00:06:34,524:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=OrthogonalMatchingPursuit(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DB8292D40>)
2023-11-02 00:06:34,524:INFO:Checking exceptions
2023-11-02 00:06:34,524:INFO:Preloading libraries
2023-11-02 00:06:34,528:INFO:Set up data.
2023-11-02 00:06:34,539:INFO:Set up index.
2023-11-02 00:08:18,208:INFO:Initializing finalize_model()
2023-11-02 00:08:18,209:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=OrthogonalMatchingPursuit(), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-02 00:08:18,209:INFO:Finalizing OrthogonalMatchingPursuit()
2023-11-02 00:08:18,214:INFO:Initializing create_model()
2023-11-02 00:08:18,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-11-02 00:08:18,214:INFO:Checking exceptions
2023-11-02 00:08:18,216:INFO:Importing libraries
2023-11-02 00:08:18,216:INFO:Copying training dataset
2023-11-02 00:08:18,216:INFO:Defining folds
2023-11-02 00:08:18,216:INFO:Declaring metric variables
2023-11-02 00:08:18,217:INFO:Importing untrained model
2023-11-02 00:08:18,217:INFO:Declaring custom model
2023-11-02 00:08:18,218:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:08:18,220:INFO:Cross validation set to False
2023-11-02 00:08:18,220:INFO:Fitting Model
2023-11-02 00:08:18,267:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:08:18,274:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'ao'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'...
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', OrthogonalMatchingPursuit())])
2023-11-02 00:08:18,274:INFO:create_model() successfully completed......................................
2023-11-02 00:08:18,648:INFO:_master_model_container: 21
2023-11-02 00:08:18,649:INFO:_display_container: 6
2023-11-02 00:08:18,657:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'ao'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'...
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', OrthogonalMatchingPursuit())])
2023-11-02 00:08:18,657:INFO:finalize_model() successfully completed......................................
2023-11-02 00:09:41,556:INFO:Initializing predict_model()
2023-11-02 00:09:41,557:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'ao'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'...
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', OrthogonalMatchingPursuit())]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DC321DBD0>)
2023-11-02 00:09:41,557:INFO:Checking exceptions
2023-11-02 00:09:41,557:INFO:Preloading libraries
2023-11-02 00:09:41,559:INFO:Set up data.
2023-11-02 00:09:41,564:INFO:Set up index.
2023-11-02 00:11:27,541:INFO:Initializing predict_model()
2023-11-02 00:11:27,541:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DB8BCE7A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'ao'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'...
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', OrthogonalMatchingPursuit())]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DB70CA950>)
2023-11-02 00:11:27,541:INFO:Checking exceptions
2023-11-02 00:11:27,541:INFO:Preloading libraries
2023-11-02 00:11:27,543:INFO:Set up data.
2023-11-02 00:11:27,549:INFO:Set up index.
2023-11-02 00:23:56,959:INFO:PyCaret RegressionExperiment
2023-11-02 00:23:56,959:INFO:Logging name: reg-default-name
2023-11-02 00:23:56,959:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 00:23:56,959:INFO:version 3.1.0
2023-11-02 00:23:56,959:INFO:Initializing setup()
2023-11-02 00:23:56,959:INFO:self.USI: c532
2023-11-02 00:23:56,959:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-02 00:23:56,959:INFO:Checking environment
2023-11-02 00:23:56,960:INFO:python_version: 3.10.6
2023-11-02 00:23:56,960:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-02 00:23:56,960:INFO:machine: AMD64
2023-11-02 00:23:56,960:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-02 00:23:56,960:INFO:Memory: svmem(total=8273383424, available=1128656896, percent=86.4, used=7144726528, free=1128656896)
2023-11-02 00:23:56,960:INFO:Physical Core: 4
2023-11-02 00:23:56,960:INFO:Logical Core: 8
2023-11-02 00:23:56,960:INFO:Checking libraries
2023-11-02 00:23:56,960:INFO:System:
2023-11-02 00:23:56,960:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-02 00:23:56,960:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-02 00:23:56,960:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-02 00:23:56,960:INFO:PyCaret required dependencies:
2023-11-02 00:23:56,960:INFO:                 pip: 22.2.1
2023-11-02 00:23:56,960:INFO:          setuptools: 63.2.0
2023-11-02 00:23:56,960:INFO:             pycaret: 3.1.0
2023-11-02 00:23:56,960:INFO:             IPython: 8.4.0
2023-11-02 00:23:56,960:INFO:          ipywidgets: 8.1.1
2023-11-02 00:23:56,960:INFO:                tqdm: 4.66.1
2023-11-02 00:23:56,960:INFO:               numpy: 1.23.2
2023-11-02 00:23:56,960:INFO:              pandas: 1.4.3
2023-11-02 00:23:56,960:INFO:              jinja2: 3.1.2
2023-11-02 00:23:56,960:INFO:               scipy: 1.10.1
2023-11-02 00:23:56,960:INFO:              joblib: 1.2.0
2023-11-02 00:23:56,960:INFO:             sklearn: 1.1.2
2023-11-02 00:23:56,960:INFO:                pyod: 1.1.0
2023-11-02 00:23:56,961:INFO:            imblearn: 0.11.0
2023-11-02 00:23:56,961:INFO:   category_encoders: 2.6.2
2023-11-02 00:23:56,961:INFO:            lightgbm: 4.1.0
2023-11-02 00:23:56,961:INFO:               numba: 0.58.0
2023-11-02 00:23:56,961:INFO:            requests: 2.28.1
2023-11-02 00:23:56,961:INFO:          matplotlib: 3.6.0
2023-11-02 00:23:56,961:INFO:          scikitplot: 0.3.7
2023-11-02 00:23:56,961:INFO:         yellowbrick: 1.5
2023-11-02 00:23:56,961:INFO:              plotly: 5.17.0
2023-11-02 00:23:56,961:INFO:    plotly-resampler: Not installed
2023-11-02 00:23:56,961:INFO:             kaleido: 0.2.1
2023-11-02 00:23:56,961:INFO:           schemdraw: 0.15
2023-11-02 00:23:56,961:INFO:         statsmodels: 0.13.2
2023-11-02 00:23:56,961:INFO:              sktime: 0.21.1
2023-11-02 00:23:56,961:INFO:               tbats: 1.1.3
2023-11-02 00:23:56,961:INFO:            pmdarima: 2.0.3
2023-11-02 00:23:56,961:INFO:              psutil: 5.9.1
2023-11-02 00:23:56,961:INFO:          markupsafe: 2.1.1
2023-11-02 00:23:56,961:INFO:             pickle5: Not installed
2023-11-02 00:23:56,961:INFO:         cloudpickle: 2.2.1
2023-11-02 00:23:56,961:INFO:         deprecation: 2.1.0
2023-11-02 00:23:56,962:INFO:              xxhash: 3.4.1
2023-11-02 00:23:56,962:INFO:           wurlitzer: Not installed
2023-11-02 00:23:56,962:INFO:PyCaret optional dependencies:
2023-11-02 00:23:56,962:INFO:                shap: Not installed
2023-11-02 00:23:56,962:INFO:           interpret: Not installed
2023-11-02 00:23:56,962:INFO:                umap: Not installed
2023-11-02 00:23:56,962:INFO:     ydata_profiling: Not installed
2023-11-02 00:23:56,962:INFO:  explainerdashboard: Not installed
2023-11-02 00:23:56,962:INFO:             autoviz: Not installed
2023-11-02 00:23:56,962:INFO:           fairlearn: Not installed
2023-11-02 00:23:56,962:INFO:          deepchecks: Not installed
2023-11-02 00:23:56,962:INFO:             xgboost: 2.0.0
2023-11-02 00:23:56,962:INFO:            catboost: Not installed
2023-11-02 00:23:56,962:INFO:              kmodes: Not installed
2023-11-02 00:23:56,962:INFO:             mlxtend: Not installed
2023-11-02 00:23:56,962:INFO:       statsforecast: Not installed
2023-11-02 00:23:56,962:INFO:        tune_sklearn: Not installed
2023-11-02 00:23:56,962:INFO:                 ray: Not installed
2023-11-02 00:23:56,962:INFO:            hyperopt: Not installed
2023-11-02 00:23:56,962:INFO:              optuna: Not installed
2023-11-02 00:23:56,962:INFO:               skopt: Not installed
2023-11-02 00:23:56,963:INFO:              mlflow: Not installed
2023-11-02 00:23:56,963:INFO:              gradio: Not installed
2023-11-02 00:23:56,963:INFO:             fastapi: Not installed
2023-11-02 00:23:56,963:INFO:             uvicorn: Not installed
2023-11-02 00:23:56,963:INFO:              m2cgen: Not installed
2023-11-02 00:23:56,963:INFO:           evidently: Not installed
2023-11-02 00:23:56,963:INFO:               fugue: Not installed
2023-11-02 00:23:56,963:INFO:           streamlit: Not installed
2023-11-02 00:23:56,963:INFO:             prophet: 1.1.5
2023-11-02 00:23:56,963:INFO:None
2023-11-02 00:23:56,963:INFO:Set up data.
2023-11-02 00:23:56,969:INFO:Set up folding strategy.
2023-11-02 00:23:56,969:INFO:Set up train/test split.
2023-11-02 00:23:56,969:INFO:Set up data.
2023-11-02 00:23:56,976:INFO:Set up index.
2023-11-02 00:23:56,976:INFO:Assigning column types.
2023-11-02 00:23:56,982:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 00:23:56,983:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:23:56,989:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:23:56,994:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,090:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,093:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,097:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,150:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,190:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,193:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 00:23:57,196:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,201:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,294:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,301:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,386:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,389:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 00:23:57,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,443:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,481:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,543:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,580:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,583:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 00:23:57,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,678:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,735:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,772:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,774:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 00:23:57,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,864:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:23:57,960:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:57,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:57,963:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 00:23:58,064:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:58,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:58,165:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:58,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:58,168:INFO:Preparing preprocessing pipeline...
2023-11-02 00:23:58,169:INFO:Set up simple imputation.
2023-11-02 00:23:58,169:INFO:Set up feature normalization.
2023-11-02 00:23:58,169:INFO:Set up column name cleaning.
2023-11-02 00:23:58,200:INFO:Finished creating preprocessing pipeline.
2023-11-02 00:23:58,205:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'mes', 'ao',
                                             'trimestre'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 00:23:58,205:INFO:Creating final display dataframe.
2023-11-02 00:23:58,292:INFO:Setup _display_container:                     Description             Value
0                    Session id             11222
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (140, 12)
4        Transformed data shape         (140, 11)
5   Transformed train set shape         (128, 11)
6    Transformed test set shape          (12, 11)
7               Ignore features                 5
8              Numeric features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   TimeSeriesSplit
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              c532
2023-11-02 00:23:58,382:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:58,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:58,473:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:23:58,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:23:58,475:INFO:setup() successfully completed in 1.52s...............
2023-11-02 00:24:01,455:INFO:PyCaret RegressionExperiment
2023-11-02 00:24:01,455:INFO:Logging name: reg-default-name
2023-11-02 00:24:01,455:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 00:24:01,455:INFO:version 3.1.0
2023-11-02 00:24:01,456:INFO:Initializing setup()
2023-11-02 00:24:01,456:INFO:self.USI: e6f1
2023-11-02 00:24:01,456:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-02 00:24:01,456:INFO:Checking environment
2023-11-02 00:24:01,456:INFO:python_version: 3.10.6
2023-11-02 00:24:01,456:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-02 00:24:01,456:INFO:machine: AMD64
2023-11-02 00:24:01,456:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-02 00:24:01,456:INFO:Memory: svmem(total=8273383424, available=1102999552, percent=86.7, used=7170383872, free=1102999552)
2023-11-02 00:24:01,456:INFO:Physical Core: 4
2023-11-02 00:24:01,456:INFO:Logical Core: 8
2023-11-02 00:24:01,456:INFO:Checking libraries
2023-11-02 00:24:01,456:INFO:System:
2023-11-02 00:24:01,456:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-02 00:24:01,456:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-02 00:24:01,456:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-02 00:24:01,456:INFO:PyCaret required dependencies:
2023-11-02 00:24:01,456:INFO:                 pip: 22.2.1
2023-11-02 00:24:01,456:INFO:          setuptools: 63.2.0
2023-11-02 00:24:01,457:INFO:             pycaret: 3.1.0
2023-11-02 00:24:01,457:INFO:             IPython: 8.4.0
2023-11-02 00:24:01,457:INFO:          ipywidgets: 8.1.1
2023-11-02 00:24:01,457:INFO:                tqdm: 4.66.1
2023-11-02 00:24:01,457:INFO:               numpy: 1.23.2
2023-11-02 00:24:01,457:INFO:              pandas: 1.4.3
2023-11-02 00:24:01,457:INFO:              jinja2: 3.1.2
2023-11-02 00:24:01,457:INFO:               scipy: 1.10.1
2023-11-02 00:24:01,457:INFO:              joblib: 1.2.0
2023-11-02 00:24:01,457:INFO:             sklearn: 1.1.2
2023-11-02 00:24:01,457:INFO:                pyod: 1.1.0
2023-11-02 00:24:01,457:INFO:            imblearn: 0.11.0
2023-11-02 00:24:01,457:INFO:   category_encoders: 2.6.2
2023-11-02 00:24:01,457:INFO:            lightgbm: 4.1.0
2023-11-02 00:24:01,457:INFO:               numba: 0.58.0
2023-11-02 00:24:01,457:INFO:            requests: 2.28.1
2023-11-02 00:24:01,457:INFO:          matplotlib: 3.6.0
2023-11-02 00:24:01,457:INFO:          scikitplot: 0.3.7
2023-11-02 00:24:01,457:INFO:         yellowbrick: 1.5
2023-11-02 00:24:01,457:INFO:              plotly: 5.17.0
2023-11-02 00:24:01,457:INFO:    plotly-resampler: Not installed
2023-11-02 00:24:01,457:INFO:             kaleido: 0.2.1
2023-11-02 00:24:01,457:INFO:           schemdraw: 0.15
2023-11-02 00:24:01,457:INFO:         statsmodels: 0.13.2
2023-11-02 00:24:01,458:INFO:              sktime: 0.21.1
2023-11-02 00:24:01,458:INFO:               tbats: 1.1.3
2023-11-02 00:24:01,458:INFO:            pmdarima: 2.0.3
2023-11-02 00:24:01,458:INFO:              psutil: 5.9.1
2023-11-02 00:24:01,458:INFO:          markupsafe: 2.1.1
2023-11-02 00:24:01,458:INFO:             pickle5: Not installed
2023-11-02 00:24:01,458:INFO:         cloudpickle: 2.2.1
2023-11-02 00:24:01,458:INFO:         deprecation: 2.1.0
2023-11-02 00:24:01,458:INFO:              xxhash: 3.4.1
2023-11-02 00:24:01,458:INFO:           wurlitzer: Not installed
2023-11-02 00:24:01,458:INFO:PyCaret optional dependencies:
2023-11-02 00:24:01,458:INFO:                shap: Not installed
2023-11-02 00:24:01,458:INFO:           interpret: Not installed
2023-11-02 00:24:01,458:INFO:                umap: Not installed
2023-11-02 00:24:01,458:INFO:     ydata_profiling: Not installed
2023-11-02 00:24:01,458:INFO:  explainerdashboard: Not installed
2023-11-02 00:24:01,458:INFO:             autoviz: Not installed
2023-11-02 00:24:01,458:INFO:           fairlearn: Not installed
2023-11-02 00:24:01,458:INFO:          deepchecks: Not installed
2023-11-02 00:24:01,458:INFO:             xgboost: 2.0.0
2023-11-02 00:24:01,458:INFO:            catboost: Not installed
2023-11-02 00:24:01,458:INFO:              kmodes: Not installed
2023-11-02 00:24:01,458:INFO:             mlxtend: Not installed
2023-11-02 00:24:01,458:INFO:       statsforecast: Not installed
2023-11-02 00:24:01,458:INFO:        tune_sklearn: Not installed
2023-11-02 00:24:01,458:INFO:                 ray: Not installed
2023-11-02 00:24:01,458:INFO:            hyperopt: Not installed
2023-11-02 00:24:01,458:INFO:              optuna: Not installed
2023-11-02 00:24:01,458:INFO:               skopt: Not installed
2023-11-02 00:24:01,459:INFO:              mlflow: Not installed
2023-11-02 00:24:01,459:INFO:              gradio: Not installed
2023-11-02 00:24:01,459:INFO:             fastapi: Not installed
2023-11-02 00:24:01,459:INFO:             uvicorn: Not installed
2023-11-02 00:24:01,459:INFO:              m2cgen: Not installed
2023-11-02 00:24:01,459:INFO:           evidently: Not installed
2023-11-02 00:24:01,459:INFO:               fugue: Not installed
2023-11-02 00:24:01,459:INFO:           streamlit: Not installed
2023-11-02 00:24:01,459:INFO:             prophet: 1.1.5
2023-11-02 00:24:01,459:INFO:None
2023-11-02 00:24:01,459:INFO:Set up data.
2023-11-02 00:24:01,469:INFO:Set up folding strategy.
2023-11-02 00:24:01,469:INFO:Set up train/test split.
2023-11-02 00:24:01,469:INFO:Set up data.
2023-11-02 00:24:01,476:INFO:Set up index.
2023-11-02 00:24:01,477:INFO:Assigning column types.
2023-11-02 00:24:01,481:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 00:24:01,481:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,486:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,492:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,588:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:01,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:01,591:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,595:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,684:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:01,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:01,687:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 00:24:01,690:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,694:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,783:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:01,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:01,789:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,793:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,842:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,879:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:01,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:01,882:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 00:24:01,889:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,942:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:01,979:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:01,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:01,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,037:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,074:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,077:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 00:24:02,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,172:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,270:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,272:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 00:24:02,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,369:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:24:02,467:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,469:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 00:24:02,563:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,663:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,667:INFO:Preparing preprocessing pipeline...
2023-11-02 00:24:02,667:INFO:Set up simple imputation.
2023-11-02 00:24:02,667:INFO:Set up feature normalization.
2023-11-02 00:24:02,668:INFO:Set up column name cleaning.
2023-11-02 00:24:02,691:INFO:Finished creating preprocessing pipeline.
2023-11-02 00:24:02,696:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'mes', 'ao',
                                             'trimestre'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 00:24:02,696:INFO:Creating final display dataframe.
2023-11-02 00:24:02,784:INFO:Setup _display_container:                     Description             Value
0                    Session id           1122233
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (140, 12)
4        Transformed data shape         (140, 11)
5   Transformed train set shape         (128, 11)
6    Transformed test set shape          (12, 11)
7               Ignore features                 5
8              Numeric features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   TimeSeriesSplit
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              e6f1
2023-11-02 00:24:02,877:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,972:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:24:02,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:24:02,975:INFO:setup() successfully completed in 1.52s...............
2023-11-02 00:24:04,927:INFO:Initializing compare_models()
2023-11-02 00:24:04,928:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-02 00:24:04,928:INFO:Checking exceptions
2023-11-02 00:24:04,931:INFO:Preparing display monitor
2023-11-02 00:24:04,965:INFO:Initializing Linear Regression
2023-11-02 00:24:04,966:INFO:Total runtime is 1.6617774963378907e-05 minutes
2023-11-02 00:24:04,971:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:04,972:INFO:Initializing create_model()
2023-11-02 00:24:04,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=lr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:04,972:INFO:Checking exceptions
2023-11-02 00:24:04,972:INFO:Importing libraries
2023-11-02 00:24:04,972:INFO:Copying training dataset
2023-11-02 00:24:04,978:INFO:Defining folds
2023-11-02 00:24:04,978:INFO:Declaring metric variables
2023-11-02 00:24:04,983:INFO:Importing untrained model
2023-11-02 00:24:04,988:INFO:Linear Regression Imported successfully
2023-11-02 00:24:04,997:INFO:Starting cross validation
2023-11-02 00:24:04,999:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:12,093:INFO:Calculating mean and std
2023-11-02 00:24:12,096:INFO:Creating metrics dataframe
2023-11-02 00:24:12,100:INFO:Uploading results into container
2023-11-02 00:24:12,101:INFO:Uploading model into container now
2023-11-02 00:24:12,102:INFO:_master_model_container: 1
2023-11-02 00:24:12,102:INFO:_display_container: 2
2023-11-02 00:24:12,103:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:24:12,103:INFO:create_model() successfully completed......................................
2023-11-02 00:24:13,063:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:13,063:INFO:Creating metrics dataframe
2023-11-02 00:24:13,070:INFO:Initializing Lasso Regression
2023-11-02 00:24:13,071:INFO:Total runtime is 0.13509981632232665 minutes
2023-11-02 00:24:13,075:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:13,075:INFO:Initializing create_model()
2023-11-02 00:24:13,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=lasso, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:13,076:INFO:Checking exceptions
2023-11-02 00:24:13,076:INFO:Importing libraries
2023-11-02 00:24:13,076:INFO:Copying training dataset
2023-11-02 00:24:13,080:INFO:Defining folds
2023-11-02 00:24:13,081:INFO:Declaring metric variables
2023-11-02 00:24:13,085:INFO:Importing untrained model
2023-11-02 00:24:13,089:INFO:Lasso Regression Imported successfully
2023-11-02 00:24:13,097:INFO:Starting cross validation
2023-11-02 00:24:13,099:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:13,212:INFO:Calculating mean and std
2023-11-02 00:24:13,215:INFO:Creating metrics dataframe
2023-11-02 00:24:13,219:INFO:Uploading results into container
2023-11-02 00:24:13,220:INFO:Uploading model into container now
2023-11-02 00:24:13,220:INFO:_master_model_container: 2
2023-11-02 00:24:13,220:INFO:_display_container: 2
2023-11-02 00:24:13,221:INFO:Lasso(random_state=1122233)
2023-11-02 00:24:13,221:INFO:create_model() successfully completed......................................
2023-11-02 00:24:13,643:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:13,643:INFO:Creating metrics dataframe
2023-11-02 00:24:13,654:INFO:Initializing Ridge Regression
2023-11-02 00:24:13,654:INFO:Total runtime is 0.14482024908065794 minutes
2023-11-02 00:24:13,661:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:13,661:INFO:Initializing create_model()
2023-11-02 00:24:13,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=ridge, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:13,661:INFO:Checking exceptions
2023-11-02 00:24:13,661:INFO:Importing libraries
2023-11-02 00:24:13,661:INFO:Copying training dataset
2023-11-02 00:24:13,666:INFO:Defining folds
2023-11-02 00:24:13,666:INFO:Declaring metric variables
2023-11-02 00:24:13,671:INFO:Importing untrained model
2023-11-02 00:24:13,676:INFO:Ridge Regression Imported successfully
2023-11-02 00:24:13,685:INFO:Starting cross validation
2023-11-02 00:24:13,686:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:13,790:INFO:Calculating mean and std
2023-11-02 00:24:13,792:INFO:Creating metrics dataframe
2023-11-02 00:24:13,795:INFO:Uploading results into container
2023-11-02 00:24:13,795:INFO:Uploading model into container now
2023-11-02 00:24:13,796:INFO:_master_model_container: 3
2023-11-02 00:24:13,796:INFO:_display_container: 2
2023-11-02 00:24:13,796:INFO:Ridge(random_state=1122233)
2023-11-02 00:24:13,796:INFO:create_model() successfully completed......................................
2023-11-02 00:24:14,169:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:14,169:INFO:Creating metrics dataframe
2023-11-02 00:24:14,177:INFO:Initializing Elastic Net
2023-11-02 00:24:14,177:INFO:Total runtime is 0.15353577931722004 minutes
2023-11-02 00:24:14,180:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:14,180:INFO:Initializing create_model()
2023-11-02 00:24:14,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=en, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:14,180:INFO:Checking exceptions
2023-11-02 00:24:14,180:INFO:Importing libraries
2023-11-02 00:24:14,181:INFO:Copying training dataset
2023-11-02 00:24:14,185:INFO:Defining folds
2023-11-02 00:24:14,185:INFO:Declaring metric variables
2023-11-02 00:24:14,188:INFO:Importing untrained model
2023-11-02 00:24:14,194:INFO:Elastic Net Imported successfully
2023-11-02 00:24:14,201:INFO:Starting cross validation
2023-11-02 00:24:14,202:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:14,291:INFO:Calculating mean and std
2023-11-02 00:24:14,293:INFO:Creating metrics dataframe
2023-11-02 00:24:14,297:INFO:Uploading results into container
2023-11-02 00:24:14,297:INFO:Uploading model into container now
2023-11-02 00:24:14,298:INFO:_master_model_container: 4
2023-11-02 00:24:14,298:INFO:_display_container: 2
2023-11-02 00:24:14,298:INFO:ElasticNet(random_state=1122233)
2023-11-02 00:24:14,298:INFO:create_model() successfully completed......................................
2023-11-02 00:24:14,647:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:14,647:INFO:Creating metrics dataframe
2023-11-02 00:24:14,655:INFO:Initializing Least Angle Regression
2023-11-02 00:24:14,656:INFO:Total runtime is 0.1615131855010986 minutes
2023-11-02 00:24:14,660:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:14,661:INFO:Initializing create_model()
2023-11-02 00:24:14,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=lar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:14,661:INFO:Checking exceptions
2023-11-02 00:24:14,661:INFO:Importing libraries
2023-11-02 00:24:14,661:INFO:Copying training dataset
2023-11-02 00:24:14,666:INFO:Defining folds
2023-11-02 00:24:14,666:INFO:Declaring metric variables
2023-11-02 00:24:14,669:INFO:Importing untrained model
2023-11-02 00:24:14,673:INFO:Least Angle Regression Imported successfully
2023-11-02 00:24:14,682:INFO:Starting cross validation
2023-11-02 00:24:14,683:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:14,713:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,717:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,719:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,725:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,736:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,741:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,749:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,757:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,763:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,769:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:14,780:INFO:Calculating mean and std
2023-11-02 00:24:14,781:INFO:Creating metrics dataframe
2023-11-02 00:24:14,784:INFO:Uploading results into container
2023-11-02 00:24:14,784:INFO:Uploading model into container now
2023-11-02 00:24:14,785:INFO:_master_model_container: 5
2023-11-02 00:24:14,785:INFO:_display_container: 2
2023-11-02 00:24:14,786:INFO:Lars(random_state=1122233)
2023-11-02 00:24:14,786:INFO:create_model() successfully completed......................................
2023-11-02 00:24:15,130:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:15,130:INFO:Creating metrics dataframe
2023-11-02 00:24:15,139:INFO:Initializing Lasso Least Angle Regression
2023-11-02 00:24:15,139:INFO:Total runtime is 0.16956623395284015 minutes
2023-11-02 00:24:15,144:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:15,144:INFO:Initializing create_model()
2023-11-02 00:24:15,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=llar, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:15,145:INFO:Checking exceptions
2023-11-02 00:24:15,145:INFO:Importing libraries
2023-11-02 00:24:15,145:INFO:Copying training dataset
2023-11-02 00:24:15,149:INFO:Defining folds
2023-11-02 00:24:15,149:INFO:Declaring metric variables
2023-11-02 00:24:15,153:INFO:Importing untrained model
2023-11-02 00:24:15,158:INFO:Lasso Least Angle Regression Imported successfully
2023-11-02 00:24:15,165:INFO:Starting cross validation
2023-11-02 00:24:15,166:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:15,193:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,194:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,199:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,206:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,210:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,226:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,228:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,235:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,242:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:24:15,251:INFO:Calculating mean and std
2023-11-02 00:24:15,252:INFO:Creating metrics dataframe
2023-11-02 00:24:15,254:INFO:Uploading results into container
2023-11-02 00:24:15,256:INFO:Uploading model into container now
2023-11-02 00:24:15,257:INFO:_master_model_container: 6
2023-11-02 00:24:15,257:INFO:_display_container: 2
2023-11-02 00:24:15,258:INFO:LassoLars(random_state=1122233)
2023-11-02 00:24:15,258:INFO:create_model() successfully completed......................................
2023-11-02 00:24:15,601:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:15,601:INFO:Creating metrics dataframe
2023-11-02 00:24:15,610:INFO:Initializing Orthogonal Matching Pursuit
2023-11-02 00:24:15,611:INFO:Total runtime is 0.17742278178532916 minutes
2023-11-02 00:24:15,613:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:15,614:INFO:Initializing create_model()
2023-11-02 00:24:15,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=omp, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:15,614:INFO:Checking exceptions
2023-11-02 00:24:15,614:INFO:Importing libraries
2023-11-02 00:24:15,614:INFO:Copying training dataset
2023-11-02 00:24:15,618:INFO:Defining folds
2023-11-02 00:24:15,618:INFO:Declaring metric variables
2023-11-02 00:24:15,622:INFO:Importing untrained model
2023-11-02 00:24:15,627:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:24:15,634:INFO:Starting cross validation
2023-11-02 00:24:15,636:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:15,666:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,666:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,672:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,678:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,685:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,689:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,697:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,710:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,716:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:24:15,725:INFO:Calculating mean and std
2023-11-02 00:24:15,727:INFO:Creating metrics dataframe
2023-11-02 00:24:15,729:INFO:Uploading results into container
2023-11-02 00:24:15,730:INFO:Uploading model into container now
2023-11-02 00:24:15,730:INFO:_master_model_container: 7
2023-11-02 00:24:15,730:INFO:_display_container: 2
2023-11-02 00:24:15,730:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:24:15,730:INFO:create_model() successfully completed......................................
2023-11-02 00:24:16,067:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:16,067:INFO:Creating metrics dataframe
2023-11-02 00:24:16,077:INFO:Initializing Bayesian Ridge
2023-11-02 00:24:16,077:INFO:Total runtime is 0.18520096540451048 minutes
2023-11-02 00:24:16,080:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:16,080:INFO:Initializing create_model()
2023-11-02 00:24:16,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=br, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:16,080:INFO:Checking exceptions
2023-11-02 00:24:16,081:INFO:Importing libraries
2023-11-02 00:24:16,081:INFO:Copying training dataset
2023-11-02 00:24:16,085:INFO:Defining folds
2023-11-02 00:24:16,085:INFO:Declaring metric variables
2023-11-02 00:24:16,089:INFO:Importing untrained model
2023-11-02 00:24:16,094:INFO:Bayesian Ridge Imported successfully
2023-11-02 00:24:16,103:INFO:Starting cross validation
2023-11-02 00:24:16,105:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:16,187:INFO:Calculating mean and std
2023-11-02 00:24:16,188:INFO:Creating metrics dataframe
2023-11-02 00:24:16,191:INFO:Uploading results into container
2023-11-02 00:24:16,192:INFO:Uploading model into container now
2023-11-02 00:24:16,192:INFO:_master_model_container: 8
2023-11-02 00:24:16,193:INFO:_display_container: 2
2023-11-02 00:24:16,193:INFO:BayesianRidge()
2023-11-02 00:24:16,193:INFO:create_model() successfully completed......................................
2023-11-02 00:24:16,584:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:16,584:INFO:Creating metrics dataframe
2023-11-02 00:24:16,593:INFO:Initializing Passive Aggressive Regressor
2023-11-02 00:24:16,593:INFO:Total runtime is 0.19379952748616533 minutes
2023-11-02 00:24:16,596:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:16,597:INFO:Initializing create_model()
2023-11-02 00:24:16,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=par, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:16,597:INFO:Checking exceptions
2023-11-02 00:24:16,597:INFO:Importing libraries
2023-11-02 00:24:16,597:INFO:Copying training dataset
2023-11-02 00:24:16,601:INFO:Defining folds
2023-11-02 00:24:16,601:INFO:Declaring metric variables
2023-11-02 00:24:16,604:INFO:Importing untrained model
2023-11-02 00:24:16,611:INFO:Passive Aggressive Regressor Imported successfully
2023-11-02 00:24:16,616:INFO:Starting cross validation
2023-11-02 00:24:16,617:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:16,648:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,650:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,658:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,662:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,670:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,677:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,684:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,691:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,697:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,699:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:24:16,707:INFO:Calculating mean and std
2023-11-02 00:24:16,709:INFO:Creating metrics dataframe
2023-11-02 00:24:16,711:INFO:Uploading results into container
2023-11-02 00:24:16,712:INFO:Uploading model into container now
2023-11-02 00:24:16,712:INFO:_master_model_container: 9
2023-11-02 00:24:16,712:INFO:_display_container: 2
2023-11-02 00:24:16,712:INFO:PassiveAggressiveRegressor(random_state=1122233)
2023-11-02 00:24:16,712:INFO:create_model() successfully completed......................................
2023-11-02 00:24:17,042:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:17,042:INFO:Creating metrics dataframe
2023-11-02 00:24:17,051:INFO:Initializing Huber Regressor
2023-11-02 00:24:17,051:INFO:Total runtime is 0.20142539342244462 minutes
2023-11-02 00:24:17,056:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:17,056:INFO:Initializing create_model()
2023-11-02 00:24:17,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=huber, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:17,057:INFO:Checking exceptions
2023-11-02 00:24:17,057:INFO:Importing libraries
2023-11-02 00:24:17,057:INFO:Copying training dataset
2023-11-02 00:24:17,063:INFO:Defining folds
2023-11-02 00:24:17,064:INFO:Declaring metric variables
2023-11-02 00:24:17,067:INFO:Importing untrained model
2023-11-02 00:24:17,072:INFO:Huber Regressor Imported successfully
2023-11-02 00:24:17,079:INFO:Starting cross validation
2023-11-02 00:24:17,080:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:17,184:INFO:Calculating mean and std
2023-11-02 00:24:17,186:INFO:Creating metrics dataframe
2023-11-02 00:24:17,188:INFO:Uploading results into container
2023-11-02 00:24:17,189:INFO:Uploading model into container now
2023-11-02 00:24:17,190:INFO:_master_model_container: 10
2023-11-02 00:24:17,190:INFO:_display_container: 2
2023-11-02 00:24:17,190:INFO:HuberRegressor()
2023-11-02 00:24:17,190:INFO:create_model() successfully completed......................................
2023-11-02 00:24:17,524:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:17,524:INFO:Creating metrics dataframe
2023-11-02 00:24:17,535:INFO:Initializing K Neighbors Regressor
2023-11-02 00:24:17,536:INFO:Total runtime is 0.20951084295908606 minutes
2023-11-02 00:24:17,540:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:17,540:INFO:Initializing create_model()
2023-11-02 00:24:17,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=knn, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:17,540:INFO:Checking exceptions
2023-11-02 00:24:17,540:INFO:Importing libraries
2023-11-02 00:24:17,540:INFO:Copying training dataset
2023-11-02 00:24:17,545:INFO:Defining folds
2023-11-02 00:24:17,546:INFO:Declaring metric variables
2023-11-02 00:24:17,549:INFO:Importing untrained model
2023-11-02 00:24:17,554:INFO:K Neighbors Regressor Imported successfully
2023-11-02 00:24:17,562:INFO:Starting cross validation
2023-11-02 00:24:17,563:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:17,680:INFO:Calculating mean and std
2023-11-02 00:24:17,681:INFO:Creating metrics dataframe
2023-11-02 00:24:17,684:INFO:Uploading results into container
2023-11-02 00:24:17,684:INFO:Uploading model into container now
2023-11-02 00:24:17,685:INFO:_master_model_container: 11
2023-11-02 00:24:17,685:INFO:_display_container: 2
2023-11-02 00:24:17,685:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-02 00:24:17,685:INFO:create_model() successfully completed......................................
2023-11-02 00:24:18,032:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:18,032:INFO:Creating metrics dataframe
2023-11-02 00:24:18,041:INFO:Initializing Decision Tree Regressor
2023-11-02 00:24:18,041:INFO:Total runtime is 0.2179289619127909 minutes
2023-11-02 00:24:18,044:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:18,045:INFO:Initializing create_model()
2023-11-02 00:24:18,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=dt, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:18,045:INFO:Checking exceptions
2023-11-02 00:24:18,045:INFO:Importing libraries
2023-11-02 00:24:18,045:INFO:Copying training dataset
2023-11-02 00:24:18,049:INFO:Defining folds
2023-11-02 00:24:18,050:INFO:Declaring metric variables
2023-11-02 00:24:18,052:INFO:Importing untrained model
2023-11-02 00:24:18,060:INFO:Decision Tree Regressor Imported successfully
2023-11-02 00:24:18,067:INFO:Starting cross validation
2023-11-02 00:24:18,068:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:18,150:INFO:Calculating mean and std
2023-11-02 00:24:18,151:INFO:Creating metrics dataframe
2023-11-02 00:24:18,153:INFO:Uploading results into container
2023-11-02 00:24:18,154:INFO:Uploading model into container now
2023-11-02 00:24:18,155:INFO:_master_model_container: 12
2023-11-02 00:24:18,155:INFO:_display_container: 2
2023-11-02 00:24:18,155:INFO:DecisionTreeRegressor(random_state=1122233)
2023-11-02 00:24:18,155:INFO:create_model() successfully completed......................................
2023-11-02 00:24:18,497:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:18,497:INFO:Creating metrics dataframe
2023-11-02 00:24:18,507:INFO:Initializing Random Forest Regressor
2023-11-02 00:24:18,507:INFO:Total runtime is 0.22569671869277952 minutes
2023-11-02 00:24:18,511:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:18,512:INFO:Initializing create_model()
2023-11-02 00:24:18,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=rf, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:18,512:INFO:Checking exceptions
2023-11-02 00:24:18,512:INFO:Importing libraries
2023-11-02 00:24:18,512:INFO:Copying training dataset
2023-11-02 00:24:18,516:INFO:Defining folds
2023-11-02 00:24:18,516:INFO:Declaring metric variables
2023-11-02 00:24:18,518:INFO:Importing untrained model
2023-11-02 00:24:18,523:INFO:Random Forest Regressor Imported successfully
2023-11-02 00:24:18,529:INFO:Starting cross validation
2023-11-02 00:24:18,530:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:18,945:INFO:Calculating mean and std
2023-11-02 00:24:18,946:INFO:Creating metrics dataframe
2023-11-02 00:24:18,948:INFO:Uploading results into container
2023-11-02 00:24:18,949:INFO:Uploading model into container now
2023-11-02 00:24:18,949:INFO:_master_model_container: 13
2023-11-02 00:24:18,949:INFO:_display_container: 2
2023-11-02 00:24:18,949:INFO:RandomForestRegressor(n_jobs=-1, random_state=1122233)
2023-11-02 00:24:18,949:INFO:create_model() successfully completed......................................
2023-11-02 00:24:19,286:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:19,286:INFO:Creating metrics dataframe
2023-11-02 00:24:19,299:INFO:Initializing Extra Trees Regressor
2023-11-02 00:24:19,299:INFO:Total runtime is 0.2388968269030253 minutes
2023-11-02 00:24:19,301:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:19,302:INFO:Initializing create_model()
2023-11-02 00:24:19,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=et, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:19,302:INFO:Checking exceptions
2023-11-02 00:24:19,302:INFO:Importing libraries
2023-11-02 00:24:19,302:INFO:Copying training dataset
2023-11-02 00:24:19,309:INFO:Defining folds
2023-11-02 00:24:19,309:INFO:Declaring metric variables
2023-11-02 00:24:19,313:INFO:Importing untrained model
2023-11-02 00:24:19,317:INFO:Extra Trees Regressor Imported successfully
2023-11-02 00:24:19,325:INFO:Starting cross validation
2023-11-02 00:24:19,327:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:19,660:INFO:Calculating mean and std
2023-11-02 00:24:19,661:INFO:Creating metrics dataframe
2023-11-02 00:24:19,664:INFO:Uploading results into container
2023-11-02 00:24:19,664:INFO:Uploading model into container now
2023-11-02 00:24:19,665:INFO:_master_model_container: 14
2023-11-02 00:24:19,665:INFO:_display_container: 2
2023-11-02 00:24:19,665:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1122233)
2023-11-02 00:24:19,665:INFO:create_model() successfully completed......................................
2023-11-02 00:24:20,003:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:20,003:INFO:Creating metrics dataframe
2023-11-02 00:24:20,018:INFO:Initializing AdaBoost Regressor
2023-11-02 00:24:20,018:INFO:Total runtime is 0.25088541507720946 minutes
2023-11-02 00:24:20,022:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:20,022:INFO:Initializing create_model()
2023-11-02 00:24:20,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=ada, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:20,023:INFO:Checking exceptions
2023-11-02 00:24:20,023:INFO:Importing libraries
2023-11-02 00:24:20,023:INFO:Copying training dataset
2023-11-02 00:24:20,028:INFO:Defining folds
2023-11-02 00:24:20,028:INFO:Declaring metric variables
2023-11-02 00:24:20,032:INFO:Importing untrained model
2023-11-02 00:24:20,035:INFO:AdaBoost Regressor Imported successfully
2023-11-02 00:24:20,046:INFO:Starting cross validation
2023-11-02 00:24:20,047:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:20,267:INFO:Calculating mean and std
2023-11-02 00:24:20,268:INFO:Creating metrics dataframe
2023-11-02 00:24:20,271:INFO:Uploading results into container
2023-11-02 00:24:20,272:INFO:Uploading model into container now
2023-11-02 00:24:20,272:INFO:_master_model_container: 15
2023-11-02 00:24:20,273:INFO:_display_container: 2
2023-11-02 00:24:20,273:INFO:AdaBoostRegressor(random_state=1122233)
2023-11-02 00:24:20,273:INFO:create_model() successfully completed......................................
2023-11-02 00:24:20,608:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:20,608:INFO:Creating metrics dataframe
2023-11-02 00:24:20,618:INFO:Initializing Gradient Boosting Regressor
2023-11-02 00:24:20,618:INFO:Total runtime is 0.26088358561197916 minutes
2023-11-02 00:24:20,621:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:20,622:INFO:Initializing create_model()
2023-11-02 00:24:20,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=gbr, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:20,622:INFO:Checking exceptions
2023-11-02 00:24:20,622:INFO:Importing libraries
2023-11-02 00:24:20,622:INFO:Copying training dataset
2023-11-02 00:24:20,626:INFO:Defining folds
2023-11-02 00:24:20,626:INFO:Declaring metric variables
2023-11-02 00:24:20,629:INFO:Importing untrained model
2023-11-02 00:24:20,633:INFO:Gradient Boosting Regressor Imported successfully
2023-11-02 00:24:20,642:INFO:Starting cross validation
2023-11-02 00:24:20,643:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:20,788:INFO:Calculating mean and std
2023-11-02 00:24:20,791:INFO:Creating metrics dataframe
2023-11-02 00:24:20,794:INFO:Uploading results into container
2023-11-02 00:24:20,795:INFO:Uploading model into container now
2023-11-02 00:24:20,795:INFO:_master_model_container: 16
2023-11-02 00:24:20,795:INFO:_display_container: 2
2023-11-02 00:24:20,796:INFO:GradientBoostingRegressor(random_state=1122233)
2023-11-02 00:24:20,796:INFO:create_model() successfully completed......................................
2023-11-02 00:24:21,141:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:21,141:INFO:Creating metrics dataframe
2023-11-02 00:24:21,152:INFO:Initializing Extreme Gradient Boosting
2023-11-02 00:24:21,152:INFO:Total runtime is 0.2697757363319397 minutes
2023-11-02 00:24:21,156:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:21,157:INFO:Initializing create_model()
2023-11-02 00:24:21,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=xgboost, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:21,157:INFO:Checking exceptions
2023-11-02 00:24:21,157:INFO:Importing libraries
2023-11-02 00:24:21,157:INFO:Copying training dataset
2023-11-02 00:24:21,162:INFO:Defining folds
2023-11-02 00:24:21,162:INFO:Declaring metric variables
2023-11-02 00:24:21,165:INFO:Importing untrained model
2023-11-02 00:24:21,169:INFO:Extreme Gradient Boosting Imported successfully
2023-11-02 00:24:21,177:INFO:Starting cross validation
2023-11-02 00:24:21,178:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:21,462:INFO:Calculating mean and std
2023-11-02 00:24:21,463:INFO:Creating metrics dataframe
2023-11-02 00:24:21,466:INFO:Uploading results into container
2023-11-02 00:24:21,466:INFO:Uploading model into container now
2023-11-02 00:24:21,467:INFO:_master_model_container: 17
2023-11-02 00:24:21,467:INFO:_display_container: 2
2023-11-02 00:24:21,468:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1122233, ...)
2023-11-02 00:24:21,468:INFO:create_model() successfully completed......................................
2023-11-02 00:24:21,871:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:21,871:INFO:Creating metrics dataframe
2023-11-02 00:24:21,882:INFO:Initializing Light Gradient Boosting Machine
2023-11-02 00:24:21,882:INFO:Total runtime is 0.28194620609283444 minutes
2023-11-02 00:24:21,884:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:21,885:INFO:Initializing create_model()
2023-11-02 00:24:21,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=lightgbm, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:21,885:INFO:Checking exceptions
2023-11-02 00:24:21,885:INFO:Importing libraries
2023-11-02 00:24:21,885:INFO:Copying training dataset
2023-11-02 00:24:21,892:INFO:Defining folds
2023-11-02 00:24:21,892:INFO:Declaring metric variables
2023-11-02 00:24:21,896:INFO:Importing untrained model
2023-11-02 00:24:21,900:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 00:24:21,910:INFO:Starting cross validation
2023-11-02 00:24:21,911:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:22,187:INFO:Calculating mean and std
2023-11-02 00:24:22,190:INFO:Creating metrics dataframe
2023-11-02 00:24:22,196:INFO:Uploading results into container
2023-11-02 00:24:22,197:INFO:Uploading model into container now
2023-11-02 00:24:22,197:INFO:_master_model_container: 18
2023-11-02 00:24:22,197:INFO:_display_container: 2
2023-11-02 00:24:22,198:INFO:LGBMRegressor(n_jobs=-1, random_state=1122233)
2023-11-02 00:24:22,198:INFO:create_model() successfully completed......................................
2023-11-02 00:24:22,567:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:22,567:INFO:Creating metrics dataframe
2023-11-02 00:24:22,579:INFO:Initializing Dummy Regressor
2023-11-02 00:24:22,579:INFO:Total runtime is 0.2935697038968404 minutes
2023-11-02 00:24:22,582:INFO:SubProcess create_model() called ==================================
2023-11-02 00:24:22,582:INFO:Initializing create_model()
2023-11-02 00:24:22,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=dummy, fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC72C1960>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:22,582:INFO:Checking exceptions
2023-11-02 00:24:22,582:INFO:Importing libraries
2023-11-02 00:24:22,582:INFO:Copying training dataset
2023-11-02 00:24:22,587:INFO:Defining folds
2023-11-02 00:24:22,588:INFO:Declaring metric variables
2023-11-02 00:24:22,592:INFO:Importing untrained model
2023-11-02 00:24:22,595:INFO:Dummy Regressor Imported successfully
2023-11-02 00:24:22,603:INFO:Starting cross validation
2023-11-02 00:24:22,605:INFO:Cross validating with TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), n_jobs=-1
2023-11-02 00:24:22,734:INFO:Calculating mean and std
2023-11-02 00:24:22,735:INFO:Creating metrics dataframe
2023-11-02 00:24:22,740:INFO:Uploading results into container
2023-11-02 00:24:22,740:INFO:Uploading model into container now
2023-11-02 00:24:22,741:INFO:_master_model_container: 19
2023-11-02 00:24:22,741:INFO:_display_container: 2
2023-11-02 00:24:22,741:INFO:DummyRegressor()
2023-11-02 00:24:22,741:INFO:create_model() successfully completed......................................
2023-11-02 00:24:23,096:INFO:SubProcess create_model() end ==================================
2023-11-02 00:24:23,096:INFO:Creating metrics dataframe
2023-11-02 00:24:23,115:INFO:Initializing create_model()
2023-11-02 00:24:23,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC729CEB0>, estimator=LinearRegression(n_jobs=-1), fold=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=None), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:24:23,116:INFO:Checking exceptions
2023-11-02 00:24:23,117:INFO:Importing libraries
2023-11-02 00:24:23,117:INFO:Copying training dataset
2023-11-02 00:24:23,123:INFO:Defining folds
2023-11-02 00:24:23,124:INFO:Declaring metric variables
2023-11-02 00:24:23,124:INFO:Importing untrained model
2023-11-02 00:24:23,124:INFO:Declaring custom model
2023-11-02 00:24:23,124:INFO:Linear Regression Imported successfully
2023-11-02 00:24:23,126:INFO:Cross validation set to False
2023-11-02 00:24:23,126:INFO:Fitting Model
2023-11-02 00:24:23,138:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:24:23,138:INFO:create_model() successfully completed......................................
2023-11-02 00:24:23,515:INFO:_master_model_container: 19
2023-11-02 00:24:23,515:INFO:_display_container: 2
2023-11-02 00:24:23,515:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:24:23,515:INFO:compare_models() successfully completed......................................
2023-11-02 00:25:08,377:INFO:PyCaret RegressionExperiment
2023-11-02 00:25:08,377:INFO:Logging name: reg-default-name
2023-11-02 00:25:08,377:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 00:25:08,377:INFO:version 3.1.0
2023-11-02 00:25:08,377:INFO:Initializing setup()
2023-11-02 00:25:08,377:INFO:self.USI: 2abe
2023-11-02 00:25:08,377:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-02 00:25:08,377:INFO:Checking environment
2023-11-02 00:25:08,377:INFO:python_version: 3.10.6
2023-11-02 00:25:08,377:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-02 00:25:08,377:INFO:machine: AMD64
2023-11-02 00:25:08,377:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-02 00:25:08,377:INFO:Memory: svmem(total=8273383424, available=534462464, percent=93.5, used=7738920960, free=534462464)
2023-11-02 00:25:08,378:INFO:Physical Core: 4
2023-11-02 00:25:08,378:INFO:Logical Core: 8
2023-11-02 00:25:08,378:INFO:Checking libraries
2023-11-02 00:25:08,378:INFO:System:
2023-11-02 00:25:08,378:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-02 00:25:08,378:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-02 00:25:08,378:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-02 00:25:08,379:INFO:PyCaret required dependencies:
2023-11-02 00:25:08,379:INFO:                 pip: 22.2.1
2023-11-02 00:25:08,379:INFO:          setuptools: 63.2.0
2023-11-02 00:25:08,379:INFO:             pycaret: 3.1.0
2023-11-02 00:25:08,379:INFO:             IPython: 8.4.0
2023-11-02 00:25:08,379:INFO:          ipywidgets: 8.1.1
2023-11-02 00:25:08,379:INFO:                tqdm: 4.66.1
2023-11-02 00:25:08,379:INFO:               numpy: 1.23.2
2023-11-02 00:25:08,379:INFO:              pandas: 1.4.3
2023-11-02 00:25:08,379:INFO:              jinja2: 3.1.2
2023-11-02 00:25:08,379:INFO:               scipy: 1.10.1
2023-11-02 00:25:08,379:INFO:              joblib: 1.2.0
2023-11-02 00:25:08,379:INFO:             sklearn: 1.1.2
2023-11-02 00:25:08,379:INFO:                pyod: 1.1.0
2023-11-02 00:25:08,379:INFO:            imblearn: 0.11.0
2023-11-02 00:25:08,379:INFO:   category_encoders: 2.6.2
2023-11-02 00:25:08,379:INFO:            lightgbm: 4.1.0
2023-11-02 00:25:08,379:INFO:               numba: 0.58.0
2023-11-02 00:25:08,380:INFO:            requests: 2.28.1
2023-11-02 00:25:08,380:INFO:          matplotlib: 3.6.0
2023-11-02 00:25:08,380:INFO:          scikitplot: 0.3.7
2023-11-02 00:25:08,380:INFO:         yellowbrick: 1.5
2023-11-02 00:25:08,380:INFO:              plotly: 5.17.0
2023-11-02 00:25:08,380:INFO:    plotly-resampler: Not installed
2023-11-02 00:25:08,380:INFO:             kaleido: 0.2.1
2023-11-02 00:25:08,380:INFO:           schemdraw: 0.15
2023-11-02 00:25:08,380:INFO:         statsmodels: 0.13.2
2023-11-02 00:25:08,380:INFO:              sktime: 0.21.1
2023-11-02 00:25:08,380:INFO:               tbats: 1.1.3
2023-11-02 00:25:08,380:INFO:            pmdarima: 2.0.3
2023-11-02 00:25:08,380:INFO:              psutil: 5.9.1
2023-11-02 00:25:08,380:INFO:          markupsafe: 2.1.1
2023-11-02 00:25:08,380:INFO:             pickle5: Not installed
2023-11-02 00:25:08,380:INFO:         cloudpickle: 2.2.1
2023-11-02 00:25:08,380:INFO:         deprecation: 2.1.0
2023-11-02 00:25:08,380:INFO:              xxhash: 3.4.1
2023-11-02 00:25:08,380:INFO:           wurlitzer: Not installed
2023-11-02 00:25:08,380:INFO:PyCaret optional dependencies:
2023-11-02 00:25:08,380:INFO:                shap: Not installed
2023-11-02 00:25:08,380:INFO:           interpret: Not installed
2023-11-02 00:25:08,380:INFO:                umap: Not installed
2023-11-02 00:25:08,380:INFO:     ydata_profiling: Not installed
2023-11-02 00:25:08,380:INFO:  explainerdashboard: Not installed
2023-11-02 00:25:08,381:INFO:             autoviz: Not installed
2023-11-02 00:25:08,381:INFO:           fairlearn: Not installed
2023-11-02 00:25:08,381:INFO:          deepchecks: Not installed
2023-11-02 00:25:08,381:INFO:             xgboost: 2.0.0
2023-11-02 00:25:08,381:INFO:            catboost: Not installed
2023-11-02 00:25:08,381:INFO:              kmodes: Not installed
2023-11-02 00:25:08,381:INFO:             mlxtend: Not installed
2023-11-02 00:25:08,381:INFO:       statsforecast: Not installed
2023-11-02 00:25:08,381:INFO:        tune_sklearn: Not installed
2023-11-02 00:25:08,381:INFO:                 ray: Not installed
2023-11-02 00:25:08,381:INFO:            hyperopt: Not installed
2023-11-02 00:25:08,381:INFO:              optuna: Not installed
2023-11-02 00:25:08,381:INFO:               skopt: Not installed
2023-11-02 00:25:08,381:INFO:              mlflow: Not installed
2023-11-02 00:25:08,381:INFO:              gradio: Not installed
2023-11-02 00:25:08,381:INFO:             fastapi: Not installed
2023-11-02 00:25:08,381:INFO:             uvicorn: Not installed
2023-11-02 00:25:08,381:INFO:              m2cgen: Not installed
2023-11-02 00:25:08,381:INFO:           evidently: Not installed
2023-11-02 00:25:08,381:INFO:               fugue: Not installed
2023-11-02 00:25:08,381:INFO:           streamlit: Not installed
2023-11-02 00:25:08,381:INFO:             prophet: 1.1.5
2023-11-02 00:25:08,381:INFO:None
2023-11-02 00:25:08,381:INFO:Set up data.
2023-11-02 00:25:08,391:INFO:Set up folding strategy.
2023-11-02 00:25:08,391:INFO:Set up train/test split.
2023-11-02 00:25:08,398:INFO:Set up index.
2023-11-02 00:25:08,399:INFO:Assigning column types.
2023-11-02 00:25:08,402:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 00:25:08,402:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,545:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:08,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:08,548:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,553:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,689:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:08,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:08,693:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 00:25:08,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,857:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:08,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:08,867:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:08,998:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,001:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 00:25:09,012:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,132:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,274:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,278:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 00:25:09,355:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,410:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,543:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,547:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 00:25:09,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,678:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:25:09,813:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:09,817:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 00:25:09,949:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:09,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:10,090:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:10,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:10,099:INFO:Preparing preprocessing pipeline...
2023-11-02 00:25:10,099:INFO:Set up simple imputation.
2023-11-02 00:25:10,101:INFO:Set up encoding of categorical features.
2023-11-02 00:25:10,101:INFO:Set up feature normalization.
2023-11-02 00:25:10,101:INFO:Set up column name cleaning.
2023-11-02 00:25:10,166:INFO:Finished creating preprocessing pipeline.
2023-11-02 00:25:10,172:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'ao'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['mes', 'trimestre'],
                                    transformer=OneHotEncoder(cols=['mes',
                                                                    'trimestre'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 00:25:10,172:INFO:Creating final display dataframe.
2023-11-02 00:25:10,330:INFO:Setup _display_container:                     Description             Value
0                    Session id              1122
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (128, 12)
4        Transformed data shape         (128, 25)
5   Transformed train set shape          (89, 25)
6    Transformed test set shape          (39, 25)
7               Ignore features                 5
8              Numeric features                 8
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              2abe
2023-11-02 00:25:10,460:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:10,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:10,601:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:25:10,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:25:10,607:INFO:setup() successfully completed in 2.23s...............
2023-11-02 00:25:14,711:INFO:Initializing compare_models()
2023-11-02 00:25:14,712:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-02 00:25:14,712:INFO:Checking exceptions
2023-11-02 00:25:14,713:INFO:Preparing display monitor
2023-11-02 00:25:14,757:INFO:Initializing Linear Regression
2023-11-02 00:25:14,757:INFO:Total runtime is 0.0 minutes
2023-11-02 00:25:14,761:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:14,762:INFO:Initializing create_model()
2023-11-02 00:25:14,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:14,762:INFO:Checking exceptions
2023-11-02 00:25:14,762:INFO:Importing libraries
2023-11-02 00:25:14,762:INFO:Copying training dataset
2023-11-02 00:25:14,767:INFO:Defining folds
2023-11-02 00:25:14,767:INFO:Declaring metric variables
2023-11-02 00:25:14,772:INFO:Importing untrained model
2023-11-02 00:25:14,777:INFO:Linear Regression Imported successfully
2023-11-02 00:25:14,785:INFO:Starting cross validation
2023-11-02 00:25:14,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:15,424:INFO:Calculating mean and std
2023-11-02 00:25:15,424:INFO:Creating metrics dataframe
2023-11-02 00:25:15,427:INFO:Uploading results into container
2023-11-02 00:25:15,427:INFO:Uploading model into container now
2023-11-02 00:25:15,427:INFO:_master_model_container: 1
2023-11-02 00:25:15,427:INFO:_display_container: 2
2023-11-02 00:25:15,428:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:25:15,428:INFO:create_model() successfully completed......................................
2023-11-02 00:25:15,952:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:15,953:INFO:Creating metrics dataframe
2023-11-02 00:25:15,975:INFO:Initializing Lasso Regression
2023-11-02 00:25:15,976:INFO:Total runtime is 0.020309940973917643 minutes
2023-11-02 00:25:15,981:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:15,981:INFO:Initializing create_model()
2023-11-02 00:25:15,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:15,982:INFO:Checking exceptions
2023-11-02 00:25:15,982:INFO:Importing libraries
2023-11-02 00:25:15,982:INFO:Copying training dataset
2023-11-02 00:25:15,993:INFO:Defining folds
2023-11-02 00:25:15,993:INFO:Declaring metric variables
2023-11-02 00:25:15,998:INFO:Importing untrained model
2023-11-02 00:25:16,005:INFO:Lasso Regression Imported successfully
2023-11-02 00:25:16,015:INFO:Starting cross validation
2023-11-02 00:25:16,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:16,290:INFO:Calculating mean and std
2023-11-02 00:25:16,292:INFO:Creating metrics dataframe
2023-11-02 00:25:16,294:INFO:Uploading results into container
2023-11-02 00:25:16,295:INFO:Uploading model into container now
2023-11-02 00:25:16,295:INFO:_master_model_container: 2
2023-11-02 00:25:16,295:INFO:_display_container: 2
2023-11-02 00:25:16,295:INFO:Lasso(random_state=1122)
2023-11-02 00:25:16,295:INFO:create_model() successfully completed......................................
2023-11-02 00:25:16,667:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:16,667:INFO:Creating metrics dataframe
2023-11-02 00:25:16,681:INFO:Initializing Ridge Regression
2023-11-02 00:25:16,681:INFO:Total runtime is 0.03206443786621094 minutes
2023-11-02 00:25:16,684:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:16,685:INFO:Initializing create_model()
2023-11-02 00:25:16,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:16,686:INFO:Checking exceptions
2023-11-02 00:25:16,686:INFO:Importing libraries
2023-11-02 00:25:16,686:INFO:Copying training dataset
2023-11-02 00:25:16,690:INFO:Defining folds
2023-11-02 00:25:16,690:INFO:Declaring metric variables
2023-11-02 00:25:16,693:INFO:Importing untrained model
2023-11-02 00:25:16,698:INFO:Ridge Regression Imported successfully
2023-11-02 00:25:16,706:INFO:Starting cross validation
2023-11-02 00:25:16,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:16,937:INFO:Calculating mean and std
2023-11-02 00:25:16,939:INFO:Creating metrics dataframe
2023-11-02 00:25:16,941:INFO:Uploading results into container
2023-11-02 00:25:16,941:INFO:Uploading model into container now
2023-11-02 00:25:16,941:INFO:_master_model_container: 3
2023-11-02 00:25:16,941:INFO:_display_container: 2
2023-11-02 00:25:16,942:INFO:Ridge(random_state=1122)
2023-11-02 00:25:16,942:INFO:create_model() successfully completed......................................
2023-11-02 00:25:17,288:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:17,288:INFO:Creating metrics dataframe
2023-11-02 00:25:17,297:INFO:Initializing Elastic Net
2023-11-02 00:25:17,297:INFO:Total runtime is 0.04233881632486979 minutes
2023-11-02 00:25:17,302:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:17,302:INFO:Initializing create_model()
2023-11-02 00:25:17,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:17,303:INFO:Checking exceptions
2023-11-02 00:25:17,303:INFO:Importing libraries
2023-11-02 00:25:17,303:INFO:Copying training dataset
2023-11-02 00:25:17,308:INFO:Defining folds
2023-11-02 00:25:17,308:INFO:Declaring metric variables
2023-11-02 00:25:17,312:INFO:Importing untrained model
2023-11-02 00:25:17,317:INFO:Elastic Net Imported successfully
2023-11-02 00:25:17,324:INFO:Starting cross validation
2023-11-02 00:25:17,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:17,573:INFO:Calculating mean and std
2023-11-02 00:25:17,574:INFO:Creating metrics dataframe
2023-11-02 00:25:17,577:INFO:Uploading results into container
2023-11-02 00:25:17,578:INFO:Uploading model into container now
2023-11-02 00:25:17,578:INFO:_master_model_container: 4
2023-11-02 00:25:17,578:INFO:_display_container: 2
2023-11-02 00:25:17,579:INFO:ElasticNet(random_state=1122)
2023-11-02 00:25:17,579:INFO:create_model() successfully completed......................................
2023-11-02 00:25:17,956:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:17,956:INFO:Creating metrics dataframe
2023-11-02 00:25:17,965:INFO:Initializing Least Angle Regression
2023-11-02 00:25:17,965:INFO:Total runtime is 0.05346277554829915 minutes
2023-11-02 00:25:17,968:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:17,969:INFO:Initializing create_model()
2023-11-02 00:25:17,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:17,970:INFO:Checking exceptions
2023-11-02 00:25:17,970:INFO:Importing libraries
2023-11-02 00:25:17,970:INFO:Copying training dataset
2023-11-02 00:25:17,975:INFO:Defining folds
2023-11-02 00:25:17,975:INFO:Declaring metric variables
2023-11-02 00:25:17,979:INFO:Importing untrained model
2023-11-02 00:25:17,982:INFO:Least Angle Regression Imported successfully
2023-11-02 00:25:17,991:INFO:Starting cross validation
2023-11-02 00:25:17,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:18,098:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,098:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,103:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,106:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.901e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,106:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.973e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,107:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.267e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,107:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.201e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,107:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.621e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,107:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.381e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.812e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.822e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.527e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.066e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.932e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.191e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.041e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,108:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.544e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.023e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.025e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.112e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.307e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.129e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.204e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,112:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,113:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,117:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.615e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,118:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.946e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,119:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.898e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,119:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.425e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,119:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.486e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,119:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.215e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,120:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.336e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,120:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.627e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,120:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.373e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,120:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.336e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,121:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=7.141e-07, with an active set of 21 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,121:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.675e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,121:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.372e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,121:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.510e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,122:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.498e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,122:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.535e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,122:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.504e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,122:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.986e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,123:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.332e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,123:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=7.155e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,129:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.254e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,129:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.226e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,130:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.864e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,130:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.514e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,130:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.309e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,130:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.047e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,131:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.384e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,131:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.310e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,136:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,140:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,141:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.065e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,141:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.990e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,141:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.923e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,142:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.765e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,142:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.909e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,142:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.887e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,142:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.545e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,143:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.017e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,146:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.095e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,146:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,146:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.861e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,146:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.773e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,146:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.267e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,147:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.969e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,153:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.147e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,154:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.794e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,155:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.602e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,155:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.120e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,156:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=8.724e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,156:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.568e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,156:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.771e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,156:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.218e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,213:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,214:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:18,215:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.111e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.972e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.492e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.303e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.746e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.213e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.806e-07, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,216:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.906e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,217:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.851e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,217:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.915e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,217:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.824e-04, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,217:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.065e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-11-02 00:25:18,241:INFO:Calculating mean and std
2023-11-02 00:25:18,243:INFO:Creating metrics dataframe
2023-11-02 00:25:18,245:INFO:Uploading results into container
2023-11-02 00:25:18,245:INFO:Uploading model into container now
2023-11-02 00:25:18,245:INFO:_master_model_container: 5
2023-11-02 00:25:18,246:INFO:_display_container: 2
2023-11-02 00:25:18,246:INFO:Lars(random_state=1122)
2023-11-02 00:25:18,246:INFO:create_model() successfully completed......................................
2023-11-02 00:25:18,598:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:18,598:INFO:Creating metrics dataframe
2023-11-02 00:25:18,607:INFO:Initializing Lasso Least Angle Regression
2023-11-02 00:25:18,607:INFO:Total runtime is 0.06416518688201904 minutes
2023-11-02 00:25:18,609:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:18,610:INFO:Initializing create_model()
2023-11-02 00:25:18,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:18,610:INFO:Checking exceptions
2023-11-02 00:25:18,610:INFO:Importing libraries
2023-11-02 00:25:18,610:INFO:Copying training dataset
2023-11-02 00:25:18,614:INFO:Defining folds
2023-11-02 00:25:18,614:INFO:Declaring metric variables
2023-11-02 00:25:18,617:INFO:Importing untrained model
2023-11-02 00:25:18,623:INFO:Lasso Least Angle Regression Imported successfully
2023-11-02 00:25:18,630:INFO:Starting cross validation
2023-11-02 00:25:18,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:18,715:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,726:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,729:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,731:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,746:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,748:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,769:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,791:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,830:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,846:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:25:18,870:INFO:Calculating mean and std
2023-11-02 00:25:18,871:INFO:Creating metrics dataframe
2023-11-02 00:25:18,873:INFO:Uploading results into container
2023-11-02 00:25:18,874:INFO:Uploading model into container now
2023-11-02 00:25:18,877:INFO:_master_model_container: 6
2023-11-02 00:25:18,877:INFO:_display_container: 2
2023-11-02 00:25:18,877:INFO:LassoLars(random_state=1122)
2023-11-02 00:25:18,877:INFO:create_model() successfully completed......................................
2023-11-02 00:25:19,224:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:19,224:INFO:Creating metrics dataframe
2023-11-02 00:25:19,232:INFO:Initializing Orthogonal Matching Pursuit
2023-11-02 00:25:19,232:INFO:Total runtime is 0.07458115816116333 minutes
2023-11-02 00:25:19,235:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:19,236:INFO:Initializing create_model()
2023-11-02 00:25:19,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:19,236:INFO:Checking exceptions
2023-11-02 00:25:19,236:INFO:Importing libraries
2023-11-02 00:25:19,236:INFO:Copying training dataset
2023-11-02 00:25:19,242:INFO:Defining folds
2023-11-02 00:25:19,242:INFO:Declaring metric variables
2023-11-02 00:25:19,245:INFO:Importing untrained model
2023-11-02 00:25:19,249:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:25:19,259:INFO:Starting cross validation
2023-11-02 00:25:19,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:19,346:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,346:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,351:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,354:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,373:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,381:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,391:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,416:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,455:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,458:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:19,480:INFO:Calculating mean and std
2023-11-02 00:25:19,481:INFO:Creating metrics dataframe
2023-11-02 00:25:19,484:INFO:Uploading results into container
2023-11-02 00:25:19,486:INFO:Uploading model into container now
2023-11-02 00:25:19,487:INFO:_master_model_container: 7
2023-11-02 00:25:19,487:INFO:_display_container: 2
2023-11-02 00:25:19,487:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:25:19,487:INFO:create_model() successfully completed......................................
2023-11-02 00:25:19,882:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:19,882:INFO:Creating metrics dataframe
2023-11-02 00:25:19,894:INFO:Initializing Bayesian Ridge
2023-11-02 00:25:19,894:INFO:Total runtime is 0.08561059633890787 minutes
2023-11-02 00:25:19,898:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:19,898:INFO:Initializing create_model()
2023-11-02 00:25:19,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:19,899:INFO:Checking exceptions
2023-11-02 00:25:19,899:INFO:Importing libraries
2023-11-02 00:25:19,899:INFO:Copying training dataset
2023-11-02 00:25:19,906:INFO:Defining folds
2023-11-02 00:25:19,906:INFO:Declaring metric variables
2023-11-02 00:25:19,912:INFO:Importing untrained model
2023-11-02 00:25:19,915:INFO:Bayesian Ridge Imported successfully
2023-11-02 00:25:19,922:INFO:Starting cross validation
2023-11-02 00:25:19,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:20,199:INFO:Calculating mean and std
2023-11-02 00:25:20,201:INFO:Creating metrics dataframe
2023-11-02 00:25:20,205:INFO:Uploading results into container
2023-11-02 00:25:20,205:INFO:Uploading model into container now
2023-11-02 00:25:20,206:INFO:_master_model_container: 8
2023-11-02 00:25:20,206:INFO:_display_container: 2
2023-11-02 00:25:20,206:INFO:BayesianRidge()
2023-11-02 00:25:20,206:INFO:create_model() successfully completed......................................
2023-11-02 00:25:20,548:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:20,548:INFO:Creating metrics dataframe
2023-11-02 00:25:20,559:INFO:Initializing Passive Aggressive Regressor
2023-11-02 00:25:20,559:INFO:Total runtime is 0.09670224587122599 minutes
2023-11-02 00:25:20,562:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:20,562:INFO:Initializing create_model()
2023-11-02 00:25:20,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:20,563:INFO:Checking exceptions
2023-11-02 00:25:20,563:INFO:Importing libraries
2023-11-02 00:25:20,563:INFO:Copying training dataset
2023-11-02 00:25:20,568:INFO:Defining folds
2023-11-02 00:25:20,568:INFO:Declaring metric variables
2023-11-02 00:25:20,573:INFO:Importing untrained model
2023-11-02 00:25:20,576:INFO:Passive Aggressive Regressor Imported successfully
2023-11-02 00:25:20,583:INFO:Starting cross validation
2023-11-02 00:25:20,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:20,684:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,685:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,697:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,701:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,704:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,706:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,717:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,742:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,793:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,805:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:25:20,826:INFO:Calculating mean and std
2023-11-02 00:25:20,827:INFO:Creating metrics dataframe
2023-11-02 00:25:20,830:INFO:Uploading results into container
2023-11-02 00:25:20,830:INFO:Uploading model into container now
2023-11-02 00:25:20,830:INFO:_master_model_container: 9
2023-11-02 00:25:20,830:INFO:_display_container: 2
2023-11-02 00:25:20,831:INFO:PassiveAggressiveRegressor(random_state=1122)
2023-11-02 00:25:20,831:INFO:create_model() successfully completed......................................
2023-11-02 00:25:21,171:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:21,171:INFO:Creating metrics dataframe
2023-11-02 00:25:21,180:INFO:Initializing Huber Regressor
2023-11-02 00:25:21,180:INFO:Total runtime is 0.10705190896987915 minutes
2023-11-02 00:25:21,183:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:21,183:INFO:Initializing create_model()
2023-11-02 00:25:21,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:21,184:INFO:Checking exceptions
2023-11-02 00:25:21,184:INFO:Importing libraries
2023-11-02 00:25:21,184:INFO:Copying training dataset
2023-11-02 00:25:21,189:INFO:Defining folds
2023-11-02 00:25:21,190:INFO:Declaring metric variables
2023-11-02 00:25:21,193:INFO:Importing untrained model
2023-11-02 00:25:21,198:INFO:Huber Regressor Imported successfully
2023-11-02 00:25:21,206:INFO:Starting cross validation
2023-11-02 00:25:21,208:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:21,457:INFO:Calculating mean and std
2023-11-02 00:25:21,458:INFO:Creating metrics dataframe
2023-11-02 00:25:21,462:INFO:Uploading results into container
2023-11-02 00:25:21,462:INFO:Uploading model into container now
2023-11-02 00:25:21,463:INFO:_master_model_container: 10
2023-11-02 00:25:21,463:INFO:_display_container: 2
2023-11-02 00:25:21,463:INFO:HuberRegressor()
2023-11-02 00:25:21,463:INFO:create_model() successfully completed......................................
2023-11-02 00:25:21,877:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:21,877:INFO:Creating metrics dataframe
2023-11-02 00:25:21,889:INFO:Initializing K Neighbors Regressor
2023-11-02 00:25:21,889:INFO:Total runtime is 0.11886935234069824 minutes
2023-11-02 00:25:21,892:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:21,893:INFO:Initializing create_model()
2023-11-02 00:25:21,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:21,893:INFO:Checking exceptions
2023-11-02 00:25:21,893:INFO:Importing libraries
2023-11-02 00:25:21,893:INFO:Copying training dataset
2023-11-02 00:25:21,897:INFO:Defining folds
2023-11-02 00:25:21,897:INFO:Declaring metric variables
2023-11-02 00:25:21,901:INFO:Importing untrained model
2023-11-02 00:25:21,907:INFO:K Neighbors Regressor Imported successfully
2023-11-02 00:25:21,912:INFO:Starting cross validation
2023-11-02 00:25:21,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:22,393:INFO:Calculating mean and std
2023-11-02 00:25:22,395:INFO:Creating metrics dataframe
2023-11-02 00:25:22,397:INFO:Uploading results into container
2023-11-02 00:25:22,397:INFO:Uploading model into container now
2023-11-02 00:25:22,397:INFO:_master_model_container: 11
2023-11-02 00:25:22,397:INFO:_display_container: 2
2023-11-02 00:25:22,398:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-02 00:25:22,398:INFO:create_model() successfully completed......................................
2023-11-02 00:25:22,764:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:22,764:INFO:Creating metrics dataframe
2023-11-02 00:25:22,776:INFO:Initializing Decision Tree Regressor
2023-11-02 00:25:22,776:INFO:Total runtime is 0.13364437023798625 minutes
2023-11-02 00:25:22,778:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:22,779:INFO:Initializing create_model()
2023-11-02 00:25:22,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:22,779:INFO:Checking exceptions
2023-11-02 00:25:22,779:INFO:Importing libraries
2023-11-02 00:25:22,779:INFO:Copying training dataset
2023-11-02 00:25:22,785:INFO:Defining folds
2023-11-02 00:25:22,786:INFO:Declaring metric variables
2023-11-02 00:25:22,789:INFO:Importing untrained model
2023-11-02 00:25:22,793:INFO:Decision Tree Regressor Imported successfully
2023-11-02 00:25:22,800:INFO:Starting cross validation
2023-11-02 00:25:22,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:23,030:INFO:Calculating mean and std
2023-11-02 00:25:23,031:INFO:Creating metrics dataframe
2023-11-02 00:25:23,034:INFO:Uploading results into container
2023-11-02 00:25:23,035:INFO:Uploading model into container now
2023-11-02 00:25:23,036:INFO:_master_model_container: 12
2023-11-02 00:25:23,036:INFO:_display_container: 2
2023-11-02 00:25:23,037:INFO:DecisionTreeRegressor(random_state=1122)
2023-11-02 00:25:23,037:INFO:create_model() successfully completed......................................
2023-11-02 00:25:23,413:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:23,413:INFO:Creating metrics dataframe
2023-11-02 00:25:23,427:INFO:Initializing Random Forest Regressor
2023-11-02 00:25:23,427:INFO:Total runtime is 0.1445026993751526 minutes
2023-11-02 00:25:23,430:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:23,430:INFO:Initializing create_model()
2023-11-02 00:25:23,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:23,431:INFO:Checking exceptions
2023-11-02 00:25:23,431:INFO:Importing libraries
2023-11-02 00:25:23,431:INFO:Copying training dataset
2023-11-02 00:25:23,437:INFO:Defining folds
2023-11-02 00:25:23,437:INFO:Declaring metric variables
2023-11-02 00:25:23,441:INFO:Importing untrained model
2023-11-02 00:25:23,444:INFO:Random Forest Regressor Imported successfully
2023-11-02 00:25:23,452:INFO:Starting cross validation
2023-11-02 00:25:23,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:24,108:INFO:Calculating mean and std
2023-11-02 00:25:24,110:INFO:Creating metrics dataframe
2023-11-02 00:25:24,112:INFO:Uploading results into container
2023-11-02 00:25:24,112:INFO:Uploading model into container now
2023-11-02 00:25:24,113:INFO:_master_model_container: 13
2023-11-02 00:25:24,113:INFO:_display_container: 2
2023-11-02 00:25:24,113:INFO:RandomForestRegressor(n_jobs=-1, random_state=1122)
2023-11-02 00:25:24,113:INFO:create_model() successfully completed......................................
2023-11-02 00:25:24,477:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:24,477:INFO:Creating metrics dataframe
2023-11-02 00:25:24,487:INFO:Initializing Extra Trees Regressor
2023-11-02 00:25:24,487:INFO:Total runtime is 0.16216005484263102 minutes
2023-11-02 00:25:24,490:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:24,491:INFO:Initializing create_model()
2023-11-02 00:25:24,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:24,491:INFO:Checking exceptions
2023-11-02 00:25:24,491:INFO:Importing libraries
2023-11-02 00:25:24,491:INFO:Copying training dataset
2023-11-02 00:25:24,494:INFO:Defining folds
2023-11-02 00:25:24,495:INFO:Declaring metric variables
2023-11-02 00:25:24,498:INFO:Importing untrained model
2023-11-02 00:25:24,503:INFO:Extra Trees Regressor Imported successfully
2023-11-02 00:25:24,508:INFO:Starting cross validation
2023-11-02 00:25:24,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:25,173:INFO:Calculating mean and std
2023-11-02 00:25:25,174:INFO:Creating metrics dataframe
2023-11-02 00:25:25,177:INFO:Uploading results into container
2023-11-02 00:25:25,177:INFO:Uploading model into container now
2023-11-02 00:25:25,177:INFO:_master_model_container: 14
2023-11-02 00:25:25,178:INFO:_display_container: 2
2023-11-02 00:25:25,178:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1122)
2023-11-02 00:25:25,178:INFO:create_model() successfully completed......................................
2023-11-02 00:25:25,563:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:25,563:INFO:Creating metrics dataframe
2023-11-02 00:25:25,577:INFO:Initializing AdaBoost Regressor
2023-11-02 00:25:25,577:INFO:Total runtime is 0.18033314148585 minutes
2023-11-02 00:25:25,581:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:25,582:INFO:Initializing create_model()
2023-11-02 00:25:25,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:25,582:INFO:Checking exceptions
2023-11-02 00:25:25,583:INFO:Importing libraries
2023-11-02 00:25:25,583:INFO:Copying training dataset
2023-11-02 00:25:25,588:INFO:Defining folds
2023-11-02 00:25:25,588:INFO:Declaring metric variables
2023-11-02 00:25:25,592:INFO:Importing untrained model
2023-11-02 00:25:25,595:INFO:AdaBoost Regressor Imported successfully
2023-11-02 00:25:25,603:INFO:Starting cross validation
2023-11-02 00:25:25,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:25,974:INFO:Calculating mean and std
2023-11-02 00:25:25,975:INFO:Creating metrics dataframe
2023-11-02 00:25:25,978:INFO:Uploading results into container
2023-11-02 00:25:25,979:INFO:Uploading model into container now
2023-11-02 00:25:25,979:INFO:_master_model_container: 15
2023-11-02 00:25:25,979:INFO:_display_container: 2
2023-11-02 00:25:25,979:INFO:AdaBoostRegressor(random_state=1122)
2023-11-02 00:25:25,980:INFO:create_model() successfully completed......................................
2023-11-02 00:25:26,324:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:26,324:INFO:Creating metrics dataframe
2023-11-02 00:25:26,333:INFO:Initializing Gradient Boosting Regressor
2023-11-02 00:25:26,334:INFO:Total runtime is 0.19295312563578287 minutes
2023-11-02 00:25:26,338:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:26,338:INFO:Initializing create_model()
2023-11-02 00:25:26,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:26,338:INFO:Checking exceptions
2023-11-02 00:25:26,338:INFO:Importing libraries
2023-11-02 00:25:26,338:INFO:Copying training dataset
2023-11-02 00:25:26,342:INFO:Defining folds
2023-11-02 00:25:26,342:INFO:Declaring metric variables
2023-11-02 00:25:26,345:INFO:Importing untrained model
2023-11-02 00:25:26,351:INFO:Gradient Boosting Regressor Imported successfully
2023-11-02 00:25:26,360:INFO:Starting cross validation
2023-11-02 00:25:26,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:26,647:INFO:Calculating mean and std
2023-11-02 00:25:26,649:INFO:Creating metrics dataframe
2023-11-02 00:25:26,652:INFO:Uploading results into container
2023-11-02 00:25:26,652:INFO:Uploading model into container now
2023-11-02 00:25:26,653:INFO:_master_model_container: 16
2023-11-02 00:25:26,653:INFO:_display_container: 2
2023-11-02 00:25:26,653:INFO:GradientBoostingRegressor(random_state=1122)
2023-11-02 00:25:26,653:INFO:create_model() successfully completed......................................
2023-11-02 00:25:26,983:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:26,983:INFO:Creating metrics dataframe
2023-11-02 00:25:26,994:INFO:Initializing Extreme Gradient Boosting
2023-11-02 00:25:26,994:INFO:Total runtime is 0.20394572416941326 minutes
2023-11-02 00:25:26,997:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:26,997:INFO:Initializing create_model()
2023-11-02 00:25:26,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:26,997:INFO:Checking exceptions
2023-11-02 00:25:26,997:INFO:Importing libraries
2023-11-02 00:25:26,997:INFO:Copying training dataset
2023-11-02 00:25:27,003:INFO:Defining folds
2023-11-02 00:25:27,003:INFO:Declaring metric variables
2023-11-02 00:25:27,006:INFO:Importing untrained model
2023-11-02 00:25:27,009:INFO:Extreme Gradient Boosting Imported successfully
2023-11-02 00:25:27,019:INFO:Starting cross validation
2023-11-02 00:25:27,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:27,652:INFO:Calculating mean and std
2023-11-02 00:25:27,654:INFO:Creating metrics dataframe
2023-11-02 00:25:27,658:INFO:Uploading results into container
2023-11-02 00:25:27,658:INFO:Uploading model into container now
2023-11-02 00:25:27,658:INFO:_master_model_container: 17
2023-11-02 00:25:27,659:INFO:_display_container: 2
2023-11-02 00:25:27,660:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1122, ...)
2023-11-02 00:25:27,660:INFO:create_model() successfully completed......................................
2023-11-02 00:25:28,003:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:28,003:INFO:Creating metrics dataframe
2023-11-02 00:25:28,013:INFO:Initializing Light Gradient Boosting Machine
2023-11-02 00:25:28,013:INFO:Total runtime is 0.2209266742070516 minutes
2023-11-02 00:25:28,018:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:28,018:INFO:Initializing create_model()
2023-11-02 00:25:28,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:28,019:INFO:Checking exceptions
2023-11-02 00:25:28,019:INFO:Importing libraries
2023-11-02 00:25:28,019:INFO:Copying training dataset
2023-11-02 00:25:28,024:INFO:Defining folds
2023-11-02 00:25:28,024:INFO:Declaring metric variables
2023-11-02 00:25:28,027:INFO:Importing untrained model
2023-11-02 00:25:28,033:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 00:25:28,041:INFO:Starting cross validation
2023-11-02 00:25:28,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:28,504:INFO:Calculating mean and std
2023-11-02 00:25:28,506:INFO:Creating metrics dataframe
2023-11-02 00:25:28,509:INFO:Uploading results into container
2023-11-02 00:25:28,510:INFO:Uploading model into container now
2023-11-02 00:25:28,510:INFO:_master_model_container: 18
2023-11-02 00:25:28,510:INFO:_display_container: 2
2023-11-02 00:25:28,511:INFO:LGBMRegressor(n_jobs=-1, random_state=1122)
2023-11-02 00:25:28,511:INFO:create_model() successfully completed......................................
2023-11-02 00:25:28,888:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:28,888:INFO:Creating metrics dataframe
2023-11-02 00:25:28,897:INFO:Initializing Dummy Regressor
2023-11-02 00:25:28,898:INFO:Total runtime is 0.23567301034927368 minutes
2023-11-02 00:25:28,902:INFO:SubProcess create_model() called ==================================
2023-11-02 00:25:28,902:INFO:Initializing create_model()
2023-11-02 00:25:28,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC6A1E950>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:28,902:INFO:Checking exceptions
2023-11-02 00:25:28,903:INFO:Importing libraries
2023-11-02 00:25:28,903:INFO:Copying training dataset
2023-11-02 00:25:28,907:INFO:Defining folds
2023-11-02 00:25:28,907:INFO:Declaring metric variables
2023-11-02 00:25:28,910:INFO:Importing untrained model
2023-11-02 00:25:28,914:INFO:Dummy Regressor Imported successfully
2023-11-02 00:25:28,922:INFO:Starting cross validation
2023-11-02 00:25:28,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:29,163:INFO:Calculating mean and std
2023-11-02 00:25:29,166:INFO:Creating metrics dataframe
2023-11-02 00:25:29,169:INFO:Uploading results into container
2023-11-02 00:25:29,170:INFO:Uploading model into container now
2023-11-02 00:25:29,170:INFO:_master_model_container: 19
2023-11-02 00:25:29,170:INFO:_display_container: 2
2023-11-02 00:25:29,170:INFO:DummyRegressor()
2023-11-02 00:25:29,170:INFO:create_model() successfully completed......................................
2023-11-02 00:25:29,565:INFO:SubProcess create_model() end ==================================
2023-11-02 00:25:29,565:INFO:Creating metrics dataframe
2023-11-02 00:25:29,587:INFO:Initializing create_model()
2023-11-02 00:25:29,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:29,588:INFO:Checking exceptions
2023-11-02 00:25:29,590:INFO:Importing libraries
2023-11-02 00:25:29,590:INFO:Copying training dataset
2023-11-02 00:25:29,593:INFO:Defining folds
2023-11-02 00:25:29,593:INFO:Declaring metric variables
2023-11-02 00:25:29,593:INFO:Importing untrained model
2023-11-02 00:25:29,593:INFO:Declaring custom model
2023-11-02 00:25:29,594:INFO:Linear Regression Imported successfully
2023-11-02 00:25:29,595:INFO:Cross validation set to False
2023-11-02 00:25:29,595:INFO:Fitting Model
2023-11-02 00:25:29,642:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:25:29,642:INFO:create_model() successfully completed......................................
2023-11-02 00:25:30,041:INFO:_master_model_container: 19
2023-11-02 00:25:30,042:INFO:_display_container: 2
2023-11-02 00:25:30,042:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:25:30,042:INFO:compare_models() successfully completed......................................
2023-11-02 00:25:47,376:INFO:Initializing create_model()
2023-11-02 00:25:47,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:25:47,377:INFO:Checking exceptions
2023-11-02 00:25:47,410:INFO:Importing libraries
2023-11-02 00:25:47,410:INFO:Copying training dataset
2023-11-02 00:25:47,413:INFO:Defining folds
2023-11-02 00:25:47,414:INFO:Declaring metric variables
2023-11-02 00:25:47,417:INFO:Importing untrained model
2023-11-02 00:25:47,420:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:25:47,430:INFO:Starting cross validation
2023-11-02 00:25:47,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:25:47,521:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,532:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,543:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,546:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,555:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,567:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,568:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,612:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,645:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,665:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:25:47,701:INFO:Calculating mean and std
2023-11-02 00:25:47,702:INFO:Creating metrics dataframe
2023-11-02 00:25:47,706:INFO:Finalizing model
2023-11-02 00:25:47,796:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:25:47,809:INFO:Uploading results into container
2023-11-02 00:25:47,810:INFO:Uploading model into container now
2023-11-02 00:25:47,818:INFO:_master_model_container: 20
2023-11-02 00:25:47,819:INFO:_display_container: 3
2023-11-02 00:25:47,819:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:25:47,820:INFO:create_model() successfully completed......................................
2023-11-02 00:25:53,091:INFO:Initializing plot_model()
2023-11-02 00:25:53,091:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=OrthogonalMatchingPursuit(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC740E590>, system=True)
2023-11-02 00:25:53,091:INFO:Checking exceptions
2023-11-02 00:25:53,097:INFO:Preloading libraries
2023-11-02 00:25:53,097:INFO:Copying training dataset
2023-11-02 00:25:53,097:INFO:Plot type: feature
2023-11-02 00:25:53,354:INFO:Visual Rendered Successfully
2023-11-02 00:25:53,719:INFO:plot_model() successfully completed......................................
2023-11-02 00:26:15,017:INFO:PyCaret RegressionExperiment
2023-11-02 00:26:15,017:INFO:Logging name: reg-default-name
2023-11-02 00:26:15,017:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-02 00:26:15,017:INFO:version 3.1.0
2023-11-02 00:26:15,017:INFO:Initializing setup()
2023-11-02 00:26:15,017:INFO:self.USI: dc03
2023-11-02 00:26:15,017:INFO:self._variable_keys: {'X_train', 'memory', 'fold_shuffle_param', 'X', 'X_test', 'exp_name_log', 'exp_id', 'idx', 'USI', '_available_plots', 'logging_param', 'y', 'y_train', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'log_plots_param', 'target_param', 'html_param', 'gpu_param', 'pipeline', 'n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', '_ml_usecase', 'seed'}
2023-11-02 00:26:15,017:INFO:Checking environment
2023-11-02 00:26:15,017:INFO:python_version: 3.10.6
2023-11-02 00:26:15,017:INFO:python_build: ('tags/v3.10.6:9c7b4bd', 'Aug  1 2022 21:53:49')
2023-11-02 00:26:15,017:INFO:machine: AMD64
2023-11-02 00:26:15,017:INFO:platform: Windows-10-10.0.22621-SP0
2023-11-02 00:26:15,017:INFO:Memory: svmem(total=8273383424, available=881987584, percent=89.3, used=7391395840, free=881987584)
2023-11-02 00:26:15,017:INFO:Physical Core: 4
2023-11-02 00:26:15,017:INFO:Logical Core: 8
2023-11-02 00:26:15,017:INFO:Checking libraries
2023-11-02 00:26:15,017:INFO:System:
2023-11-02 00:26:15,017:INFO:    python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
2023-11-02 00:26:15,018:INFO:executable: c:\Users\manue\AppData\Local\Programs\Python\Python310\python.exe
2023-11-02 00:26:15,018:INFO:   machine: Windows-10-10.0.22621-SP0
2023-11-02 00:26:15,018:INFO:PyCaret required dependencies:
2023-11-02 00:26:15,018:INFO:                 pip: 22.2.1
2023-11-02 00:26:15,018:INFO:          setuptools: 63.2.0
2023-11-02 00:26:15,018:INFO:             pycaret: 3.1.0
2023-11-02 00:26:15,018:INFO:             IPython: 8.4.0
2023-11-02 00:26:15,018:INFO:          ipywidgets: 8.1.1
2023-11-02 00:26:15,018:INFO:                tqdm: 4.66.1
2023-11-02 00:26:15,018:INFO:               numpy: 1.23.2
2023-11-02 00:26:15,018:INFO:              pandas: 1.4.3
2023-11-02 00:26:15,018:INFO:              jinja2: 3.1.2
2023-11-02 00:26:15,018:INFO:               scipy: 1.10.1
2023-11-02 00:26:15,018:INFO:              joblib: 1.2.0
2023-11-02 00:26:15,018:INFO:             sklearn: 1.1.2
2023-11-02 00:26:15,018:INFO:                pyod: 1.1.0
2023-11-02 00:26:15,018:INFO:            imblearn: 0.11.0
2023-11-02 00:26:15,018:INFO:   category_encoders: 2.6.2
2023-11-02 00:26:15,018:INFO:            lightgbm: 4.1.0
2023-11-02 00:26:15,018:INFO:               numba: 0.58.0
2023-11-02 00:26:15,018:INFO:            requests: 2.28.1
2023-11-02 00:26:15,018:INFO:          matplotlib: 3.6.0
2023-11-02 00:26:15,018:INFO:          scikitplot: 0.3.7
2023-11-02 00:26:15,018:INFO:         yellowbrick: 1.5
2023-11-02 00:26:15,018:INFO:              plotly: 5.17.0
2023-11-02 00:26:15,018:INFO:    plotly-resampler: Not installed
2023-11-02 00:26:15,018:INFO:             kaleido: 0.2.1
2023-11-02 00:26:15,018:INFO:           schemdraw: 0.15
2023-11-02 00:26:15,018:INFO:         statsmodels: 0.13.2
2023-11-02 00:26:15,018:INFO:              sktime: 0.21.1
2023-11-02 00:26:15,018:INFO:               tbats: 1.1.3
2023-11-02 00:26:15,018:INFO:            pmdarima: 2.0.3
2023-11-02 00:26:15,018:INFO:              psutil: 5.9.1
2023-11-02 00:26:15,018:INFO:          markupsafe: 2.1.1
2023-11-02 00:26:15,018:INFO:             pickle5: Not installed
2023-11-02 00:26:15,018:INFO:         cloudpickle: 2.2.1
2023-11-02 00:26:15,018:INFO:         deprecation: 2.1.0
2023-11-02 00:26:15,018:INFO:              xxhash: 3.4.1
2023-11-02 00:26:15,018:INFO:           wurlitzer: Not installed
2023-11-02 00:26:15,018:INFO:PyCaret optional dependencies:
2023-11-02 00:26:15,019:INFO:                shap: Not installed
2023-11-02 00:26:15,019:INFO:           interpret: Not installed
2023-11-02 00:26:15,019:INFO:                umap: Not installed
2023-11-02 00:26:15,019:INFO:     ydata_profiling: Not installed
2023-11-02 00:26:15,019:INFO:  explainerdashboard: Not installed
2023-11-02 00:26:15,019:INFO:             autoviz: Not installed
2023-11-02 00:26:15,019:INFO:           fairlearn: Not installed
2023-11-02 00:26:15,019:INFO:          deepchecks: Not installed
2023-11-02 00:26:15,019:INFO:             xgboost: 2.0.0
2023-11-02 00:26:15,019:INFO:            catboost: Not installed
2023-11-02 00:26:15,019:INFO:              kmodes: Not installed
2023-11-02 00:26:15,019:INFO:             mlxtend: Not installed
2023-11-02 00:26:15,019:INFO:       statsforecast: Not installed
2023-11-02 00:26:15,019:INFO:        tune_sklearn: Not installed
2023-11-02 00:26:15,019:INFO:                 ray: Not installed
2023-11-02 00:26:15,019:INFO:            hyperopt: Not installed
2023-11-02 00:26:15,019:INFO:              optuna: Not installed
2023-11-02 00:26:15,019:INFO:               skopt: Not installed
2023-11-02 00:26:15,019:INFO:              mlflow: Not installed
2023-11-02 00:26:15,019:INFO:              gradio: Not installed
2023-11-02 00:26:15,019:INFO:             fastapi: Not installed
2023-11-02 00:26:15,019:INFO:             uvicorn: Not installed
2023-11-02 00:26:15,019:INFO:              m2cgen: Not installed
2023-11-02 00:26:15,019:INFO:           evidently: Not installed
2023-11-02 00:26:15,019:INFO:               fugue: Not installed
2023-11-02 00:26:15,019:INFO:           streamlit: Not installed
2023-11-02 00:26:15,019:INFO:             prophet: 1.1.5
2023-11-02 00:26:15,019:INFO:None
2023-11-02 00:26:15,019:INFO:Set up data.
2023-11-02 00:26:15,024:INFO:Set up folding strategy.
2023-11-02 00:26:15,025:INFO:Set up train/test split.
2023-11-02 00:26:15,025:INFO:Set up data.
2023-11-02 00:26:15,030:INFO:Set up index.
2023-11-02 00:26:15,031:INFO:Assigning column types.
2023-11-02 00:26:15,036:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-02 00:26:15,036:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,041:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,047:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,177:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:15,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:15,180:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,186:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,321:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:15,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:15,324:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-02 00:26:15,329:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,403:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,458:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:15,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:15,467:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,472:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,602:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:15,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:15,605:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-02 00:26:15,616:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,736:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:15,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:15,751:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,819:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:15,875:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:15,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:15,878:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-02 00:26:15,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:16,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:16,017:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:16,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:16,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-02 00:26:16,159:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:16,162:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-02 00:26:16,238:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:16,289:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:16,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-02 00:26:16,427:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:16,430:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-02 00:26:16,572:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:16,704:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:16,709:INFO:Preparing preprocessing pipeline...
2023-11-02 00:26:16,709:INFO:Set up simple imputation.
2023-11-02 00:26:16,709:INFO:Set up feature normalization.
2023-11-02 00:26:16,710:INFO:Set up column name cleaning.
2023-11-02 00:26:16,737:INFO:Finished creating preprocessing pipeline.
2023-11-02 00:26:16,741:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\manue\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'mes', 'ao',
                                             'trimestre'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-11-02 00:26:16,741:INFO:Creating final display dataframe.
2023-11-02 00:26:16,808:INFO:Setup _display_container:                     Description             Value
0                    Session id              1122
1                        Target     demanda_total
2                   Target type        Regression
3           Original data shape         (140, 12)
4        Transformed data shape         (140, 11)
5   Transformed train set shape         (128, 11)
6    Transformed test set shape          (12, 11)
7               Ignore features                 5
8              Numeric features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              dc03
2023-11-02 00:26:16,938:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:16,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:17,070:INFO:Soft dependency imported: xgboost: 2.0.0
2023-11-02 00:26:17,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-02 00:26:17,074:INFO:setup() successfully completed in 2.06s...............
2023-11-02 00:26:24,388:INFO:Initializing compare_models()
2023-11-02 00:26:24,389:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-02 00:26:24,389:INFO:Checking exceptions
2023-11-02 00:26:24,391:INFO:Preparing display monitor
2023-11-02 00:26:24,436:INFO:Initializing Linear Regression
2023-11-02 00:26:24,436:INFO:Total runtime is 0.0 minutes
2023-11-02 00:26:24,440:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:24,440:INFO:Initializing create_model()
2023-11-02 00:26:24,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:24,441:INFO:Checking exceptions
2023-11-02 00:26:24,441:INFO:Importing libraries
2023-11-02 00:26:24,441:INFO:Copying training dataset
2023-11-02 00:26:24,447:INFO:Defining folds
2023-11-02 00:26:24,447:INFO:Declaring metric variables
2023-11-02 00:26:24,451:INFO:Importing untrained model
2023-11-02 00:26:24,456:INFO:Linear Regression Imported successfully
2023-11-02 00:26:24,463:INFO:Starting cross validation
2023-11-02 00:26:24,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:24,570:INFO:Calculating mean and std
2023-11-02 00:26:24,570:INFO:Creating metrics dataframe
2023-11-02 00:26:24,573:INFO:Uploading results into container
2023-11-02 00:26:24,574:INFO:Uploading model into container now
2023-11-02 00:26:24,574:INFO:_master_model_container: 1
2023-11-02 00:26:24,575:INFO:_display_container: 2
2023-11-02 00:26:24,575:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:26:24,575:INFO:create_model() successfully completed......................................
2023-11-02 00:26:25,053:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:25,053:INFO:Creating metrics dataframe
2023-11-02 00:26:25,060:INFO:Initializing Lasso Regression
2023-11-02 00:26:25,060:INFO:Total runtime is 0.010408635934193928 minutes
2023-11-02 00:26:25,064:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:25,064:INFO:Initializing create_model()
2023-11-02 00:26:25,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:25,065:INFO:Checking exceptions
2023-11-02 00:26:25,065:INFO:Importing libraries
2023-11-02 00:26:25,065:INFO:Copying training dataset
2023-11-02 00:26:25,069:INFO:Defining folds
2023-11-02 00:26:25,069:INFO:Declaring metric variables
2023-11-02 00:26:25,073:INFO:Importing untrained model
2023-11-02 00:26:25,075:INFO:Lasso Regression Imported successfully
2023-11-02 00:26:25,083:INFO:Starting cross validation
2023-11-02 00:26:25,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:25,172:INFO:Calculating mean and std
2023-11-02 00:26:25,172:INFO:Creating metrics dataframe
2023-11-02 00:26:25,175:INFO:Uploading results into container
2023-11-02 00:26:25,175:INFO:Uploading model into container now
2023-11-02 00:26:25,175:INFO:_master_model_container: 2
2023-11-02 00:26:25,175:INFO:_display_container: 2
2023-11-02 00:26:25,176:INFO:Lasso(random_state=1122)
2023-11-02 00:26:25,176:INFO:create_model() successfully completed......................................
2023-11-02 00:26:25,584:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:25,584:INFO:Creating metrics dataframe
2023-11-02 00:26:25,593:INFO:Initializing Ridge Regression
2023-11-02 00:26:25,593:INFO:Total runtime is 0.019285360972086586 minutes
2023-11-02 00:26:25,596:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:25,597:INFO:Initializing create_model()
2023-11-02 00:26:25,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:25,598:INFO:Checking exceptions
2023-11-02 00:26:25,598:INFO:Importing libraries
2023-11-02 00:26:25,598:INFO:Copying training dataset
2023-11-02 00:26:25,605:INFO:Defining folds
2023-11-02 00:26:25,605:INFO:Declaring metric variables
2023-11-02 00:26:25,609:INFO:Importing untrained model
2023-11-02 00:26:25,615:INFO:Ridge Regression Imported successfully
2023-11-02 00:26:25,622:INFO:Starting cross validation
2023-11-02 00:26:25,623:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:25,712:INFO:Calculating mean and std
2023-11-02 00:26:25,714:INFO:Creating metrics dataframe
2023-11-02 00:26:25,717:INFO:Uploading results into container
2023-11-02 00:26:25,718:INFO:Uploading model into container now
2023-11-02 00:26:25,719:INFO:_master_model_container: 3
2023-11-02 00:26:25,719:INFO:_display_container: 2
2023-11-02 00:26:25,719:INFO:Ridge(random_state=1122)
2023-11-02 00:26:25,719:INFO:create_model() successfully completed......................................
2023-11-02 00:26:26,106:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:26,107:INFO:Creating metrics dataframe
2023-11-02 00:26:26,120:INFO:Initializing Elastic Net
2023-11-02 00:26:26,120:INFO:Total runtime is 0.028065812587738034 minutes
2023-11-02 00:26:26,123:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:26,123:INFO:Initializing create_model()
2023-11-02 00:26:26,123:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:26,123:INFO:Checking exceptions
2023-11-02 00:26:26,123:INFO:Importing libraries
2023-11-02 00:26:26,123:INFO:Copying training dataset
2023-11-02 00:26:26,127:INFO:Defining folds
2023-11-02 00:26:26,128:INFO:Declaring metric variables
2023-11-02 00:26:26,133:INFO:Importing untrained model
2023-11-02 00:26:26,137:INFO:Elastic Net Imported successfully
2023-11-02 00:26:26,143:INFO:Starting cross validation
2023-11-02 00:26:26,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:26,238:INFO:Calculating mean and std
2023-11-02 00:26:26,241:INFO:Creating metrics dataframe
2023-11-02 00:26:26,246:INFO:Uploading results into container
2023-11-02 00:26:26,247:INFO:Uploading model into container now
2023-11-02 00:26:26,248:INFO:_master_model_container: 4
2023-11-02 00:26:26,248:INFO:_display_container: 2
2023-11-02 00:26:26,248:INFO:ElasticNet(random_state=1122)
2023-11-02 00:26:26,248:INFO:create_model() successfully completed......................................
2023-11-02 00:26:26,603:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:26,603:INFO:Creating metrics dataframe
2023-11-02 00:26:26,609:INFO:Initializing Least Angle Regression
2023-11-02 00:26:26,609:INFO:Total runtime is 0.03623177607854207 minutes
2023-11-02 00:26:26,613:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:26,613:INFO:Initializing create_model()
2023-11-02 00:26:26,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:26,614:INFO:Checking exceptions
2023-11-02 00:26:26,614:INFO:Importing libraries
2023-11-02 00:26:26,614:INFO:Copying training dataset
2023-11-02 00:26:26,619:INFO:Defining folds
2023-11-02 00:26:26,619:INFO:Declaring metric variables
2023-11-02 00:26:26,622:INFO:Importing untrained model
2023-11-02 00:26:26,626:INFO:Least Angle Regression Imported successfully
2023-11-02 00:26:26,636:INFO:Starting cross validation
2023-11-02 00:26:26,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:26,664:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,670:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,676:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,681:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,689:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,695:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,700:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,703:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,711:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,717:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:26,728:INFO:Calculating mean and std
2023-11-02 00:26:26,730:INFO:Creating metrics dataframe
2023-11-02 00:26:26,733:INFO:Uploading results into container
2023-11-02 00:26:26,734:INFO:Uploading model into container now
2023-11-02 00:26:26,734:INFO:_master_model_container: 5
2023-11-02 00:26:26,734:INFO:_display_container: 2
2023-11-02 00:26:26,735:INFO:Lars(random_state=1122)
2023-11-02 00:26:26,735:INFO:create_model() successfully completed......................................
2023-11-02 00:26:27,105:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:27,105:INFO:Creating metrics dataframe
2023-11-02 00:26:27,114:INFO:Initializing Lasso Least Angle Regression
2023-11-02 00:26:27,114:INFO:Total runtime is 0.0446326732635498 minutes
2023-11-02 00:26:27,118:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:27,119:INFO:Initializing create_model()
2023-11-02 00:26:27,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:27,119:INFO:Checking exceptions
2023-11-02 00:26:27,120:INFO:Importing libraries
2023-11-02 00:26:27,120:INFO:Copying training dataset
2023-11-02 00:26:27,125:INFO:Defining folds
2023-11-02 00:26:27,125:INFO:Declaring metric variables
2023-11-02 00:26:27,130:INFO:Importing untrained model
2023-11-02 00:26:27,136:INFO:Lasso Least Angle Regression Imported successfully
2023-11-02 00:26:27,147:INFO:Starting cross validation
2023-11-02 00:26:27,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:27,182:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,185:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,191:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,199:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,206:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,209:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,217:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,221:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,226:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,232:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-11-02 00:26:27,239:INFO:Calculating mean and std
2023-11-02 00:26:27,241:INFO:Creating metrics dataframe
2023-11-02 00:26:27,244:INFO:Uploading results into container
2023-11-02 00:26:27,245:INFO:Uploading model into container now
2023-11-02 00:26:27,245:INFO:_master_model_container: 6
2023-11-02 00:26:27,246:INFO:_display_container: 2
2023-11-02 00:26:27,246:INFO:LassoLars(random_state=1122)
2023-11-02 00:26:27,246:INFO:create_model() successfully completed......................................
2023-11-02 00:26:27,604:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:27,604:INFO:Creating metrics dataframe
2023-11-02 00:26:27,614:INFO:Initializing Orthogonal Matching Pursuit
2023-11-02 00:26:27,614:INFO:Total runtime is 0.0529770811398824 minutes
2023-11-02 00:26:27,618:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:27,618:INFO:Initializing create_model()
2023-11-02 00:26:27,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:27,618:INFO:Checking exceptions
2023-11-02 00:26:27,618:INFO:Importing libraries
2023-11-02 00:26:27,618:INFO:Copying training dataset
2023-11-02 00:26:27,621:INFO:Defining folds
2023-11-02 00:26:27,622:INFO:Declaring metric variables
2023-11-02 00:26:27,625:INFO:Importing untrained model
2023-11-02 00:26:27,629:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:26:27,639:INFO:Starting cross validation
2023-11-02 00:26:27,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:27,666:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,670:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,678:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,686:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,691:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,698:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,702:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,709:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,716:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,719:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:26:27,727:INFO:Calculating mean and std
2023-11-02 00:26:27,728:INFO:Creating metrics dataframe
2023-11-02 00:26:27,731:INFO:Uploading results into container
2023-11-02 00:26:27,731:INFO:Uploading model into container now
2023-11-02 00:26:27,732:INFO:_master_model_container: 7
2023-11-02 00:26:27,732:INFO:_display_container: 2
2023-11-02 00:26:27,732:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:26:27,732:INFO:create_model() successfully completed......................................
2023-11-02 00:26:28,109:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:28,109:INFO:Creating metrics dataframe
2023-11-02 00:26:28,121:INFO:Initializing Bayesian Ridge
2023-11-02 00:26:28,121:INFO:Total runtime is 0.0614208420117696 minutes
2023-11-02 00:26:28,124:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:28,124:INFO:Initializing create_model()
2023-11-02 00:26:28,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:28,124:INFO:Checking exceptions
2023-11-02 00:26:28,124:INFO:Importing libraries
2023-11-02 00:26:28,124:INFO:Copying training dataset
2023-11-02 00:26:28,130:INFO:Defining folds
2023-11-02 00:26:28,131:INFO:Declaring metric variables
2023-11-02 00:26:28,134:INFO:Importing untrained model
2023-11-02 00:26:28,138:INFO:Bayesian Ridge Imported successfully
2023-11-02 00:26:28,146:INFO:Starting cross validation
2023-11-02 00:26:28,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:28,240:INFO:Calculating mean and std
2023-11-02 00:26:28,242:INFO:Creating metrics dataframe
2023-11-02 00:26:28,247:INFO:Uploading results into container
2023-11-02 00:26:28,248:INFO:Uploading model into container now
2023-11-02 00:26:28,248:INFO:_master_model_container: 8
2023-11-02 00:26:28,248:INFO:_display_container: 2
2023-11-02 00:26:28,249:INFO:BayesianRidge()
2023-11-02 00:26:28,249:INFO:create_model() successfully completed......................................
2023-11-02 00:26:28,603:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:28,603:INFO:Creating metrics dataframe
2023-11-02 00:26:28,613:INFO:Initializing Passive Aggressive Regressor
2023-11-02 00:26:28,613:INFO:Total runtime is 0.06962522268295288 minutes
2023-11-02 00:26:28,617:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:28,617:INFO:Initializing create_model()
2023-11-02 00:26:28,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:28,617:INFO:Checking exceptions
2023-11-02 00:26:28,618:INFO:Importing libraries
2023-11-02 00:26:28,618:INFO:Copying training dataset
2023-11-02 00:26:28,622:INFO:Defining folds
2023-11-02 00:26:28,622:INFO:Declaring metric variables
2023-11-02 00:26:28,625:INFO:Importing untrained model
2023-11-02 00:26:28,630:INFO:Passive Aggressive Regressor Imported successfully
2023-11-02 00:26:28,640:INFO:Starting cross validation
2023-11-02 00:26:28,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:28,684:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,690:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,695:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,705:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,714:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,732:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,745:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,749:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,754:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,764:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2023-11-02 00:26:28,775:INFO:Calculating mean and std
2023-11-02 00:26:28,777:INFO:Creating metrics dataframe
2023-11-02 00:26:28,782:INFO:Uploading results into container
2023-11-02 00:26:28,782:INFO:Uploading model into container now
2023-11-02 00:26:28,783:INFO:_master_model_container: 9
2023-11-02 00:26:28,783:INFO:_display_container: 2
2023-11-02 00:26:28,783:INFO:PassiveAggressiveRegressor(random_state=1122)
2023-11-02 00:26:28,783:INFO:create_model() successfully completed......................................
2023-11-02 00:26:29,143:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:29,143:INFO:Creating metrics dataframe
2023-11-02 00:26:29,153:INFO:Initializing Huber Regressor
2023-11-02 00:26:29,153:INFO:Total runtime is 0.07862345774968464 minutes
2023-11-02 00:26:29,156:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:29,156:INFO:Initializing create_model()
2023-11-02 00:26:29,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:29,156:INFO:Checking exceptions
2023-11-02 00:26:29,156:INFO:Importing libraries
2023-11-02 00:26:29,156:INFO:Copying training dataset
2023-11-02 00:26:29,162:INFO:Defining folds
2023-11-02 00:26:29,163:INFO:Declaring metric variables
2023-11-02 00:26:29,167:INFO:Importing untrained model
2023-11-02 00:26:29,172:INFO:Huber Regressor Imported successfully
2023-11-02 00:26:29,179:INFO:Starting cross validation
2023-11-02 00:26:29,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:29,304:INFO:Calculating mean and std
2023-11-02 00:26:29,306:INFO:Creating metrics dataframe
2023-11-02 00:26:29,308:INFO:Uploading results into container
2023-11-02 00:26:29,309:INFO:Uploading model into container now
2023-11-02 00:26:29,309:INFO:_master_model_container: 10
2023-11-02 00:26:29,309:INFO:_display_container: 2
2023-11-02 00:26:29,309:INFO:HuberRegressor()
2023-11-02 00:26:29,309:INFO:create_model() successfully completed......................................
2023-11-02 00:26:29,660:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:29,660:INFO:Creating metrics dataframe
2023-11-02 00:26:29,673:INFO:Initializing K Neighbors Regressor
2023-11-02 00:26:29,673:INFO:Total runtime is 0.08729102611541747 minutes
2023-11-02 00:26:29,677:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:29,678:INFO:Initializing create_model()
2023-11-02 00:26:29,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:29,678:INFO:Checking exceptions
2023-11-02 00:26:29,678:INFO:Importing libraries
2023-11-02 00:26:29,678:INFO:Copying training dataset
2023-11-02 00:26:29,684:INFO:Defining folds
2023-11-02 00:26:29,684:INFO:Declaring metric variables
2023-11-02 00:26:29,687:INFO:Importing untrained model
2023-11-02 00:26:29,692:INFO:K Neighbors Regressor Imported successfully
2023-11-02 00:26:29,700:INFO:Starting cross validation
2023-11-02 00:26:29,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:29,888:INFO:Calculating mean and std
2023-11-02 00:26:29,889:INFO:Creating metrics dataframe
2023-11-02 00:26:29,893:INFO:Uploading results into container
2023-11-02 00:26:29,893:INFO:Uploading model into container now
2023-11-02 00:26:29,894:INFO:_master_model_container: 11
2023-11-02 00:26:29,894:INFO:_display_container: 2
2023-11-02 00:26:29,894:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-02 00:26:29,895:INFO:create_model() successfully completed......................................
2023-11-02 00:26:30,242:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:30,243:INFO:Creating metrics dataframe
2023-11-02 00:26:30,253:INFO:Initializing Decision Tree Regressor
2023-11-02 00:26:30,254:INFO:Total runtime is 0.09695538679758707 minutes
2023-11-02 00:26:30,256:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:30,257:INFO:Initializing create_model()
2023-11-02 00:26:30,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:30,257:INFO:Checking exceptions
2023-11-02 00:26:30,257:INFO:Importing libraries
2023-11-02 00:26:30,257:INFO:Copying training dataset
2023-11-02 00:26:30,262:INFO:Defining folds
2023-11-02 00:26:30,262:INFO:Declaring metric variables
2023-11-02 00:26:30,265:INFO:Importing untrained model
2023-11-02 00:26:30,269:INFO:Decision Tree Regressor Imported successfully
2023-11-02 00:26:30,275:INFO:Starting cross validation
2023-11-02 00:26:30,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:30,367:INFO:Calculating mean and std
2023-11-02 00:26:30,369:INFO:Creating metrics dataframe
2023-11-02 00:26:30,372:INFO:Uploading results into container
2023-11-02 00:26:30,372:INFO:Uploading model into container now
2023-11-02 00:26:30,373:INFO:_master_model_container: 12
2023-11-02 00:26:30,373:INFO:_display_container: 2
2023-11-02 00:26:30,373:INFO:DecisionTreeRegressor(random_state=1122)
2023-11-02 00:26:30,373:INFO:create_model() successfully completed......................................
2023-11-02 00:26:30,719:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:30,719:INFO:Creating metrics dataframe
2023-11-02 00:26:30,730:INFO:Initializing Random Forest Regressor
2023-11-02 00:26:30,731:INFO:Total runtime is 0.10492763916651407 minutes
2023-11-02 00:26:30,734:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:30,736:INFO:Initializing create_model()
2023-11-02 00:26:30,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:30,736:INFO:Checking exceptions
2023-11-02 00:26:30,736:INFO:Importing libraries
2023-11-02 00:26:30,736:INFO:Copying training dataset
2023-11-02 00:26:30,741:INFO:Defining folds
2023-11-02 00:26:30,741:INFO:Declaring metric variables
2023-11-02 00:26:30,745:INFO:Importing untrained model
2023-11-02 00:26:30,751:INFO:Random Forest Regressor Imported successfully
2023-11-02 00:26:30,758:INFO:Starting cross validation
2023-11-02 00:26:30,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:31,214:INFO:Calculating mean and std
2023-11-02 00:26:31,215:INFO:Creating metrics dataframe
2023-11-02 00:26:31,218:INFO:Uploading results into container
2023-11-02 00:26:31,218:INFO:Uploading model into container now
2023-11-02 00:26:31,219:INFO:_master_model_container: 13
2023-11-02 00:26:31,219:INFO:_display_container: 2
2023-11-02 00:26:31,219:INFO:RandomForestRegressor(n_jobs=-1, random_state=1122)
2023-11-02 00:26:31,219:INFO:create_model() successfully completed......................................
2023-11-02 00:26:31,565:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:31,565:INFO:Creating metrics dataframe
2023-11-02 00:26:31,575:INFO:Initializing Extra Trees Regressor
2023-11-02 00:26:31,576:INFO:Total runtime is 0.1190112312634786 minutes
2023-11-02 00:26:31,580:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:31,580:INFO:Initializing create_model()
2023-11-02 00:26:31,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:31,580:INFO:Checking exceptions
2023-11-02 00:26:31,580:INFO:Importing libraries
2023-11-02 00:26:31,580:INFO:Copying training dataset
2023-11-02 00:26:31,585:INFO:Defining folds
2023-11-02 00:26:31,585:INFO:Declaring metric variables
2023-11-02 00:26:31,589:INFO:Importing untrained model
2023-11-02 00:26:31,592:INFO:Extra Trees Regressor Imported successfully
2023-11-02 00:26:31,600:INFO:Starting cross validation
2023-11-02 00:26:31,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:31,987:INFO:Calculating mean and std
2023-11-02 00:26:31,988:INFO:Creating metrics dataframe
2023-11-02 00:26:31,991:INFO:Uploading results into container
2023-11-02 00:26:31,991:INFO:Uploading model into container now
2023-11-02 00:26:31,993:INFO:_master_model_container: 14
2023-11-02 00:26:31,994:INFO:_display_container: 2
2023-11-02 00:26:31,995:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1122)
2023-11-02 00:26:31,995:INFO:create_model() successfully completed......................................
2023-11-02 00:26:32,357:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:32,357:INFO:Creating metrics dataframe
2023-11-02 00:26:32,371:INFO:Initializing AdaBoost Regressor
2023-11-02 00:26:32,371:INFO:Total runtime is 0.1322553793589274 minutes
2023-11-02 00:26:32,373:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:32,374:INFO:Initializing create_model()
2023-11-02 00:26:32,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:32,374:INFO:Checking exceptions
2023-11-02 00:26:32,374:INFO:Importing libraries
2023-11-02 00:26:32,374:INFO:Copying training dataset
2023-11-02 00:26:32,380:INFO:Defining folds
2023-11-02 00:26:32,380:INFO:Declaring metric variables
2023-11-02 00:26:32,384:INFO:Importing untrained model
2023-11-02 00:26:32,388:INFO:AdaBoost Regressor Imported successfully
2023-11-02 00:26:32,395:INFO:Starting cross validation
2023-11-02 00:26:32,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:32,619:INFO:Calculating mean and std
2023-11-02 00:26:32,621:INFO:Creating metrics dataframe
2023-11-02 00:26:32,623:INFO:Uploading results into container
2023-11-02 00:26:32,624:INFO:Uploading model into container now
2023-11-02 00:26:32,624:INFO:_master_model_container: 15
2023-11-02 00:26:32,625:INFO:_display_container: 2
2023-11-02 00:26:32,625:INFO:AdaBoostRegressor(random_state=1122)
2023-11-02 00:26:32,626:INFO:create_model() successfully completed......................................
2023-11-02 00:26:32,994:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:32,994:INFO:Creating metrics dataframe
2023-11-02 00:26:33,005:INFO:Initializing Gradient Boosting Regressor
2023-11-02 00:26:33,005:INFO:Total runtime is 0.14282150268554686 minutes
2023-11-02 00:26:33,010:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:33,011:INFO:Initializing create_model()
2023-11-02 00:26:33,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:33,011:INFO:Checking exceptions
2023-11-02 00:26:33,011:INFO:Importing libraries
2023-11-02 00:26:33,011:INFO:Copying training dataset
2023-11-02 00:26:33,015:INFO:Defining folds
2023-11-02 00:26:33,016:INFO:Declaring metric variables
2023-11-02 00:26:33,018:INFO:Importing untrained model
2023-11-02 00:26:33,022:INFO:Gradient Boosting Regressor Imported successfully
2023-11-02 00:26:33,032:INFO:Starting cross validation
2023-11-02 00:26:33,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:33,186:INFO:Calculating mean and std
2023-11-02 00:26:33,187:INFO:Creating metrics dataframe
2023-11-02 00:26:33,190:INFO:Uploading results into container
2023-11-02 00:26:33,190:INFO:Uploading model into container now
2023-11-02 00:26:33,191:INFO:_master_model_container: 16
2023-11-02 00:26:33,191:INFO:_display_container: 2
2023-11-02 00:26:33,191:INFO:GradientBoostingRegressor(random_state=1122)
2023-11-02 00:26:33,191:INFO:create_model() successfully completed......................................
2023-11-02 00:26:33,537:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:33,537:INFO:Creating metrics dataframe
2023-11-02 00:26:33,551:INFO:Initializing Extreme Gradient Boosting
2023-11-02 00:26:33,551:INFO:Total runtime is 0.15191930532455442 minutes
2023-11-02 00:26:33,554:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:33,555:INFO:Initializing create_model()
2023-11-02 00:26:33,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:33,555:INFO:Checking exceptions
2023-11-02 00:26:33,555:INFO:Importing libraries
2023-11-02 00:26:33,555:INFO:Copying training dataset
2023-11-02 00:26:33,562:INFO:Defining folds
2023-11-02 00:26:33,562:INFO:Declaring metric variables
2023-11-02 00:26:33,566:INFO:Importing untrained model
2023-11-02 00:26:33,568:INFO:Extreme Gradient Boosting Imported successfully
2023-11-02 00:26:33,574:INFO:Starting cross validation
2023-11-02 00:26:33,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:34,098:INFO:Calculating mean and std
2023-11-02 00:26:34,101:INFO:Creating metrics dataframe
2023-11-02 00:26:34,104:INFO:Uploading results into container
2023-11-02 00:26:34,105:INFO:Uploading model into container now
2023-11-02 00:26:34,105:INFO:_master_model_container: 17
2023-11-02 00:26:34,106:INFO:_display_container: 2
2023-11-02 00:26:34,107:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1122, ...)
2023-11-02 00:26:34,107:INFO:create_model() successfully completed......................................
2023-11-02 00:26:34,450:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:34,450:INFO:Creating metrics dataframe
2023-11-02 00:26:34,459:INFO:Initializing Light Gradient Boosting Machine
2023-11-02 00:26:34,460:INFO:Total runtime is 0.16706691582997638 minutes
2023-11-02 00:26:34,463:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:34,463:INFO:Initializing create_model()
2023-11-02 00:26:34,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:34,463:INFO:Checking exceptions
2023-11-02 00:26:34,463:INFO:Importing libraries
2023-11-02 00:26:34,463:INFO:Copying training dataset
2023-11-02 00:26:34,467:INFO:Defining folds
2023-11-02 00:26:34,468:INFO:Declaring metric variables
2023-11-02 00:26:34,471:INFO:Importing untrained model
2023-11-02 00:26:34,475:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-02 00:26:34,484:INFO:Starting cross validation
2023-11-02 00:26:34,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:34,886:INFO:Calculating mean and std
2023-11-02 00:26:34,888:INFO:Creating metrics dataframe
2023-11-02 00:26:34,892:INFO:Uploading results into container
2023-11-02 00:26:34,893:INFO:Uploading model into container now
2023-11-02 00:26:34,894:INFO:_master_model_container: 18
2023-11-02 00:26:34,894:INFO:_display_container: 2
2023-11-02 00:26:34,894:INFO:LGBMRegressor(n_jobs=-1, random_state=1122)
2023-11-02 00:26:34,894:INFO:create_model() successfully completed......................................
2023-11-02 00:26:35,233:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:35,233:INFO:Creating metrics dataframe
2023-11-02 00:26:35,245:INFO:Initializing Dummy Regressor
2023-11-02 00:26:35,245:INFO:Total runtime is 0.18015567859013873 minutes
2023-11-02 00:26:35,247:INFO:SubProcess create_model() called ==================================
2023-11-02 00:26:35,248:INFO:Initializing create_model()
2023-11-02 00:26:35,248:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DACFB2F50>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:35,248:INFO:Checking exceptions
2023-11-02 00:26:35,248:INFO:Importing libraries
2023-11-02 00:26:35,248:INFO:Copying training dataset
2023-11-02 00:26:35,252:INFO:Defining folds
2023-11-02 00:26:35,253:INFO:Declaring metric variables
2023-11-02 00:26:35,257:INFO:Importing untrained model
2023-11-02 00:26:35,261:INFO:Dummy Regressor Imported successfully
2023-11-02 00:26:35,270:INFO:Starting cross validation
2023-11-02 00:26:35,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:26:35,359:INFO:Calculating mean and std
2023-11-02 00:26:35,361:INFO:Creating metrics dataframe
2023-11-02 00:26:35,363:INFO:Uploading results into container
2023-11-02 00:26:35,364:INFO:Uploading model into container now
2023-11-02 00:26:35,364:INFO:_master_model_container: 19
2023-11-02 00:26:35,364:INFO:_display_container: 2
2023-11-02 00:26:35,364:INFO:DummyRegressor()
2023-11-02 00:26:35,364:INFO:create_model() successfully completed......................................
2023-11-02 00:26:35,681:INFO:SubProcess create_model() end ==================================
2023-11-02 00:26:35,681:INFO:Creating metrics dataframe
2023-11-02 00:26:35,702:INFO:Initializing create_model()
2023-11-02 00:26:35,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:26:35,703:INFO:Checking exceptions
2023-11-02 00:26:35,704:INFO:Importing libraries
2023-11-02 00:26:35,704:INFO:Copying training dataset
2023-11-02 00:26:35,709:INFO:Defining folds
2023-11-02 00:26:35,709:INFO:Declaring metric variables
2023-11-02 00:26:35,709:INFO:Importing untrained model
2023-11-02 00:26:35,709:INFO:Declaring custom model
2023-11-02 00:26:35,711:INFO:Linear Regression Imported successfully
2023-11-02 00:26:35,712:INFO:Cross validation set to False
2023-11-02 00:26:35,712:INFO:Fitting Model
2023-11-02 00:26:35,722:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:26:35,722:INFO:create_model() successfully completed......................................
2023-11-02 00:26:36,139:INFO:_master_model_container: 19
2023-11-02 00:26:36,139:INFO:_display_container: 2
2023-11-02 00:26:36,139:INFO:LinearRegression(n_jobs=-1)
2023-11-02 00:26:36,140:INFO:compare_models() successfully completed......................................
2023-11-02 00:27:44,013:INFO:Initializing create_model()
2023-11-02 00:27:44,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:27:44,013:INFO:Checking exceptions
2023-11-02 00:27:44,044:INFO:Importing libraries
2023-11-02 00:27:44,044:INFO:Copying training dataset
2023-11-02 00:27:44,048:INFO:Defining folds
2023-11-02 00:27:44,048:INFO:Declaring metric variables
2023-11-02 00:27:44,053:INFO:Importing untrained model
2023-11-02 00:27:44,057:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-02 00:27:44,066:INFO:Starting cross validation
2023-11-02 00:27:44,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:27:44,098:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,110:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,114:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,120:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,127:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,133:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,139:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,148:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,152:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,159:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:44,173:INFO:Calculating mean and std
2023-11-02 00:27:44,173:INFO:Creating metrics dataframe
2023-11-02 00:27:44,178:INFO:Finalizing model
2023-11-02 00:27:44,192:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:27:44,197:INFO:Uploading results into container
2023-11-02 00:27:44,199:INFO:Uploading model into container now
2023-11-02 00:27:44,213:INFO:_master_model_container: 20
2023-11-02 00:27:44,213:INFO:_display_container: 3
2023-11-02 00:27:44,213:INFO:OrthogonalMatchingPursuit()
2023-11-02 00:27:44,213:INFO:create_model() successfully completed......................................
2023-11-02 00:27:58,994:INFO:Initializing create_model()
2023-11-02 00:27:58,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=lar, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:27:58,994:INFO:Checking exceptions
2023-11-02 00:27:59,029:INFO:Importing libraries
2023-11-02 00:27:59,029:INFO:Copying training dataset
2023-11-02 00:27:59,037:INFO:Defining folds
2023-11-02 00:27:59,037:INFO:Declaring metric variables
2023-11-02 00:27:59,041:INFO:Importing untrained model
2023-11-02 00:27:59,044:INFO:Least Angle Regression Imported successfully
2023-11-02 00:27:59,054:INFO:Starting cross validation
2023-11-02 00:27:59,056:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:27:59,093:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,100:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,106:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,109:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,124:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,128:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,128:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,136:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,148:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,149:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:27:59,162:INFO:Calculating mean and std
2023-11-02 00:27:59,163:INFO:Creating metrics dataframe
2023-11-02 00:27:59,168:INFO:Finalizing model
2023-11-02 00:27:59,181:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:27:59,188:INFO:Uploading results into container
2023-11-02 00:27:59,189:INFO:Uploading model into container now
2023-11-02 00:27:59,198:INFO:_master_model_container: 21
2023-11-02 00:27:59,198:INFO:_display_container: 4
2023-11-02 00:27:59,198:INFO:Lars(random_state=1122)
2023-11-02 00:27:59,199:INFO:create_model() successfully completed......................................
2023-11-02 00:28:06,779:INFO:Initializing plot_model()
2023-11-02 00:28:06,779:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Lars(random_state=1122), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, system=True)
2023-11-02 00:28:06,780:INFO:Checking exceptions
2023-11-02 00:28:06,785:INFO:Preloading libraries
2023-11-02 00:28:06,786:INFO:Copying training dataset
2023-11-02 00:28:06,786:INFO:Plot type: feature
2023-11-02 00:28:06,997:INFO:Visual Rendered Successfully
2023-11-02 00:28:07,361:INFO:plot_model() successfully completed......................................
2023-11-02 00:28:16,245:INFO:Initializing ensemble_model()
2023-11-02 00:28:16,245:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=Lars(random_state=1122), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-02 00:28:16,245:INFO:Checking exceptions
2023-11-02 00:28:16,282:INFO:Importing libraries
2023-11-02 00:28:16,282:INFO:Copying training dataset
2023-11-02 00:28:16,282:INFO:Checking base model
2023-11-02 00:28:16,283:INFO:Base model : Least Angle Regression
2023-11-02 00:28:16,293:INFO:Importing untrained ensembler
2023-11-02 00:28:16,293:INFO:Ensemble method set to Bagging
2023-11-02 00:28:16,294:INFO:SubProcess create_model() called ==================================
2023-11-02 00:28:16,294:INFO:Initializing create_model()
2023-11-02 00:28:16,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=BaggingRegressor(base_estimator=Lars(random_state=1122), random_state=1122), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026DC729D630>, model_only=True, return_train_score=False, kwargs={})
2023-11-02 00:28:16,295:INFO:Checking exceptions
2023-11-02 00:28:16,295:INFO:Importing libraries
2023-11-02 00:28:16,295:INFO:Copying training dataset
2023-11-02 00:28:16,298:INFO:Defining folds
2023-11-02 00:28:16,298:INFO:Declaring metric variables
2023-11-02 00:28:16,301:INFO:Importing untrained model
2023-11-02 00:28:16,301:INFO:Declaring custom model
2023-11-02 00:28:16,305:INFO:Least Angle Regression Imported successfully
2023-11-02 00:28:16,316:INFO:Starting cross validation
2023-11-02 00:28:16,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-02 00:28:16,359:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,361:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,363:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,364:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,367:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,368:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,371:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,371:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,375:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,377:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,379:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,381:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,382:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,383:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,384:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,385:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,387:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,390:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,391:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,393:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,395:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,397:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,398:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,400:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,401:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,403:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,406:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,409:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,417:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,427:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,427:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,430:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,430:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,433:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,434:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,434:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,434:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,437:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,440:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,440:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,440:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,441:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,442:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,443:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,444:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,444:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,444:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,445:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,446:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,447:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,447:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,448:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,450:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,453:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,456:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,460:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,462:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,463:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,463:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,464:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,465:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,466:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,466:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,467:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,468:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,470:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,470:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,474:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,476:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,476:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,478:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,479:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,481:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,482:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,483:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,485:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,485:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,486:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,487:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,488:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,489:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,492:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,494:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,496:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,498:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,502:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,506:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,510:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,514:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,517:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-11-02 00:28:16,539:INFO:Calculating mean and std
2023-11-02 00:28:16,540:INFO:Creating metrics dataframe
2023-11-02 00:28:16,549:INFO:Finalizing model
2023-11-02 00:28:16,572:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,577:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,579:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,583:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,585:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,588:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,591:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,594:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,597:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,648:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:16,675:INFO:Uploading results into container
2023-11-02 00:28:16,676:INFO:Uploading model into container now
2023-11-02 00:28:16,677:INFO:_master_model_container: 22
2023-11-02 00:28:16,677:INFO:_display_container: 5
2023-11-02 00:28:16,678:INFO:BaggingRegressor(base_estimator=Lars(random_state=1122), random_state=1122)
2023-11-02 00:28:16,678:INFO:create_model() successfully completed......................................
2023-11-02 00:28:17,067:INFO:SubProcess create_model() end ==================================
2023-11-02 00:28:17,076:INFO:_master_model_container: 22
2023-11-02 00:28:17,076:INFO:_display_container: 5
2023-11-02 00:28:17,076:INFO:BaggingRegressor(base_estimator=Lars(random_state=1122), random_state=1122)
2023-11-02 00:28:17,076:INFO:ensemble_model() successfully completed......................................
2023-11-02 00:28:25,527:INFO:Initializing predict_model()
2023-11-02 00:28:25,527:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=Lars(random_state=1122), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DC4C98B80>)
2023-11-02 00:28:25,527:INFO:Checking exceptions
2023-11-02 00:28:25,527:INFO:Preloading libraries
2023-11-02 00:28:25,529:INFO:Set up data.
2023-11-02 00:28:25,535:INFO:Set up index.
2023-11-02 00:28:35,531:INFO:Initializing finalize_model()
2023-11-02 00:28:35,531:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=Lars(random_state=1122), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-02 00:28:35,531:INFO:Finalizing Lars(random_state=1122)
2023-11-02 00:28:35,534:INFO:Initializing create_model()
2023-11-02 00:28:35,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=Lars(random_state=1122), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-11-02 00:28:35,534:INFO:Checking exceptions
2023-11-02 00:28:35,537:INFO:Importing libraries
2023-11-02 00:28:35,537:INFO:Copying training dataset
2023-11-02 00:28:35,537:INFO:Defining folds
2023-11-02 00:28:35,538:INFO:Declaring metric variables
2023-11-02 00:28:35,539:INFO:Importing untrained model
2023-11-02 00:28:35,539:INFO:Declaring custom model
2023-11-02 00:28:35,540:INFO:Least Angle Regression Imported successfully
2023-11-02 00:28:35,541:INFO:Cross validation set to False
2023-11-02 00:28:35,542:INFO:Fitting Model
2023-11-02 00:28:35,556:WARNING:c:\Users\manue\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning:

The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)




2023-11-02 00:28:35,563:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'mes', 'ao',
                                             'trimestre'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', Lars(random_state=1122))])
2023-11-02 00:28:35,564:INFO:create_model() successfully completed......................................
2023-11-02 00:28:35,937:INFO:_master_model_container: 22
2023-11-02 00:28:35,937:INFO:_display_container: 6
2023-11-02 00:28:35,943:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'mes', 'ao',
                                             'trimestre'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', Lars(random_state=1122))])
2023-11-02 00:28:35,943:INFO:finalize_model() successfully completed......................................
2023-11-02 00:28:48,906:INFO:Initializing predict_model()
2023-11-02 00:28:48,907:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026DC7431030>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['demanda_gu', 'demanda_di',
                                             'cantidad_GU', 'cantidad_DI',
                                             'emae', 'temperatura_media_C',
                                             'dolar_oficial', 'mes', 'ao',
                                             'trimestre'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', Lars(random_state=1122))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026DC73C8820>)
2023-11-02 00:28:48,907:INFO:Checking exceptions
2023-11-02 00:28:48,907:INFO:Preloading libraries
2023-11-02 00:28:48,909:INFO:Set up data.
2023-11-02 00:28:48,915:INFO:Set up index.
